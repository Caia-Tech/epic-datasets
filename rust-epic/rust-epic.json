[
  {
    "output": "```rust\n// This function demonstrates proper error handling in Rust using Result<T, E>\n// The Result type is Rust's way of handling recoverable errors without panics\n\nfn safe_divide(numerator: f64, denominator: f64) -> Result<f64, String> {\n    if denominator == 0.0 {\n        Err(\"Division by zero\".to_string())\n    } else {\n        Ok(numerator / denominator)\n    }\n}\n\n// Usage example:\nfn main() {\n    match safe_divide(10.0, 2.0) {\n        Ok(result) => println!(\"Result: {}\", result),\n        Err(e) => println!(\"Error: {}\", e),\n    }\n    \n    // Handling division by zero\n    match safe_divide(10.0, 0.0) {\n        Ok(result) => println!(\"Result: {}\", result),\n        Err(e) => println!(\"Error: {}\", e),\n    }\n}\n\n// Key concepts:\n// - Result<T, E> for error handling\n// - Pattern matching with match\n// - Returning early with Err for error cases\n// - Idiomatic error messages as String\n```",
    "tags": [
      "error-handling",
      "result",
      "functions"
    ],
    "instruction": "Write a function that safely divides two numbers and handles division by zero"
  },
  {
    "output": "```rust\n// This example demonstrates Rust's ownership system with vectors\n// Ownership is Rust's key feature that ensures memory safety without garbage collection\n\nfn main() {\n    // Creating a vector - the variable 'numbers' owns the Vec\n    let mut numbers = vec![1, 2, 3, 4, 5];\n    println!(\"Original vector: {:?}\", numbers);\n    \n    // Moving ownership to another variable\n    let moved_numbers = numbers;\n    // numbers is no longer valid here - it has been moved\n    \n    // This would cause a compile error:\n    // println!(\"Original vector: {:?}\", numbers); // Error: value borrowed after move\n    \n    println!(\"Moved vector: {:?}\", moved_numbers);\n    \n    // Demonstrating borrowing instead of moving\n    let another_vec = vec![10, 20, 30];\n    let borrowed_ref = &another_vec; // Borrowing instead of moving\n    \n    println!(\"Original: {:?}\", another_vec); // Still valid!\n    println!(\"Borrowed: {:?}\", borrowed_ref);\n    \n    // Function that takes ownership\n    take_ownership(moved_numbers);\n    // moved_numbers is no longer valid here\n    \n    // Function that borrows\n    borrow_vec(&another_vec);\n    println!(\"Still accessible: {:?}\", another_vec); // Still valid!\n}\n\nfn take_ownership(v: Vec<i32>) {\n    println!(\"Took ownership of: {:?}\", v);\n    // v is dropped when this function ends\n}\n\nfn borrow_vec(v: &Vec<i32>) {\n    println!(\"Borrowed: {:?}\", v);\n    // v is just a reference, original owner still has the data\n}\n\n// Key concepts:\n// - Move semantics: ownership transfers from one variable to another\n// - Borrowing: creating references without taking ownership\n// - After a move, the original variable is no longer valid\n// - References allow multiple readers without transferring ownership\n```",
    "tags": [
      "ownership",
      "borrowing",
      "vectors",
      "move-semantics"
    ],
    "instruction": "Create a Vec and demonstrate basic ownership principles"
  },
  {
    "output": "```rust\n// This example demonstrates structs, methods, and trait implementation\n// Traits define shared behavior that multiple types can implement\n\n#[derive(Debug, Clone)]\nstruct Rectangle {\n    width: f64,\n    height: f64,\n}\n\n// Implementation block for Rectangle methods\nimpl Rectangle {\n    // Associated function (constructor)\n    fn new(width: f64, height: f64) -> Self {\n        Rectangle { width, height }\n    }\n    \n    // Method that borrows self\n    fn area(&self) -> f64 {\n        self.width * self.height\n    }\n    \n    // Method that borrows self mutably\n    fn scale(&mut self, factor: f64) {\n        self.width *= factor;\n        self.height *= factor;\n    }\n    \n    // Method that takes ownership of self\n    fn into_square(self) -> Rectangle {\n        let side = (self.area()).sqrt();\n        Rectangle::new(side, side)\n    }\n}\n\n// Define a custom trait\ntrait Shape {\n    fn perimeter(&self) -> f64;\n    fn describe(&self) -> String;\n}\n\n// Implement the trait for Rectangle\nimpl Shape for Rectangle {\n    fn perimeter(&self) -> f64 {\n        2.0 * (self.width + self.height)\n    }\n    \n    fn describe(&self) -> String {\n        format!(\"Rectangle with width {} and height {}\", self.width, self.height)\n    }\n}\n\n// Implement Display trait for pretty printing\nimpl std::fmt::Display for Rectangle {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        write!(f, \"{}\u00d7{} rectangle\", self.width, self.height)\n    }\n}\n\nfn main() {\n    let mut rect = Rectangle::new(5.0, 3.0);\n    println!(\"Rectangle: {}\", rect);\n    println!(\"Area: {}\", rect.area());\n    println!(\"Perimeter: {}\", rect.perimeter());\n    println!(\"{}\", rect.describe());\n    \n    // Mutate the rectangle\n    rect.scale(2.0);\n    println!(\"After scaling: {}\", rect);\n    \n    // Convert to square (consumes the rectangle)\n    let square = rect.into_square();\n    println!(\"Equivalent square: {}\", square);\n    \n    // rect is no longer accessible here due to move\n}\n\n// Key concepts:\n// - Structs group related data\n// - impl blocks define methods and associated functions\n// - &self borrows, &mut self mutably borrows, self takes ownership\n// - Traits define shared behavior across types\n// - derive macro automatically implements common traits\n// - Custom Display implementation for pretty printing\n```",
    "tags": [
      "structs",
      "methods",
      "traits",
      "impl-blocks",
      "derive"
    ],
    "instruction": "Implement a struct with methods and demonstrate trait implementation"
  },
  {
    "output": "```rust\n// This example demonstrates async/await and concurrent programming in Rust\n// Async allows non-blocking operations and concurrent execution\n\nuse std::time::Duration;\nuse tokio::time::sleep;\n\n// Async function that simulates fetching data from a remote source\nasync fn fetch_user_data(user_id: u32) -> Result<String, &'static str> {\n    println!(\"Fetching user data for ID: {}\", user_id);\n    \n    // Simulate network delay\n    sleep(Duration::from_millis(100)).await;\n    \n    // Simulate potential failure\n    if user_id == 0 {\n        return Err(\"Invalid user ID\");\n    }\n    \n    Ok(format!(\"User {} data\", user_id))\n}\n\nasync fn fetch_user_posts(user_id: u32) -> Result<Vec<String>, &'static str> {\n    println!(\"Fetching posts for user: {}\", user_id);\n    \n    sleep(Duration::from_millis(150)).await;\n    \n    Ok(vec![\n        format!(\"Post 1 by user {}\", user_id),\n        format!(\"Post 2 by user {}\", user_id),\n    ])\n}\n\nasync fn fetch_user_profile(user_id: u32) -> Result<String, &'static str> {\n    println!(\"Fetching profile for user: {}\", user_id);\n    \n    sleep(Duration::from_millis(80)).await;\n    \n    Ok(format!(\"Profile of user {}\", user_id))\n}\n\n// Function that fetches all user information concurrently\nasync fn fetch_complete_user_info(user_id: u32) -> Result<(String, Vec<String>, String), Box<dyn std::error::Error>> {\n    // Using tokio::join! to run multiple async operations concurrently\n    let (user_data_result, posts_result, profile_result) = tokio::join!(\n        fetch_user_data(user_id),\n        fetch_user_posts(user_id),\n        fetch_user_profile(user_id)\n    );\n    \n    // Handle results - all operations run concurrently, but we wait for all to complete\n    let user_data = user_data_result?;\n    let posts = posts_result?;\n    let profile = profile_result?;\n    \n    Ok((user_data, posts, profile))\n}\n\n// Alternative approach using try_join! for early failure\nasync fn fetch_user_info_fail_fast(user_id: u32) -> Result<(String, Vec<String>, String), Box<dyn std::error::Error>> {\n    // try_join! will cancel other operations if any fails\n    let (user_data, posts, profile) = tokio::try_join!(\n        fetch_user_data(user_id),\n        fetch_user_posts(user_id),\n        fetch_user_profile(user_id)\n    )?;\n    \n    Ok((user_data, posts, profile))\n}\n\n#[tokio::main]\nasync fn main() -> Result<(), Box<dyn std::error::Error>> {\n    println!(\"=== Concurrent fetch example ===\");\n    \n    let start = std::time::Instant::now();\n    \n    match fetch_complete_user_info(123).await {\n        Ok((data, posts, profile)) => {\n            println!(\"User data: {}\", data);\n            println!(\"Posts: {:?}\", posts);\n            println!(\"Profile: {}\", profile);\n        }\n        Err(e) => println!(\"Error: {}\", e),\n    }\n    \n    println!(\"Time taken: {:?}\", start.elapsed());\n    println!(\"(Sequential would take ~330ms, concurrent takes ~150ms)\");\n    \n    // Example with error handling\n    println!(\"\\n=== Error handling example ===\");\n    match fetch_user_info_fail_fast(0).await {\n        Ok(_) => println!(\"Success\"),\n        Err(e) => println!(\"Failed fast: {}\", e),\n    }\n    \n    Ok(())\n}\n\n// Key concepts:\n// - async/await enables non-blocking asynchronous operations\n// - tokio::join! runs multiple async operations concurrently\n// - tokio::try_join! provides fail-fast behavior\n// - .await suspends execution until the future completes\n// - Async functions return Future<Output = T>\n// - Error handling works with Result types as usual\n// - #[tokio::main] sets up the async runtime\n```",
    "tags": [
      "async",
      "concurrency",
      "tokio",
      "futures",
      "error-handling"
    ],
    "instruction": "Create an async function that fetches data from multiple sources concurrently"
  },
  {
    "output": "```rust\n// This example demonstrates Rust's lifetime system and string slices\n// Lifetimes ensure that references are valid for as long as needed\n\n// Function that returns the longest of two string slices\n// The lifetime parameter 'a indicates that the returned slice\n// will live as long as the shorter of the two input slices\nfn longest<'a>(x: &'a str, y: &'a str) -> &'a str {\n    if x.len() > y.len() {\n        x\n    } else {\n        y\n    }\n}\n\n// Function that always returns the first parameter\n// We can use different lifetime parameters when inputs have different lifetimes\nfn first_str<'a, 'b>(x: &'a str, _y: &'b str) -> &'a str {\n    x\n}\n\n// Struct that holds a reference with an explicit lifetime\nstruct ImportantExcerpt<'a> {\n    part: &'a str,\n}\n\nimpl<'a> ImportantExcerpt<'a> {\n    // Method with lifetime elision - Rust can infer the lifetimes\n    fn level(&self) -> i32 {\n        3\n    }\n    \n    // Method that returns a string slice with the same lifetime as self\n    fn announce_and_return_part(&self, announcement: &str) -> &str {\n        println!(\"Attention please: {}\", announcement);\n        self.part // Returned reference has the same lifetime as self\n    }\n}\n\n// Function demonstrating string slice operations\nfn string_operations(s: &str) -> (&str, &str, &str) {\n    let bytes = s.as_bytes();\n    \n    // Find first space\n    for (i, &item) in bytes.iter().enumerate() {\n        if item == b' ' {\n            // Return slices of the original string\n            return (&s[0..i], &s[i+1..], s); // first word, rest, original\n        }\n    }\n    \n    (s, \"\", s) // No space found\n}\n\nfn main() {\n    // Basic string slice usage\n    let string1 = String::from(\"Hello, World!\");\n    let string2 = \"Rust programming\";\n    \n    // Both string1.as_str() and string2 are &str (string slices)\n    let result = longest(string1.as_str(), string2);\n    println!(\"Longest string: {}\", result);\n    \n    // Demonstrating lifetime constraints\n    {\n        let string3 = String::from(\"Short\");\n        let result2 = longest(string1.as_str(), string3.as_str());\n        println!(\"Longest in inner scope: {}\", result2);\n        // result2 is valid here because both string1 and string3 are valid\n    }\n    // string3 is dropped here, but that's OK because we're not using result2\n    \n    // Using struct with lifetime\n    let novel = String::from(\"Call me Ishmael. Some years ago...\");\n    let first_sentence = novel.split('.').next().expect(\"Could not find a '.'\");\n    let i = ImportantExcerpt {\n        part: first_sentence,\n    };\n    println!(\"Important excerpt: {}\", i.part);\n    println!(\"Level: {}\", i.level());\n    \n    // String operations\n    let sentence = \"Hello world from Rust\";\n    let (first_word, rest, original) = string_operations(sentence);\n    println!(\"First word: '{}'\", first_word);\n    println!(\"Rest: '{}'\", rest);\n    println!(\"Original: '{}'\", original);\n    \n    // Demonstrating that string slices are references\n    let s = String::from(\"hello world\");\n    let hello = &s[0..5];  // String slice\n    let world = &s[6..11]; // Another string slice\n    \n    println!(\"Slice 1: {}\", hello);\n    println!(\"Slice 2: {}\", world);\n    // Both slices reference parts of the original string s\n    \n    // Lifetime elision in action - Rust infers the lifetimes\n    fn get_first_word(s: &str) -> &str {\n        s.split_whitespace().next().unwrap_or(\"\")\n    }\n    \n    let first = get_first_word(\"Rust is awesome\");\n    println!(\"First word: {}\", first);\n}\n\n// Key concepts:\n// - Lifetimes ensure references don't outlive the data they point to\n// - Lifetime parameters connect the lifetimes of inputs and outputs\n// - String slices (&str) are references to parts of strings\n// - Lifetime elision lets Rust infer common lifetime patterns\n// - Structs can hold references with explicit lifetime parameters\n// - The borrow checker enforces lifetime rules at compile time\n```",
    "tags": [
      "lifetimes",
      "borrowing",
      "string-slices",
      "references",
      "borrow-checker"
    ],
    "instruction": "Demonstrate lifetimes and borrowing with string slices"
  },
  {
    "output": "```rust\n// This example demonstrates how to implement a custom iterator in Rust\n// We'll create a Fibonacci iterator that generates numbers infinitely\n\nstruct Fibonacci {\n    current: u64,\n    next: u64,\n}\n\nimpl Fibonacci {\n    // Constructor for our Fibonacci iterator\n    fn new() -> Self {\n        Fibonacci {\n            current: 0,\n            next: 1,\n        }\n    }\n}\n\n// Implement the Iterator trait for our Fibonacci struct\nimpl Iterator for Fibonacci {\n    // The Item associated type specifies what type this iterator yields\n    type Item = u64;\n    \n    // The next() method is the only required method for Iterator\n    fn next(&mut self) -> Option<Self::Item> {\n        let current = self.current;\n        \n        // Calculate next Fibonacci number\n        self.current = self.next;\n        self.next = current + self.next;\n        \n        // Iterator never ends (returns Some forever)\n        Some(current)\n    }\n}\n\n// Create a bounded Fibonacci iterator that stops at a limit\nstruct BoundedFibonacci {\n    fib: Fibonacci,\n    limit: u64,\n}\n\nimpl BoundedFibonacci {\n    fn new(limit: u64) -> Self {\n        BoundedFibonacci {\n            fib: Fibonacci::new(),\n            limit,\n        }\n    }\n}\n\nimpl Iterator for BoundedFibonacci {\n    type Item = u64;\n    \n    fn next(&mut self) -> Option<Self::Item> {\n        // Get next Fibonacci number\n        let next_val = self.fib.next()?;\n        \n        // Check if we've exceeded our limit\n        if next_val > self.limit {\n            None // Stop iteration\n        } else {\n            Some(next_val)\n        }\n    }\n}\n\n// Fibonacci iterator with index tracking\nstruct IndexedFibonacci {\n    fib: Fibonacci,\n    index: usize,\n}\n\nimpl IndexedFibonacci {\n    fn new() -> Self {\n        IndexedFibonacci {\n            fib: Fibonacci::new(),\n            index: 0,\n        }\n    }\n}\n\nimpl Iterator for IndexedFibonacci {\n    type Item = (usize, u64); // Returns (index, value) pairs\n    \n    fn next(&mut self) -> Option<Self::Item> {\n        let value = self.fib.next()?;\n        let index = self.index;\n        self.index += 1;\n        Some((index, value))\n    }\n}\n\nfn main() {\n    // Basic Fibonacci iterator usage\n    println!(\"=== First 10 Fibonacci numbers ===\");\n    let mut fib = Fibonacci::new();\n    for _ in 0..10 {\n        println!(\"{}\", fib.next().unwrap());\n    }\n    \n    // Using iterator methods with our custom iterator\n    println!(\"\\n=== Using iterator combinators ===\");\n    let fib_sum: u64 = Fibonacci::new()\n        .take(10)          // Take first 10 numbers\n        .sum();            // Sum them up\n    println!(\"Sum of first 10 Fibonacci numbers: {}\", fib_sum);\n    \n    // Collect into a vector\n    let fib_vec: Vec<u64> = Fibonacci::new()\n        .take(8)\n        .collect();\n    println!(\"First 8 Fibonacci numbers: {:?}\", fib_vec);\n    \n    // Filter and map operations\n    println!(\"\\n=== Even Fibonacci numbers under 100 ===\");\n    let even_fibs: Vec<u64> = Fibonacci::new()\n        .take_while(|&n| n < 100)  // Stop when we reach 100\n        .filter(|&n| n % 2 == 0)    // Only even numbers\n        .collect();\n    println!(\"{:?}\", even_fibs);\n    \n    // Using bounded Fibonacci iterator\n    println!(\"\\n=== Bounded Fibonacci (limit: 1000) ===\");\n    let bounded: Vec<u64> = BoundedFibonacci::new(1000).collect();\n    println!(\"{:?}\", bounded);\n    \n    // Using indexed Fibonacci iterator\n    println!(\"\\n=== Indexed Fibonacci ===\");\n    for (i, value) in IndexedFibonacci::new().take(5) {\n        println!(\"F({}) = {}\", i, value);\n    }\n    \n    // Chaining multiple operations\n    println!(\"\\n=== Complex iterator chain ===\");\n    let result: Vec<String> = Fibonacci::new()\n        .skip(5)                    // Skip first 5\n        .take(5)                    // Take next 5\n        .map(|n| n * 2)            // Double each\n        .map(|n| format!(\"2\u00d7F = {}\", n)) // Format as string\n        .collect();\n    \n    for s in result {\n        println!(\"{}\", s);\n    }\n    \n    // Using zip with our iterator\n    println!(\"\\n=== Zipping with natural numbers ===\");\n    let naturals = 1..;\n    let zipped: Vec<(u32, u64)> = naturals\n        .zip(Fibonacci::new())\n        .take(5)\n        .collect();\n    \n    for (n, fib) in zipped {\n        println!(\"Position {}: {}\", n, fib);\n    }\n}\n\n// Key concepts:\n// - Custom iterators implement the Iterator trait\n// - Only next() method is required, returning Option<Item>\n// - Iterators can be infinite (always return Some)\n// - Iterator combinators work with custom iterators\n// - Can compose complex operations with method chaining\n// - Associated type Item defines what the iterator yields\n```",
    "tags": [
      "iterators",
      "custom-iterator",
      "fibonacci",
      "iterator-trait",
      "combinators"
    ],
    "instruction": "Implement a custom iterator that generates Fibonacci numbers"
  },
  {
    "output": "```rust\n// This example showcases various iterator combinators and how to chain them\n// Iterator combinators are methods that transform iterators into new iterators\n\nuse std::collections::HashMap;\n\n#[derive(Debug, Clone)]\nstruct Product {\n    name: String,\n    price: f64,\n    category: String,\n    in_stock: bool,\n}\n\nimpl Product {\n    fn new(name: &str, price: f64, category: &str, in_stock: bool) -> Self {\n        Product {\n            name: name.to_string(),\n            price,\n            category: category.to_string(),\n            in_stock,\n        }\n    }\n}\n\nfn main() {\n    // Sample data\n    let products = vec![\n        Product::new(\"Laptop\", 999.99, \"Electronics\", true),\n        Product::new(\"Mouse\", 25.50, \"Electronics\", true),\n        Product::new(\"Desk\", 350.00, \"Furniture\", false),\n        Product::new(\"Chair\", 150.00, \"Furniture\", true),\n        Product::new(\"Monitor\", 299.99, \"Electronics\", true),\n        Product::new(\"Keyboard\", 79.99, \"Electronics\", false),\n        Product::new(\"Lamp\", 45.00, \"Furniture\", true),\n    ];\n    \n    // MAP: Transform each element\n    println!(\"=== Map: Product names ===\");\n    let names: Vec<String> = products\n        .iter()\n        .map(|p| p.name.clone())\n        .collect();\n    println!(\"{:?}\\n\", names);\n    \n    // FILTER: Keep only elements that match a condition\n    println!(\"=== Filter: In-stock products ===\");\n    let in_stock: Vec<&Product> = products\n        .iter()\n        .filter(|p| p.in_stock)\n        .collect();\n    for product in &in_stock {\n        println!(\"- {}: ${}\", product.name, product.price);\n    }\n    \n    // FILTER_MAP: Filter and transform in one step\n    println!(\"\\n=== Filter_map: Prices of in-stock electronics ===\");\n    let electronic_prices: Vec<f64> = products\n        .iter()\n        .filter_map(|p| {\n            if p.category == \"Electronics\" && p.in_stock {\n                Some(p.price)\n            } else {\n                None\n            }\n        })\n        .collect();\n    println!(\"{:?}\\n\", electronic_prices);\n    \n    // FOLD: Reduce to a single value (like reduce in other languages)\n    println!(\"=== Fold: Total value of in-stock inventory ===\");\n    let total_value = products\n        .iter()\n        .filter(|p| p.in_stock)\n        .fold(0.0, |acc, p| acc + p.price);\n    println!(\"Total: ${:.2}\\n\", total_value);\n    \n    // Complex fold: Group by category\n    println!(\"=== Complex fold: Group products by category ===\");\n    let grouped: HashMap<String, Vec<String>> = products\n        .iter()\n        .fold(HashMap::new(), |mut acc, product| {\n            acc.entry(product.category.clone())\n                .or_insert_with(Vec::new)\n                .push(product.name.clone());\n            acc\n        });\n    for (category, items) in &grouped {\n        println!(\"{}: {:?}\", category, items);\n    }\n    \n    // TAKE, SKIP, TAKE_WHILE\n    println!(\"\\n=== Take/Skip combinators ===\");\n    let numbers: Vec<i32> = (1..=10).collect();\n    \n    let first_three: Vec<i32> = numbers.iter().copied().take(3).collect();\n    println!(\"Take 3: {:?}\", first_three);\n    \n    let skip_first_five: Vec<i32> = numbers.iter().copied().skip(5).collect();\n    println!(\"Skip 5: {:?}\", skip_first_five);\n    \n    let take_while_small: Vec<i32> = numbers\n        .iter()\n        .copied()\n        .take_while(|&x| x < 5)\n        .collect();\n    println!(\"Take while < 5: {:?}\", take_while_small);\n    \n    // CHAIN: Combine multiple iterators\n    println!(\"\\n=== Chain: Combine iterators ===\");\n    let first_range = 1..=3;\n    let second_range = 10..=12;\n    let chained: Vec<i32> = first_range.chain(second_range).collect();\n    println!(\"Chained: {:?}\", chained);\n    \n    // ZIP: Pair elements from two iterators\n    println!(\"\\n=== Zip: Pair products with discounts ===\");\n    let discounts = vec![0.1, 0.15, 0.0, 0.2, 0.1, 0.0, 0.25];\n    let with_discounts: Vec<(&Product, f64)> = products\n        .iter()\n        .zip(discounts.iter())\n        .map(|(p, &d)| (p, p.price * (1.0 - d)))\n        .collect();\n    \n    for (product, discounted_price) in &with_discounts {\n        println!(\"{}: ${:.2} (was ${:.2})\", \n                 product.name, discounted_price, product.price);\n    }\n    \n    // ENUMERATE: Add index to elements\n    println!(\"\\n=== Enumerate: Products with index ===\");\n    for (i, product) in products.iter().enumerate().take(3) {\n        println!(\"{}. {}\", i + 1, product.name);\n    }\n    \n    // FLAT_MAP: Map and flatten nested structures\n    println!(\"\\n=== Flat_map: All words from product names ===\");\n    let all_words: Vec<String> = products\n        .iter()\n        .flat_map(|p| p.name.split_whitespace())\n        .map(|s| s.to_lowercase())\n        .collect();\n    println!(\"{:?}\", all_words);\n    \n    // PARTITION: Split into two collections based on predicate\n    println!(\"\\n=== Partition: Split by availability ===\");\n    let (available, out_of_stock): (Vec<&Product>, Vec<&Product>) = \n        products.iter().partition(|p| p.in_stock);\n    \n    println!(\"Available: {} items\", available.len());\n    println!(\"Out of stock: {} items\", out_of_stock.len());\n    \n    // Complex chaining example\n    println!(\"\\n=== Complex chain: Top 3 expensive in-stock electronics ===\");\n    let top_electronics: Vec<String> = products\n        .iter()\n        .filter(|p| p.category == \"Electronics\")\n        .filter(|p| p.in_stock)\n        .map(|p| (p.name.clone(), p.price))\n        .fold(Vec::new(), |mut acc, item| {\n            acc.push(item);\n            acc.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap());\n            acc.truncate(3);\n            acc\n        })\n        .into_iter()\n        .map(|(name, price)| format!(\"{}: ${:.2}\", name, price))\n        .collect();\n    \n    for item in top_electronics {\n        println!(\"- {}\", item);\n    }\n    \n    // SCAN: Like fold but yields intermediate values\n    println!(\"\\n=== Scan: Running totals ===\");\n    let prices = vec![10.0, 20.0, 15.0, 25.0];\n    let running_totals: Vec<f64> = prices\n        .iter()\n        .scan(0.0, |acc, &x| {\n            *acc += x;\n            Some(*acc)\n        })\n        .collect();\n    println!(\"Prices: {:?}\", prices);\n    println!(\"Running totals: {:?}\", running_totals);\n}\n\n// Key concepts:\n// - map() transforms each element\n// - filter() keeps elements matching a predicate\n// - fold() reduces to a single value with an accumulator\n// - filter_map() combines filtering and mapping\n// - chain() concatenates iterators\n// - zip() pairs elements from multiple iterators\n// - enumerate() adds indices\n// - flat_map() maps and flattens nested structures\n// - partition() splits based on a predicate\n// - Iterator combinators can be chained for complex operations\n```",
    "tags": [
      "iterators",
      "combinators",
      "map",
      "filter",
      "fold",
      "chain",
      "functional"
    ],
    "instruction": "Demonstrate iterator combinators like map, filter, fold, and their chaining"
  },
  {
    "output": "```rust\n// This example demonstrates HashSet operations and set theory concepts\n// HashSet provides O(1) average insert, remove, and lookup operations\n\nuse std::collections::HashSet;\nuse std::iter::FromIterator;\n\n#[derive(Debug, Hash, PartialEq, Eq, Clone)]\nstruct Student {\n    name: String,\n    id: u32,\n}\n\nimpl Student {\n    fn new(name: &str, id: u32) -> Self {\n        Student {\n            name: name.to_string(),\n            id,\n        }\n    }\n}\n\nfn main() {\n    // Basic HashSet creation and operations\n    println!(\"=== Basic HashSet Operations ===\");\n    let mut numbers: HashSet<i32> = HashSet::new();\n    \n    // Insert elements\n    numbers.insert(1);\n    numbers.insert(2);\n    numbers.insert(3);\n    numbers.insert(2); // Duplicate - won't be added\n    \n    println!(\"Numbers set: {:?}\", numbers);\n    println!(\"Size: {}\", numbers.len());\n    \n    // Check membership\n    if numbers.contains(&2) {\n        println!(\"Set contains 2\");\n    }\n    \n    // Remove elements\n    if numbers.remove(&3) {\n        println!(\"Removed 3 from set\");\n    }\n    println!(\"After removal: {:?}\", numbers);\n    \n    // Creating HashSet from iterator\n    println!(\"\\n=== Creating from Collections ===\");\n    let vec_with_duplicates = vec![1, 2, 3, 2, 4, 3, 5];\n    let unique_numbers: HashSet<i32> = vec_with_duplicates.into_iter().collect();\n    println!(\"Original vec: [1, 2, 3, 2, 4, 3, 5]\");\n    println!(\"Unique numbers: {:?}\", unique_numbers);\n    \n    // Using HashSet::from_iter\n    let words = [\"hello\", \"world\", \"hello\", \"rust\"];\n    let unique_words: HashSet<&str> = HashSet::from_iter(words);\n    println!(\"Unique words: {:?}\", unique_words);\n    \n    // Set Theory Operations\n    println!(\"\\n=== Set Theory Operations ===\");\n    let set_a: HashSet<i32> = [1, 2, 3, 4, 5].into_iter().collect();\n    let set_b: HashSet<i32> = [4, 5, 6, 7, 8].into_iter().collect();\n    \n    println!(\"Set A: {:?}\", set_a);\n    println!(\"Set B: {:?}\", set_b);\n    \n    // Union: all elements from both sets\n    let union: HashSet<i32> = set_a.union(&set_b).copied().collect();\n    println!(\"A \u222a B (union): {:?}\", union);\n    \n    // Intersection: elements in both sets\n    let intersection: HashSet<i32> = set_a.intersection(&set_b).copied().collect();\n    println!(\"A \u2229 B (intersection): {:?}\", intersection);\n    \n    // Difference: elements in A but not in B\n    let difference: HashSet<i32> = set_a.difference(&set_b).copied().collect();\n    println!(\"A - B (difference): {:?}\", difference);\n    \n    // Symmetric difference: elements in either A or B, but not both\n    let sym_diff: HashSet<i32> = set_a.symmetric_difference(&set_b).copied().collect();\n    println!(\"A \u2206 B (symmetric difference): {:?}\", sym_diff);\n    \n    // Set relationships\n    println!(\"\\n=== Set Relationships ===\");\n    let small_set: HashSet<i32> = [2, 3].into_iter().collect();\n    let large_set: HashSet<i32> = [1, 2, 3, 4, 5].into_iter().collect();\n    \n    println!(\"Small set: {:?}\", small_set);\n    println!(\"Large set: {:?}\", large_set);\n    \n    // Subset check\n    if small_set.is_subset(&large_set) {\n        println!(\"Small set is a subset of large set\");\n    }\n    \n    // Superset check\n    if large_set.is_superset(&small_set) {\n        println!(\"Large set is a superset of small set\");\n    }\n    \n    // Disjoint check\n    let disjoint_set: HashSet<i32> = [10, 11, 12].into_iter().collect();\n    if small_set.is_disjoint(&disjoint_set) {\n        println!(\"Small set and disjoint set have no common elements\");\n    }\n    \n    // Working with custom types\n    println!(\"\\n=== Custom Types in HashSet ===\");\n    let mut students: HashSet<Student> = HashSet::new();\n    \n    students.insert(Student::new(\"Alice\", 101));\n    students.insert(Student::new(\"Bob\", 102));\n    students.insert(Student::new(\"Charlie\", 103));\n    students.insert(Student::new(\"Alice\", 101)); // Duplicate - won't be added\n    \n    println!(\"Students: {:#?}\", students);\n    println!(\"Number of unique students: {}\", students.len());\n    \n    // Check if specific student exists\n    let alice = Student::new(\"Alice\", 101);\n    if students.contains(&alice) {\n        println!(\"Alice is enrolled\");\n    }\n    \n    // Practical examples\n    println!(\"\\n=== Practical Examples ===\");\n    \n    // 1. Finding unique characters in a string\n    let text = \"hello world\";\n    let unique_chars: HashSet<char> = text.chars().filter(|&c| c != ' ').collect();\n    println!(\"Unique characters in '{}': {:?}\", text, unique_chars);\n    \n    // 2. Finding common interests\n    let alice_interests: HashSet<&str> = [\"reading\", \"coding\", \"hiking\"].into_iter().collect();\n    let bob_interests: HashSet<&str> = [\"coding\", \"gaming\", \"hiking\"].into_iter().collect();\n    \n    let common_interests: Vec<&str> = alice_interests\n        .intersection(&bob_interests)\n        .copied()\n        .collect();\n    \n    println!(\"Alice's interests: {:?}\", alice_interests);\n    println!(\"Bob's interests: {:?}\", bob_interests);\n    println!(\"Common interests: {:?}\", common_interests);\n    \n    // 3. Deduplicating a list while preserving some order\n    let numbers = vec![1, 3, 2, 3, 4, 2, 5, 1];\n    let mut seen = HashSet::new();\n    let deduplicated: Vec<i32> = numbers\n        .into_iter()\n        .filter(|x| seen.insert(*x))\n        .collect();\n    \n    println!(\"Original: [1, 3, 2, 3, 4, 2, 5, 1]\");\n    println!(\"Deduplicated (first occurrence): {:?}\", deduplicated);\n    \n    // 4. Filtering based on blacklist/whitelist\n    let all_users = [\"admin\", \"user1\", \"guest\", \"user2\", \"banned\"];\n    let blacklist: HashSet<&str> = [\"guest\", \"banned\"].into_iter().collect();\n    \n    let allowed_users: Vec<&str> = all_users\n        .into_iter()\n        .filter(|user| !blacklist.contains(user))\n        .collect();\n    \n    println!(\"All users: {:?}\", all_users);\n    println!(\"Blacklist: {:?}\", blacklist);\n    println!(\"Allowed users: {:?}\", allowed_users);\n    \n    // Performance characteristics\n    println!(\"\\n=== Performance Notes ===\");\n    println!(\"HashSet operations:\");\n    println!(\"- Insert: O(1) average, O(n) worst case\");\n    println!(\"- Remove: O(1) average, O(n) worst case\");\n    println!(\"- Contains: O(1) average, O(n) worst case\");\n    println!(\"- Union/Intersection: O(n + m) where n, m are set sizes\");\n    \n    // Memory usage\n    let large_set: HashSet<i32> = (0..1000).collect();\n    println!(\"\\nCreated HashSet with 1000 elements\");\n    println!(\"Memory overhead: HashSet has some overhead for hash table\");\n    \n    // Iteration order\n    println!(\"\\n=== Iteration Order ===\");\n    let ordered_insert: HashSet<i32> = [3, 1, 4, 1, 5, 9, 2, 6].into_iter().collect();\n    println!(\"Inserted in order: [3, 1, 4, 1, 5, 9, 2, 6]\");\n    print!(\"Iteration order: \");\n    for num in &ordered_insert {\n        print!(\"{} \", num);\n    }\n    println!(\"\\n(Order is not guaranteed and may vary)\");\n}\n\n// Key concepts:\n// - HashSet stores unique values with O(1) average operations\n// - Automatically handles duplicates by ignoring them\n// - Supports set theory operations: union, intersection, difference\n// - Requires Hash + Eq traits for element types\n// - No guaranteed iteration order (unlike BTreeSet)\n// - Useful for membership testing and deduplication\n// - Set relationships: subset, superset, disjoint\n```",
    "tags": [
      "hashset",
      "collections",
      "set-theory",
      "deduplication",
      "membership",
      "union",
      "intersection"
    ],
    "instruction": "Demonstrate HashSet operations and set theory with examples"
  },
  {
    "output": "```rust\n// This example demonstrates VecDeque (double-ended queue) and its use as a circular buffer\n// VecDeque allows efficient insertion and removal from both ends\n\nuse std::collections::VecDeque;\nuse std::fmt;\n\n// Custom circular buffer implementation using VecDeque\nstruct CircularBuffer<T> {\n    buffer: VecDeque<T>,\n    capacity: usize,\n}\n\nimpl<T: Clone> CircularBuffer<T> {\n    fn new(capacity: usize) -> Self {\n        CircularBuffer {\n            buffer: VecDeque::with_capacity(capacity),\n            capacity,\n        }\n    }\n    \n    fn push(&mut self, item: T) {\n        if self.buffer.len() == self.capacity {\n            // Remove oldest item when at capacity\n            self.buffer.pop_front();\n        }\n        self.buffer.push_back(item);\n    }\n    \n    fn get(&self, index: usize) -> Option<&T> {\n        self.buffer.get(index)\n    }\n    \n    fn len(&self) -> usize {\n        self.buffer.len()\n    }\n    \n    fn is_full(&self) -> bool {\n        self.buffer.len() == self.capacity\n    }\n    \n    fn iter(&self) -> std::collections::vec_deque::Iter<T> {\n        self.buffer.iter()\n    }\n    \n    fn latest(&self) -> Option<&T> {\n        self.buffer.back()\n    }\n    \n    fn oldest(&self) -> Option<&T> {\n        self.buffer.front()\n    }\n}\n\nimpl<T: fmt::Debug> fmt::Debug for CircularBuffer<T> {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        write!(f, \"CircularBuffer({:?})\", self.buffer)\n    }\n}\n\nfn main() {\n    // Basic VecDeque operations\n    println!(\"=== Basic VecDeque Operations ===\");\n    let mut deque: VecDeque<i32> = VecDeque::new();\n    \n    // Add elements to both ends\n    deque.push_back(1);    // [1]\n    deque.push_back(2);    // [1, 2]\n    deque.push_front(0);   // [0, 1, 2]\n    deque.push_front(-1);  // [-1, 0, 1, 2]\n    \n    println!(\"After pushes: {:?}\", deque);\n    \n    // Remove elements from both ends\n    if let Some(back) = deque.pop_back() {\n        println!(\"Popped from back: {}\", back);  // 2\n    }\n    \n    if let Some(front) = deque.pop_front() {\n        println!(\"Popped from front: {}\", front); // -1\n    }\n    \n    println!(\"After pops: {:?}\", deque); // [0, 1]\n    \n    // Access front and back without removing\n    if let Some(front) = deque.front() {\n        println!(\"Front element: {}\", front);\n    }\n    \n    if let Some(back) = deque.back() {\n        println!(\"Back element: {}\", back);\n    }\n    \n    // VecDeque as a queue (FIFO)\n    println!(\"\\n=== VecDeque as Queue (FIFO) ===\");\n    let mut queue: VecDeque<&str> = VecDeque::new();\n    \n    // Enqueue items (add to back)\n    queue.push_back(\"First\");\n    queue.push_back(\"Second\");\n    queue.push_back(\"Third\");\n    \n    println!(\"Queue: {:?}\", queue);\n    \n    // Dequeue items (remove from front)\n    while let Some(item) = queue.pop_front() {\n        println!(\"Processing: {}\", item);\n    }\n    \n    // VecDeque as a stack (LIFO)\n    println!(\"\\n=== VecDeque as Stack (LIFO) ===\");\n    let mut stack: VecDeque<i32> = VecDeque::new();\n    \n    // Push items (add to back)\n    stack.push_back(10);\n    stack.push_back(20);\n    stack.push_back(30);\n    \n    println!(\"Stack: {:?}\", stack);\n    \n    // Pop items (remove from back)\n    while let Some(item) = stack.pop_back() {\n        println!(\"Popped: {}\", item);\n    }\n    \n    // Circular buffer demonstration\n    println!(\"\\n=== Circular Buffer ===\");\n    let mut circular = CircularBuffer::new(3);\n    \n    // Add items beyond capacity\n    circular.push(1);\n    println!(\"After push(1): {:?}\", circular);\n    \n    circular.push(2);\n    println!(\"After push(2): {:?}\", circular);\n    \n    circular.push(3);\n    println!(\"After push(3): {:?}\", circular);\n    println!(\"Buffer is full: {}\", circular.is_full());\n    \n    // This will remove the oldest (1) and add 4\n    circular.push(4);\n    println!(\"After push(4): {:?}\", circular);\n    \n    circular.push(5);\n    println!(\"After push(5): {:?}\", circular);\n    \n    println!(\"Latest: {:?}\", circular.latest());\n    println!(\"Oldest: {:?}\", circular.oldest());\n    \n    // Practical example: Moving average calculator\n    println!(\"\\n=== Moving Average Calculator ===\");\n    struct MovingAverage {\n        buffer: CircularBuffer<f64>,\n    }\n    \n    impl MovingAverage {\n        fn new(window_size: usize) -> Self {\n            MovingAverage {\n                buffer: CircularBuffer::new(window_size),\n            }\n        }\n        \n        fn add_value(&mut self, value: f64) {\n            self.buffer.push(value);\n        }\n        \n        fn average(&self) -> f64 {\n            if self.buffer.len() == 0 {\n                return 0.0;\n            }\n            \n            let sum: f64 = self.buffer.iter().sum();\n            sum / self.buffer.len() as f64\n        }\n    }\n    \n    let mut ma = MovingAverage::new(3);\n    let values = [1.0, 2.0, 3.0, 4.0, 5.0, 6.0];\n    \n    for value in values {\n        ma.add_value(value);\n        println!(\"Added {:.1}, moving average: {:.2}\", value, ma.average());\n    }\n    \n    // Advanced VecDeque operations\n    println!(\"\\n=== Advanced Operations ===\");\n    let mut advanced: VecDeque<i32> = VecDeque::from([1, 2, 3, 4, 5]);\n    \n    // Insert and remove at arbitrary positions\n    advanced.insert(2, 99);  // Insert 99 at index 2\n    println!(\"After insert(2, 99): {:?}\", advanced);\n    \n    if let Some(removed) = advanced.remove(3) {\n        println!(\"Removed element at index 3: {}\", removed);\n    }\n    println!(\"After remove(3): {:?}\", advanced);\n    \n    // Rotate elements\n    advanced.rotate_left(2);  // Rotate left by 2 positions\n    println!(\"After rotate_left(2): {:?}\", advanced);\n    \n    advanced.rotate_right(1); // Rotate right by 1 position\n    println!(\"After rotate_right(1): {:?}\", advanced);\n    \n    // Split at position\n    let mut original = VecDeque::from([1, 2, 3, 4, 5]);\n    let split_off = original.split_off(3);\n    println!(\"Original after split_off(3): {:?}\", original);\n    println!(\"Split off part: {:?}\", split_off);\n    \n    // Append another VecDeque\n    original.append(&mut VecDeque::from([6, 7, 8]));\n    println!(\"After append: {:?}\", original);\n    \n    // Reserve capacity for performance\n    let mut efficient: VecDeque<i32> = VecDeque::with_capacity(1000);\n    println!(\"Initial capacity: {}\", efficient.capacity());\n    \n    // Drain elements with a range\n    let mut drain_example = VecDeque::from([1, 2, 3, 4, 5, 6]);\n    let drained: Vec<i32> = drain_example.drain(1..4).collect();\n    println!(\"Drained elements 1..4: {:?}\", drained);\n    println!(\"Remaining: {:?}\", drain_example);\n    \n    // Real-world example: Undo/Redo system\n    println!(\"\\n=== Undo/Redo System ===\");\n    struct UndoRedoSystem<T> {\n        undo_stack: VecDeque<T>,\n        redo_stack: VecDeque<T>,\n        max_history: usize,\n    }\n    \n    impl<T> UndoRedoSystem<T> {\n        fn new(max_history: usize) -> Self {\n            UndoRedoSystem {\n                undo_stack: VecDeque::new(),\n                redo_stack: VecDeque::new(),\n                max_history,\n            }\n        }\n        \n        fn execute(&mut self, action: T) {\n            // Clear redo stack when new action is executed\n            self.redo_stack.clear();\n            \n            // Add to undo stack\n            self.undo_stack.push_back(action);\n            \n            // Maintain max history\n            if self.undo_stack.len() > self.max_history {\n                self.undo_stack.pop_front();\n            }\n        }\n        \n        fn undo(&mut self) -> Option<T> {\n            if let Some(action) = self.undo_stack.pop_back() {\n                self.redo_stack.push_back(action);\n                self.undo_stack.back().cloned()\n            } else {\n                None\n            }\n        }\n        \n        fn redo(&mut self) -> Option<T> {\n            if let Some(action) = self.redo_stack.pop_back() {\n                self.undo_stack.push_back(action);\n                self.undo_stack.back().cloned()\n            } else {\n                None\n            }\n        }\n        \n        fn can_undo(&self) -> bool {\n            !self.undo_stack.is_empty()\n        }\n        \n        fn can_redo(&self) -> bool {\n            !self.redo_stack.is_empty()\n        }\n    }\n    \n    let mut undo_redo: UndoRedoSystem<String> = UndoRedoSystem::new(5);\n    \n    undo_redo.execute(\"Type 'Hello'\".to_string());\n    undo_redo.execute(\"Type ' World'\".to_string());\n    undo_redo.execute(\"Delete 'World'\".to_string());\n    \n    println!(\"Can undo: {}\", undo_redo.can_undo());\n    println!(\"Can redo: {}\", undo_redo.can_redo());\n    \n    // Performance characteristics\n    println!(\"\\n=== Performance Characteristics ===\");\n    println!(\"VecDeque operations:\");\n    println!(\"- push_front/push_back: O(1) amortized\");\n    println!(\"- pop_front/pop_back: O(1)\");\n    println!(\"- insert/remove at arbitrary position: O(n)\");\n    println!(\"- Access by index: O(1)\");\n    println!(\"- Good for: queues, stacks, sliding windows, circular buffers\");\n}\n\n// Key concepts:\n// - VecDeque provides O(1) insertion/removal at both ends\n// - Excellent for implementing queues, stacks, and circular buffers\n// - Grows dynamically like Vec but optimized for front operations\n// - Can be used as sliding window for algorithms\n// - Supports rotation and arbitrary insertion/removal\n// - Memory efficient with good cache locality\n```",
    "tags": [
      "vecdeque",
      "collections",
      "circular-buffer",
      "queue",
      "stack",
      "deque",
      "sliding-window"
    ],
    "instruction": "Use VecDeque as a circular buffer and demonstrate its capabilities"
  },
  {
    "output": "```rust\n// This example demonstrates advanced iterator adaptors and lazy evaluation\n// Iterator adaptors are composable and only execute when consumed\n\nuse std::collections::HashMap;\n\n#[derive(Debug, Clone)]\nstruct LogEntry {\n    timestamp: u64,\n    level: String,\n    message: String,\n    module: String,\n}\n\nimpl LogEntry {\n    fn new(timestamp: u64, level: &str, message: &str, module: &str) -> Self {\n        LogEntry {\n            timestamp,\n            level: level.to_string(),\n            message: message.to_string(),\n            module: module.to_string(),\n        }\n    }\n}\n\nfn main() {\n    println!(\"=== Lazy Evaluation Demonstration ===\");\n    \n    // Iterators are lazy - they do nothing until consumed\n    let numbers = vec![1, 2, 3, 4, 5, 6, 7, 8, 9, 10];\n    \n    // This creates an iterator chain but doesn't execute anything yet\n    let lazy_chain = numbers\n        .iter()\n        .inspect(|x| println!(\"Processing: {}\", x))  // Side effect for observation\n        .filter(|&&x| {\n            println!(\"  Filtering: {}\", x);\n            x % 2 == 0\n        })\n        .map(|&x| {\n            println!(\"  Mapping: {} -> {}\", x, x * x);\n            x * x\n        });\n    \n    println!(\"Iterator chain created (no output yet - lazy!)\");\n    \n    // Only when we consume the iterator does the chain execute\n    println!(\"\\nConsuming iterator:\");\n    let results: Vec<i32> = lazy_chain.collect();\n    println!(\"Results: {:?}\", results);\n    \n    // Advanced iterator adaptors\n    println!(\"\\n=== Advanced Iterator Adaptors ===\");\n    \n    // STEP_BY: Take every nth element\n    let every_third: Vec<i32> = (0..20).step_by(3).collect();\n    println!(\"Every 3rd number from 0-19: {:?}\", every_third);\n    \n    // CYCLE: Repeat iterator infinitely\n    let colors = vec![\"red\", \"green\", \"blue\"];\n    let repeated: Vec<&str> = colors.iter().cycle().take(10).cloned().collect();\n    println!(\"Cycling colors: {:?}\", repeated);\n    \n    // REPEAT and REPEAT_WITH\n    let repeated_value: Vec<i32> = std::iter::repeat(42).take(5).collect();\n    println!(\"Repeat value: {:?}\", repeated_value);\n    \n    let mut counter = 0;\n    let generated: Vec<i32> = std::iter::repeat_with(|| {\n        counter += 1;\n        counter * 10\n    }).take(5).collect();\n    println!(\"Generated with repeat_with: {:?}\", generated);\n    \n    // WINDOWS and CHUNKS\n    println!(\"\\n=== Windows and Chunks ===\");\n    let data = vec![1, 2, 3, 4, 5, 6, 7, 8];\n    \n    // Windows: overlapping slices\n    println!(\"Windows of size 3:\");\n    for window in data.windows(3) {\n        println!(\"  {:?}\", window);\n    }\n    \n    // Chunks: non-overlapping slices\n    println!(\"Chunks of size 3:\");\n    for chunk in data.chunks(3) {\n        println!(\"  {:?}\", chunk);\n    }\n    \n    // ENUMERATE with complex logic\n    println!(\"\\n=== Advanced Enumerate Usage ===\");\n    let words = [\"hello\", \"world\", \"rust\", \"programming\"];\n    let indexed_and_filtered: Vec<(usize, &str)> = words\n        .iter()\n        .enumerate()\n        .filter(|(i, word)| i % 2 == 0 && word.len() > 4)\n        .map(|(i, &word)| (i, word))\n        .collect();\n    \n    println!(\"Even indices with words > 4 chars: {:?}\", indexed_and_filtered);\n    \n    // PEEKABLE: Look ahead without consuming\n    println!(\"\\n=== Peekable Iterator ===\");\n    let mut peekable = [1, 2, 2, 3, 3, 3, 4].iter().peekable();\n    \n    while let Some(&current) = peekable.next() {\n        let mut count = 1;\n        \n        // Count consecutive identical elements\n        while let Some(&&next) = peekable.peek() {\n            if next == current {\n                count += 1;\n                peekable.next(); // Consume the peeked element\n            } else {\n                break;\n            }\n        }\n        \n        println!(\"{} appears {} time(s)\", current, count);\n    }\n    \n    // Complex real-world example: Log processing\n    println!(\"\\n=== Log Processing Example ===\");\n    let logs = vec![\n        LogEntry::new(1000, \"INFO\", \"Server started\", \"main\"),\n        LogEntry::new(1001, \"DEBUG\", \"Loading config\", \"config\"),\n        LogEntry::new(1002, \"ERROR\", \"Database connection failed\", \"db\"),\n        LogEntry::new(1003, \"INFO\", \"Retrying connection\", \"db\"),\n        LogEntry::new(1004, \"ERROR\", \"Authentication failed\", \"auth\"),\n        LogEntry::new(1005, \"INFO\", \"User logged in\", \"auth\"),\n        LogEntry::new(1006, \"DEBUG\", \"Processing request\", \"api\"),\n        LogEntry::new(1007, \"ERROR\", \"Request timeout\", \"api\"),\n    ];\n    \n    // Complex iterator chain for log analysis\n    let error_summary: HashMap<String, Vec<String>> = logs\n        .iter()\n        .filter(|log| log.level == \"ERROR\")  // Only errors\n        .group_by_module()  // Group by module (custom extension)\n        .into_iter()\n        .map(|(module, errors)| {\n            let messages: Vec<String> = errors\n                .map(|log| log.message.clone())\n                .collect();\n            (module, messages)\n        })\n        .collect();\n    \n    println!(\"Error summary by module:\");\n    for (module, messages) in error_summary {\n        println!(\"  {}: {:?}\", module, messages);\n    }\n    \n    // SCAN for running calculations\n    println!(\"\\n=== Scan for Running Calculations ===\");\n    let daily_sales = vec![100, 150, 80, 200, 120, 90, 180];\n    \n    // Running total\n    let running_total: Vec<i32> = daily_sales\n        .iter()\n        .scan(0, |total, &sale| {\n            *total += sale;\n            Some(*total)\n        })\n        .collect();\n    \n    println!(\"Daily sales: {:?}\", daily_sales);\n    println!(\"Running total: {:?}\", running_total);\n    \n    // Running average\n    let running_avg: Vec<f64> = daily_sales\n        .iter()\n        .enumerate()\n        .scan(0, |sum, (i, &sale)| {\n            *sum += sale;\n            Some(*sum as f64 / (i + 1) as f64)\n        })\n        .collect();\n    \n    println!(\"Running average: {:?}\", running_avg);\n    \n    // FLAT_MAP for nested structures\n    println!(\"\\n=== Flat Map for Nested Data ===\");\n    let departments = vec![\n        (\"Engineering\", vec![\"Alice\", \"Bob\", \"Charlie\"]),\n        (\"Marketing\", vec![\"Diana\", \"Eve\"]),\n        (\"Sales\", vec![\"Frank\", \"Grace\", \"Henry\", \"Ivy\"]),\n    ];\n    \n    // Flatten all employees\n    let all_employees: Vec<&str> = departments\n        .iter()\n        .flat_map(|(_, employees)| employees.iter())\n        .copied()\n        .collect();\n    \n    println!(\"All employees: {:?}\", all_employees);\n    \n    // Employees with their departments\n    let employees_with_dept: Vec<(String, &str)> = departments\n        .iter()\n        .flat_map(|(dept, employees)| {\n            employees.iter().map(move |&emp| (dept.to_string(), emp))\n        })\n        .collect();\n    \n    println!(\"Employees with departments:\");\n    for (dept, emp) in employees_with_dept {\n        println!(\"  {} - {}\", emp, dept);\n    }\n    \n    // Performance consideration: Early termination\n    println!(\"\\n=== Early Termination for Performance ===\");\n    let large_dataset = 1..1_000_000;\n    \n    // Find first 5 numbers divisible by 12345\n    let start = std::time::Instant::now();\n    let special_numbers: Vec<i32> = large_dataset\n        .filter(|&x| x % 12345 == 0)\n        .take(5)  // Early termination - stops after finding 5\n        .collect();\n    let duration = start.elapsed();\n    \n    println!(\"First 5 numbers divisible by 12345: {:?}\", special_numbers);\n    println!(\"Time taken: {:?}\", duration);\n    \n    // Iterator fusion optimization\n    println!(\"\\n=== Iterator Fusion Optimization ===\");\n    let data = vec![1, 2, 3, 4, 5, 6, 7, 8, 9, 10];\n    \n    // Multiple map operations get fused into a single pass\n    let optimized: Vec<i32> = data\n        .iter()\n        .map(|&x| x + 1)     // These three maps\n        .map(|x| x * 2)      // get fused by the\n        .map(|x| x - 3)      // Rust compiler\n        .collect();\n    \n    println!(\"Fused operations result: {:?}\", optimized);\n    \n    // Custom iterator adaptor\n    println!(\"\\n=== Custom Iterator Extension ===\");\n    \n    // Using a custom trait to extend iterator functionality\n    trait IteratorExt: Iterator {\n        fn inspect_enumerate(self) -> InspectEnumerate<Self>\n        where\n            Self: Sized,\n        {\n            InspectEnumerate {\n                iter: self.enumerate(),\n            }\n        }\n    }\n    \n    impl<I: Iterator> IteratorExt for I {}\n    \n    struct InspectEnumerate<I> {\n        iter: I,\n    }\n    \n    impl<I> Iterator for InspectEnumerate<I>\n    where\n        I: Iterator<Item = (usize, I::Item)>,\n    {\n        type Item = I::Item;\n        \n        fn next(&mut self) -> Option<Self::Item> {\n            self.iter.next().map(|(i, item)| {\n                println!(\"Item {} at index {}\", \n                    std::any::type_name::<I::Item>(), i);\n                item\n            })\n        }\n    }\n    \n    let custom_result: Vec<i32> = vec![10, 20, 30]\n        .into_iter()\n        .inspect_enumerate()\n        .collect();\n    \n    println!(\"Custom adaptor result: {:?}\", custom_result);\n    \n    // Memory efficiency demonstration\n    println!(\"\\n=== Memory Efficiency ===\");\n    println!(\"Iterators are zero-cost abstractions:\");\n    println!(\"- No heap allocation for iterator chains\");\n    println!(\"- Optimized to simple loops by the compiler\");\n    println!(\"- Lazy evaluation prevents unnecessary work\");\n    \n    // Example of memory-efficient processing\n    let memory_efficient_count = (0..1_000_000)\n        .filter(|&x| x % 7 == 0)\n        .map(|x| x * x)\n        .filter(|&x| x > 100_000)\n        .count();  // Only count, don't collect\n    \n    println!(\"Count of large squares divisible by 7: {}\", memory_efficient_count);\n}\n\n// Custom extension trait for grouping\ntrait LogGrouping {\n    fn group_by_module(self) -> std::collections::HashMap<String, Vec<LogEntry>>;\n}\n\nimpl<I> LogGrouping for I\nwhere\n    I: Iterator<Item = &LogEntry>,\n{\n    fn group_by_module(self) -> HashMap<String, Vec<LogEntry>> {\n        let mut groups: HashMap<String, Vec<LogEntry>> = HashMap::new();\n        \n        for log in self {\n            groups.entry(log.module.clone())\n                .or_insert_with(Vec::new)\n                .push(log.clone());\n        }\n        \n        groups\n    }\n}\n\n// Key concepts:\n// - Iterator adaptors are lazy and only execute when consumed\n// - Multiple adaptors can be chained efficiently\n// - Early termination with take() improves performance\n// - Iterator fusion optimizes multiple map operations\n// - Custom adaptors can extend iterator functionality\n// - Zero-cost abstractions compile to efficient loops\n// - Memory efficient - no intermediate collections created\n```",
    "tags": [
      "iterators",
      "adaptors",
      "lazy-evaluation",
      "performance",
      "zero-cost",
      "scan",
      "peekable",
      "flat-map"
    ],
    "instruction": "Demonstrate advanced iterator adaptors and lazy evaluation concepts"
  },
  {
    "output": "```rust\n// This example demonstrates designing comprehensive error types using enums\n// Custom error types provide better error handling and debugging capabilities\n\nuse std::error::Error;\nuse std::fmt;\nuse std::fs::File;\nuse std::io;\nuse std::num::ParseIntError;\nuse std::str::Utf8Error;\n\n// Basic custom error enum\n#[derive(Debug, Clone, PartialEq)]\nenum DatabaseError {\n    ConnectionFailed {\n        host: String,\n        port: u16,\n        underlying_error: String,\n    },\n    QueryError {\n        query: String,\n        error_code: i32,\n        message: String,\n    },\n    RecordNotFound {\n        table: String,\n        id: String,\n    },\n    DuplicateKey {\n        table: String,\n        key: String,\n        value: String,\n    },\n    TransactionFailed {\n        reason: String,\n        rollback_successful: bool,\n    },\n    PermissionDenied {\n        user: String,\n        operation: String,\n        resource: String,\n    },\n    DataValidationError {\n        field: String,\n        value: String,\n        constraint: String,\n    },\n}\n\n// Implementing Display trait for user-friendly error messages\nimpl fmt::Display for DatabaseError {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        match self {\n            DatabaseError::ConnectionFailed { host, port, underlying_error } => {\n                write!(f, \"Failed to connect to database at {}:{} - {}\", host, port, underlying_error)\n            }\n            DatabaseError::QueryError { query, error_code, message } => {\n                write!(f, \"Query failed (code {}): {} - Query: {}\", error_code, message, query)\n            }\n            DatabaseError::RecordNotFound { table, id } => {\n                write!(f, \"Record with ID '{}' not found in table '{}'\", id, table)\n            }\n            DatabaseError::DuplicateKey { table, key, value } => {\n                write!(f, \"Duplicate key '{}' = '{}' in table '{}'\", key, value, table)\n            }\n            DatabaseError::TransactionFailed { reason, rollback_successful } => {\n                if *rollback_successful {\n                    write!(f, \"Transaction failed: {} (successfully rolled back)\", reason)\n                } else {\n                    write!(f, \"Transaction failed: {} (rollback also failed!)\", reason)\n                }\n            }\n            DatabaseError::PermissionDenied { user, operation, resource } => {\n                write!(f, \"User '{}' denied permission to '{}' on resource '{}'\", user, operation, resource)\n            }\n            DatabaseError::DataValidationError { field, value, constraint } => {\n                write!(f, \"Validation failed for field '{}': value '{}' violates constraint '{}'\", field, value, constraint)\n            }\n        }\n    }\n}\n\n// Implementing Error trait for proper error handling\nimpl Error for DatabaseError {\n    fn source(&self) -> Option<&(dyn Error + 'static)> {\n        // Most variants don't have underlying errors in this simplified example\n        None\n    }\n    \n    fn description(&self) -> &str {\n        match self {\n            DatabaseError::ConnectionFailed { .. } => \"database connection failed\",\n            DatabaseError::QueryError { .. } => \"database query error\",\n            DatabaseError::RecordNotFound { .. } => \"record not found\",\n            DatabaseError::DuplicateKey { .. } => \"duplicate key error\",\n            DatabaseError::TransactionFailed { .. } => \"transaction failed\",\n            DatabaseError::PermissionDenied { .. } => \"permission denied\",\n            DatabaseError::DataValidationError { .. } => \"data validation error\",\n        }\n    }\n}\n\n// Application-level error that can contain multiple error types\n#[derive(Debug)]\nenum AppError {\n    Database(DatabaseError),\n    Io(io::Error),\n    Parse(ParseIntError),\n    Utf8(Utf8Error),\n    Network {\n        url: String,\n        status_code: Option<u16>,\n        message: String,\n    },\n    Configuration {\n        file: String,\n        line: usize,\n        issue: String,\n    },\n    Business {\n        code: String,\n        message: String,\n        severity: ErrorSeverity,\n    },\n    Authentication {\n        user_id: Option<String>,\n        reason: AuthFailureReason,\n    },\n    RateLimit {\n        resource: String,\n        limit: u32,\n        reset_time: u64,\n    },\n}\n\n#[derive(Debug, Clone, PartialEq)]\nenum ErrorSeverity {\n    Low,\n    Medium,\n    High,\n    Critical,\n}\n\n#[derive(Debug, Clone, PartialEq)]\nenum AuthFailureReason {\n    InvalidCredentials,\n    AccountLocked,\n    TokenExpired,\n    InsufficientPermissions,\n    TwoFactorRequired,\n}\n\nimpl fmt::Display for AppError {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        match self {\n            AppError::Database(err) => write!(f, \"Database error: {}\", err),\n            AppError::Io(err) => write!(f, \"I/O error: {}\", err),\n            AppError::Parse(err) => write!(f, \"Parse error: {}\", err),\n            AppError::Utf8(err) => write!(f, \"UTF-8 error: {}\", err),\n            AppError::Network { url, status_code, message } => {\n                match status_code {\n                    Some(code) => write!(f, \"Network error ({}): {} - {}\", code, message, url),\n                    None => write!(f, \"Network error: {} - {}\", message, url),\n                }\n            }\n            AppError::Configuration { file, line, issue } => {\n                write!(f, \"Configuration error in {} at line {}: {}\", file, line, issue)\n            }\n            AppError::Business { code, message, severity } => {\n                write!(f, \"Business error [{:?}] {}: {}\", severity, code, message)\n            }\n            AppError::Authentication { user_id, reason } => {\n                match user_id {\n                    Some(id) => write!(f, \"Authentication failed for user {}: {:?}\", id, reason),\n                    None => write!(f, \"Authentication failed: {:?}\", reason),\n                }\n            }\n            AppError::RateLimit { resource, limit, reset_time } => {\n                write!(f, \"Rate limit exceeded for {}: {} requests/hour, resets at {}\", \n                       resource, limit, reset_time)\n            }\n        }\n    }\n}\n\nimpl Error for AppError {\n    fn source(&self) -> Option<&(dyn Error + 'static)> {\n        match self {\n            AppError::Database(err) => Some(err),\n            AppError::Io(err) => Some(err),\n            AppError::Parse(err) => Some(err),\n            AppError::Utf8(err) => Some(err),\n            _ => None,\n        }\n    }\n}\n\n// Implementing From traits for easy error conversion\nimpl From<DatabaseError> for AppError {\n    fn from(err: DatabaseError) -> Self {\n        AppError::Database(err)\n    }\n}\n\nimpl From<io::Error> for AppError {\n    fn from(err: io::Error) -> Self {\n        AppError::Io(err)\n    }\n}\n\nimpl From<ParseIntError> for AppError {\n    fn from(err: ParseIntError) -> Self {\n        AppError::Parse(err)\n    }\n}\n\nimpl From<Utf8Error> for AppError {\n    fn from(err: Utf8Error) -> Self {\n        AppError::Utf8(err)\n    }\n}\n\n// Result type aliases for cleaner code\ntype DatabaseResult<T> = Result<T, DatabaseError>;\ntype AppResult<T> = Result<T, AppError>;\n\nfn main() {\n    println!(\"=== Database Error Examples ===\");\n    \n    // Simulating various database errors\n    let db_errors = vec![\n        DatabaseError::ConnectionFailed {\n            host: \"localhost\".to_string(),\n            port: 5432,\n            underlying_error: \"Connection refused\".to_string(),\n        },\n        DatabaseError::QueryError {\n            query: \"SELECT * FROM users WHERE id = $1\".to_string(),\n            error_code: 1062,\n            message: \"Syntax error\".to_string(),\n        },\n        DatabaseError::RecordNotFound {\n            table: \"users\".to_string(),\n            id: \"12345\".to_string(),\n        },\n        DatabaseError::DuplicateKey {\n            table: \"users\".to_string(),\n            key: \"email\".to_string(),\n            value: \"user@example.com\".to_string(),\n        },\n        DatabaseError::PermissionDenied {\n            user: \"readonly_user\".to_string(),\n            operation: \"DELETE\".to_string(),\n            resource: \"users\".to_string(),\n        },\n    ];\n    \n    for error in &db_errors {\n        println!(\"\u274c {}\", error);\n        println!(\"   Type: {}\", error.description());\n        \n        // Pattern matching on error types for specific handling\n        match error {\n            DatabaseError::ConnectionFailed { host, port, .. } => {\n                println!(\"   \ud83d\udd27 Retry connection to {}:{}\", host, port);\n            }\n            DatabaseError::RecordNotFound { table, id } => {\n                println!(\"   \ud83d\udccb Log missing record: {} in {}\", id, table);\n            }\n            DatabaseError::PermissionDenied { user, operation, .. } => {\n                println!(\"   \ud83d\udd12 Audit security violation: {} attempted {}\", user, operation);\n            }\n            _ => println!(\"   \u2139\ufe0f  Standard error handling\"),\n        }\n        println!();\n    }\n    \n    println!(\"=== Application Error Composition ===\");\n    \n    // Function that can produce various error types\n    fn process_user_data(user_id: &str) -> AppResult<String> {\n        // Simulate parsing user ID\n        let id: u32 = user_id.parse()?; // ParseIntError -> AppError\n        \n        // Simulate database lookup\n        if id == 999 {\n            return Err(DatabaseError::RecordNotFound {\n                table: \"users\".to_string(),\n                id: user_id.to_string(),\n            }.into()); // DatabaseError -> AppError\n        }\n        \n        // Simulate business logic error\n        if id < 100 {\n            return Err(AppError::Business {\n                code: \"INVALID_USER_ID\".to_string(),\n                message: \"User ID must be 100 or greater\".to_string(),\n                severity: ErrorSeverity::Medium,\n            });\n        }\n        \n        Ok(format!(\"User data for ID {}\", id))\n    }\n    \n    let test_ids = [\"123\", \"50\", \"invalid\", \"999\", \"12345\"];\n    \n    for test_id in &test_ids {\n        match process_user_data(test_id) {\n            Ok(data) => println!(\"\u2705 Success: {}\", data),\n            Err(err) => {\n                println!(\"\u274c Error processing '{}': {}\", test_id, err);\n                \n                // Error chain inspection\n                let mut source = err.source();\n                let mut depth = 1;\n                while let Some(err) = source {\n                    println!(\"   {}\u2514\u2500 Caused by: {}\", \"  \".repeat(depth), err);\n                    source = err.source();\n                    depth += 1;\n                }\n                \n                // Specific error handling based on type\n                match &err {\n                    AppError::Parse(_) => println!(\"   \ud83d\udca1 Suggestion: Check input format\"),\n                    AppError::Database(DatabaseError::RecordNotFound { .. }) => {\n                        println!(\"   \ud83d\udca1 Suggestion: Create new user record\")\n                    }\n                    AppError::Business { severity: ErrorSeverity::Critical, .. } => {\n                        println!(\"   \ud83d\udea8 Alert: Critical business error requires immediate attention\")\n                    }\n                    _ => println!(\"   \u2139\ufe0f  Standard error handling\"),\n                }\n            }\n        }\n        println!();\n    }\n    \n    println!(\"=== Error Recovery Patterns ===\");\n    \n    // Function demonstrating error recovery\n    fn robust_operation() -> AppResult<String> {\n        // Try primary operation\n        match primary_operation() {\n            Ok(result) => Ok(result),\n            Err(AppError::Network { .. }) => {\n                println!(\"Primary operation failed, trying fallback...\");\n                fallback_operation()\n            }\n            Err(AppError::RateLimit { reset_time, .. }) => {\n                println!(\"Rate limited, scheduling retry at {}\", reset_time);\n                Err(AppError::RateLimit {\n                    resource: \"api\".to_string(),\n                    limit: 100,\n                    reset_time: *reset_time,\n                })\n            }\n            Err(other) => Err(other), // Propagate other errors\n        }\n    }\n    \n    fn primary_operation() -> AppResult<String> {\n        Err(AppError::Network {\n            url: \"https://api.primary.com\".to_string(),\n            status_code: Some(503),\n            message: \"Service temporarily unavailable\".to_string(),\n        })\n    }\n    \n    fn fallback_operation() -> AppResult<String> {\n        Ok(\"Fallback operation successful\".to_string())\n    }\n    \n    match robust_operation() {\n        Ok(result) => println!(\"\u2705 Operation result: {}\", result),\n        Err(err) => println!(\"\u274c Operation failed: {}\", err),\n    }\n    \n    println!(\"\\n=== Error Design Best Practices ===\");\n    println!(\"\u2705 Use enums to represent different error categories\");\n    println!(\"\u2705 Include relevant context data in error variants\");\n    println!(\"\u2705 Implement Display for user-friendly messages\");\n    println!(\"\u2705 Implement Error trait for standard error handling\");\n    println!(\"\u2705 Use From traits for automatic error conversion\");\n    println!(\"\u2705 Create type aliases for common Result types\");\n    println!(\"\u2705 Pattern match on errors for specific handling\");\n    println!(\"\u2705 Chain errors to preserve context\");\n    println!(\"\u2705 Design errors for both humans and machines\");\n    println!(\"\u2705 Include error codes for programmatic handling\");\n}\n\n// Helper functions for error categorization\nimpl DatabaseError {\n    fn is_retryable(&self) -> bool {\n        match self {\n            DatabaseError::ConnectionFailed { .. } => true,\n            DatabaseError::TransactionFailed { .. } => true,\n            DatabaseError::QueryError { error_code, .. } => *error_code >= 500,\n            _ => false,\n        }\n    }\n    \n    fn severity(&self) -> ErrorSeverity {\n        match self {\n            DatabaseError::ConnectionFailed { .. } => ErrorSeverity::High,\n            DatabaseError::TransactionFailed { rollback_successful: false, .. } => ErrorSeverity::Critical,\n            DatabaseError::PermissionDenied { .. } => ErrorSeverity::High,\n            DatabaseError::DataValidationError { .. } => ErrorSeverity::Medium,\n            _ => ErrorSeverity::Low,\n        }\n    }\n}\n\n// Key concepts:\n// - Enums provide structured, type-safe error representation\n// - Associated data in variants captures error context\n// - Display trait provides user-friendly error messages\n// - Error trait enables standard error handling patterns\n// - From traits allow automatic error type conversion\n// - Pattern matching enables specific error handling\n// - Error chaining preserves context through call stack\n// - Custom error types improve debugging and monitoring\n// - Well-designed errors aid both development and operations\n```",
    "tags": [
      "custom-errors",
      "error-handling",
      "enums",
      "error-trait",
      "from-trait",
      "error-chaining",
      "result-types",
      "error-recovery"
    ],
    "instruction": "Design comprehensive error types using enums with proper error trait implementations"
  },
  {
    "output": "```rust\n// This example demonstrates match ergonomics and reference patterns\n// Match ergonomics make pattern matching more ergonomic by automatically dereferencing\n\nuse std::collections::HashMap;\n\n#[derive(Debug, Clone, PartialEq)]\nstruct Person {\n    name: String,\n    age: u32,\n    city: String,\n}\n\n#[derive(Debug, Clone, PartialEq)]\nenum Status {\n    Active,\n    Inactive,\n    Pending { since: u64 },\n    Suspended { reason: String, until: Option<u64> },\n}\n\n#[derive(Debug, Clone)]\nstruct User {\n    id: u32,\n    person: Person,\n    status: Status,\n    preferences: UserPreferences,\n}\n\n#[derive(Debug, Clone)]\nstruct UserPreferences {\n    theme: String,\n    notifications: bool,\n    language: Option<String>,\n}\n\nfn main() {\n    println!(\"=== Basic Reference Patterns ===\");\n    \n    let numbers = vec![1, 2, 3, 4, 5];\n    \n    // Traditional way - explicit referencing\n    for number in &numbers {\n        match number {\n            &1 => println!(\"Found one (explicit &)\"),\n            &n if n > &3 => println!(\"Found {} > 3 (explicit &)\", n),\n            _ => println!(\"Other number: {}\", number),\n        }\n    }\n    \n    println!();\n    \n    // Match ergonomics - automatic dereferencing (Rust 2018+)\n    for number in &numbers {\n        match number {\n            1 => println!(\"Found one (automatic deref)\"),\n            n if *n > 3 => println!(\"Found {} > 3 (automatic deref)\", n),\n            _ => println!(\"Other number: {}\", number),\n        }\n    }\n    \n    println!();\n    \n    // Even more ergonomic with direct matching\n    for &number in &numbers {\n        match number {\n            1 => println!(\"Found one (destructured in for loop)\"),\n            n if n > 3 => println!(\"Found {} > 3 (destructured)\", n),\n            _ => println!(\"Other number: {}\", number),\n        }\n    }\n    \n    println!(\"\\n=== Option Reference Patterns ===\");\n    \n    let maybe_numbers = vec![Some(1), None, Some(3), Some(4), None];\n    \n    // Traditional way with explicit references\n    for opt in &maybe_numbers {\n        match opt {\n            &Some(ref n) => println!(\"Traditional: Found number {}\", n),\n            &None => println!(\"Traditional: Found None\"),\n        }\n    }\n    \n    println!();\n    \n    // Match ergonomics - much cleaner\n    for opt in &maybe_numbers {\n        match opt {\n            Some(n) => println!(\"Ergonomic: Found number {}\", n),\n            None => println!(\"Ergonomic: Found None\"),\n        }\n    }\n    \n    println!();\n    \n    // Destructuring in the iterator\n    for opt in &maybe_numbers {\n        match opt {\n            Some(n) if *n > 2 => println!(\"Large number: {}\", n),\n            Some(n) => println!(\"Small number: {}\", n),\n            None => println!(\"No number\"),\n        }\n    }\n    \n    println!(\"\\n=== Struct Reference Patterns ===\");\n    \n    let person = Person {\n        name: \"Alice\".to_string(),\n        age: 30,\n        city: \"New York\".to_string(),\n    };\n    \n    // Matching against a reference to struct\n    match &person {\n        Person { name, age, city } => {\n            println!(\"Person: {} is {} years old in {}\", name, age, city);\n        }\n    }\n    \n    // Pattern matching with guards on references\n    match &person {\n        Person { age, .. } if *age >= 30 => {\n            println!(\"Adult: {}\", person.name);\n        }\n        Person { age, .. } if *age >= 18 => {\n            println!(\"Young adult: {}\", person.name);\n        }\n        _ => {\n            println!(\"Minor: {}\", person.name);\n        }\n    }\n    \n    // Multiple people\n    let people = vec![\n        Person { name: \"Alice\".to_string(), age: 30, city: \"NYC\".to_string() },\n        Person { name: \"Bob\".to_string(), age: 25, city: \"LA\".to_string() },\n        Person { name: \"Charlie\".to_string(), age: 35, city: \"Chicago\".to_string() },\n    ];\n    \n    println!(\"\\nAnalyzing people:\");\n    for person in &people {\n        match person {\n            Person { name, age: 30..=40, city } => {\n                println!(\"{} is in their 30s, living in {}\", name, city);\n            }\n            Person { name, age: 20..=29, city } => {\n                println!(\"{} is in their 20s, living in {}\", name, city);\n            }\n            Person { name, age, city } => {\n                println!(\"{} is {} years old, living in {}\", name, age, city);\n            }\n        }\n    }\n    \n    println!(\"\\n=== Complex Nested Patterns ===\");\n    \n    let users = vec![\n        User {\n            id: 1,\n            person: Person {\n                name: \"Alice\".to_string(),\n                age: 30,\n                city: \"NYC\".to_string(),\n            },\n            status: Status::Active,\n            preferences: UserPreferences {\n                theme: \"dark\".to_string(),\n                notifications: true,\n                language: Some(\"en\".to_string()),\n            },\n        },\n        User {\n            id: 2,\n            person: Person {\n                name: \"Bob\".to_string(),\n                age: 25,\n                city: \"LA\".to_string(),\n            },\n            status: Status::Suspended {\n                reason: \"Policy violation\".to_string(),\n                until: Some(1234567890),\n            },\n            preferences: UserPreferences {\n                theme: \"light\".to_string(),\n                notifications: false,\n                language: None,\n            },\n        },\n        User {\n            id: 3,\n            person: Person {\n                name: \"Charlie\".to_string(),\n                age: 35,\n                city: \"Chicago\".to_string(),\n            },\n            status: Status::Pending { since: 1234567800 },\n            preferences: UserPreferences {\n                theme: \"dark\".to_string(),\n                notifications: true,\n                language: Some(\"es\".to_string()),\n            },\n        },\n    ];\n    \n    // Complex nested pattern matching with references\n    for user in &users {\n        match user {\n            User {\n                id,\n                person: Person { name, age, .. },\n                status: Status::Active,\n                preferences: UserPreferences { theme, notifications: true, .. },\n            } => {\n                println!(\"Active user {} (ID: {}, age: {}) prefers {} theme with notifications\", \n                        name, id, age, theme);\n            }\n            \n            User {\n                person: Person { name, .. },\n                status: Status::Suspended { reason, until: Some(until_time) },\n                ..\n            } => {\n                println!(\"User {} suspended: {} (until {})\", name, reason, until_time);\n            }\n            \n            User {\n                person: Person { name, .. },\n                status: Status::Pending { since },\n                ..\n            } => {\n                println!(\"User {} pending since {}\", name, since);\n            }\n            \n            _ => println!(\"Other user status\"),\n        }\n    }\n    \n    println!(\"\\n=== HashMap Reference Patterns ===\");\n    \n    let mut user_scores: HashMap<String, u32> = HashMap::new();\n    user_scores.insert(\"Alice\".to_string(), 95);\n    user_scores.insert(\"Bob\".to_string(), 87);\n    user_scores.insert(\"Charlie\".to_string(), 92);\n    \n    // Pattern matching on HashMap entries\n    for (name, score) in &user_scores {\n        match score {\n            90..=100 => println!(\"{} has an excellent score: {}\", name, score),\n            80..=89 => println!(\"{} has a good score: {}\", name, score),\n            score => println!(\"{} has a score of {}\", name, score),\n        }\n    }\n    \n    // Lookup with pattern matching\n    let names_to_check = [\"Alice\", \"David\", \"Bob\"];\n    \n    for name in &names_to_check {\n        match user_scores.get(name) {\n            Some(score) if *score >= 90 => {\n                println!(\"{} found with high score: {}\", name, score);\n            }\n            Some(score) => {\n                println!(\"{} found with score: {}\", name, score);\n            }\n            None => {\n                println!(\"{} not found in scores\", name);\n            }\n        }\n    }\n    \n    println!(\"\\n=== Iterator Reference Patterns ===\");\n    \n    let words = vec![\"hello\", \"world\", \"rust\", \"programming\", \"language\"];\n    \n    // Filter with pattern matching\n    let long_words: Vec<&str> = words\n        .iter()\n        .filter_map(|&word| match word.len() {\n            6..=10 => Some(word),\n            _ => None,\n        })\n        .collect();\n    \n    println!(\"Long words (6-10 chars): {:?}\", long_words);\n    \n    // Complex filtering with multiple conditions\n    let special_words: Vec<&str> = words\n        .iter()\n        .filter_map(|word| match word {\n            w if w.starts_with('r') && w.len() > 4 => Some(*w),\n            w if w.contains('o') && w.len() == 5 => Some(*w),\n            _ => None,\n        })\n        .collect();\n    \n    println!(\"Special words: {:?}\", special_words);\n    \n    println!(\"\\n=== Reference Patterns with Slices ===\");\n    \n    let data = vec![1, 2, 3, 4, 5, 6, 7, 8, 9, 10];\n    \n    // Matching on slice references\n    fn analyze_slice(slice: &[i32]) -> String {\n        match slice {\n            [] => \"Empty slice\".to_string(),\n            [single] => format!(\"Single element: {}\", single),\n            [first, rest @ ..] if rest.len() == 1 => {\n                format!(\"Two elements: {} and {}\", first, rest[0])\n            }\n            [first, .., last] if first == last => {\n                format!(\"Same first and last: {} (length: {})\", first, slice.len())\n            }\n            [first, second, .., last] => {\n                format!(\"Starts: {}, {}, ..., ends: {} (length: {})\", \n                       first, second, last, slice.len())\n            }\n        }\n    }\n    \n    let test_slices = [\n        &data[..0],     // Empty\n        &data[..1],     // Single\n        &data[..2],     // Two elements\n        &data[..],      // Full slice\n        &[5, 1, 2, 3, 5], // Same first and last\n    ];\n    \n    for slice in &test_slices {\n        println!(\"{:?} -> {}\", slice, analyze_slice(slice));\n    }\n    \n    println!(\"\\n=== Advanced Reference Ergonomics ===\");\n    \n    // Nested Options and Results\n    let nested_data: Vec<Option<Result<i32, String>>> = vec![\n        Some(Ok(42)),\n        Some(Err(\"Error\".to_string())),\n        None,\n        Some(Ok(100)),\n    ];\n    \n    for item in &nested_data {\n        match item {\n            Some(Ok(n)) if *n > 50 => println!(\"Large success: {}\", n),\n            Some(Ok(n)) => println!(\"Small success: {}\", n),\n            Some(Err(e)) => println!(\"Error: {}\", e),\n            None => println!(\"No data\"),\n        }\n    }\n    \n    // Complex struct with references\n    #[derive(Debug)]\n    struct Config<'a> {\n        name: &'a str,\n        values: Vec<&'a str>,\n        enabled: bool,\n    }\n    \n    let configs = vec![\n        Config {\n            name: \"database\",\n            values: vec![\"localhost\", \"5432\"],\n            enabled: true,\n        },\n        Config {\n            name: \"cache\",\n            values: vec![\"redis\", \"6379\"],\n            enabled: false,\n        },\n        Config {\n            name: \"api\",\n            values: vec![\"0.0.0.0\", \"8080\", \"https\"],\n            enabled: true,\n        },\n    ];\n    \n    println!(\"\\nConfiguration analysis:\");\n    for config in &configs {\n        match config {\n            Config { name, values, enabled: true } if values.len() >= 3 => {\n                println!(\"{} is enabled with {} values: {:?}\", name, values.len(), values);\n            }\n            Config { name, enabled: true, .. } => {\n                println!(\"{} is enabled\", name);\n            }\n            Config { name, enabled: false, .. } => {\n                println!(\"{} is disabled\", name);\n            }\n        }\n    }\n    \n    println!(\"\\n=== Pattern Matching with Mutable References ===\");\n    \n    let mut scores = vec![85, 92, 78, 95, 88];\n    \n    // Modify elements based on patterns\n    for score in &mut scores {\n        match score {\n            s if *s >= 90 => *s += 5,  // Bonus for high scores\n            s if *s < 80 => *s += 10,  // Boost for low scores\n            _ => {},                   // No change for medium scores\n        }\n    }\n    \n    println!(\"Adjusted scores: {:?}\", scores);\n    \n    // Conditional modifications\n    let mut user_list = vec![\n        (\"Alice\", 30, true),\n        (\"Bob\", 25, false),\n        (\"Charlie\", 35, true),\n    ];\n    \n    for user in &mut user_list {\n        match user {\n            (name, age, active) if *age >= 30 && *active => {\n                println!(\"{} is a senior active user\", name);\n            }\n            (name, _, active) if !*active => {\n                println!(\"{} is inactive, activating...\", name);\n                *active = true;\n            }\n            _ => {},\n        }\n    }\n    \n    println!(\"Updated user list: {:?}\", user_list);\n    \n    println!(\"\\n=== Match Ergonomics Benefits ===\");\n    println!(\"\u2705 Automatic dereferencing reduces boilerplate\");\n    println!(\"\u2705 More readable pattern matching\");\n    println!(\"\u2705 Consistent behavior across reference types\");\n    println!(\"\u2705 Works with nested structures\");\n    println!(\"\u2705 Reduces need for explicit ref/& patterns\");\n    println!(\"\u2705 Maintains zero-cost abstraction\");\n    println!(\"\u2705 Backwards compatible with explicit patterns\");\n}\n\n// Helper function demonstrating reference patterns in function parameters\nfn process_optional_data(data: &Option<Vec<i32>>) -> String {\n    match data {\n        Some(vec) if vec.is_empty() => \"Empty vector\".to_string(),\n        Some(vec) if vec.len() == 1 => format!(\"Single value: {}\", vec[0]),\n        Some(vec) => format!(\"Vector with {} elements: {:?}\", vec.len(), vec),\n        None => \"No data\".to_string(),\n    }\n}\n\n// Function with complex pattern matching on references\nfn analyze_user_status(user: &User) -> String {\n    match user {\n        User {\n            person: Person { age, .. },\n            status: Status::Active,\n            preferences: UserPreferences { notifications: true, .. },\n        } if *age >= 30 => \"Senior active user with notifications\".to_string(),\n        \n        User {\n            status: Status::Suspended { reason, .. },\n            ..\n        } => format!(\"Suspended user: {}\", reason),\n        \n        User {\n            person: Person { name, .. },\n            status: Status::Pending { .. },\n            ..\n        } => format!(\"User {} is pending approval\", name),\n        \n        _ => \"Regular user\".to_string(),\n    }\n}\n\n// Key concepts:\n// - Match ergonomics automatically dereference patterns in Rust 2018+\n// - Reduces need for explicit & and ref patterns\n// - Works seamlessly with nested structures\n// - Maintains zero-cost abstraction guarantees\n// - Pattern guards work naturally with dereferenced values\n// - Mutable references can be pattern matched and modified\n// - Slice patterns work ergonomically with references\n// - Iterator patterns benefit from automatic dereferencing\n// - Complex nested patterns become more readable\n```",
    "tags": [
      "match-ergonomics",
      "reference-patterns",
      "automatic-deref",
      "pattern-matching",
      "rust-2018",
      "ergonomic",
      "references",
      "destructuring"
    ],
    "instruction": "Demonstrate match ergonomics and reference patterns in Rust"
  },
  {
    "output": "```rust\n// This example demonstrates generic functions and structs in Rust\n// Generics enable code reuse while maintaining type safety and performance\n\nuse std::fmt::Display;\nuse std::cmp::PartialOrd;\n\n// Basic generic struct\n#[derive(Debug, Clone, PartialEq)]\nstruct Point<T> {\n    x: T,\n    y: T,\n}\n\n// Implementation block for all types T\nimpl<T> Point<T> {\n    fn new(x: T, y: T) -> Self {\n        Point { x, y }\n    }\n    \n    // Method that consumes self\n    fn into_tuple(self) -> (T, T) {\n        (self.x, self.y)\n    }\n    \n    // Method that borrows self\n    fn as_tuple(&self) -> (&T, &T) {\n        (&self.x, &self.y)\n    }\n}\n\n// Implementation with trait bounds\nimpl<T> Point<T>\nwhere\n    T: Copy + std::ops::Add<Output = T>,\n{\n    fn distance_from_origin(&self) -> T\n    where\n        T: std::ops::Mul<Output = T>,\n    {\n        self.x * self.x + self.y * self.y\n    }\n}\n\n// Implementation for specific types\nimpl Point<f64> {\n    fn euclidean_distance(&self, other: &Point<f64>) -> f64 {\n        let dx = self.x - other.x;\n        let dy = self.y - other.y;\n        (dx * dx + dy * dy).sqrt()\n    }\n    \n    fn to_polar(&self) -> (f64, f64) {\n        let r = (self.x * self.x + self.y * self.y).sqrt();\n        let theta = self.y.atan2(self.x);\n        (r, theta)\n    }\n}\n\n// Generic struct with multiple type parameters\n#[derive(Debug, Clone)]\nstruct Pair<T, U> {\n    first: T,\n    second: U,\n}\n\nimpl<T, U> Pair<T, U> {\n    fn new(first: T, second: U) -> Self {\n        Pair { first, second }\n    }\n    \n    fn swap(self) -> Pair<U, T> {\n        Pair {\n            first: self.second,\n            second: self.first,\n        }\n    }\n    \n    fn map_first<V>(self, f: impl FnOnce(T) -> V) -> Pair<V, U> {\n        Pair {\n            first: f(self.first),\n            second: self.second,\n        }\n    }\n    \n    fn map_second<V>(self, f: impl FnOnce(U) -> V) -> Pair<T, V> {\n        Pair {\n            first: self.first,\n            second: f(self.second),\n        }\n    }\n}\n\n// Generic container with lifetime parameter\n#[derive(Debug)]\nstruct Container<'a, T> {\n    items: Vec<&'a T>,\n    name: &'a str,\n}\n\nimpl<'a, T> Container<'a, T> {\n    fn new(name: &'a str) -> Self {\n        Container {\n            items: Vec::new(),\n            name,\n        }\n    }\n    \n    fn add(&mut self, item: &'a T) {\n        self.items.push(item);\n    }\n    \n    fn len(&self) -> usize {\n        self.items.len()\n    }\n    \n    fn get(&self, index: usize) -> Option<&T> {\n        self.items.get(index).copied()\n    }\n}\n\n// Generic enum\n#[derive(Debug, Clone, PartialEq)]\nenum Either<L, R> {\n    Left(L),\n    Right(R),\n}\n\nimpl<L, R> Either<L, R> {\n    fn is_left(&self) -> bool {\n        matches!(self, Either::Left(_))\n    }\n    \n    fn is_right(&self) -> bool {\n        matches!(self, Either::Right(_))\n    }\n    \n    fn left(self) -> Option<L> {\n        match self {\n            Either::Left(l) => Some(l),\n            Either::Right(_) => None,\n        }\n    }\n    \n    fn right(self) -> Option<R> {\n        match self {\n            Either::Left(_) => None,\n            Either::Right(r) => Some(r),\n        }\n    }\n    \n    fn map_left<T>(self, f: impl FnOnce(L) -> T) -> Either<T, R> {\n        match self {\n            Either::Left(l) => Either::Left(f(l)),\n            Either::Right(r) => Either::Right(r),\n        }\n    }\n    \n    fn map_right<T>(self, f: impl FnOnce(R) -> T) -> Either<L, T> {\n        match self {\n            Either::Left(l) => Either::Left(l),\n            Either::Right(r) => Either::Right(f(r)),\n        }\n    }\n}\n\n// Generic functions\nfn max<T>(a: T, b: T) -> T\nwhere\n    T: PartialOrd,\n{\n    if a >= b { a } else { b }\n}\n\nfn min<T>(a: T, b: T) -> T\nwhere\n    T: PartialOrd,\n{\n    if a <= b { a } else { b }\n}\n\n// Generic function with multiple type parameters\nfn combine<T, U, V>(first: T, second: U, combiner: impl FnOnce(T, U) -> V) -> V {\n    combiner(first, second)\n}\n\n// Generic function that works with collections\nfn find_max<T>(items: &[T]) -> Option<&T>\nwhere\n    T: PartialOrd,\n{\n    items.iter().max()\n}\n\nfn filter_and_collect<T, F>(items: Vec<T>, predicate: F) -> Vec<T>\nwhere\n    F: Fn(&T) -> bool,\n{\n    items.into_iter().filter(|item| predicate(item)).collect()\n}\n\n// Function with complex generic constraints\nfn print_and_return<T>(value: T) -> T\nwhere\n    T: Display + Clone,\n{\n    println!(\"Value: {}\", value);\n    value.clone()\n}\n\n// Generic function with lifetime parameters\nfn longest<'a>(x: &'a str, y: &'a str) -> &'a str {\n    if x.len() > y.len() {\n        x\n    } else {\n        y\n    }\n}\n\n// Function that returns a generic type\nfn create_pair<T: Clone>(value: T) -> Pair<T, T> {\n    Pair::new(value.clone(), value)\n}\n\n// Generic function with default type parameters (using associated types pattern)\ntrait DefaultValue {\n    type Output;\n    fn default_value() -> Self::Output;\n}\n\nstruct IntDefault;\nimpl DefaultValue for IntDefault {\n    type Output = i32;\n    fn default_value() -> Self::Output { 0 }\n}\n\nstruct StringDefault;\nimpl DefaultValue for StringDefault {\n    type Output = String;\n    fn default_value() -> Self::Output { String::new() }\n}\n\nfn get_default<T: DefaultValue>() -> T::Output {\n    T::default_value()\n}\n\nfn main() {\n    println!(\"=== Generic Structs ===\");\n    \n    // Points with different types\n    let int_point = Point::new(3, 4);\n    let float_point = Point::new(3.0, 4.0);\n    let string_point = Point::new(\"hello\".to_string(), \"world\".to_string());\n    \n    println!(\"Integer point: {:?}\", int_point);\n    println!(\"Float point: {:?}\", float_point);\n    println!(\"String point: {:?}\", string_point);\n    \n    // Using generic methods\n    let (x, y) = int_point.as_tuple();\n    println!(\"Point coordinates: ({}, {})\", x, y);\n    \n    let tuple = float_point.clone().into_tuple();\n    println!(\"Point as tuple: {:?}\", tuple);\n    \n    // Type-specific methods\n    let point1 = Point::new(0.0, 0.0);\n    let point2 = Point::new(3.0, 4.0);\n    let distance = point1.euclidean_distance(&point2);\n    println!(\"Distance between {:?} and {:?}: {:.2}\", point1, point2, distance);\n    \n    let (r, theta) = point2.to_polar();\n    println!(\"Point {:?} in polar coordinates: r={:.2}, \u03b8={:.2}\", point2, r, theta);\n    \n    println!(\"\\n=== Generic Pairs ===\");\n    \n    // Pairs with different type combinations\n    let name_age = Pair::new(\"Alice\".to_string(), 30);\n    let coordinates = Pair::new(10.5, 20.3);\n    let mixed = Pair::new(42, \"answer\".to_string());\n    \n    println!(\"Name and age: {:?}\", name_age);\n    println!(\"Coordinates: {:?}\", coordinates);\n    println!(\"Mixed pair: {:?}\", mixed);\n    \n    // Using pair methods\n    let swapped = mixed.clone().swap();\n    println!(\"Swapped pair: {:?}\", swapped);\n    \n    let mapped_first = name_age.clone().map_first(|name| name.len());\n    println!(\"Mapped first (name length): {:?}\", mapped_first);\n    \n    let mapped_second = name_age.map_second(|age| age * 12); // months\n    println!(\"Mapped second (age in months): {:?}\", mapped_second);\n    \n    println!(\"\\n=== Generic Container ===\");\n    \n    let numbers = vec![1, 2, 3, 4, 5];\n    let mut number_container = Container::new(\"Numbers\");\n    \n    for num in &numbers {\n        number_container.add(num);\n    }\n    \n    println!(\"Container '{}' has {} items\", number_container.name, number_container.len());\n    \n    for i in 0..number_container.len() {\n        if let Some(item) = number_container.get(i) {\n            println!(\"  Item {}: {}\", i, item);\n        }\n    }\n    \n    println!(\"\\n=== Generic Either Enum ===\");\n    \n    let values: Vec<Either<i32, String>> = vec![\n        Either::Left(42),\n        Either::Right(\"hello\".to_string()),\n        Either::Left(100),\n        Either::Right(\"world\".to_string()),\n    ];\n    \n    for (i, value) in values.iter().enumerate() {\n        match value {\n            Either::Left(num) => println!(\"Value {}: Left({})\", i, num),\n            Either::Right(text) => println!(\"Value {}: Right({})\", i, text),\n        }\n    }\n    \n    // Transform Either values\n    let transformed: Vec<Either<i32, usize>> = values\n        .into_iter()\n        .map(|either| either.map_right(|s| s.len()))\n        .collect();\n    \n    println!(\"\\nTransformed (string lengths):\");\n    for (i, value) in transformed.iter().enumerate() {\n        println!(\"  {}: {:?}\", i, value);\n    }\n    \n    println!(\"\\n=== Generic Functions ===\");\n    \n    // Using generic max/min functions\n    println!(\"Max of 5 and 10: {}\", max(5, 10));\n    println!(\"Min of 3.14 and 2.71: {}\", min(3.14, 2.71));\n    println!(\"Max of 'apple' and 'banana': {}\", max(\"apple\", \"banana\"));\n    \n    // Using combine function\n    let sum = combine(5, 10, |a, b| a + b);\n    let concat = combine(\"Hello, \".to_string(), \"World!\", |a, b| a + &b);\n    let pair = combine(1, \"one\", |num, text| Pair::new(num, text));\n    \n    println!(\"Combined sum: {}\", sum);\n    println!(\"Combined string: {}\", concat);\n    println!(\"Combined pair: {:?}\", pair);\n    \n    // Working with collections\n    let numbers = vec![1, 5, 3, 9, 2, 8, 4];\n    if let Some(max_num) = find_max(&numbers) {\n        println!(\"Maximum number: {}\", max_num);\n    }\n    \n    let words = vec![\"rust\", \"is\", \"awesome\", \"language\", \"for\", \"systems\"];\n    if let Some(longest_word) = find_max(&words) {\n        println!(\"Longest word: {}\", longest_word);\n    }\n    \n    // Filtering with generic functions\n    let even_numbers = filter_and_collect(numbers.clone(), |&x| x % 2 == 0);\n    let long_words = filter_and_collect(words.into_iter().collect(), |&w| w.len() > 3);\n    \n    println!(\"Even numbers: {:?}\", even_numbers);\n    println!(\"Long words: {:?}\", long_words);\n    \n    println!(\"\\n=== Generic Functions with Display ===\");\n    \n    let returned_int = print_and_return(42);\n    let returned_string = print_and_return(\"Hello, Generics!\".to_string());\n    let returned_float = print_and_return(3.14159);\n    \n    println!(\"Returned values: {}, {}, {}\", returned_int, returned_string, returned_float);\n    \n    println!(\"\\n=== Lifetime Parameters ===\");\n    \n    let str1 = \"short\";\n    let str2 = \"this is a longer string\";\n    let result = longest(str1, str2);\n    println!(\"Longest of '{}' and '{}': '{}'\", str1, str2, result);\n    \n    println!(\"\\n=== Default Values with Generics ===\");\n    \n    let default_int: i32 = get_default::<IntDefault>();\n    let default_string: String = get_default::<StringDefault>();\n    \n    println!(\"Default int: {}\", default_int);\n    println!(\"Default string: '{}'\", default_string);\n    \n    println!(\"\\n=== Creating Generic Types ===\");\n    \n    let int_pair = create_pair(42);\n    let string_pair = create_pair(\"hello\".to_string());\n    let bool_pair = create_pair(true);\n    \n    println!(\"Integer pair: {:?}\", int_pair);\n    println!(\"String pair: {:?}\", string_pair);\n    println!(\"Boolean pair: {:?}\", bool_pair);\n    \n    println!(\"\\n=== Complex Generic Operations ===\");\n    \n    // Chain generic operations\n    let result = vec![1, 2, 3, 4, 5]\n        .into_iter()\n        .map(|x| Point::new(x, x * 2))\n        .filter(|p| p.x > 2)\n        .map(|p| p.into_tuple())\n        .collect::<Vec<_>>();\n    \n    println!(\"Chained operations result: {:?}\", result);\n    \n    // Generic closure capture\n    let multiplier = 3;\n    let multiply_point = |p: Point<i32>| Point::new(p.x * multiplier, p.y * multiplier);\n    \n    let original = Point::new(2, 3);\n    let scaled = multiply_point(original);\n    println!(\"Scaled point: {:?}\", scaled);\n    \n    println!(\"\\n=== Type Inference Examples ===\");\n    \n    // Type inference with generics\n    let inferred_point = Point::new(1.5, 2.5); // f64 inferred\n    let inferred_pair = Pair::new(\"key\", 42);   // (&str, i32) inferred\n    \n    println!(\"Inferred point type (f64): {:?}\", inferred_point);\n    println!(\"Inferred pair type (&str, i32): {:?}\", inferred_pair);\n    \n    // Explicit type annotation when needed\n    let explicit_point: Point<f32> = Point::new(1.0, 2.0);\n    let explicit_vec: Vec<i32> = vec![];\n    \n    println!(\"Explicit f32 point: {:?}\", explicit_point);\n    println!(\"Explicit empty i32 vec length: {}\", explicit_vec.len());\n    \n    println!(\"\\n=== Generic Performance Notes ===\");\n    println!(\"\u2705 Generics are zero-cost abstractions\");\n    println!(\"\u2705 Monomorphization creates specialized versions at compile time\");\n    println!(\"\u2705 No runtime overhead compared to hand-written specialized code\");\n    println!(\"\u2705 Type safety enforced at compile time\");\n    println!(\"\u2705 Enables code reuse without sacrificing performance\");\n}\n\n// Advanced generic pattern: Generic wrapper\n#[derive(Debug, Clone)]\nstruct Wrapper<T> {\n    value: T,\n    metadata: String,\n}\n\nimpl<T> Wrapper<T> {\n    fn new(value: T, metadata: String) -> Self {\n        Wrapper { value, metadata }\n    }\n    \n    fn unwrap(self) -> T {\n        self.value\n    }\n    \n    fn map<U>(self, f: impl FnOnce(T) -> U) -> Wrapper<U> {\n        Wrapper {\n            value: f(self.value),\n            metadata: self.metadata,\n        }\n    }\n}\n\n// Generic trait implementation\nimpl<T: Display> Display for Wrapper<T> {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        write!(f, \"{}[{}]\", self.value, self.metadata)\n    }\n}\n\n// Key concepts:\n// - Generics enable writing code that works with multiple types\n// - Type parameters are specified in angle brackets <T, U, V>\n// - Trait bounds constrain what types can be used\n// - Monomorphization creates specialized code at compile time\n// - Generic functions and structs maintain type safety\n// - Zero-cost abstraction - no runtime overhead\n// - Type inference reduces the need for explicit type annotations\n// - Lifetime parameters can be combined with type parameters\n// - Generic implementations can be specialized for specific types\n```",
    "tags": [
      "generics",
      "type-parameters",
      "trait-bounds",
      "monomorphization",
      "zero-cost",
      "type-safety",
      "code-reuse",
      "type-inference"
    ],
    "instruction": "Demonstrate generic functions and structs with comprehensive examples"
  },
  {
    "output": "```rust\n// This example demonstrates trait bounds and where clauses for complex generic constraints\n// Trait bounds specify what capabilities a generic type must have\n\nuse std::fmt::{Debug, Display};\nuse std::ops::{Add, Mul, Sub};\nuse std::cmp::{PartialEq, PartialOrd, Ordering};\nuse std::iter::Sum;\nuse std::str::FromStr;\n\n// Basic trait bounds in struct definition\n#[derive(Debug, Clone)]\nstruct Calculator<T>\nwhere\n    T: Add<Output = T> + Sub<Output = T> + Mul<Output = T> + Copy + Debug,\n{\n    value: T,\n    history: Vec<T>,\n}\n\nimpl<T> Calculator<T>\nwhere\n    T: Add<Output = T> + Sub<Output = T> + Mul<Output = T> + Copy + Debug,\n{\n    fn new(initial: T) -> Self {\n        Calculator {\n            value: initial,\n            history: vec![initial],\n        }\n    }\n    \n    fn add(&mut self, other: T) -> &mut Self {\n        self.value = self.value + other;\n        self.history.push(self.value);\n        self\n    }\n    \n    fn subtract(&mut self, other: T) -> &mut Self {\n        self.value = self.value - other;\n        self.history.push(self.value);\n        self\n    }\n    \n    fn multiply(&mut self, other: T) -> &mut Self {\n        self.value = self.value * other;\n        self.history.push(self.value);\n        self\n    }\n    \n    fn get_value(&self) -> T {\n        self.value\n    }\n    \n    fn get_history(&self) -> &[T] {\n        &self.history\n    }\n}\n\n// Additional methods with more specific bounds\nimpl<T> Calculator<T>\nwhere\n    T: Add<Output = T> + Sub<Output = T> + Mul<Output = T> + Copy + Debug + Default + PartialEq,\n{\n    fn reset(&mut self) -> &mut Self {\n        self.value = T::default();\n        self.history.clear();\n        self.history.push(self.value);\n        self\n    }\n    \n    fn is_zero(&self) -> bool {\n        self.value == T::default()\n    }\n}\n\n// Trait bounds with Display for pretty printing\nimpl<T> Calculator<T>\nwhere\n    T: Add<Output = T> + Sub<Output = T> + Mul<Output = T> + Copy + Debug + Display,\n{\n    fn print_status(&self) {\n        println!(\"Calculator value: {}\", self.value);\n        print!(\"History: \");\n        for (i, &val) in self.history.iter().enumerate() {\n            if i > 0 { print!(\" -> \"); }\n            print!(\"{}\", val);\n        }\n        println!();\n    }\n}\n\n// Complex generic function with multiple trait bounds\nfn find_statistics<T>(data: &[T]) -> Option<Statistics<T>>\nwhere\n    T: Copy + PartialOrd + Add<Output = T> + Sub<Output = T> + Mul<Output = T> + Sum + Default + Debug,\n{\n    if data.is_empty() {\n        return None;\n    }\n    \n    let min = *data.iter().min()?;\n    let max = *data.iter().max()?;\n    let sum = data.iter().copied().sum::<T>();\n    \n    Some(Statistics { min, max, sum, count: data.len() })\n}\n\n#[derive(Debug, Clone)]\nstruct Statistics<T> {\n    min: T,\n    max: T,\n    sum: T,\n    count: usize,\n}\n\n// Generic function with where clause for complex bounds\nfn process_comparable_data<T, U>(input: T, processor: impl Fn(T) -> U) -> ProcessedData<U>\nwhere\n    T: Clone + Debug + PartialEq,\n    U: Display + Clone,\n{\n    let processed = processor(input.clone());\n    ProcessedData {\n        original_debug: format!(\"{:?}\", input),\n        processed: processed.clone(),\n        processed_display: format!(\"{}\", processed),\n    }\n}\n\n#[derive(Debug)]\nstruct ProcessedData<T> {\n    original_debug: String,\n    processed: T,\n    processed_display: String,\n}\n\n// Multiple type parameters with different bounds\nfn convert_and_combine<T, U, V>(first: T, second: U, combiner: impl Fn(T, U) -> V) -> V\nwhere\n    T: Clone + Debug,\n    U: Clone + Display,\n    V: Debug + Clone,\n{\n    println!(\"Converting {:?} and {}\", first, second);\n    let result = combiner(first, second);\n    println!(\"Result: {:?}\", result);\n    result\n}\n\n// Trait bounds with associated types\ntrait Processor {\n    type Input;\n    type Output;\n    type Error;\n    \n    fn process(&self, input: Self::Input) -> Result<Self::Output, Self::Error>;\n}\n\n// Generic function that works with any Processor\nfn batch_process<P>(processor: &P, inputs: Vec<P::Input>) -> Vec<Result<P::Output, P::Error>>\nwhere\n    P: Processor,\n    P::Input: Clone,\n    P::Output: Clone,\n    P::Error: Clone,\n{\n    inputs.into_iter()\n        .map(|input| processor.process(input))\n        .collect()\n}\n\n// Concrete implementations of Processor trait\nstruct StringLengthProcessor;\n\nimpl Processor for StringLengthProcessor {\n    type Input = String;\n    type Output = usize;\n    type Error = &'static str;\n    \n    fn process(&self, input: Self::Input) -> Result<Self::Output, Self::Error> {\n        if input.is_empty() {\n            Err(\"Empty string not allowed\")\n        } else {\n            Ok(input.len())\n        }\n    }\n}\n\nstruct NumberSquareProcessor;\n\nimpl Processor for NumberSquareProcessor {\n    type Input = i32;\n    type Output = i32;\n    type Error = String;\n    \n    fn process(&self, input: Self::Input) -> Result<Self::Output, Self::Error> {\n        if input < 0 {\n            Err(format!(\"Negative number not supported: {}\", input))\n        } else {\n            Ok(input * input)\n        }\n    }\n}\n\n// Higher-ranked trait bounds (HRTB)\nfn apply_to_all<F, T>(mut data: Vec<T>, func: F) -> Vec<T>\nwhere\n    F: for<'a> Fn(&'a T) -> T,\n    T: Clone,\n{\n    for item in &mut data {\n        *item = func(item);\n    }\n    data\n}\n\n// Complex where clause with multiple constraints\nfn advanced_computation<T, U, V>(x: T, y: U, z: V) -> String\nwhere\n    T: Display + Clone + PartialEq + Debug,\n    U: Add<V, Output = V> + Copy + Debug,\n    V: Display + Sub<Output = V> + Mul<Output = V> + Copy + PartialOrd,\n{\n    let result = y + z;\n    let computed = result - z;\n    let final_result = computed * z;\n    \n    format!(\n        \"Input: x={}, y={:?}, z={}\\nComputation: ({:?} + {}) - {} * {} = {}\",\n        x, y, z, y, z, z, z, final_result\n    )\n}\n\n// Trait bounds with lifetime parameters\nfn process_with_lifetime<'a, T>(data: &'a [T], predicate: impl Fn(&T) -> bool) -> Vec<&'a T>\nwhere\n    T: Debug + PartialEq,\n{\n    data.iter()\n        .filter(|&item| predicate(item))\n        .collect()\n}\n\n// Generic struct with phantom type for compile-time checks\nuse std::marker::PhantomData;\n\n#[derive(Debug)]\nstruct TypedId<T> {\n    id: u64,\n    _phantom: PhantomData<T>,\n}\n\nimpl<T> TypedId<T> {\n    fn new(id: u64) -> Self {\n        TypedId {\n            id,\n            _phantom: PhantomData,\n        }\n    }\n    \n    fn value(&self) -> u64 {\n        self.id\n    }\n}\n\n// Marker types for type safety\nstruct User;\nstruct Product;\nstruct Order;\n\n// Functions that ensure type safety through bounds\nfn get_user_name<T>(user_id: TypedId<T>) -> String\nwhere\n    T: 'static,\n    TypedId<T>: UserIdTrait,\n{\n    format!(\"User with ID: {}\", user_id.value())\n}\n\ntrait UserIdTrait {\n    fn is_valid(&self) -> bool;\n}\n\nimpl UserIdTrait for TypedId<User> {\n    fn is_valid(&self) -> bool {\n        self.id > 0 && self.id < 1_000_000\n    }\n}\n\n// Conditional trait implementations\nstruct Container<T> {\n    items: Vec<T>,\n}\n\nimpl<T> Container<T> {\n    fn new() -> Self {\n        Container { items: Vec::new() }\n    }\n    \n    fn add(&mut self, item: T) {\n        self.items.push(item);\n    }\n    \n    fn len(&self) -> usize {\n        self.items.len()\n    }\n}\n\n// Only implement Debug if T implements Debug\nimpl<T: Debug> Debug for Container<T> {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        f.debug_struct(\"Container\")\n            .field(\"items\", &self.items)\n            .finish()\n    }\n}\n\n// Only implement Display if T implements Display\nimpl<T: Display> Display for Container<T> {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        write!(f, \"Container with {} items: \", self.items.len())?;\n        for (i, item) in self.items.iter().enumerate() {\n            if i > 0 { write!(f, \", \")?; }\n            write!(f, \"{}\", item)?;\n        }\n        Ok(())\n    }\n}\n\n// Blanket implementations with bounds\ntrait Summarizable {\n    fn summarize(&self) -> String;\n}\n\n// Blanket implementation for all types that implement Display and Debug\nimpl<T> Summarizable for T\nwhere\n    T: Display + Debug,\n{\n    fn summarize(&self) -> String {\n        format!(\"Display: {}, Debug: {:?}\", self, self)\n    }\n}\n\nfn main() {\n    println!(\"=== Calculator with Trait Bounds ===\");\n    \n    let mut calc = Calculator::new(10);\n    calc.add(5).multiply(2).subtract(3);\n    \n    println!(\"Final value: {}\", calc.get_value());\n    println!(\"History: {:?}\", calc.get_history());\n    calc.print_status();\n    \n    // Test with different numeric types\n    let mut float_calc = Calculator::new(3.14);\n    float_calc.add(2.86).multiply(2.0);\n    float_calc.print_status();\n    \n    println!(\"\\n=== Statistics with Complex Bounds ===\");\n    \n    let numbers = vec![1, 5, 3, 9, 2, 8, 4, 7, 6];\n    if let Some(stats) = find_statistics(&numbers) {\n        println!(\"Statistics: {:?}\", stats);\n    }\n    \n    let floats = vec![1.1, 5.5, 3.3, 9.9, 2.2];\n    if let Some(float_stats) = find_statistics(&floats) {\n        println!(\"Float statistics: {:?}\", float_stats);\n    }\n    \n    println!(\"\\n=== Data Processing with Where Clauses ===\");\n    \n    let processed = process_comparable_data(42, |x| format!(\"Number: {}\", x * 2));\n    println!(\"Processed: {:?}\", processed);\n    \n    let text_processed = process_comparable_data(\n        \"hello\".to_string(),\n        |s| s.to_uppercase()\n    );\n    println!(\"Text processed: {:?}\", text_processed);\n    \n    println!(\"\\n=== Convert and Combine ===\");\n    \n    let result = convert_and_combine(\n        vec![1, 2, 3],\n        \"items\",\n        |nums, suffix| format!(\"{:?} {}\", nums, suffix)\n    );\n    println!(\"Combined result: {}\", result);\n    \n    println!(\"\\n=== Processor Trait with Associated Types ===\");\n    \n    let string_processor = StringLengthProcessor;\n    let strings = vec![\n        \"hello\".to_string(),\n        \"world\".to_string(),\n        \"\".to_string(),\n        \"rust\".to_string(),\n    ];\n    \n    let string_results = batch_process(&string_processor, strings);\n    println!(\"String processing results:\");\n    for (i, result) in string_results.iter().enumerate() {\n        match result {\n            Ok(length) => println!(\"  String {}: length = {}\", i, length),\n            Err(error) => println!(\"  String {}: error = {}\", i, error),\n        }\n    }\n    \n    let number_processor = NumberSquareProcessor;\n    let numbers = vec![1, -2, 3, 4, -5];\n    \n    let number_results = batch_process(&number_processor, numbers);\n    println!(\"\\nNumber processing results:\");\n    for (i, result) in number_results.iter().enumerate() {\n        match result {\n            Ok(square) => println!(\"  Number {}: square = {}\", i, square),\n            Err(error) => println!(\"  Number {}: error = {}\", i, error),\n        }\n    }\n    \n    println!(\"\\n=== Higher-Ranked Trait Bounds ===\");\n    \n    let data = vec![1, 2, 3, 4, 5];\n    let doubled = apply_to_all(data, |&x| x * 2);\n    println!(\"Doubled: {:?}\", doubled);\n    \n    let strings = vec![\"hello\".to_string(), \"world\".to_string()];\n    let uppercased = apply_to_all(strings, |s| s.to_uppercase());\n    println!(\"Uppercased: {:?}\", uppercased);\n    \n    println!(\"\\n=== Advanced Computation ===\");\n    \n    let computation_result = advanced_computation(\"test\", 5, 3.0);\n    println!(\"{}\", computation_result);\n    \n    println!(\"\\n=== Lifetime Bounds ===\");\n    \n    let numbers = vec![1, 2, 3, 4, 5, 6, 7, 8, 9, 10];\n    let even_numbers = process_with_lifetime(&numbers, |&x| x % 2 == 0);\n    println!(\"Even numbers: {:?}\", even_numbers);\n    \n    let words = vec![\"hello\", \"world\", \"rust\", \"programming\", \"is\", \"fun\"];\n    let long_words = process_with_lifetime(&words, |&word| word.len() > 4);\n    println!(\"Long words: {:?}\", long_words);\n    \n    println!(\"\\n=== Typed IDs for Type Safety ===\");\n    \n    let user_id: TypedId<User> = TypedId::new(12345);\n    let product_id: TypedId<Product> = TypedId::new(67890);\n    \n    println!(\"User ID: {:?}\", user_id);\n    println!(\"Product ID: {:?}\", product_id);\n    \n    // This would work:\n    let user_name = get_user_name(user_id);\n    println!(\"{}\", user_name);\n    \n    // This would NOT compile (type mismatch):\n    // let invalid = get_user_name(product_id); // Error!\n    \n    println!(\"\\n=== Conditional Implementations ===\");\n    \n    let mut string_container = Container::new();\n    string_container.add(\"hello\".to_string());\n    string_container.add(\"world\".to_string());\n    \n    println!(\"String container (Debug): {:?}\", string_container);\n    println!(\"String container (Display): {}\", string_container);\n    \n    let mut number_container = Container::new();\n    number_container.add(1);\n    number_container.add(2);\n    number_container.add(3);\n    \n    println!(\"Number container (Debug): {:?}\", number_container);\n    println!(\"Number container (Display): {}\", number_container);\n    \n    println!(\"\\n=== Blanket Implementations ===\");\n    \n    let number = 42;\n    let text = \"hello\";\n    let float = 3.14;\n    \n    println!(\"Number summary: {}\", number.summarize());\n    println!(\"Text summary: {}\", text.summarize());\n    println!(\"Float summary: {}\", float.summarize());\n    \n    println!(\"\\n=== Complex Constraint Examples ===\");\n    \n    // Function with very specific bounds\n    fn specialized_function<T>(value: T) -> String\n    where\n        T: Display + Debug + Clone + PartialEq + Send + Sync + 'static,\n    {\n        format!(\"Specialized processing of: {} (debug: {:?})\", value, value)\n    }\n    \n    let result = specialized_function(\"test data\");\n    println!(\"{}\", result);\n    \n    // Multiple where clauses for clarity\n    fn multi_constraint_function<T, U, F>(data: T, converter: F) -> U\n    where\n        T: Clone + Debug,\n        U: Display + Clone,\n        F: Fn(T) -> U,\n        F: Send + Sync,\n    {\n        let converted = converter(data);\n        println!(\"Converted to: {}\", converted);\n        converted\n    }\n    \n    let converted = multi_constraint_function(vec![1, 2, 3], |v| format!(\"{:?}\", v));\n    println!(\"Final result: {}\", converted);\n    \n    println!(\"\\n=== Trait Bound Benefits ===\");\n    println!(\"\u2705 Ensure types have required capabilities\");\n    println!(\"\u2705 Enable powerful generic programming\");\n    println!(\"\u2705 Maintain type safety at compile time\");\n    println!(\"\u2705 Allow conditional implementations\");\n    println!(\"\u2705 Support blanket implementations\");\n    println!(\"\u2705 Enable zero-cost abstractions\");\n    println!(\"\u2705 Improve code reusability and maintainability\");\n}\n\n// Key concepts:\n// - Trait bounds specify required capabilities for generic types\n// - Where clauses provide cleaner syntax for complex bounds\n// - Multiple bounds can be combined with + operator\n// - Associated types work with trait bounds\n// - Higher-ranked trait bounds handle lifetime polymorphism\n// - Conditional implementations only apply when bounds are met\n// - Blanket implementations provide traits for entire categories\n// - Type safety is enforced at compile time\n// - Zero-cost abstraction - no runtime performance penalty\n```",
    "tags": [
      "trait-bounds",
      "where-clauses",
      "generic-constraints",
      "associated-types",
      "conditional-impl",
      "blanket-impl",
      "hrtb",
      "type-safety"
    ],
    "instruction": "Demonstrate trait bounds and where clauses with complex generic constraints"
  },
  {
    "output": "```rust\n// This example compares associated types vs generics in traits\n// Shows when to use each approach and their trade-offs\n\nuse std::fmt::Debug;\nuse std::collections::HashMap;\n\n// =============================================================================\n// EXAMPLE 1: Iterator Pattern - Associated Types (Preferred)\n// =============================================================================\n\n// Using associated types - each implementor has ONE output type\ntrait MyIterator {\n    type Item;  // Associated type - one Item type per implementation\n    \n    fn next(&mut self) -> Option<Self::Item>;\n    \n    // Default implementations can use the associated type\n    fn collect_all(mut self) -> Vec<Self::Item>\n    where\n        Self: Sized,\n    {\n        let mut result = Vec::new();\n        while let Some(item) = self.next() {\n            result.push(item);\n        }\n        result\n    }\n    \n    fn count(mut self) -> usize\n    where\n        Self: Sized,\n    {\n        let mut count = 0;\n        while self.next().is_some() {\n            count += 1;\n        }\n        count\n    }\n}\n\n// Simple range iterator\nstruct Range {\n    current: i32,\n    end: i32,\n}\n\nimpl Range {\n    fn new(start: i32, end: i32) -> Self {\n        Range { current: start, end }\n    }\n}\n\nimpl MyIterator for Range {\n    type Item = i32;  // Concrete type for this implementation\n    \n    fn next(&mut self) -> Option<Self::Item> {\n        if self.current < self.end {\n            let current = self.current;\n            self.current += 1;\n            Some(current)\n        } else {\n            None\n        }\n    }\n}\n\n// String character iterator\nstruct CharIterator {\n    chars: std::str::Chars<'static>,\n    data: String,  // Own the data to ensure 'static lifetime\n}\n\nimpl CharIterator {\n    fn new(s: String) -> Self {\n        // We need to be careful with lifetimes here\n        // This is a simplified example\n        CharIterator {\n            chars: unsafe { std::mem::transmute(s.chars()) },\n            data: s,\n        }\n    }\n}\n\nimpl MyIterator for CharIterator {\n    type Item = char;  // Different type for this implementation\n    \n    fn next(&mut self) -> Option<Self::Item> {\n        self.chars.next()\n    }\n}\n\n// =============================================================================\n// EXAMPLE 2: Generic Trait Version (Less Flexible)\n// =============================================================================\n\n// Using generics - can implement multiple times with different types\ntrait GenericIterator<T> {\n    fn next(&mut self) -> Option<T>;\n    \n    // Default implementations are more complex with generics\n    fn collect_all(mut self) -> Vec<T>\n    where\n        Self: Sized,\n    {\n        let mut result = Vec::new();\n        while let Some(item) = self.next() {\n            result.push(item);\n        }\n        result\n    }\n}\n\n// Can implement for multiple types, but this creates complexity\nstruct MultiIterator {\n    number: i32,\n    text: String,\n}\n\nimpl MultiIterator {\n    fn new(number: i32, text: String) -> Self {\n        MultiIterator { number, text }\n    }\n}\n\n// Multiple implementations for the same struct\nimpl GenericIterator<i32> for MultiIterator {\n    fn next(&mut self) -> Option<i32> {\n        if self.number > 0 {\n            let current = self.number;\n            self.number -= 1;\n            Some(current)\n        } else {\n            None\n        }\n    }\n}\n\nimpl GenericIterator<char> for MultiIterator {\n    fn next(&mut self) -> Option<char> {\n        self.text.pop()\n    }\n}\n\n// =============================================================================\n// EXAMPLE 3: Parser Pattern - Associated Types Shine\n// =============================================================================\n\n// Parser trait with associated types\ntrait Parser {\n    type Input;   // What we're parsing from\n    type Output;  // What we're parsing to\n    type Error;   // Error type for this parser\n    \n    fn parse(&self, input: Self::Input) -> Result<Self::Output, Self::Error>;\n    \n    // Combinator that works with associated types\n    fn map<F, U>(self, f: F) -> MapParser<Self, F, U>\n    where\n        Self: Sized,\n        F: Fn(Self::Output) -> U,\n    {\n        MapParser {\n            parser: self,\n            mapper: f,\n            _phantom: std::marker::PhantomData,\n        }\n    }\n    \n    fn and_then<F, P>(self, f: F) -> AndThenParser<Self, F>\n    where\n        Self: Sized,\n        F: Fn(Self::Output) -> P,\n        P: Parser<Input = Self::Input, Error = Self::Error>,\n    {\n        AndThenParser {\n            first: self,\n            second: f,\n        }\n    }\n}\n\n// Parser combinator using map\nstruct MapParser<P, F, U> {\n    parser: P,\n    mapper: F,\n    _phantom: std::marker::PhantomData<U>,\n}\n\nimpl<P, F, U> Parser for MapParser<P, F, U>\nwhere\n    P: Parser,\n    F: Fn(P::Output) -> U,\n{\n    type Input = P::Input;\n    type Output = U;\n    type Error = P::Error;\n    \n    fn parse(&self, input: Self::Input) -> Result<Self::Output, Self::Error> {\n        self.parser.parse(input).map(&self.mapper)\n    }\n}\n\n// Parser combinator using and_then\nstruct AndThenParser<P, F> {\n    first: P,\n    second: F,\n}\n\nimpl<P, F, P2> Parser for AndThenParser<P, F>\nwhere\n    P: Parser,\n    F: Fn(P::Output) -> P2,\n    P2: Parser<Input = P::Input, Error = P::Error>,\n{\n    type Input = P::Input;\n    type Output = P2::Output;\n    type Error = P::Error;\n    \n    fn parse(&self, input: Self::Input) -> Result<Self::Output, Self::Error> {\n        let intermediate = self.first.parse(input)?;\n        let second_parser = (self.second)(intermediate);\n        // Note: In a real implementation, we'd need to handle the input properly\n        // This is simplified for demonstration\n        Ok(second_parser.parse(input)?)\n    }\n}\n\n// Concrete parser implementations\nstruct IntParser;\n\nimpl Parser for IntParser {\n    type Input = String;\n    type Output = i32;\n    type Error = std::num::ParseIntError;\n    \n    fn parse(&self, input: Self::Input) -> Result<Self::Output, Self::Error> {\n        input.parse()\n    }\n}\n\nstruct FloatParser;\n\nimpl Parser for FloatParser {\n    type Input = String;\n    type Output = f64;\n    type Error = std::num::ParseFloatError;\n    \n    fn parse(&self, input: Self::Input) -> Result<Self::Output, Self::Error> {\n        input.parse()\n    }\n}\n\n// =============================================================================\n// EXAMPLE 4: Database Connection Pattern\n// =============================================================================\n\n// Database trait with associated types (preferred for this use case)\ntrait Database {\n    type Connection;\n    type Transaction;\n    type Error;\n    type QueryResult;\n    \n    fn connect(&self) -> Result<Self::Connection, Self::Error>;\n    fn begin_transaction(&self, conn: &mut Self::Connection) -> Result<Self::Transaction, Self::Error>;\n    fn execute_query(&self, conn: &Self::Connection, query: &str) -> Result<Self::QueryResult, Self::Error>;\n}\n\n// PostgreSQL implementation\nstruct PostgresDatabase {\n    connection_string: String,\n}\n\n#[derive(Debug)]\nstruct PostgresConnection {\n    host: String,\n    connected: bool,\n}\n\n#[derive(Debug)]\nstruct PostgresTransaction {\n    id: u64,\n}\n\n#[derive(Debug)]\nstruct PostgresQueryResult {\n    rows: Vec<HashMap<String, String>>,\n}\n\n#[derive(Debug)]\nenum PostgresError {\n    ConnectionFailed(String),\n    QueryFailed(String),\n    TransactionFailed(String),\n}\n\nimpl Database for PostgresDatabase {\n    type Connection = PostgresConnection;\n    type Transaction = PostgresTransaction;\n    type Error = PostgresError;\n    type QueryResult = PostgresQueryResult;\n    \n    fn connect(&self) -> Result<Self::Connection, Self::Error> {\n        // Simulate connection\n        if self.connection_string.contains(\"localhost\") {\n            Ok(PostgresConnection {\n                host: \"localhost\".to_string(),\n                connected: true,\n            })\n        } else {\n            Err(PostgresError::ConnectionFailed(\"Invalid host\".to_string()))\n        }\n    }\n    \n    fn begin_transaction(&self, _conn: &mut Self::Connection) -> Result<Self::Transaction, Self::Error> {\n        Ok(PostgresTransaction { id: 12345 })\n    }\n    \n    fn execute_query(&self, _conn: &Self::Connection, query: &str) -> Result<Self::QueryResult, Self::Error> {\n        if query.starts_with(\"SELECT\") {\n            let mut row = HashMap::new();\n            row.insert(\"id\".to_string(), \"1\".to_string());\n            row.insert(\"name\".to_string(), \"test\".to_string());\n            \n            Ok(PostgresQueryResult {\n                rows: vec![row],\n            })\n        } else {\n            Err(PostgresError::QueryFailed(\"Invalid query\".to_string()))\n        }\n    }\n}\n\n// Generic function that works with any Database implementation\nfn perform_database_operations<D: Database>(db: &D) -> Result<(), D::Error>\nwhere\n    D::Error: Debug,\n    D::Connection: Debug,\n    D::QueryResult: Debug,\n{\n    println!(\"Connecting to database...\");\n    let mut conn = db.connect()?;\n    println!(\"Connected: {:?}\", conn);\n    \n    println!(\"Beginning transaction...\");\n    let _tx = db.begin_transaction(&mut conn)?;\n    \n    println!(\"Executing query...\");\n    let result = db.execute_query(&conn, \"SELECT * FROM users\")?;\n    println!(\"Query result: {:?}\", result);\n    \n    Ok(())\n}\n\n// =============================================================================\n// EXAMPLE 5: When Generics Might Be Better - Conversion Traits\n// =============================================================================\n\n// Generic trait for conversions (like From/Into)\ntrait Convert<T> {\n    type Error;\n    \n    fn convert(&self) -> Result<T, Self::Error>;\n}\n\n// Multiple implementations for different target types\nstruct StringData {\n    data: String,\n}\n\nimpl Convert<i32> for StringData {\n    type Error = std::num::ParseIntError;\n    \n    fn convert(&self) -> Result<i32, Self::Error> {\n        self.data.parse()\n    }\n}\n\nimpl Convert<f64> for StringData {\n    type Error = std::num::ParseFloatError;\n    \n    fn convert(&self) -> Result<f64, Self::Error> {\n        self.data.parse()\n    }\n}\n\nimpl Convert<bool> for StringData {\n    type Error = std::str::ParseBoolError;\n    \n    fn convert(&self) -> Result<bool, Self::Error> {\n        self.data.parse()\n    }\n}\n\n// Generic function that works with any conversion\nfn convert_and_print<T, F>(data: &StringData)\nwhere\n    StringData: Convert<T>,\n    T: Debug,\n    <StringData as Convert<T>>::Error: Debug,\n{\n    match data.convert() {\n        Ok(value) => println!(\"Converted successfully: {:?}\", value),\n        Err(error) => println!(\"Conversion failed: {:?}\", error),\n    }\n}\n\n// =============================================================================\n// EXAMPLE 6: Collection Pattern Comparison\n// =============================================================================\n\n// Associated types version (preferred for collections)\ntrait Collection {\n    type Item;\n    type Iter: Iterator<Item = Self::Item>;\n    \n    fn len(&self) -> usize;\n    fn is_empty(&self) -> bool {\n        self.len() == 0\n    }\n    fn iter(&self) -> Self::Iter;\n    fn contains(&self, item: &Self::Item) -> bool\n    where\n        Self::Item: PartialEq;\n}\n\n// Generic version (more flexible but complex)\ntrait GenericCollection<T> {\n    type Iter: Iterator<Item = T>;\n    \n    fn len(&self) -> usize;\n    fn iter(&self) -> Self::Iter;\n    fn contains(&self, item: &T) -> bool\n    where\n        T: PartialEq;\n}\n\nfn main() {\n    println!(\"=== Associated Types vs Generics Comparison ===\");\n    \n    println!(\"\\n=== Iterator Example (Associated Types) ===\");\n    \n    let mut range = Range::new(1, 5);\n    println!(\"Range iterator:\");\n    while let Some(num) = range.next() {\n        println!(\"  {}\", num);\n    }\n    \n    let range2 = Range::new(10, 13);\n    let collected: Vec<i32> = range2.collect_all();\n    println!(\"Collected range: {:?}\", collected);\n    \n    let char_iter = CharIterator::new(\"hello\".to_string());\n    let collected_chars: Vec<char> = char_iter.collect_all();\n    println!(\"Collected chars: {:?}\", collected_chars);\n    \n    println!(\"\\n=== Generic Iterator Example ===\");\n    \n    let mut multi = MultiIterator::new(3, \"abc\".to_string());\n    \n    // Different behaviors based on type parameter\n    println!(\"Numbers from MultiIterator:\");\n    let numbers: Vec<i32> = GenericIterator::<i32>::collect_all(multi);\n    println!(\"  {:?}\", numbers);\n    \n    // Note: We can't use the same instance again because it was moved\n    let mut multi2 = MultiIterator::new(3, \"xyz\".to_string());\n    println!(\"Chars from MultiIterator:\");\n    let chars: Vec<char> = GenericIterator::<char>::collect_all(multi2);\n    println!(\"  {:?}\", chars);\n    \n    println!(\"\\n=== Parser Example (Associated Types) ===\");\n    \n    let int_parser = IntParser;\n    let float_parser = FloatParser;\n    \n    match int_parser.parse(\"42\".to_string()) {\n        Ok(num) => println!(\"Parsed integer: {}\", num),\n        Err(e) => println!(\"Failed to parse integer: {}\", e),\n    }\n    \n    match float_parser.parse(\"3.14\".to_string()) {\n        Ok(num) => println!(\"Parsed float: {}\", num),\n        Err(e) => println!(\"Failed to parse float: {}\", e),\n    }\n    \n    // Parser combinators\n    let mapped_parser = int_parser.map(|x| x * 2);\n    match mapped_parser.parse(\"21\".to_string()) {\n        Ok(doubled) => println!(\"Parsed and doubled: {}\", doubled),\n        Err(e) => println!(\"Failed: {:?}\", e),\n    }\n    \n    println!(\"\\n=== Database Example (Associated Types) ===\");\n    \n    let postgres_db = PostgresDatabase {\n        connection_string: \"postgresql://localhost:5432/mydb\".to_string(),\n    };\n    \n    match perform_database_operations(&postgres_db) {\n        Ok(()) => println!(\"Database operations completed successfully\"),\n        Err(e) => println!(\"Database operations failed: {:?}\", e),\n    }\n    \n    println!(\"\\n=== Conversion Example (Generics) ===\");\n    \n    let string_data = StringData {\n        data: \"42\".to_string(),\n    };\n    \n    println!(\"Converting '42' to different types:\");\n    convert_and_print::<i32, _>(&string_data);\n    convert_and_print::<f64, _>(&string_data);\n    \n    let bool_data = StringData {\n        data: \"true\".to_string(),\n    };\n    \n    println!(\"Converting 'true' to bool:\");\n    convert_and_print::<bool, _>(&bool_data);\n    \n    println!(\"\\n=== When to Use Each Pattern ===\");\n    \n    println!(\"\\n\ud83d\udccb Use Associated Types When:\");\n    println!(\"  \u2705 Each implementation has exactly ONE logical type for the associated type\");\n    println!(\"  \u2705 The type is fundamental to the trait's purpose (like Iterator::Item)\");\n    println!(\"  \u2705 You want cleaner syntax and better type inference\");\n    println!(\"  \u2705 Building trait objects is important\");\n    println!(\"  \u2705 The relationship is one-to-one (one impl, one type)\");\n    \n    println!(\"\\n\ud83d\udccb Use Generics When:\");\n    println!(\"  \u2705 You might want multiple implementations for different types\");\n    println!(\"  \u2705 The type parameter is an input to the trait's behavior\");\n    println!(\"  \u2705 You need the flexibility to specify the type at call site\");\n    println!(\"  \u2705 The type is more of a parameter than a fundamental part\");\n    println!(\"  \u2705 You want conversion-like behavior (From<T>, Into<T>)\");\n    \n    println!(\"\\n\ud83d\udccb Key Differences:\");\n    println!(\"  \ud83d\udd39 Associated types: One implementation per type\");\n    println!(\"  \ud83d\udd39 Generics: Multiple implementations possible\");\n    println!(\"  \ud83d\udd39 Associated types: Better type inference\");\n    println!(\"  \ud83d\udd39 Generics: More explicit type specification needed\");\n    println!(\"  \ud83d\udd39 Associated types: Can form trait objects more easily\");\n    println!(\"  \ud83d\udd39 Generics: Trait objects require type parameters\");\n    \n    println!(\"\\n\ud83d\udccb Performance:\");\n    println!(\"  \u2705 Both are zero-cost abstractions\");\n    println!(\"  \u2705 Compile-time resolution in both cases\");\n    println!(\"  \u2705 No runtime overhead\");\n    println!(\"  \u2705 Monomorphization applies to both\");\n}\n\n// Helper function demonstrating trait object differences\nfn demonstrate_trait_objects() {\n    // Associated types work well with trait objects\n    let parsers: Vec<Box<dyn Parser<Input = String, Output = i32, Error = std::num::ParseIntError>>> = vec![\n        Box::new(IntParser),\n        // Box::new(FloatParser), // This wouldn't work - different Output type\n    ];\n    \n    // Generic traits are harder to make into trait objects\n    // let generic_iterators: Vec<Box<dyn GenericIterator<i32>>> = vec![\n    //     Box::new(MultiIterator::new(5, \"test\".to_string())),\n    // ];\n    \n    println!(\"Trait objects work better with associated types\");\n}\n\n// Key concepts:\n// - Associated types: one implementation maps to one type\n// - Generics: one implementation can work with multiple types\n// - Associated types provide better type inference\n// - Generics offer more flexibility at call site\n// - Associated types work better with trait objects\n// - Both are zero-cost abstractions\n// - Choice depends on the relationship between trait and types\n// - Associated types for fundamental relationships\n// - Generics for parameterized behavior\n```",
    "tags": [
      "associated-types",
      "generics",
      "trait-design",
      "type-relationships",
      "trait-objects",
      "zero-cost",
      "design-patterns",
      "api-design"
    ],
    "instruction": "Compare associated types vs generics and demonstrate when to use each"
  },
  {
    "output": "```rust\n// This example demonstrates generic lifetimes and complex lifetime relationships\n// Lifetimes ensure memory safety by tracking how long references are valid\n\nuse std::collections::HashMap;\nuse std::fmt::Display;\n\n// Basic struct with lifetime parameter\n#[derive(Debug)]\nstruct TextSlice<'a> {\n    content: &'a str,\n    start: usize,\n    end: usize,\n}\n\nimpl<'a> TextSlice<'a> {\n    fn new(content: &'a str, start: usize, end: usize) -> Self {\n        TextSlice {\n            content,\n            start: start.min(content.len()),\n            end: end.min(content.len()),\n        }\n    }\n    \n    fn slice(&self) -> &'a str {\n        &self.content[self.start..self.end]\n    }\n    \n    fn len(&self) -> usize {\n        self.end - self.start\n    }\n    \n    // Method that borrows self and returns a reference with the same lifetime\n    fn get_content(&self) -> &'a str {\n        self.content\n    }\n    \n    // Method that takes another TextSlice and returns the longer one\n    fn longer(self, other: TextSlice<'a>) -> TextSlice<'a> {\n        if self.len() >= other.len() {\n            self\n        } else {\n            other\n        }\n    }\n}\n\n// Struct with multiple lifetime parameters\n#[derive(Debug)]\nstruct Pair<'a, 'b> {\n    first: &'a str,\n    second: &'b str,\n}\n\nimpl<'a, 'b> Pair<'a, 'b> {\n    fn new(first: &'a str, second: &'b str) -> Self {\n        Pair { first, second }\n    }\n    \n    // Method returning reference with first lifetime\n    fn get_first(&self) -> &'a str {\n        self.first\n    }\n    \n    // Method returning reference with second lifetime\n    fn get_second(&self) -> &'b str {\n        self.second\n    }\n    \n    // Method that requires both lifetimes to be at least as long as 'c\n    fn combine<'c>(&'c self) -> String\n    where\n        'a: 'c,\n        'b: 'c,\n    {\n        format!(\"{} {}\", self.first, self.second)\n    }\n}\n\n// Generic struct with both type parameters and lifetime parameters\n#[derive(Debug)]\nstruct Container<'a, T> {\n    data: &'a [T],\n    name: &'a str,\n}\n\nimpl<'a, T> Container<'a, T> {\n    fn new(data: &'a [T], name: &'a str) -> Self {\n        Container { data, name }\n    }\n    \n    fn len(&self) -> usize {\n        self.data.len()\n    }\n    \n    fn get(&self, index: usize) -> Option<&'a T> {\n        self.data.get(index)\n    }\n    \n    fn name(&self) -> &'a str {\n        self.name\n    }\n    \n    // Method with additional lifetime parameter\n    fn find_matching<'b>(&self, predicate: &'b dyn Fn(&T) -> bool) -> Option<&'a T>\n    where\n        T: Clone,\n    {\n        self.data.iter().find(|&item| predicate(item))\n    }\n}\n\n// Generic function with lifetime parameters\nfn longest<'a>(x: &'a str, y: &'a str) -> &'a str {\n    if x.len() > y.len() {\n        x\n    } else {\n        y\n    }\n}\n\n// Function with multiple lifetime parameters\nfn choose_string<'a, 'b>(first: &'a str, second: &'b str, choose_first: bool) -> (&'a str, &'b str) {\n    if choose_first {\n        (first, second)\n    } else {\n        (first, second)\n    }\n}\n\n// Function that demonstrates lifetime subtyping\nfn process_text<'long, 'short>(long_text: &'long str, short_text: &'short str) -> &'long str\nwhere\n    'long: 'short,  // 'long outlives 'short\n{\n    if long_text.len() > short_text.len() {\n        long_text\n    } else {\n        // This is safe because 'long: 'short means 'long outlives 'short\n        unsafe { std::mem::transmute(short_text) }\n    }\n}\n\n// Higher-Ranked Trait Bounds (HRTB) with lifetimes\nfn apply_to_string<F>(text: &str, func: F) -> String\nwhere\n    F: for<'a> Fn(&'a str) -> &'a str,\n{\n    func(text).to_string()\n}\n\n// Struct with self-referential pattern using lifetimes\n#[derive(Debug)]\nstruct Parser<'input> {\n    input: &'input str,\n    position: usize,\n}\n\nimpl<'input> Parser<'input> {\n    fn new(input: &'input str) -> Self {\n        Parser { input, position: 0 }\n    }\n    \n    fn current_char(&self) -> Option<char> {\n        self.input.chars().nth(self.position)\n    }\n    \n    fn advance(&mut self) {\n        if self.position < self.input.len() {\n            self.position += 1;\n        }\n    }\n    \n    // Parse a word and return a slice with the same lifetime as input\n    fn parse_word(&mut self) -> Option<&'input str> {\n        let start = self.position;\n        \n        while let Some(ch) = self.current_char() {\n            if ch.is_alphabetic() {\n                self.advance();\n            } else {\n                break;\n            }\n        }\n        \n        if start < self.position {\n            Some(&self.input[start..self.position])\n        } else {\n            None\n        }\n    }\n    \n    // Skip whitespace\n    fn skip_whitespace(&mut self) {\n        while let Some(ch) = self.current_char() {\n            if ch.is_whitespace() {\n                self.advance();\n            } else {\n                break;\n            }\n        }\n    }\n    \n    // Parse all words from the input\n    fn parse_all_words(&mut self) -> Vec<&'input str> {\n        let mut words = Vec::new();\n        \n        loop {\n            self.skip_whitespace();\n            \n            if let Some(word) = self.parse_word() {\n                words.push(word);\n            } else {\n                break;\n            }\n        }\n        \n        words\n    }\n}\n\n// Generic trait with lifetime parameters\ntrait Processor<'a> {\n    type Input;\n    type Output;\n    \n    fn process(&self, input: &'a Self::Input) -> Self::Output;\n}\n\n// Implementation with specific lifetime requirements\nstruct StringProcessor;\n\nimpl<'a> Processor<'a> for StringProcessor {\n    type Input = str;\n    type Output = &'a str;\n    \n    fn process(&self, input: &'a Self::Input) -> Self::Output {\n        // Return a slice of the input\n        let len = input.len();\n        if len > 10 {\n            &input[..10]\n        } else {\n            input\n        }\n    }\n}\n\n// Complex lifetime relationships in a data structure\n#[derive(Debug)]\nstruct Graph<'a> {\n    nodes: Vec<Node<'a>>,\n    edges: Vec<Edge<'a>>,\n}\n\n#[derive(Debug)]\nstruct Node<'a> {\n    id: usize,\n    label: &'a str,\n}\n\n#[derive(Debug)]\nstruct Edge<'a> {\n    from: &'a Node<'a>,\n    to: &'a Node<'a>,\n    weight: f64,\n}\n\nimpl<'a> Graph<'a> {\n    fn new() -> Self {\n        Graph {\n            nodes: Vec::new(),\n            edges: Vec::new(),\n        }\n    }\n    \n    fn add_node(&mut self, id: usize, label: &'a str) {\n        self.nodes.push(Node { id, label });\n    }\n    \n    fn find_node(&self, id: usize) -> Option<&Node<'a>> {\n        self.nodes.iter().find(|node| node.id == id)\n    }\n    \n    fn add_edge(&mut self, from_id: usize, to_id: usize, weight: f64) -> Result<(), &'static str> {\n        let from_node = self.find_node(from_id).ok_or(\"From node not found\")?;\n        let to_node = self.find_node(to_id).ok_or(\"To node not found\")?;\n        \n        // This is tricky - we need to get references that live as long as 'a\n        // In a real implementation, we'd use indices instead of direct references\n        // This is simplified for demonstration\n        \n        println!(\"Would add edge from {} to {} with weight {}\", \n                from_node.label, to_node.label, weight);\n        Ok(())\n    }\n}\n\n// Function demonstrating lifetime elision rules\nfn first_word(s: &str) -> &str {\n    // Lifetime elision: equivalent to:\n    // fn first_word<'a>(s: &'a str) -> &'a str\n    \n    let bytes = s.as_bytes();\n    \n    for (i, &item) in bytes.iter().enumerate() {\n        if item == b' ' {\n            return &s[0..i];\n        }\n    }\n    \n    &s[..]\n}\n\n// Complex lifetime scenario: caching system\nstruct Cache<'data> {\n    storage: HashMap<String, &'data str>,\n}\n\nimpl<'data> Cache<'data> {\n    fn new() -> Self {\n        Cache {\n            storage: HashMap::new(),\n        }\n    }\n    \n    fn get(&self, key: &str) -> Option<&'data str> {\n        self.storage.get(key).copied()\n    }\n    \n    fn insert(&mut self, key: String, value: &'data str) {\n        self.storage.insert(key, value);\n    }\n    \n    // Method that works with borrowed key but returns owned result\n    fn get_or_default(&self, key: &str, default: &'data str) -> &'data str {\n        self.storage.get(key).copied().unwrap_or(default)\n    }\n}\n\n// Demonstrate lifetime polymorphism\nfn process_multiple_lifetimes<'a, 'b, 'c>(\n    short: &'a str,\n    medium: &'b str,\n    long: &'c str,\n) -> (&'a str, &'b str, &'c str)\nwhere\n    'c: 'b,  // long outlives medium\n    'b: 'a,  // medium outlives short\n{\n    println!(\"Processing: {}, {}, {}\", short, medium, long);\n    (short, medium, long)\n}\n\nfn main() {\n    println!(\"=== Basic Lifetime Parameters ===\");\n    \n    let text = \"Hello, Rust lifetimes!\";\n    let slice1 = TextSlice::new(text, 0, 5);\n    let slice2 = TextSlice::new(text, 7, 11);\n    \n    println!(\"Slice 1: {:?} -> '{}'\", slice1, slice1.slice());\n    println!(\"Slice 2: {:?} -> '{}'\", slice2, slice2.slice());\n    \n    let longer = slice1.longer(slice2);\n    println!(\"Longer slice: '{}'\", longer.slice());\n    \n    println!(\"\\n=== Multiple Lifetime Parameters ===\");\n    \n    let first_text = \"Hello\";\n    let second_text = \"World!\";\n    \n    let pair = Pair::new(first_text, second_text);\n    println!(\"Pair: {:?}\", pair);\n    println!(\"First: {}\", pair.get_first());\n    println!(\"Second: {}\", pair.get_second());\n    println!(\"Combined: {}\", pair.combine());\n    \n    println!(\"\\n=== Generic Container with Lifetimes ===\");\n    \n    let numbers = [1, 2, 3, 4, 5];\n    let container_name = \"Number Container\";\n    let container = Container::new(&numbers, container_name);\n    \n    println!(\"Container '{}' has {} items\", container.name(), container.len());\n    \n    for i in 0..container.len() {\n        if let Some(item) = container.get(i) {\n            println!(\"  Item {}: {}\", i, item);\n        }\n    }\n    \n    // Find matching element\n    let predicate = |&x| x > 3;\n    if let Some(found) = container.find_matching(&predicate) {\n        println!(\"Found number > 3: {}\", found);\n    }\n    \n    println!(\"\\n=== Lifetime Functions ===\");\n    \n    let str1 = \"short\";\n    let str2 = \"this is a longer string\";\n    let result = longest(str1, str2);\n    println!(\"Longest of '{}' and '{}': '{}'\", str1, str2, result);\n    \n    let (chosen_first, chosen_second) = choose_string(str1, str2, true);\n    println!(\"Chosen: '{}' and '{}'\", chosen_first, chosen_second);\n    \n    println!(\"\\n=== Parser with Lifetimes ===\");\n    \n    let input = \"hello world rust programming\";\n    let mut parser = Parser::new(input);\n    \n    println!(\"Parsing: '{}'\", input);\n    let words = parser.parse_all_words();\n    println!(\"Parsed words: {:?}\", words);\n    \n    // Words have the same lifetime as the original input\n    for word in &words {\n        println!(\"Word: '{}' (length: {})\", word, word.len());\n    }\n    \n    println!(\"\\n=== Processor Trait with Lifetimes ===\");\n    \n    let processor = StringProcessor;\n    let long_text = \"This is a very long string that will be truncated\";\n    let processed = processor.process(long_text);\n    println!(\"Original: '{}'\", long_text);\n    println!(\"Processed: '{}'\", processed);\n    \n    println!(\"\\n=== Graph with Complex Lifetimes ===\");\n    \n    let node_labels = [\"Start\", \"Middle\", \"End\"];\n    let mut graph = Graph::new();\n    \n    // Add nodes\n    for (i, &label) in node_labels.iter().enumerate() {\n        graph.add_node(i, label);\n    }\n    \n    println!(\"Graph nodes: {:?}\", graph.nodes);\n    \n    // Try to add edges (simplified)\n    let _ = graph.add_edge(0, 1, 1.0);\n    let _ = graph.add_edge(1, 2, 2.0);\n    \n    println!(\"\\n=== Lifetime Elision ===\");\n    \n    let sentence = \"Hello world from Rust\";\n    let word = first_word(sentence);\n    println!(\"First word of '{}': '{}'\", sentence, word);\n    \n    println!(\"\\n=== Cache with Lifetimes ===\");\n    \n    let cached_data = [\"value1\", \"value2\", \"value3\"];\n    let mut cache = Cache::new();\n    \n    // Insert data into cache\n    cache.insert(\"key1\".to_string(), cached_data[0]);\n    cache.insert(\"key2\".to_string(), cached_data[1]);\n    \n    // Retrieve from cache\n    if let Some(value) = cache.get(\"key1\") {\n        println!(\"Cache hit for key1: {}\", value);\n    }\n    \n    let default_value = \"default\";\n    let result = cache.get_or_default(\"key3\", default_value);\n    println!(\"Cache miss for key3, using default: {}\", result);\n    \n    println!(\"\\n=== Higher-Ranked Trait Bounds ===\");\n    \n    // Function that works with any lifetime\n    let trim_func = |s: &str| s.trim();\n    let text_with_spaces = \"  hello world  \";\n    let trimmed = apply_to_string(text_with_spaces, trim_func);\n    println!(\"Original: '{}'\", text_with_spaces);\n    println!(\"Trimmed: '{}'\", trimmed);\n    \n    println!(\"\\n=== Complex Lifetime Relationships ===\");\n    \n    let long_lived = \"This string lives for the entire program\";\n    {\n        let medium_lived = \"This string lives for this block\";\n        {\n            let short_lived = \"This string has the shortest life\";\n            \n            // All three references are valid here\n            let (a, b, c) = process_multiple_lifetimes(short_lived, medium_lived, long_lived);\n            println!(\"Processed: '{}', '{}', '{}'\", a, b, c);\n        }\n        // short_lived is no longer valid here\n    }\n    // medium_lived is no longer valid here\n    // long_lived is still valid\n    \n    println!(\"\\n=== Lifetime Best Practices ===\");\n    println!(\"\u2705 Use lifetime elision when possible\");\n    println!(\"\u2705 Prefer fewer lifetime parameters\");\n    println!(\"\u2705 Use 'static for truly static data\");\n    println!(\"\u2705 Consider lifetime subtyping relationships\");\n    println!(\"\u2705 Use HRTB for maximum flexibility\");\n    println!(\"\u2705 Avoid complex lifetime relationships when possible\");\n    println!(\"\u2705 Design APIs to minimize lifetime dependencies\");\n    \n    println!(\"\\n=== Lifetime Performance Notes ===\");\n    println!(\"\u2705 Lifetimes are zero-cost - no runtime overhead\");\n    println!(\"\u2705 Compile-time checking prevents memory errors\");\n    println!(\"\u2705 No garbage collection needed\");\n    println!(\"\u2705 Enables efficient borrowing patterns\");\n    println!(\"\u2705 Prevents use-after-free and dangling pointers\");\n}\n\n// Advanced pattern: Iterator with lifetimes\nstruct SliceIterator<'a, T> {\n    slice: &'a [T],\n    index: usize,\n}\n\nimpl<'a, T> SliceIterator<'a, T> {\n    fn new(slice: &'a [T]) -> Self {\n        SliceIterator { slice, index: 0 }\n    }\n}\n\nimpl<'a, T> Iterator for SliceIterator<'a, T> {\n    type Item = &'a T;\n    \n    fn next(&mut self) -> Option<Self::Item> {\n        if self.index < self.slice.len() {\n            let item = &self.slice[self.index];\n            self.index += 1;\n            Some(item)\n        } else {\n            None\n        }\n    }\n}\n\n// Helper function demonstrating lifetime variance\nfn demonstrate_variance() {\n    // Covariance: &'long T can be used where &'short T is expected\n    let long_string = String::from(\"long lived\");\n    let long_ref: &'static str = \"static string\";\n    \n    // This works because 'static: 'a for any 'a\n    fn use_string_ref(s: &str) {\n        println!(\"Using: {}\", s);\n    }\n    \n    use_string_ref(long_ref);  // 'static ref used as shorter lifetime\n    use_string_ref(&long_string);  // longer lifetime used as shorter\n}\n\n// Key concepts:\n// - Generic lifetimes track how long references are valid\n// - Multiple lifetime parameters allow complex relationships\n// - Lifetime bounds specify outlives relationships\n// - Higher-ranked trait bounds work with any lifetime\n// - Lifetime elision reduces annotation burden\n// - Zero-cost abstraction - no runtime overhead\n// - Enables memory safety without garbage collection\n// - Variance rules allow flexible lifetime relationships\n// - Subtyping based on lifetime relationships\n```",
    "tags": [
      "generic-lifetimes",
      "lifetime-parameters",
      "lifetime-bounds",
      "lifetime-elision",
      "hrtb",
      "variance",
      "memory-safety",
      "zero-cost"
    ],
    "instruction": "Demonstrate generic lifetimes with complex lifetime relationships"
  },
  {
    "output": "Great question! These are three different smart pointer types in Rust, each serving different purposes:\n\n**Box<T>** - Single Ownership on the Heap\n- Stores data on the heap instead of the stack\n- Single owner, moves when passed around\n- Zero runtime overhead\n- Use when: data is too large for stack, need heap allocation, or recursive types\n\nExample:\n```rust\nlet boxed_value = Box::new(42);\nlet another_box = boxed_value; // boxed_value is moved\n// println!(\"{}\", boxed_value); // Error! Value was moved\n```\n\n**Rc<T>** - Reference Counted (Single-threaded)\n- Multiple owners can share the same data\n- Reference counting tracks how many owners exist\n- Only works in single-threaded contexts\n- Use when: multiple parts of code need to own the same data\n\nExample:\n```rust\nuse std::rc::Rc;\n\nlet shared_data = Rc::new(vec![1, 2, 3]);\nlet reference1 = Rc::clone(&shared_data);\nlet reference2 = Rc::clone(&shared_data);\n\nprintln!(\"Reference count: {}\", Rc::strong_count(&shared_data)); // 3\n```\n\n**Arc<T>** - Atomic Reference Counted (Thread-safe)\n- Like Rc but thread-safe using atomic operations\n- Multiple owners across multiple threads\n- Slightly more overhead than Rc due to atomic operations\n- Use when: sharing data between threads\n\nExample:\n```rust\nuse std::sync::Arc;\nuse std::thread;\n\nlet shared_data = Arc::new(vec![1, 2, 3]);\nlet data_clone = Arc::clone(&shared_data);\n\nthread::spawn(move || {\n    println!(\"From thread: {:?}\", data_clone);\n});\n\nprintln!(\"From main: {:?}\", shared_data);\n```\n\n**Quick Decision Guide:**\n- Need heap allocation with single owner? \u2192 **Box<T>**\n- Need multiple owners, single thread? \u2192 **Rc<T>**\n- Need multiple owners across threads? \u2192 **Arc<T>**\n\n**Performance:**\n- Box: Zero runtime cost\n- Rc: Small overhead for reference counting\n- Arc: Slightly more overhead due to atomic operations\n\nRemember: All three provide automatic cleanup when the last owner goes out of scope!",
    "tags": [
      "smart-pointers",
      "box",
      "rc",
      "arc",
      "memory-management",
      "qa",
      "ownership"
    ],
    "instruction": "What are the main differences between Box, Rc, and Arc in Rust?"
  },
  {
    "output": "Coming from Python, Rust's ownership system will feel quite different! Let me break it down:\n\n## Python vs Rust Memory Management\n\n**Python:**\n```python\n# Python - garbage collected\nmy_list = [1, 2, 3]\nanother_ref = my_list  # Both variables point to same object\nmy_list.append(4)      # Both see the change\nprint(another_ref)     # [1, 2, 3, 4]\n```\n\n**Rust:**\n```rust\n// Rust - ownership system\nlet my_vec = vec![1, 2, 3];\nlet another_vec = my_vec;  // my_vec is MOVED, no longer accessible\n// my_vec.push(4);        // ERROR! my_vec was moved\nprintln!(\"{:?}\", another_vec); // Only this works\n```\n\n## The Three Rules of Ownership\n\n1. **Each value has exactly one owner**\n   - Unlike Python where multiple variables can reference the same object\n   - When the owner goes out of scope, the value is dropped (freed)\n\n2. **Values are moved by default**\n   ```rust\n   let s1 = String::from(\"hello\");\n   let s2 = s1;  // s1 is moved to s2\n   // println!(\"{}\", s1); // ERROR! s1 no longer valid\n   ```\n\n3. **Only one mutable reference OR multiple immutable references**\n   ```rust\n   let mut data = vec![1, 2, 3];\n   let ref1 = &data;      // immutable borrow\n   let ref2 = &data;      // another immutable borrow - OK\n   // let ref3 = &mut data;  // ERROR! Can't have mutable with immutable\n   ```\n\n## Borrowing (Rust's \"References\")\n\nInstead of copying/moving, you can \"borrow\":\n\n```rust\nfn process_data(data: &Vec<i32>) {  // Borrowing, not taking ownership\n    println!(\"Length: {}\", data.len());\n    // data is automatically \"returned\" when function ends\n}\n\nlet my_data = vec![1, 2, 3];\nprocess_data(&my_data);  // Borrow my_data\nprintln!(\"{:?}\", my_data);  // Still accessible!\n```\n\n## Why This System?\n\n**Memory Safety Without Garbage Collection:**\n- No runtime overhead like Python's GC\n- No use-after-free bugs\n- No memory leaks (in safe Rust)\n- Predictable performance\n\n## Common Patterns for Python Developers\n\n**Cloning when you need multiple copies:**\n```rust\nlet original = String::from(\"hello\");\nlet copy = original.clone();  // Explicit copy\n// Now both original and copy are usable\n```\n\n**Using references for temporary access:**\n```rust\nfn print_length(s: &String) {\n    println!(\"Length: {}\", s.len());\n}\n\nlet my_string = String::from(\"hello\");\nprint_length(&my_string);  // Borrow\n// my_string still usable here\n```\n\n**Mutable borrowing for modification:**\n```rust\nfn add_exclamation(s: &mut String) {\n    s.push('!');\n}\n\nlet mut greeting = String::from(\"Hello\");\nadd_exclamation(&mut greeting);\nprintln!(\"{}\", greeting);  // \"Hello!\"\n```\n\n## Mental Model\n\nThink of ownership like:\n- **Python**: Multiple people can have keys to the same house\n- **Rust**: Only one person has the key at a time, but they can lend it temporarily\n\nThe borrow checker ensures:\n- No one modifies data while others are reading it\n- No one reads data while it's being modified\n- Memory is freed exactly when the owner is done\n\n## Tips for Transitioning\n\n1. **Start with borrowing (&)** - most functions should take references\n2. **Clone when stuck** - it's okay while learning\n3. **Use Rc<T> for shared ownership** - closer to Python's model\n4. **The compiler is your friend** - error messages guide you to the solution\n\nThe ownership system feels restrictive at first, but it prevents entire classes of bugs that are common in Python and other languages!",
    "tags": [
      "ownership",
      "borrowing",
      "python-comparison",
      "memory-management",
      "tutorial",
      "beginner",
      "explanation"
    ],
    "instruction": "Explain Rust's ownership system like I'm coming from Python"
  },
  {
    "output": "This is one of the most common Rust errors! Let me show you exactly what's happening and how to fix it.\n\n## What This Error Means\n\nRust's borrow checker enforces this rule:\n- You can have **many immutable borrows** (`&T`) OR\n- You can have **one mutable borrow** (`&mut T`)\n- But **NOT both at the same time**\n\n## Common Scenarios and Fixes\n\n### Scenario 1: Multiple References in Same Scope\n\n**\u274c This fails:**\n```rust\nlet mut vec = vec![1, 2, 3];\nlet first = &vec[0];        // immutable borrow\nvec.push(4);               // mutable borrow - ERROR!\nprintln!(\"First: {}\", first);\n```\n\n**\u2705 Fix: Limit borrow scope:**\n```rust\nlet mut vec = vec![1, 2, 3];\n{\n    let first = &vec[0];    // immutable borrow\n    println!(\"First: {}\", first);  // use it immediately\n}  // immutable borrow ends here\nvec.push(4);               // mutable borrow - OK!\n```\n\n**\u2705 Alternative: Copy the value:**\n```rust\nlet mut vec = vec![1, 2, 3];\nlet first = vec[0];         // copy the value, not a reference\nvec.push(4);               // OK! No borrows involved\nprintln!(\"First: {}\", first);\n```\n\n### Scenario 2: Method Calls\n\n**\u274c This fails:**\n```rust\nlet mut map = std::collections::HashMap::new();\nmap.insert(\"key\", vec![1, 2, 3]);\n\nlet values = map.get(\"key\").unwrap();  // immutable borrow\nmap.insert(\"key2\", vec![4, 5, 6]);    // mutable borrow - ERROR!\nprintln!(\"{:?}\", values);\n```\n\n**\u2705 Fix: Clone or limit scope:**\n```rust\nlet mut map = std::collections::HashMap::new();\nmap.insert(\"key\", vec![1, 2, 3]);\n\nlet values = map.get(\"key\").unwrap().clone();  // clone the data\nmap.insert(\"key2\", vec![4, 5, 6]);            // OK!\nprintln!(\"{:?}\", values);\n```\n\n### Scenario 3: Iteration and Modification\n\n**\u274c This fails:**\n```rust\nlet mut vec = vec![1, 2, 3, 4];\nfor item in &vec {          // immutable borrow of entire vec\n    if *item > 2 {\n        vec.push(*item * 2); // mutable borrow - ERROR!\n    }\n}\n```\n\n**\u2705 Fix: Collect indices first:**\n```rust\nlet mut vec = vec![1, 2, 3, 4];\nlet indices_to_process: Vec<usize> = vec.iter()\n    .enumerate()\n    .filter(|(_, &value)| value > 2)\n    .map(|(i, _)| i)\n    .collect();\n\nfor &index in &indices_to_process {\n    vec.push(vec[index] * 2);\n}\n```\n\n**\u2705 Alternative: Use drain or retain:**\n```rust\nlet mut vec = vec![1, 2, 3, 4];\nlet to_add: Vec<i32> = vec.iter()\n    .filter(|&&x| x > 2)\n    .map(|&x| x * 2)\n    .collect();\nvec.extend(to_add);\n```\n\n### Scenario 4: Struct Fields\n\n**\u274c This fails:**\n```rust\nstruct Container {\n    data: Vec<i32>,\n    name: String,\n}\n\nlet mut container = Container {\n    data: vec![1, 2, 3],\n    name: \"test\".to_string(),\n};\n\nlet data_ref = &container.data;     // immutable borrow\ncontainer.name.push_str(\"_updated\"); // mutable borrow - ERROR!\nprintln!(\"{:?}\", data_ref);\n```\n\n**\u2705 Fix: Borrow fields separately:**\n```rust\nstruct Container {\n    data: Vec<i32>,\n    name: String,\n}\n\nlet mut container = Container {\n    data: vec![1, 2, 3],\n    name: \"test\".to_string(),\n};\n\nlet data_ref = &container.data;     // borrow just this field\nlet name_ref = &mut container.name; // borrow just this field - OK!\nname_ref.push_str(\"_updated\");\nprintln!(\"{:?}\", data_ref);\n```\n\n## General Strategies\n\n### 1. **Minimize Borrow Scope**\n```rust\n// Instead of this:\nlet mut data = vec![1, 2, 3];\nlet first = &data[0];\n// ... lots of code ...\ndata.push(4);  // ERROR: first still borrowed\n\n// Do this:\nlet mut data = vec![1, 2, 3];\n{\n    let first = &data[0];\n    // use first immediately\n}\ndata.push(4);  // OK: first borrow ended\n```\n\n### 2. **Clone When Necessary**\n```rust\nlet mut data = vec![1, 2, 3];\nlet first = data[0];  // copy instead of borrow\ndata.push(4);         // OK!\n```\n\n### 3. **Restructure Your Logic**\n```rust\n// Instead of modifying while iterating:\nfor item in &collection {\n    if condition {\n        collection.modify();  // ERROR!\n    }\n}\n\n// Collect what to do first:\nlet actions: Vec<_> = collection.iter()\n    .enumerate()\n    .filter(|(_, item)| condition)\n    .collect();\n\nfor (index, _) in actions {\n    collection.modify_at(index);\n}\n```\n\n### 4. **Use Entry API for Maps**\n```rust\n// Instead of:\nif !map.contains_key(&key) {  // immutable borrow\n    map.insert(key, value);   // mutable borrow - ERROR!\n}\n\n// Use entry API:\nmap.entry(key).or_insert(value);  // Single operation\n```\n\n## Quick Debug Tips\n\n1. **Look for the lifetimes** - where does each borrow start and end?\n2. **Can you copy instead of borrow?** - for simple types like `i32`, `bool`\n3. **Can you restructure?** - often there's a more idiomatic way\n4. **Use `{}` blocks** - to limit scope of borrows\n5. **Consider `Rc<T>` or `Arc<T>`** - for shared ownership scenarios\n\nThe borrow checker is protecting you from data races and use-after-free bugs. Once you get used to thinking in terms of ownership and borrowing, these patterns become natural!",
    "tags": [
      "borrow-checker",
      "error-fixing",
      "debugging",
      "mutable-borrow",
      "immutable-borrow",
      "troubleshooting",
      "common-errors"
    ],
    "instruction": "How do I fix this Rust error: 'cannot borrow as mutable because it is also borrowed as immutable'?"
  },
  {
    "output": "Excellent question! This is one of the most important decisions when designing Rust APIs. Here's the practical guide:\n\n## The Golden Rule\n\n**For function parameters: Use `&str` unless you need to own the string.**\n\n## Why `&str` is Usually Better\n\n```rust\n// \u2705 Good: Accepts any string type\nfn process_text(text: &str) {\n    println!(\"Processing: {}\", text);\n}\n\n// Works with all of these:\nprocess_text(\"string literal\");           // &str\nprocess_text(&String::from(\"owned\"));     // &String -> &str\nprocess_text(&my_string[2..5]);          // string slice\n```\n\n```rust\n// \u274c Less flexible: Only accepts owned strings\nfn process_text_owned(text: String) {\n    println!(\"Processing: {}\", text);\n}\n\n// Caller must give up ownership or clone:\nlet my_string = String::from(\"hello\");\nprocess_text_owned(my_string.clone());  // Expensive clone\n// my_string is still usable\n\n// OR\nprocess_text_owned(my_string);  // Give up ownership\n// my_string is no longer usable!\n```\n\n## When to Use Each\n\n### Use `&str` when:\n- \u2705 **Just reading/processing the string**\n- \u2705 **Maximum flexibility for callers**\n- \u2705 **Best performance (no cloning)**\n\n```rust\nfn validate_email(email: &str) -> bool {\n    email.contains('@') && email.contains('.')\n}\n\nfn format_name(first: &str, last: &str) -> String {\n    format!(\"{} {}\", first, last)\n}\n\nfn count_words(text: &str) -> usize {\n    text.split_whitespace().count()\n}\n```\n\n### Use `String` when:\n- \u2705 **Need to own/store the string**\n- \u2705 **Will modify the string**\n- \u2705 **Need the string to outlive the function**\n\n```rust\nfn make_greeting(name: String) -> String {\n    format!(\"Hello, {}!\", name)  // Using the owned string\n}\n\nfn collect_names(mut names: Vec<String>, new_name: String) -> Vec<String> {\n    names.push(new_name);  // Taking ownership\n    names\n}\n\nstruct User {\n    name: String,  // Struct owns the string\n    email: String,\n}\n\nimpl User {\n    fn new(name: String, email: String) -> Self {\n        User { name, email }  // Taking ownership\n    }\n}\n```\n\n## Real-World Examples\n\n### Configuration Function\n```rust\n// \u2705 Good: Flexible input\nfn load_config(filename: &str) -> Result<Config, Error> {\n    std::fs::read_to_string(filename)  // &str works with fs functions\n        .map_err(|e| Error::Io(e))\n        .and_then(|content| parse_config(&content))\n}\n\n// Usage:\nload_config(\"config.toml\");              // string literal\nload_config(&config_path);               // borrowed String\nload_config(&format!(\"app-{}.toml\", env)); // temporary string\n```\n\n### Data Processing Pipeline\n```rust\n// \u2705 Good: Chain operations without ownership issues\nfn process_pipeline(input: &str) -> String {\n    input\n        .trim()              // &str -> &str\n        .to_lowercase()      // &str -> String\n        .replace(\" \", \"_\")   // String -> String\n}\n\n// Usage:\nlet result1 = process_pipeline(&user_input);\nlet result2 = process_pipeline(\"Raw Data\");\n// user_input is still available!\n```\n\n### Builder Pattern\n```rust\nstruct EmailBuilder {\n    to: Option<String>,\n    subject: Option<String>,\n    body: Option<String>,\n}\n\nimpl EmailBuilder {\n    // Take ownership - we're storing these\n    fn to(mut self, address: String) -> Self {\n        self.to = Some(address);\n        self\n    }\n    \n    // But also provide convenience method\n    fn to_str(mut self, address: &str) -> Self {\n        self.to = Some(address.to_string());\n        self\n    }\n}\n```\n\n## Advanced: `impl AsRef<str>`\n\nFor ultimate flexibility, use `AsRef<str>`:\n\n```rust\nfn super_flexible<S: AsRef<str>>(text: S) {\n    let text_str = text.as_ref();  // Convert to &str\n    println!(\"Text: {}\", text_str);\n}\n\n// Works with:\nsuper_flexible(\"literal\");           // &str\nsuper_flexible(String::from(\"owned\")); // String\nsuper_flexible(&my_string);          // &String\n```\n\n## Performance Comparison\n\n```rust\n// Performance test scenario\nlet data = vec![\"item1\", \"item2\", \"item3\"];\n\n// \u2705 Fast: No allocations\nfn process_borrowed(items: &[&str]) {\n    for item in items {\n        validate_item(item);  // &str parameter\n    }\n}\n\n// \u274c Slow: Clones every string\nfn process_owned(items: &[&str]) {\n    for item in items {\n        validate_item_owned(item.to_string());  // String parameter\n    }\n}\n```\n\n## Quick Decision Tree\n\n```\nDo you need to store the string? \n\u251c\u2500 Yes \u2192 Use String\n\u2514\u2500 No \u2192 Do you need to modify it?\n   \u251c\u2500 Yes \u2192 Use String  \n   \u2514\u2500 No \u2192 Use &str\n```\n\n## Common Patterns\n\n### Converting Between Them\n```rust\n// &str to String\nlet owned = my_str.to_string();\nlet owned = String::from(my_str);\nlet owned = my_str.to_owned();\n\n// String to &str (automatic with &)\nlet borrowed = &my_string;\nlet borrowed = my_string.as_str();\n```\n\n### API Design Best Practice\n```rust\n// \u2705 Best: Provide both when it makes sense\nimpl MyStruct {\n    fn set_name(&mut self, name: String) {\n        self.name = name;\n    }\n    \n    fn set_name_str(&mut self, name: &str) {\n        self.name = name.to_string();\n    }\n}\n\n// Or use Into<String>\nfn set_name<S: Into<String>>(&mut self, name: S) {\n    self.name = name.into();\n}\n```\n\n## Summary\n\n- **Default choice: `&str`** for parameters (more flexible)\n- **Use `String`** when you need ownership\n- **Consider `AsRef<str>` or `Into<String>`** for ultimate flexibility\n- **Think about your callers** - make their life easier\n- **Performance matters** - avoid unnecessary clones\n\nThe Rust community strongly favors `&str` parameters because they're more ergonomic for callers and more efficient. When in doubt, start with `&str`!",
    "tags": [
      "string-types",
      "api-design",
      "parameters",
      "performance",
      "str-vs-string",
      "best-practices",
      "ergonomics"
    ],
    "instruction": "Should I use String or &str in my function parameters?"
  },
  {
    "output": "You're absolutely right to be suspicious! Using `unwrap()` everywhere is indeed considered bad practice in production Rust code. Let me explain why and show you better alternatives.\n\n## What `unwrap()` Does\n\n`unwrap()` extracts the value from `Option<T>` or `Result<T, E>`, but **panics if there's an error**:\n\n```rust\nlet maybe_number: Option<i32> = Some(42);\nlet number = maybe_number.unwrap(); // Gets 42\n\nlet no_number: Option<i32> = None;\nlet number = no_number.unwrap(); // \ud83d\udca5 PANIC! Program crashes\n```\n\n## Why You See It in Examples\n\n**Examples use `unwrap()` because:**\n- \u2705 Keeps example code short and focused\n- \u2705 Avoids distracting error handling boilerplate\n- \u2705 Fine for throwaway code and learning\n\n```rust\n// Example code - focused on the main concept\nlet file_content = std::fs::read_to_string(\"config.txt\").unwrap();\nlet parsed: Config = serde_json::from_str(&file_content).unwrap();\n// \"Trust me, these work for the demo\"\n```\n\n## When `unwrap()` is Actually OK\n\n### 1. **Prototyping and Learning**\n```rust\n// Fine while exploring and learning\nfn main() {\n    let numbers = vec![\"1\", \"2\", \"3\"];\n    let parsed: Vec<i32> = numbers.iter().map(|s| s.parse().unwrap()).collect();\n    println!(\"{:?}\", parsed);\n}\n```\n\n### 2. **When You're 100% Certain It Won't Fail**\n```rust\n// OK: We know this slice is not empty\nlet numbers = vec![1, 2, 3, 4, 5];\nlet first = numbers.first().unwrap(); // Vec is definitely not empty\n\n// OK: We just checked it exists\nif env::var(\"HOME\").is_ok() {\n    let home = env::var(\"HOME\").unwrap(); // We just verified it exists\n}\n```\n\n### 3. **Tests**\n```rust\n#[test]\nfn test_parsing() {\n    let result = parse_number(\"42\").unwrap(); // Test should fail if this fails\n    assert_eq!(result, 42);\n}\n```\n\n## Better Alternatives to `unwrap()`\n\n### 1. **Pattern Matching**\n```rust\n// Instead of unwrap()\nlet file_result = std::fs::read_to_string(\"config.txt\");\nmatch file_result {\n    Ok(content) => {\n        println!(\"File content: {}\", content);\n        // Process the file\n    }\n    Err(error) => {\n        eprintln!(\"Failed to read file: {}\", error);\n        // Handle the error appropriately\n    }\n}\n```\n\n### 2. **`if let` for Simple Cases**\n```rust\n// Gracefully handle missing values\nif let Some(user) = find_user_by_id(123) {\n    println!(\"Found user: {}\", user.name);\n} else {\n    println!(\"User not found\");\n}\n\n// Handle errors without crashing\nif let Ok(config) = load_config() {\n    app.configure(config);\n} else {\n    app.use_default_config();\n}\n```\n\n### 3. **`unwrap_or()` and `unwrap_or_else()`**\n```rust\n// Provide default values\nlet timeout = config.get_timeout().unwrap_or(30); // Default to 30 seconds\nlet user_name = user.name.unwrap_or_else(|| \"Anonymous\".to_string());\n\n// Compute defaults lazily\nlet cache_size = config.cache_size.unwrap_or_else(|| {\n    // Only compute if needed\n    calculate_optimal_cache_size()\n});\n```\n\n### 4. **`?` Operator for Error Propagation**\n```rust\n// Propagate errors up the call stack\nfn load_user_config(user_id: u32) -> Result<Config, ConfigError> {\n    let user = database::find_user(user_id)?;     // Propagate DB errors\n    let config_path = user.config_path()?;        // Propagate path errors  \n    let config_data = std::fs::read_to_string(config_path)?; // Propagate IO errors\n    let config = parse_config(&config_data)?;    // Propagate parse errors\n    Ok(config)\n}\n```\n\n### 5. **`expect()` with Meaningful Messages**\n```rust\n// Better than unwrap() - explains WHY it should work\nlet config = load_config()\n    .expect(\"Config file should exist - check installation\");\n\nlet first_arg = std::env::args().nth(1)\n    .expect(\"Usage: program <input_file>\");\n```\n\n## Real-World Error Handling Patterns\n\n### Web API Response\n```rust\nuse serde_json;\n\n// \u274c Bad: Will crash on any error\nfn handle_request_bad(body: &str) -> String {\n    let request: Request = serde_json::from_str(body).unwrap();\n    let result = process_request(request).unwrap();\n    serde_json::to_string(&result).unwrap()\n}\n\n// \u2705 Good: Proper error handling\nfn handle_request_good(body: &str) -> Result<String, ApiError> {\n    let request: Request = serde_json::from_str(body)\n        .map_err(|e| ApiError::InvalidJson(e))?;\n    \n    let result = process_request(request)\n        .map_err(|e| ApiError::ProcessingFailed(e))?;\n    \n    serde_json::to_string(&result)\n        .map_err(|e| ApiError::SerializationFailed(e))\n}\n```\n\n### File Processing\n```rust\n// \u274c Bad: Crashes on missing file\nfn process_file_bad(path: &str) {\n    let content = std::fs::read_to_string(path).unwrap();\n    let lines: Vec<&str> = content.lines().collect();\n    // process lines...\n}\n\n// \u2705 Good: Graceful handling\nfn process_file_good(path: &str) -> Result<(), Box<dyn std::error::Error>> {\n    match std::fs::read_to_string(path) {\n        Ok(content) => {\n            let lines: Vec<&str> = content.lines().collect();\n            // process lines...\n            Ok(())\n        }\n        Err(e) => {\n            eprintln!(\"Failed to read {}: {}\", path, e);\n            Err(e.into())\n        }\n    }\n}\n```\n\n### Configuration Loading\n```rust\n#[derive(Default)]\nstruct AppConfig {\n    port: u16,\n    host: String,\n    timeout: u64,\n}\n\n// \u2705 Good: Fallbacks and validation\nfn load_app_config() -> AppConfig {\n    let mut config = AppConfig::default();\n    \n    // Try to load from file, fallback to defaults\n    if let Ok(config_str) = std::fs::read_to_string(\"app.toml\") {\n        if let Ok(loaded_config) = toml::from_str(&config_str) {\n            config = loaded_config;\n        } else {\n            eprintln!(\"Warning: Invalid config file, using defaults\");\n        }\n    }\n    \n    // Override with environment variables\n    if let Ok(port_str) = std::env::var(\"APP_PORT\") {\n        config.port = port_str.parse().unwrap_or(config.port);\n    }\n    \n    config\n}\n```\n\n## Quick Guidelines\n\n### \u2705 OK to use `unwrap()`:\n- Example code and tutorials\n- Prototypes and experiments\n- Tests (where failure is informative)\n- When you've just verified the value exists\n- Internal assertions that \"should never fail\"\n\n### \u274c Avoid `unwrap()` in production:\n- Library code (let callers handle errors)\n- Network operations (can always fail)\n- File I/O (files might not exist)\n- User input parsing (users make mistakes)\n- Configuration loading (configs can be malformed)\n\n### \ud83c\udfaf Better alternatives:\n- `?` operator for error propagation\n- `match` or `if let` for explicit handling\n- `unwrap_or()` for defaults\n- `expect()` with helpful messages\n- Custom error types for better error handling\n\n## The Rust Way\n\n**Rust's philosophy:** Make errors explicit and force you to think about them. `unwrap()` bypasses this philosophy, so use it sparingly!\n\n```rust\n// This is idiomatic Rust - errors are part of the API\nfn might_fail() -> Result<String, MyError> {\n    // Implementation that might fail\n}\n\n// Callers must explicitly handle the possibility of failure\nmatch might_fail() {\n    Ok(value) => { /* success case */ }\n    Err(error) => { /* error case */ }\n}\n```\n\nRemember: A program that crashes with a clear error message is often better than a program that continues with corrupted state!",
    "tags": [
      "unwrap",
      "error-handling",
      "best-practices",
      "panic",
      "result",
      "option",
      "production-code",
      "reliability"
    ],
    "instruction": "I keep seeing 'unwrap()' everywhere in Rust examples. Is this bad practice?"
  },
  {
    "output": "Great question! Vec<T> and arrays serve different purposes in Rust, and understanding when to use each is crucial for writing efficient code.\n\n## The Key Differences\n\n| Feature | Array `[T; N]` | Vec `Vec<T>` |\n|---------|----------------|---------------|\n| **Size** | Fixed at compile time | Dynamic, grows/shrinks |\n| **Memory** | Stack allocated | Heap allocated |\n| **Performance** | Fastest access | Slight overhead |\n| **Flexibility** | Cannot change size | Can push/pop elements |\n| **Type** | `[i32; 5]` | `Vec<i32>` |\n\n## Arrays: Fixed Size, Maximum Performance\n\n```rust\n// Array: size known at compile time\nlet numbers: [i32; 5] = [1, 2, 3, 4, 5];\nlet zeros = [0; 100];  // 100 zeros\nlet first = numbers[0]; // Direct memory access - super fast\n\nprintln!(\"Array length: {}\", numbers.len()); // Always 5\n// numbers.push(6); // \u274c ERROR: Cannot modify size\n```\n\n**Arrays are perfect for:**\n- \u2705 **Known, fixed data sizes** (RGB colors, coordinates, etc.)\n- \u2705 **Maximum performance** (no heap allocation)\n- \u2705 **Embedded systems** (predictable memory usage)\n- \u2705 **Mathematical operations** (vectors, matrices)\n- \u2705 **Lookup tables** (constant data)\n\n## Vec: Dynamic Size, Maximum Flexibility\n\n```rust\n// Vec: size can change at runtime\nlet mut numbers = vec![1, 2, 3, 4, 5];\nnumbers.push(6);        // \u2705 Can grow\nnumbers.pop();          // \u2705 Can shrink\nnumbers[0] = 10;        // \u2705 Can modify elements\n\nprintln!(\"Vec length: {}\", numbers.len()); // Can be any size\n```\n\n**Vec is perfect for:**\n- \u2705 **Unknown size at compile time**\n- \u2705 **Data that grows/shrinks** (user input, file contents)\n- \u2705 **Collections that need modification**\n- \u2705 **Most general-purpose use cases**\n\n## Real-World Examples\n\n### Use Arrays For:\n\n**1. Color Representation**\n```rust\n// RGB color always has exactly 3 components\nstruct Color {\n    rgb: [u8; 3],  // Always red, green, blue\n}\n\nlet red = Color { rgb: [255, 0, 0] };\nlet pixel_data: [Color; 1920] = [red; 1920]; // Fixed-size row\n```\n\n**2. Coordinate Systems**\n```rust\n// 3D point always has x, y, z\ntype Point3D = [f64; 3];\ntype Matrix4x4 = [[f64; 4]; 4];\n\nfn dot_product(a: Point3D, b: Point3D) -> f64 {\n    a[0] * b[0] + a[1] * b[1] + a[2] * b[2]\n}\n```\n\n**3. Lookup Tables**\n```rust\n// Days in each month (non-leap year)\nconst DAYS_IN_MONTH: [u8; 12] = [31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31];\n\nfn days_in_month(month: usize) -> u8 {\n    DAYS_IN_MONTH[month - 1]  // Super fast lookup\n}\n```\n\n**4. Buffer with Known Size**\n```rust\n// Network packet buffer\nstruct Packet {\n    header: [u8; 20],   // TCP header is always 20 bytes\n    data: Vec<u8>,      // Payload can vary\n}\n```\n\n### Use Vec For:\n\n**1. User Input Processing**\n```rust\n// Don't know how many items user will enter\nfn collect_user_names() -> Vec<String> {\n    let mut names = Vec::new();\n    \n    loop {\n        let mut input = String::new();\n        io::stdin().read_line(&mut input).unwrap();\n        \n        if input.trim().is_empty() {\n            break;\n        }\n        \n        names.push(input.trim().to_string());\n    }\n    \n    names\n}\n```\n\n**2. File Processing**\n```rust\n// File can have any number of lines\nfn read_lines(filename: &str) -> Result<Vec<String>, io::Error> {\n    let content = std::fs::read_to_string(filename)?;\n    Ok(content.lines().map(|s| s.to_string()).collect())\n}\n```\n\n**3. Dynamic Data Structures**\n```rust\n// Shopping cart can have any number of items\nstruct ShoppingCart {\n    items: Vec<Item>,\n    total: f64,\n}\n\nimpl ShoppingCart {\n    fn add_item(&mut self, item: Item) {\n        self.total += item.price;\n        self.items.push(item);\n    }\n    \n    fn remove_item(&mut self, index: usize) -> Option<Item> {\n        if index < self.items.len() {\n            let item = self.items.remove(index);\n            self.total -= item.price;\n            Some(item)\n        } else {\n            None\n        }\n    }\n}\n```\n\n## Performance Considerations\n\n### Arrays are Faster For:\n```rust\n// Stack allocation - no heap overhead\nfn sum_array(arr: &[i32; 1000]) -> i32 {\n    arr.iter().sum()  // Memory is contiguous on stack\n}\n\n// Compile-time optimizations\nfn process_rgb(color: [u8; 3]) {\n    // Compiler knows exact size, can optimize aggressively\n    for &component in &color {\n        // Process each component\n    }\n}\n```\n\n### Vec is More Flexible:\n```rust\n// Can grow as needed\nfn collect_results() -> Vec<i32> {\n    let mut results = Vec::new();\n    \n    for i in 0..1000 {\n        if complex_condition(i) {\n            results.push(process(i));\n        }\n    }\n    \n    results  // Return whatever we found\n}\n```\n\n## Converting Between Them\n\n```rust\n// Array to Vec\nlet arr = [1, 2, 3, 4, 5];\nlet vec = arr.to_vec();        // Copy into Vec\nlet vec = Vec::from(arr);      // Alternative syntax\n\n// Vec to Array (if size matches)\nlet vec = vec![1, 2, 3];\nlet arr: [i32; 3] = vec.try_into().unwrap(); // Runtime check\n\n// Slice to Array (known size)\nlet slice = &vec[0..3];\nlet arr: [i32; 3] = slice.try_into().unwrap();\n```\n\n## Common Patterns\n\n### Fixed-Size Working with Variable Data\n```rust\n// Process data in fixed-size chunks\nfn process_in_batches(data: Vec<u8>) {\n    for chunk in data.chunks(1024) {\n        let mut buffer = [0u8; 1024];\n        let len = chunk.len().min(1024);\n        buffer[..len].copy_from_slice(&chunk[..len]);\n        \n        // Process fixed-size buffer\n        process_buffer(&buffer[..len]);\n    }\n}\n```\n\n### Collecting into Arrays\n```rust\n// When you know the result size\nfn parse_rgb(input: &str) -> Result<[u8; 3], ParseError> {\n    let parts: Vec<u8> = input\n        .split(',')\n        .map(|s| s.parse())\n        .collect::<Result<Vec<_>, _>>()?;\n    \n    if parts.len() != 3 {\n        return Err(ParseError::WrongLength);\n    }\n    \n    Ok([parts[0], parts[1], parts[2]])\n}\n```\n\n## Decision Tree\n\n```\nDo you know the size at compile time?\n\u251c\u2500 Yes \u2192 Will the size ever change?\n\u2502  \u251c\u2500 No \u2192 Use Array [T; N]\n\u2502  \u2514\u2500 Yes \u2192 Use Vec<T>\n\u2514\u2500 No \u2192 Use Vec<T>\n\nIs performance absolutely critical?\n\u251c\u2500 Yes \u2192 Can you use a fixed size?\n\u2502  \u251c\u2500 Yes \u2192 Use Array [T; N] \n\u2502  \u2514\u2500 No \u2192 Use Vec<T> with pre-allocation\n\u2514\u2500 No \u2192 Use Vec<T> (easier to work with)\n```\n\n## Best Practices\n\n### 1. **Start with Vec, optimize to Array if needed**\n```rust\n// Start with this (flexible)\nfn process_data(items: Vec<Item>) -> Vec<Result> {\n    // Implementation\n}\n\n// Optimize to this if size is always known\nfn process_data_optimized(items: [Item; 10]) -> [Result; 10] {\n    // More efficient implementation\n}\n```\n\n### 2. **Use slices for function parameters**\n```rust\n// \u2705 Good: Works with both arrays and Vec\nfn sum_numbers(numbers: &[i32]) -> i32 {\n    numbers.iter().sum()\n}\n\n// Usage:\nlet arr = [1, 2, 3, 4, 5];\nlet vec = vec![1, 2, 3, 4, 5];\n\nsum_numbers(&arr);  // Works\nsum_numbers(&vec);  // Also works\n```\n\n### 3. **Consider using const generics for flexible arrays**\n```rust\n// Modern Rust: Generic over array size\nfn process_array<const N: usize>(arr: [i32; N]) -> i32 {\n    arr.iter().sum()\n}\n\n// Works with any array size\nlet small = [1, 2, 3];\nlet large = [1; 1000];\n\nprocess_array(small);  // N = 3\nprocess_array(large);  // N = 1000\n```\n\n## Summary\n\n- **Arrays**: Use for fixed, known sizes where performance matters\n- **Vec**: Use for dynamic data that can grow/shrink\n- **Start with Vec**: It's more flexible and easier to work with\n- **Optimize to arrays**: When you have performance requirements\n- **Use slices in APIs**: `&[T]` works with both arrays and Vec\n\nIn most cases, you'll use Vec<T> because it's more flexible. Use arrays when you have a specific performance requirement or when the size is truly fixed by the problem domain (like coordinates, color components, or protocol headers).",
    "tags": [
      "vec",
      "arrays",
      "performance",
      "memory-layout",
      "data-structures",
      "stack-vs-heap",
      "comparison",
      "best-practices"
    ],
    "instruction": "Why does Rust have both Vec<T> and arrays? When should I use each?"
  },
  {
    "output": "Absolutely! Async/await in Rust can be confusing at first, especially coming from other languages. Let me walk you through it step by step with a web API example.\n\n## What is Async/Await?\n\nAsync/await allows you to write non-blocking code that looks like synchronous code. Instead of blocking threads while waiting for I/O operations (like database queries or HTTP requests), your program can do other work.\n\n```rust\n// Without async - blocks the thread\nfn get_user_sync(id: u32) -> User {\n    let db_result = database::query(&format!(\"SELECT * FROM users WHERE id = {}\", id));\n    // Thread is blocked waiting for database\n    parse_user(db_result)\n}\n\n// With async - thread can do other work while waiting\nasync fn get_user_async(id: u32) -> User {\n    let db_result = database::query(&format!(\"SELECT * FROM users WHERE id = {}\", id)).await;\n    // .await yields control back to the runtime\n    parse_user(db_result)\n}\n```\n\n## Setting Up Your Web API\n\nLet's build a simple web API using Tokio (the most popular async runtime) and Axum (a modern web framework):\n\n```toml\n# Cargo.toml\n[dependencies]\ntokio = { version = \"1.0\", features = [\"full\"] }\naxum = \"0.7\"\nserde = { version = \"1.0\", features = [\"derive\"] }\nserde_json = \"1.0\"\nsqlx = { version = \"0.7\", features = [\"runtime-tokio-rustls\", \"postgres\"] }\n```\n\n```rust\n// main.rs\nuse axum::{\n    extract::{Path, State},\n    http::StatusCode,\n    response::Json,\n    routing::{get, post},\n    Router,\n};\nuse serde::{Deserialize, Serialize};\nuse std::collections::HashMap;\nuse tokio::time::{sleep, Duration};\n\n#[derive(Serialize, Deserialize, Clone)]\nstruct User {\n    id: u32,\n    name: String,\n    email: String,\n}\n\n#[derive(Clone)]\nstruct AppState {\n    users: std::sync::Arc<tokio::sync::Mutex<HashMap<u32, User>>>,\n}\n\n#[tokio::main]  // This macro sets up the async runtime\nasync fn main() {\n    // Initialize shared state\n    let state = AppState {\n        users: std::sync::Arc::new(tokio::sync::Mutex::new(HashMap::new())),\n    };\n    \n    // Build our application with routes\n    let app = Router::new()\n        .route(\"/users/:id\", get(get_user))\n        .route(\"/users\", post(create_user))\n        .route(\"/users/:id/slow\", get(get_user_slow))\n        .with_state(state);\n    \n    println!(\"Server running on http://localhost:3000\");\n    \n    // Start the server\n    let listener = tokio::net::TcpListener::bind(\"0.0.0.0:3000\").await.unwrap();\n    axum::serve(listener, app).await.unwrap();\n}\n```\n\n## Your First Async Handler\n\n```rust\n// Simple async handler\nasync fn get_user(\n    Path(user_id): Path<u32>,\n    State(state): State<AppState>,\n) -> Result<Json<User>, StatusCode> {\n    println!(\"Looking up user {}\", user_id);\n    \n    // Lock the mutex asynchronously\n    let users = state.users.lock().await;\n    \n    match users.get(&user_id) {\n        Some(user) => {\n            println!(\"Found user: {}\", user.name);\n            Ok(Json(user.clone()))\n        }\n        None => {\n            println!(\"User {} not found\", user_id);\n            Err(StatusCode::NOT_FOUND)\n        }\n    }\n}\n```\n\n**Key points:**\n- `async fn` makes the function asynchronous\n- `.await` is where the function can yield control\n- Other requests can be processed while this one waits\n\n## Understanding .await\n\n```rust\n// This handler simulates a slow database call\nasync fn get_user_slow(\n    Path(user_id): Path<u32>,\n    State(state): State<AppState>,\n) -> Result<Json<User>, StatusCode> {\n    println!(\"[{}] Starting slow lookup\", user_id);\n    \n    // Simulate slow database query\n    sleep(Duration::from_secs(2)).await;  // This doesn't block other requests!\n    \n    println!(\"[{}] Database query completed\", user_id);\n    \n    let users = state.users.lock().await;\n    match users.get(&user_id) {\n        Some(user) => Ok(Json(user.clone())),\n        None => Err(StatusCode::NOT_FOUND),\n    }\n}\n```\n\n**Try this:** Start the server and make multiple requests to `/users/1/slow` simultaneously. You'll see they all start processing immediately, rather than waiting for each other!\n\n## Creating Users (POST endpoint)\n\n```rust\nasync fn create_user(\n    State(state): State<AppState>,\n    Json(mut user): Json<User>,\n) -> Result<Json<User>, StatusCode> {\n    println!(\"Creating user: {}\", user.name);\n    \n    // Simulate validation with async call\n    if !validate_email(&user.email).await {\n        return Err(StatusCode::BAD_REQUEST);\n    }\n    \n    // Generate ID (in real app, this would be from database)\n    let mut users = state.users.lock().await;\n    let new_id = users.len() as u32 + 1;\n    user.id = new_id;\n    \n    users.insert(new_id, user.clone());\n    println!(\"User {} created with ID {}\", user.name, new_id);\n    \n    Ok(Json(user))\n}\n\n// Async helper function\nasync fn validate_email(email: &str) -> bool {\n    // Simulate async email validation (maybe calling external API)\n    sleep(Duration::from_millis(100)).await;\n    email.contains('@') && email.contains('.')\n}\n```\n\n## Error Handling in Async Code\n\n```rust\nuse thiserror::Error;\n\n#[derive(Error, Debug)]\nenum ApiError {\n    #[error(\"User not found\")]\n    UserNotFound,\n    #[error(\"Database error: {0}\")]\n    Database(String),\n    #[error(\"Validation failed: {0}\")]\n    Validation(String),\n}\n\n// Convert our error to HTTP response\nimpl axum::response::IntoResponse for ApiError {\n    fn into_response(self) -> axum::response::Response {\n        let (status, error_message) = match self {\n            ApiError::UserNotFound => (StatusCode::NOT_FOUND, \"User not found\"),\n            ApiError::Database(_) => (StatusCode::INTERNAL_SERVER_ERROR, \"Database error\"),\n            ApiError::Validation(_) => (StatusCode::BAD_REQUEST, \"Validation error\"),\n        };\n        \n        (status, Json(serde_json::json!({\n            \"error\": error_message,\n            \"details\": self.to_string()\n        }))).into_response()\n    }\n}\n\n// Better error handling\nasync fn get_user_with_errors(\n    Path(user_id): Path<u32>,\n    State(state): State<AppState>,\n) -> Result<Json<User>, ApiError> {\n    // Simulate database operation that might fail\n    if user_id == 999 {\n        return Err(ApiError::Database(\"Connection timeout\".to_string()));\n    }\n    \n    let users = state.users.lock().await;\n    users.get(&user_id)\n        .cloned()\n        .map(Json)\n        .ok_or(ApiError::UserNotFound)\n}\n```\n\n## Working with Real Databases\n\n```rust\nuse sqlx::{PgPool, Row};\n\n// Database connection\n#[derive(Clone)]\nstruct DatabaseState {\n    pool: PgPool,\n}\n\nasync fn get_user_from_db(\n    Path(user_id): Path<u32>,\n    State(state): State<DatabaseState>,\n) -> Result<Json<User>, ApiError> {\n    let user = sqlx::query(\n        \"SELECT id, name, email FROM users WHERE id = $1\"\n    )\n    .bind(user_id)\n    .fetch_optional(&state.pool)  // This is async!\n    .await\n    .map_err(|e| ApiError::Database(e.to_string()))?;\n    \n    match user {\n        Some(row) => {\n            let user = User {\n                id: row.get(\"id\"),\n                name: row.get(\"name\"),\n                email: row.get(\"email\"),\n            };\n            Ok(Json(user))\n        }\n        None => Err(ApiError::UserNotFound),\n    }\n}\n```\n\n## Concurrent Operations\n\n```rust\nuse tokio::try_join;\n\n// Fetch user and their posts concurrently\nasync fn get_user_with_posts(\n    Path(user_id): Path<u32>,\n    State(state): State<DatabaseState>,\n) -> Result<Json<serde_json::Value>, ApiError> {\n    // Both queries run concurrently!\n    let (user_result, posts_result) = try_join!(\n        get_user_by_id(&state.pool, user_id),\n        get_posts_by_user_id(&state.pool, user_id)\n    )?;\n    \n    Ok(Json(serde_json::json!({\n        \"user\": user_result,\n        \"posts\": posts_result\n    })))\n}\n\nasync fn get_user_by_id(pool: &PgPool, user_id: u32) -> Result<User, sqlx::Error> {\n    sqlx::query_as!(User, \"SELECT id, name, email FROM users WHERE id = $1\", user_id)\n        .fetch_one(pool)\n        .await\n}\n\nasync fn get_posts_by_user_id(pool: &PgPool, user_id: u32) -> Result<Vec<Post>, sqlx::Error> {\n    sqlx::query_as!(Post, \"SELECT id, title, content FROM posts WHERE user_id = $1\", user_id)\n        .fetch_all(pool)\n        .await\n}\n```\n\n## Testing Async Code\n\n```rust\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use axum::{\n        body::Body,\n        http::{Request, StatusCode},\n    };\n    use tower::ServiceExt; // for `oneshot`\n    \n    #[tokio::test]  // Use tokio::test for async tests\n    async fn test_get_user() {\n        let state = AppState {\n            users: std::sync::Arc::new(tokio::sync::Mutex::new(HashMap::new())),\n        };\n        \n        // Add test user\n        {\n            let mut users = state.users.lock().await;\n            users.insert(1, User {\n                id: 1,\n                name: \"Test User\".to_string(),\n                email: \"test@example.com\".to_string(),\n            });\n        }\n        \n        let app = Router::new()\n            .route(\"/users/:id\", get(get_user))\n            .with_state(state);\n        \n        let response = app\n            .oneshot(\n                Request::builder()\n                    .uri(\"/users/1\")\n                    .body(Body::empty())\n                    .unwrap(),\n            )\n            .await\n            .unwrap();\n        \n        assert_eq!(response.status(), StatusCode::OK);\n    }\n}\n```\n\n## Common Pitfalls and Solutions\n\n### 1. **Blocking in Async Context**\n```rust\n// \u274c Don't do this - blocks the entire thread\nasync fn bad_example() {\n    std::thread::sleep(Duration::from_secs(1)); // Blocks everyone!\n}\n\n// \u2705 Do this - yields to other tasks\nasync fn good_example() {\n    tokio::time::sleep(Duration::from_secs(1)).await; // Non-blocking\n}\n```\n\n### 2. **Forgetting .await**\n```rust\n// \u274c This doesn't work - returns a Future, doesn't execute\nasync fn forgot_await() {\n    let result = async_function(); // Future<Output = T>, not T\n}\n\n// \u2705 This works\nasync fn remembered_await() {\n    let result = async_function().await; // T\n}\n```\n\n### 3. **Sharing State Safely**\n```rust\n// \u274c This won't compile - Arc<Mutex> isn't Send + Sync for async\nuse std::sync::Mutex;\n\n// \u2705 Use async-aware primitives\nuse tokio::sync::Mutex;\ntype SharedState = std::sync::Arc<tokio::sync::Mutex<HashMap<u32, User>>>;\n```\n\n## Performance Tips\n\n1. **Use connection pooling for databases**\n2. **Batch operations when possible**\n3. **Use `join!` for concurrent operations**\n4. **Be careful with locks in async context**\n5. **Prefer channels for communication between tasks**\n\n## Next Steps\n\nTo get comfortable with async Rust:\n1. **Start simple** - build basic endpoints first\n2. **Add database integration** with SQLx or Diesel\n3. **Learn about channels** for task communication\n4. **Explore middleware** for authentication, logging, etc.\n5. **Study real projects** like the Axum examples\n\nThe key insight is that async/await is about **cooperation** - your code voluntarily yields control at `.await` points so other work can happen. This makes Rust incredibly efficient for I/O-heavy workloads like web APIs!\n\nWant me to dive deeper into any particular aspect?",
    "tags": [
      "async-await",
      "web-api",
      "tokio",
      "axum",
      "tutorial",
      "long-form",
      "step-by-step",
      "practical"
    ],
    "instruction": "I'm building a web API in Rust and I'm confused about async/await. Can you walk me through it step by step?"
  },
  {
    "output": "Excellent follow-up question! Understanding the runtime is key to really grasping async Rust. Let me break down what's happening under the hood.\n\n## What is the Runtime?\n\nThe async runtime is essentially a **task scheduler** that manages and executes your async functions. Think of it like an operating system scheduler, but for async tasks instead of threads.\n\n```rust\n// When you write this:\n#[tokio::main]\nasync fn main() {\n    println!(\"Hello async world!\");\n}\n\n// Tokio expands it roughly to this:\nfn main() {\n    let runtime = tokio::runtime::Runtime::new().unwrap();\n    runtime.block_on(async {\n        println!(\"Hello async world!\");\n    });\n}\n```\n\nThe runtime provides:\n- **Task execution** - Running your async functions\n- **I/O polling** - Checking if network/file operations are ready\n- **Timer management** - Handling sleep/timeout operations\n- **Work distribution** - Spreading tasks across threads\n\n## How Tasks Work\n\nWhen you call an async function, you get a `Future` - not the result, but a state machine that can be executed:\n\n```rust\n// This doesn't run immediately!\nlet future = async {\n    println!(\"This runs later\");\n    42\n};\n\n// You need to await it or spawn it\nlet result = future.await; // Now it runs\n\n// Or spawn it as a task\ntokio::spawn(async {\n    println!(\"This runs concurrently\");\n});\n```\n\nHere's what's happening:\n\n```rust\nuse tokio::time::{sleep, Duration};\n\n#[tokio::main]\nasync fn main() {\n    println!(\"Starting main\");\n    \n    // Spawn multiple tasks\n    let task1 = tokio::spawn(worker_task(\"Worker 1\", 2));\n    let task2 = tokio::spawn(worker_task(\"Worker 2\", 1));\n    let task3 = tokio::spawn(worker_task(\"Worker 3\", 3));\n    \n    println!(\"All tasks spawned, now waiting...\");\n    \n    // Wait for all to complete\n    let (result1, result2, result3) = tokio::try_join!(task1, task2, task3).unwrap();\n    \n    println!(\"Results: {}, {}, {}\", result1, result2, result3);\n}\n\nasync fn worker_task(name: &str, seconds: u64) -> String {\n    println!(\"{} starting work\", name);\n    \n    for i in 1..=seconds {\n        sleep(Duration::from_secs(1)).await;\n        println!(\"{} working... step {}/{}\", name, i, seconds);\n    }\n    \n    let result = format!(\"{} completed\", name);\n    println!(\"{}\", result);\n    result\n}\n```\n\nRun this and you'll see all workers run concurrently, not sequentially!\n\n## The Event Loop\n\nAt its core, the runtime runs an **event loop**. Here's a simplified version of what it looks like:\n\n```rust\n// Simplified runtime pseudocode\nstruct SimpleRuntime {\n    ready_tasks: VecDeque<Task>,\n    waiting_tasks: HashMap<TaskId, Task>,\n    io_poller: IoPoller,\n    timer_wheel: TimerWheel,\n}\n\nimpl SimpleRuntime {\n    fn run(&mut self) {\n        loop {\n            // 1. Run all ready tasks\n            while let Some(task) = self.ready_tasks.pop_front() {\n                match task.poll() {\n                    Poll::Ready(result) => {\n                        // Task completed\n                        task.complete(result);\n                    }\n                    Poll::Pending => {\n                        // Task is waiting for something\n                        self.waiting_tasks.insert(task.id(), task);\n                    }\n                }\n            }\n            \n            // 2. Check I/O operations\n            let ready_ios = self.io_poller.poll();\n            for io_event in ready_ios {\n                if let Some(task) = self.waiting_tasks.remove(&io_event.task_id) {\n                    self.ready_tasks.push_back(task);\n                }\n            }\n            \n            // 3. Check timers\n            let ready_timers = self.timer_wheel.poll();\n            for timer_event in ready_timers {\n                if let Some(task) = self.waiting_tasks.remove(&timer_event.task_id) {\n                    self.ready_tasks.push_back(task);\n                }\n            }\n            \n            // 4. If nothing to do, sleep briefly\n            if self.ready_tasks.is_empty() {\n                std::thread::sleep(Duration::from_millis(1));\n            }\n        }\n    }\n}\n```\n\n## What Happens at .await\n\nWhen your code hits `.await`, here's the magic:\n\n```rust\nasync fn example_function() {\n    println!(\"Before await\");      // Runs immediately\n    \n    sleep(Duration::from_secs(1)).await;  // What happens here?\n    \n    println!(\"After await\");       // Runs 1 second later\n}\n```\n\n1. **Before .await**: Code runs normally\n2. **At .await**: \n   - Runtime checks if the operation is ready\n   - If ready \u2192 continue immediately\n   - If not ready \u2192 **yield control back to runtime**\n3. **Runtime**: Runs other tasks while waiting\n4. **When ready**: Runtime resumes your function where it left off\n\n## Cooperative vs Preemptive\n\nThis is **cooperative multitasking**:\n\n```rust\n// \u274c This is bad - never yields control\nasync fn cpu_intensive_bad() {\n    for i in 0..1_000_000_000 {\n        // Expensive computation\n        let _ = i * i;\n    }\n    // Other tasks are starved!\n}\n\n// \u2705 This is good - yields periodically\nasync fn cpu_intensive_good() {\n    for i in 0..1_000_000_000 {\n        let _ = i * i;\n        \n        // Yield every 100k iterations\n        if i % 100_000 == 0 {\n            tokio::task::yield_now().await;\n        }\n    }\n}\n```\n\n## Different Runtime Types\n\nTokio offers different runtime configurations:\n\n```rust\nuse tokio::runtime::{Builder, Runtime};\n\n// 1. Default multi-threaded runtime\nfn create_default_runtime() -> Runtime {\n    Runtime::new().unwrap()\n}\n\n// 2. Single-threaded runtime\nfn create_single_threaded() -> Runtime {\n    Builder::new_current_thread()\n        .enable_all()\n        .build()\n        .unwrap()\n}\n\n// 3. Custom multi-threaded\nfn create_custom_runtime() -> Runtime {\n    Builder::new_multi_thread()\n        .worker_threads(4)          // 4 worker threads\n        .thread_name(\"my-pool\")\n        .enable_all()               // Enable I/O and time\n        .build()\n        .unwrap()\n}\n\n// Usage\nfn main() {\n    let rt = create_custom_runtime();\n    \n    rt.block_on(async {\n        // Your async code here\n    });\n}\n```\n\n## Work Stealing\n\nIn multi-threaded mode, Tokio uses **work stealing**:\n\n```rust\n#[tokio::main]\nasync fn main() {\n    println!(\"Main thread: {:?}\", std::thread::current().id());\n    \n    // Spawn many tasks\n    let handles = (0..10).map(|i| {\n        tokio::spawn(async move {\n            println!(\"Task {} on thread: {:?}\", i, std::thread::current().id());\n            \n            // Some async work\n            tokio::time::sleep(Duration::from_millis(100)).await;\n            \n            println!(\"Task {} completed on thread: {:?}\", i, std::thread::current().id());\n            i\n        })\n    }).collect::<Vec<_>>();\n    \n    // Wait for all\n    for handle in handles {\n        handle.await.unwrap();\n    }\n}\n```\n\nYou'll see tasks running on different threads!\n\n## Practical Example: Understanding Concurrency\n\nLet's trace through a real example:\n\n```rust\nuse tokio::time::{sleep, Duration, Instant};\n\n#[tokio::main]\nasync fn main() {\n    let start = Instant::now();\n    \n    println!(\"[{:?}] Starting concurrent operations\", start.elapsed());\n    \n    let future1 = slow_operation(\"Operation 1\", 2000);\n    let future2 = slow_operation(\"Operation 2\", 1000);\n    let future3 = slow_operation(\"Operation 3\", 1500);\n    \n    // This runs them concurrently!\n    let (result1, result2, result3) = tokio::join!(future1, future2, future3);\n    \n    println!(\"[{:?}] All completed: {}, {}, {}\", \n             start.elapsed(), result1, result2, result3);\n}\n\nasync fn slow_operation(name: &str, delay_ms: u64) -> String {\n    let start = Instant::now();\n    \n    println!(\"[{:?}] {} starting\", start.elapsed(), name);\n    \n    // Simulate async I/O operation\n    sleep(Duration::from_millis(delay_ms)).await;\n    \n    let result = format!(\"{} done\", name);\n    println!(\"[{:?}] {}\", start.elapsed(), result);\n    \n    result\n}\n```\n\nOutput shows they all run concurrently:\n```\n[0ms] Starting concurrent operations\n[1ms] Operation 1 starting\n[1ms] Operation 2 starting  \n[1ms] Operation 3 starting\n[1001ms] Operation 2 done\n[1501ms] Operation 3 done\n[2001ms] Operation 1 done\n[2002ms] All completed: Operation 1 done, Operation 2 done, Operation 3 done\n```\n\nTotal time: ~2 seconds (not 4.5 seconds sequential!)\n\n## Channels for Communication\n\nThe runtime also manages communication between tasks:\n\n```rust\nuse tokio::sync::{mpsc, oneshot};\n\n#[tokio::main]\nasync fn main() {\n    // Multi-producer, single-consumer channel\n    let (tx, mut rx) = mpsc::channel(100);\n    \n    // Spawn producer tasks\n    for i in 0..5 {\n        let tx_clone = tx.clone();\n        tokio::spawn(async move {\n            for j in 0..3 {\n                let message = format!(\"Message {}-{}\", i, j);\n                tx_clone.send(message).await.unwrap();\n                sleep(Duration::from_millis(100)).await;\n            }\n        });\n    }\n    \n    // Drop the original sender\n    drop(tx);\n    \n    // Receive all messages\n    while let Some(message) = rx.recv().await {\n        println!(\"Received: {}\", message);\n    }\n    \n    println!(\"All messages received!\");\n}\n```\n\n## CPU vs I/O Tasks\n\nThe runtime handles different types of work differently:\n\n```rust\nuse tokio::task;\n\n#[tokio::main]\nasync fn main() {\n    // I/O bound task - runs on main runtime\n    let io_task = tokio::spawn(async {\n        // This yields control during the sleep\n        sleep(Duration::from_secs(1)).await;\n        \"I/O task completed\"\n    });\n    \n    // CPU bound task - runs on blocking thread pool\n    let cpu_task = task::spawn_blocking(|| {\n        // This blocks the thread, so it runs on separate thread pool\n        std::thread::sleep(Duration::from_secs(1));\n        \"CPU task completed\"\n    });\n    \n    let (io_result, cpu_result) = tokio::join!(io_task, cpu_task);\n    \n    println!(\"{}\", io_result.unwrap());\n    println!(\"{}\", cpu_result.unwrap());\n}\n```\n\n## Performance Monitoring\n\nYou can monitor runtime behavior:\n\n```rust\n#[tokio::main]\nasync fn main() {\n    // Enable runtime metrics\n    let handle = tokio::runtime::Handle::current();\n    \n    tokio::spawn(async move {\n        loop {\n            let metrics = handle.metrics();\n            println!(\"Active tasks: {}\", metrics.active_tasks_count());\n            println!(\"Injection queue depth: {}\", metrics.injection_queue_depth());\n            \n            sleep(Duration::from_secs(1)).await;\n        }\n    });\n    \n    // Do some work\n    let handles: Vec<_> = (0..10).map(|i| {\n        tokio::spawn(async move {\n            sleep(Duration::from_millis(i * 100)).await;\n            i\n        })\n    }).collect();\n    \n    for handle in handles {\n        handle.await.unwrap();\n    }\n}\n```\n\n## Summary\n\nThe async runtime is like a **smart traffic controller**:\n\n1. **Tasks are like cars** - they want to get somewhere\n2. **The runtime is the traffic system** - it manages flow\n3. **`.await` points are like traffic lights** - where cars can stop/yield\n4. **While one car waits, others can go** - concurrency!\n5. **Work stealing ensures load balancing** - no idle lanes\n\n**Key insights:**\n- Async is about **cooperation**, not preemption\n- The runtime only switches tasks at `.await` points\n- You can starve other tasks if you never yield\n- I/O operations automatically yield when not ready\n- CPU-bound work should use `spawn_blocking`\n\nThis is why async Rust is so efficient - one thread can handle thousands of concurrent I/O operations because most of the time is spent waiting for network/disk, not doing CPU work!\n\nDoes this help clarify how the runtime works? Want to dive deeper into any specific aspect?",
    "tags": [
      "async-runtime",
      "tokio",
      "event-loop",
      "concurrency",
      "internals",
      "detailed-explanation",
      "follow-up",
      "conversation"
    ],
    "instruction": "That async/await explanation was really helpful! But I'm still confused about something - you mentioned that .await yields control back to the runtime. What exactly IS the runtime? And how does it manage all these tasks? Can you explain the internals?"
  },
  {
    "output": "Fantastic question! Error handling in async code is crucial, especially for production web services. Let me show you comprehensive strategies for handling failures gracefully.\n\n## The Challenge with Async Errors\n\nAsync errors are trickier because:\n1. **Multiple concurrent operations** can fail independently\n2. **Shared resources** (like DB pools) can fail and affect multiple tasks\n3. **Partial failures** - some operations succeed, others fail\n4. **Error propagation** across async boundaries\n\nLet's build a robust system step by step.\n\n## Comprehensive Error Types\n\nFirst, let's define a proper error hierarchy:\n\n```rust\nuse thiserror::Error;\nuse tokio::time::Duration;\n\n#[derive(Error, Debug)]\npub enum AppError {\n    #[error(\"Database error: {0}\")]\n    Database(#[from] sqlx::Error),\n    \n    #[error(\"Connection pool exhausted\")]\n    PoolExhausted,\n    \n    #[error(\"Service timeout after {timeout:?}\")]\n    Timeout { timeout: Duration },\n    \n    #[error(\"External service unavailable: {service}\")]\n    ServiceUnavailable { service: String },\n    \n    #[error(\"Validation failed: {field} - {message}\")]\n    Validation { field: String, message: String },\n    \n    #[error(\"Authentication failed: {reason}\")]\n    Authentication { reason: String },\n    \n    #[error(\"Rate limit exceeded: {limit} requests per {window:?}\")]\n    RateLimit { limit: u32, window: Duration },\n    \n    #[error(\"Circuit breaker open for service: {service}\")]\n    CircuitBreakerOpen { service: String },\n    \n    #[error(\"Internal server error\")]\n    Internal(#[from] Box<dyn std::error::Error + Send + Sync>),\n}\n\n// HTTP response mapping\nimpl axum::response::IntoResponse for AppError {\n    fn into_response(self) -> axum::response::Response {\n        let (status, error_message, should_retry) = match &self {\n            AppError::Database(_) => (\n                axum::http::StatusCode::INTERNAL_SERVER_ERROR,\n                \"Database temporarily unavailable\",\n                true\n            ),\n            AppError::PoolExhausted => (\n                axum::http::StatusCode::SERVICE_UNAVAILABLE,\n                \"Server overloaded, please retry\",\n                true\n            ),\n            AppError::Timeout { .. } => (\n                axum::http::StatusCode::GATEWAY_TIMEOUT,\n                \"Request timeout\",\n                true\n            ),\n            AppError::ServiceUnavailable { .. } => (\n                axum::http::StatusCode::BAD_GATEWAY,\n                \"External service unavailable\",\n                true\n            ),\n            AppError::Validation { .. } => (\n                axum::http::StatusCode::BAD_REQUEST,\n                \"Invalid request data\",\n                false\n            ),\n            AppError::Authentication { .. } => (\n                axum::http::StatusCode::UNAUTHORIZED,\n                \"Authentication required\",\n                false\n            ),\n            AppError::RateLimit { .. } => (\n                axum::http::StatusCode::TOO_MANY_REQUESTS,\n                \"Rate limit exceeded\",\n                true\n            ),\n            AppError::CircuitBreakerOpen { .. } => (\n                axum::http::StatusCode::SERVICE_UNAVAILABLE,\n                \"Service temporarily unavailable\",\n                true\n            ),\n            AppError::Internal(_) => (\n                axum::http::StatusCode::INTERNAL_SERVER_ERROR,\n                \"Internal server error\",\n                false\n            ),\n        };\n        \n        let error_response = serde_json::json!({\n            \"error\": error_message,\n            \"details\": self.to_string(),\n            \"retry_recommended\": should_retry,\n            \"timestamp\": chrono::Utc::now().to_rfc3339()\n        });\n        \n        (status, axum::Json(error_response)).into_response()\n    }\n}\n```\n\n## Database Connection Resilience\n\nHere's how to handle database failures gracefully:\n\n```rust\nuse sqlx::{PgPool, Pool, Postgres};\nuse std::sync::Arc;\nuse tokio::time::{timeout, Duration};\n\n#[derive(Clone)]\npub struct DatabaseService {\n    pool: Arc<PgPool>,\n    health_check_timeout: Duration,\n}\n\nimpl DatabaseService {\n    pub fn new(pool: PgPool) -> Self {\n        Self {\n            pool: Arc::new(pool),\n            health_check_timeout: Duration::from_secs(5),\n        }\n    }\n    \n    // Robust database operation with retries\n    pub async fn get_user_with_retry(&self, user_id: u32) -> Result<User, AppError> {\n        let max_retries = 3;\n        let mut last_error = None;\n        \n        for attempt in 1..=max_retries {\n            match self.get_user_internal(user_id).await {\n                Ok(user) => return Ok(user),\n                Err(e) => {\n                    last_error = Some(e);\n                    \n                    // Don't retry validation errors\n                    if matches!(last_error.as_ref().unwrap(), AppError::Validation { .. }) {\n                        break;\n                    }\n                    \n                    if attempt < max_retries {\n                        let delay = Duration::from_millis(100 * attempt as u64);\n                        tokio::time::sleep(delay).await;\n                        tracing::warn!(\"Database operation failed, retrying in {:?} (attempt {})\", delay, attempt);\n                    }\n                }\n            }\n        }\n        \n        Err(last_error.unwrap())\n    }\n    \n    async fn get_user_internal(&self, user_id: u32) -> Result<User, AppError> {\n        // Add timeout to prevent hanging\n        let query_future = sqlx::query_as!(\n            User,\n            \"SELECT id, name, email FROM users WHERE id = $1\",\n            user_id\n        )\n        .fetch_optional(&*self.pool);\n        \n        match timeout(Duration::from_secs(10), query_future).await {\n            Ok(Ok(Some(user))) => Ok(user),\n            Ok(Ok(None)) => Err(AppError::Validation {\n                field: \"user_id\".to_string(),\n                message: \"User not found\".to_string(),\n            }),\n            Ok(Err(sqlx_error)) => {\n                tracing::error!(\"Database query failed: {}\", sqlx_error);\n                Err(AppError::Database(sqlx_error))\n            }\n            Err(_) => {\n                tracing::error!(\"Database query timed out for user {}\", user_id);\n                Err(AppError::Timeout {\n                    timeout: Duration::from_secs(10),\n                })\n            }\n        }\n    }\n    \n    // Health check for monitoring\n    pub async fn health_check(&self) -> Result<(), AppError> {\n        let health_query = sqlx::query(\"SELECT 1\")\n            .execute(&*self.pool);\n            \n        match timeout(self.health_check_timeout, health_query).await {\n            Ok(Ok(_)) => Ok(()),\n            Ok(Err(e)) => Err(AppError::Database(e)),\n            Err(_) => Err(AppError::Timeout {\n                timeout: self.health_check_timeout,\n            }),\n        }\n    }\n}\n```\n\n## Circuit Breaker Pattern\n\nPrevent cascade failures with circuit breakers:\n\n```rust\nuse std::sync::atomic::{AtomicU32, AtomicBool, Ordering};\nuse std::sync::Arc;\nuse tokio::time::{Instant, Duration};\n\n#[derive(Debug, Clone)]\npub enum CircuitState {\n    Closed,   // Normal operation\n    Open,     // Failing, reject requests\n    HalfOpen, // Testing if service recovered\n}\n\npub struct CircuitBreaker {\n    failure_threshold: u32,\n    timeout: Duration,\n    failure_count: AtomicU32,\n    last_failure_time: Arc<tokio::sync::Mutex<Option<Instant>>>,\n    state: Arc<tokio::sync::Mutex<CircuitState>>,\n}\n\nimpl CircuitBreaker {\n    pub fn new(failure_threshold: u32, timeout: Duration) -> Self {\n        Self {\n            failure_threshold,\n            timeout,\n            failure_count: AtomicU32::new(0),\n            last_failure_time: Arc::new(tokio::sync::Mutex::new(None)),\n            state: Arc::new(tokio::sync::Mutex::new(CircuitState::Closed)),\n        }\n    }\n    \n    pub async fn call<F, Fut, T>(&self, operation: F) -> Result<T, AppError>\n    where\n        F: FnOnce() -> Fut,\n        Fut: std::future::Future<Output = Result<T, AppError>>,\n    {\n        // Check circuit state\n        {\n            let mut state = self.state.lock().await;\n            match *state {\n                CircuitState::Open => {\n                    let last_failure = self.last_failure_time.lock().await;\n                    if let Some(last_time) = *last_failure {\n                        if last_time.elapsed() > self.timeout {\n                            *state = CircuitState::HalfOpen;\n                            tracing::info!(\"Circuit breaker moving to half-open state\");\n                        } else {\n                            return Err(AppError::CircuitBreakerOpen {\n                                service: \"database\".to_string(),\n                            });\n                        }\n                    }\n                }\n                _ => {}\n            }\n        }\n        \n        // Execute operation\n        match operation().await {\n            Ok(result) => {\n                self.on_success().await;\n                Ok(result)\n            }\n            Err(error) => {\n                self.on_failure().await;\n                Err(error)\n            }\n        }\n    }\n    \n    async fn on_success(&self) {\n        self.failure_count.store(0, Ordering::Relaxed);\n        let mut state = self.state.lock().await;\n        *state = CircuitState::Closed;\n        tracing::debug!(\"Circuit breaker reset to closed state\");\n    }\n    \n    async fn on_failure(&self) {\n        let failures = self.failure_count.fetch_add(1, Ordering::Relaxed) + 1;\n        \n        if failures >= self.failure_threshold {\n            let mut state = self.state.lock().await;\n            *state = CircuitState::Open;\n            \n            let mut last_failure = self.last_failure_time.lock().await;\n            *last_failure = Some(Instant::now());\n            \n            tracing::warn!(\"Circuit breaker opened after {} failures\", failures);\n        }\n    }\n}\n```\n\n## Graceful Request Handling\n\nNow let's put it all together in request handlers:\n\n```rust\nuse axum::extract::{State, Path};\nuse axum::response::Json;\nuse std::sync::Arc;\n\n#[derive(Clone)]\npub struct AppState {\n    db: DatabaseService,\n    circuit_breaker: Arc<CircuitBreaker>,\n    external_client: reqwest::Client,\n}\n\n// Robust user endpoint with comprehensive error handling\npub async fn get_user_profile(\n    Path(user_id): Path<u32>,\n    State(state): State<AppState>,\n) -> Result<Json<UserProfile>, AppError> {\n    tracing::info!(\"Fetching profile for user {}\", user_id);\n    \n    // Use circuit breaker for database operations\n    let user = state.circuit_breaker.call(|| {\n        state.db.get_user_with_retry(user_id)\n    }).await?;\n    \n    // Fetch additional data concurrently (with individual error handling)\n    let (preferences_result, stats_result) = tokio::join!(\n        fetch_user_preferences(&state, user_id),\n        fetch_user_stats(&state, user_id)\n    );\n    \n    // Handle partial failures gracefully\n    let preferences = match preferences_result {\n        Ok(prefs) => Some(prefs),\n        Err(e) => {\n            tracing::warn!(\"Failed to fetch preferences for user {}: {}\", user_id, e);\n            None // Degrade gracefully\n        }\n    };\n    \n    let stats = match stats_result {\n        Ok(stats) => Some(stats),\n        Err(e) => {\n            tracing::warn!(\"Failed to fetch stats for user {}: {}\", user_id, e);\n            None // Degrade gracefully\n        }\n    };\n    \n    let profile = UserProfile {\n        user,\n        preferences,\n        stats,\n    };\n    \n    tracing::info!(\"Successfully fetched profile for user {}\", user_id);\n    Ok(Json(profile))\n}\n\nasync fn fetch_user_preferences(\n    state: &AppState,\n    user_id: u32,\n) -> Result<UserPreferences, AppError> {\n    // Timeout for external service calls\n    let request_future = state.external_client\n        .get(&format!(\"https://preferences-api.example.com/users/{}\", user_id))\n        .timeout(Duration::from_secs(5))\n        .send();\n    \n    match timeout(Duration::from_secs(10), request_future).await {\n        Ok(Ok(response)) => {\n            if response.status().is_success() {\n                response.json::<UserPreferences>()\n                    .await\n                    .map_err(|e| AppError::Internal(Box::new(e)))\n            } else {\n                Err(AppError::ServiceUnavailable {\n                    service: \"preferences-api\".to_string(),\n                })\n            }\n        }\n        Ok(Err(e)) => Err(AppError::ServiceUnavailable {\n            service: \"preferences-api\".to_string(),\n        }),\n        Err(_) => Err(AppError::Timeout {\n            timeout: Duration::from_secs(10),\n        }),\n    }\n}\n\nasync fn fetch_user_stats(\n    state: &AppState,\n    user_id: u32,\n) -> Result<UserStats, AppError> {\n    // Another external service with its own error handling\n    state.circuit_breaker.call(|| async {\n        state.db.get_user_stats(user_id).await\n    }).await\n}\n```\n\n## Bulk Operations with Partial Failures\n\nHandling multiple operations where some might fail:\n\n```rust\npub async fn bulk_update_users(\n    State(state): State<AppState>,\n    Json(updates): Json<Vec<UserUpdate>>,\n) -> Result<Json<BulkUpdateResult>, AppError> {\n    if updates.len() > 100 {\n        return Err(AppError::Validation {\n            field: \"updates\".to_string(),\n            message: \"Maximum 100 updates per request\".to_string(),\n        });\n    }\n    \n    tracing::info!(\"Processing {} user updates\", updates.len());\n    \n    // Process in chunks to avoid overwhelming the database\n    let chunk_size = 10;\n    let mut all_results = Vec::new();\n    \n    for (chunk_idx, chunk) in updates.chunks(chunk_size).enumerate() {\n        tracing::debug!(\"Processing chunk {} ({} items)\", chunk_idx, chunk.len());\n        \n        // Process chunk concurrently, but limit concurrency\n        let chunk_futures = chunk.iter().enumerate().map(|(idx, update)| {\n            let state = state.clone();\n            let update = update.clone();\n            \n            async move {\n                let global_idx = chunk_idx * chunk_size + idx;\n                match update_single_user(&state, update).await {\n                    Ok(user) => UpdateResult {\n                        index: global_idx,\n                        user_id: user.id,\n                        success: true,\n                        error: None,\n                    },\n                    Err(e) => {\n                        tracing::warn!(\"Failed to update user at index {}: {}\", global_idx, e);\n                        UpdateResult {\n                            index: global_idx,\n                            user_id: update.user_id,\n                            success: false,\n                            error: Some(e.to_string()),\n                        }\n                    }\n                }\n            }\n        });\n        \n        // Wait for chunk to complete\n        let chunk_results = futures::future::join_all(chunk_futures).await;\n        all_results.extend(chunk_results);\n        \n        // Brief pause between chunks to be nice to the database\n        if chunk_idx < updates.len() / chunk_size {\n            tokio::time::sleep(Duration::from_millis(100)).await;\n        }\n    }\n    \n    let success_count = all_results.iter().filter(|r| r.success).count();\n    let failure_count = all_results.len() - success_count;\n    \n    tracing::info!(\n        \"Bulk update completed: {} successes, {} failures\",\n        success_count,\n        failure_count\n    );\n    \n    Ok(Json(BulkUpdateResult {\n        total_requested: updates.len(),\n        successful: success_count,\n        failed: failure_count,\n        results: all_results,\n    }))\n}\n\nasync fn update_single_user(\n    state: &AppState,\n    update: UserUpdate,\n) -> Result<User, AppError> {\n    // Individual update with retry logic\n    state.circuit_breaker.call(|| {\n        state.db.update_user_with_retry(update.clone())\n    }).await\n}\n```\n\n## Monitoring and Observability\n\n```rust\nuse tracing::{info, warn, error, instrument};\nuse metrics::{counter, histogram, gauge};\n\n#[instrument(\n    skip(state),\n    fields(\n        user_id = %user_id,\n        endpoint = \"get_user_profile\"\n    )\n)]\npub async fn get_user_profile_monitored(\n    Path(user_id): Path<u32>,\n    State(state): State<AppState>,\n) -> Result<Json<UserProfile>, AppError> {\n    let start_time = std::time::Instant::now();\n    \n    // Increment request counter\n    counter!(\"http_requests_total\", 1, \"endpoint\" => \"get_user_profile\");\n    \n    let result = get_user_profile(Path(user_id), State(state)).await;\n    \n    // Record metrics\n    let duration = start_time.elapsed();\n    histogram!(\"http_request_duration_seconds\", duration.as_secs_f64(), \"endpoint\" => \"get_user_profile\");\n    \n    match &result {\n        Ok(_) => {\n            counter!(\"http_requests_successful_total\", 1, \"endpoint\" => \"get_user_profile\");\n            info!(\"Successfully handled request for user {}\", user_id);\n        }\n        Err(e) => {\n            counter!(\"http_requests_failed_total\", 1, \"endpoint\" => \"get_user_profile\", \"error_type\" => e.to_string());\n            error!(\"Failed to handle request for user {}: {}\", user_id, e);\n        }\n    }\n    \n    result\n}\n```\n\n## Health Checks and Graceful Shutdown\n\n```rust\nuse tokio::signal;\nuse axum::extract::State;\n\npub async fn health_check(\n    State(state): State<AppState>,\n) -> Result<Json<HealthStatus>, AppError> {\n    let start = std::time::Instant::now();\n    \n    // Check all critical dependencies\n    let (db_health, external_health) = tokio::join!(\n        check_database_health(&state),\n        check_external_services_health(&state)\n    );\n    \n    let overall_healthy = db_health.healthy && external_health.healthy;\n    \n    let status = HealthStatus {\n        healthy: overall_healthy,\n        timestamp: chrono::Utc::now(),\n        check_duration: start.elapsed(),\n        services: vec![db_health, external_health],\n    };\n    \n    if overall_healthy {\n        Ok(Json(status))\n    } else {\n        Err(AppError::ServiceUnavailable {\n            service: \"application\".to_string(),\n        })\n    }\n}\n\nasync fn check_database_health(state: &AppState) -> ServiceHealth {\n    match state.db.health_check().await {\n        Ok(_) => ServiceHealth {\n            name: \"database\".to_string(),\n            healthy: true,\n            message: None,\n        },\n        Err(e) => ServiceHealth {\n            name: \"database\".to_string(),\n            healthy: false,\n            message: Some(e.to_string()),\n        },\n    }\n}\n\n// Graceful shutdown\npub async fn run_server_with_graceful_shutdown(\n    app: Router,\n    addr: std::net::SocketAddr,\n) -> Result<(), Box<dyn std::error::Error>> {\n    let listener = tokio::net::TcpListener::bind(addr).await?;\n    info!(\"Server listening on {}\", addr);\n    \n    axum::serve(listener, app)\n        .with_graceful_shutdown(shutdown_signal())\n        .await?;\n        \n    info!(\"Server shutdown complete\");\n    Ok(())\n}\n\nasync fn shutdown_signal() {\n    let ctrl_c = async {\n        signal::ctrl_c()\n            .await\n            .expect(\"failed to install Ctrl+C handler\");\n    };\n\n    #[cfg(unix)]\n    let terminate = async {\n        signal::unix::signal(signal::unix::SignalKind::terminate())\n            .expect(\"failed to install signal handler\")\n            .recv()\n            .await;\n    };\n\n    #[cfg(not(unix))]\n    let terminate = std::future::pending::<()>();\n\n    tokio::select! {\n        _ = ctrl_c => {},\n        _ = terminate => {},\n    }\n\n    info!(\"Shutdown signal received, starting graceful shutdown\");\n}\n```\n\n## Key Principles for Async Error Handling\n\n1. **Fail Fast, Recover Gracefully**\n   - Validate inputs early\n   - Use timeouts on all external calls\n   - Implement circuit breakers for dependencies\n\n2. **Partial Failure Tolerance**\n   - Degrade functionality instead of failing completely\n   - Use default values when possible\n   - Process bulk operations in chunks\n\n3. **Observability**\n   - Log errors with context\n   - Collect metrics on error rates\n   - Implement health checks\n\n4. **Resource Management**\n   - Use connection pooling\n   - Implement backpressure\n   - Clean up resources properly\n\n5. **Testing**\n   - Test error scenarios\n   - Use chaos engineering\n   - Monitor error rates in production\n\nThis approach ensures your async web service stays resilient even when individual components fail. The key is to expect failures and design your system to handle them gracefully!\n\nWant me to dive deeper into any of these patterns, or do you have questions about implementing them in your specific use case?",
    "tags": [
      "async-error-handling",
      "resilience",
      "circuit-breaker",
      "database-failures",
      "graceful-degradation",
      "monitoring",
      "production-ready",
      "long-conversation"
    ],
    "instruction": "This is amazing! The runtime explanation really clicked for me. But now I'm wondering about error handling in async code - you showed some examples with Result, but what about when async operations fail? Like what if my database connection drops in the middle of processing multiple requests? How do I handle that gracefully without crashing the whole server?"
  },
  {
    "output": "Excellent question! Testing async code, especially failure scenarios, is indeed challenging but absolutely critical. Let me show you comprehensive strategies for testing all these complex scenarios.\n\n## Testing Strategy Overview\n\nWe'll use a multi-layered approach:\n1. **Unit tests** with mocks for individual components\n2. **Integration tests** with test databases\n3. **Chaos testing** for failure simulation\n4. **Load testing** for concurrency issues\n5. **Contract testing** for external services\n\nLet's start building a robust testing suite!\n\n## Setting Up Test Infrastructure\n\nFirst, let's organize our test dependencies:\n\n```toml\n# Cargo.toml\n[dev-dependencies]\ntokio-test = \"0.4\"\nmockall = \"0.11\"\nwiremock = \"0.5\"\ntestcontainers = \"0.14\"\nserde_json = \"1.0\"\ntempfile = \"3.0\"\nproptest = \"1.0\"  # Property-based testing\ncriterion = { version = \"0.5\", features = [\"html_reports\"] }  # Benchmarking\ntracing-test = \"0.2\"  # Testing logs\n\n[dependencies]\n# ... your regular dependencies\nasync-trait = \"0.1\"  # For mockable traits\n```\n\n## Mocking External Dependencies\n\nLet's create mockable interfaces for our dependencies:\n\n```rust\n// src/traits.rs\nuse async_trait::async_trait;\nuse mockall::automock;\n\n#[automock]\n#[async_trait]\npub trait DatabaseRepository: Send + Sync {\n    async fn get_user(&self, id: u32) -> Result<Option<User>, sqlx::Error>;\n    async fn create_user(&self, user: CreateUserRequest) -> Result<User, sqlx::Error>;\n    async fn update_user(&self, id: u32, update: UserUpdate) -> Result<User, sqlx::Error>;\n    async fn health_check(&self) -> Result<(), sqlx::Error>;\n}\n\n#[automock]\n#[async_trait]\npub trait ExternalServiceClient: Send + Sync {\n    async fn get_user_preferences(&self, user_id: u32) -> Result<UserPreferences, reqwest::Error>;\n    async fn get_user_stats(&self, user_id: u32) -> Result<UserStats, reqwest::Error>;\n}\n\n#[automock]\n#[async_trait]\npub trait NotificationService: Send + Sync {\n    async fn send_notification(&self, user_id: u32, message: &str) -> Result<(), AppError>;\n}\n\n// Real implementations\npub struct SqlxDatabaseRepository {\n    pool: sqlx::PgPool,\n}\n\n#[async_trait]\nimpl DatabaseRepository for SqlxDatabaseRepository {\n    async fn get_user(&self, id: u32) -> Result<Option<User>, sqlx::Error> {\n        sqlx::query_as!(User, \"SELECT id, name, email FROM users WHERE id = $1\", id)\n            .fetch_optional(&self.pool)\n            .await\n    }\n    \n    async fn create_user(&self, user: CreateUserRequest) -> Result<User, sqlx::Error> {\n        sqlx::query_as!(\n            User,\n            \"INSERT INTO users (name, email) VALUES ($1, $2) RETURNING id, name, email\",\n            user.name,\n            user.email\n        )\n        .fetch_one(&self.pool)\n        .await\n    }\n    \n    async fn update_user(&self, id: u32, update: UserUpdate) -> Result<User, sqlx::Error> {\n        sqlx::query_as!(\n            User,\n            \"UPDATE users SET name = $1, email = $2 WHERE id = $3 RETURNING id, name, email\",\n            update.name,\n            update.email,\n            id\n        )\n        .fetch_one(&self.pool)\n        .await\n    }\n    \n    async fn health_check(&self) -> Result<(), sqlx::Error> {\n        sqlx::query(\"SELECT 1\").execute(&self.pool).await.map(|_| ())\n    }\n}\n```\n\n## Unit Testing with Mocks\n\nNow let's test our service layer with controlled failures:\n\n```rust\n// tests/unit/user_service_test.rs\nuse tokio_test;\nuse mockall::predicate::*;\nuse std::time::Duration;\n\n#[tokio::test]\nasync fn test_get_user_success() {\n    let mut mock_db = MockDatabaseRepository::new();\n    let mut mock_external = MockExternalServiceClient::new();\n    \n    // Setup expectations\n    mock_db\n        .expect_get_user()\n        .with(eq(1))\n        .times(1)\n        .returning(|_| {\n            Ok(Some(User {\n                id: 1,\n                name: \"Test User\".to_string(),\n                email: \"test@example.com\".to_string(),\n            }))\n        });\n    \n    mock_external\n        .expect_get_user_preferences()\n        .with(eq(1))\n        .times(1)\n        .returning(|_| {\n            Ok(UserPreferences {\n                theme: \"dark\".to_string(),\n                notifications: true,\n            })\n        });\n    \n    let service = UserService::new(\n        Box::new(mock_db),\n        Box::new(mock_external),\n    );\n    \n    let result = service.get_user_profile(1).await;\n    \n    assert!(result.is_ok());\n    let profile = result.unwrap();\n    assert_eq!(profile.user.id, 1);\n    assert_eq!(profile.user.name, \"Test User\");\n    assert!(profile.preferences.is_some());\n}\n\n#[tokio::test]\nasync fn test_get_user_database_failure() {\n    let mut mock_db = MockDatabaseRepository::new();\n    let mock_external = MockExternalServiceClient::new();\n    \n    // Simulate database failure\n    mock_db\n        .expect_get_user()\n        .with(eq(1))\n        .times(1)\n        .returning(|_| Err(sqlx::Error::PoolClosed));\n    \n    let service = UserService::new(\n        Box::new(mock_db),\n        Box::new(mock_external),\n    );\n    \n    let result = service.get_user_profile(1).await;\n    \n    assert!(result.is_err());\n    match result.unwrap_err() {\n        AppError::Database(_) => {}, // Expected\n        other => panic!(\"Expected Database error, got {:?}\", other),\n    }\n}\n\n#[tokio::test]\nasync fn test_get_user_external_service_failure_graceful_degradation() {\n    let mut mock_db = MockDatabaseRepository::new();\n    let mut mock_external = MockExternalServiceClient::new();\n    \n    // Database succeeds\n    mock_db\n        .expect_get_user()\n        .returning(|_| {\n            Ok(Some(User {\n                id: 1,\n                name: \"Test User\".to_string(),\n                email: \"test@example.com\".to_string(),\n            }))\n        });\n    \n    // External service fails\n    mock_external\n        .expect_get_user_preferences()\n        .returning(|_| Err(reqwest::Error::from(reqwest::ErrorKind::Timeout)));\n    \n    let service = UserService::new(\n        Box::new(mock_db),\n        Box::new(mock_external),\n    );\n    \n    let result = service.get_user_profile(1).await;\n    \n    // Should succeed but with degraded data\n    assert!(result.is_ok());\n    let profile = result.unwrap();\n    assert_eq!(profile.user.id, 1);\n    assert!(profile.preferences.is_none()); // Gracefully degraded\n}\n\n#[tokio::test]\nasync fn test_circuit_breaker_opens_after_failures() {\n    let mut mock_db = MockDatabaseRepository::new();\n    let mock_external = MockExternalServiceClient::new();\n    \n    // Simulate repeated failures\n    mock_db\n        .expect_get_user()\n        .times(3) // Circuit breaker threshold\n        .returning(|_| Err(sqlx::Error::PoolClosed));\n    \n    let circuit_breaker = CircuitBreaker::new(3, Duration::from_secs(60));\n    let service = UserService::with_circuit_breaker(\n        Box::new(mock_db),\n        Box::new(mock_external),\n        circuit_breaker,\n    );\n    \n    // First three calls should hit the database and fail\n    for i in 1..=3 {\n        let result = service.get_user_profile(i).await;\n        assert!(result.is_err());\n        match result.unwrap_err() {\n            AppError::Database(_) => {}, // Expected for first 3\n            other => panic!(\"Expected Database error, got {:?}\", other),\n        }\n    }\n    \n    // Fourth call should be rejected by circuit breaker\n    let result = service.get_user_profile(4).await;\n    assert!(result.is_err());\n    match result.unwrap_err() {\n        AppError::CircuitBreakerOpen { .. } => {}, // Expected\n        other => panic!(\"Expected CircuitBreakerOpen, got {:?}\", other),\n    }\n}\n```\n\n## Integration Testing with Real Database\n\nFor integration tests, we'll use testcontainers to spin up real databases:\n\n```rust\n// tests/integration/database_test.rs\nuse testcontainers::{\n    clients::Cli,\n    images::postgres::Postgres,\n    Container,\n};\nuse sqlx::{PgPool, Pool, Postgres as SqlxPostgres};\n\nstruct TestContext {\n    pool: PgPool,\n    _container: Container<'static, Postgres>, // Keep container alive\n}\n\nimpl TestContext {\n    async fn new() -> Self {\n        let docker = Cli::default();\n        let container = docker.run(Postgres::default());\n        \n        let port = container.get_host_port_ipv4(5432);\n        let database_url = format!(\n            \"postgresql://postgres:postgres@localhost:{}/postgres\",\n            port\n        );\n        \n        let pool = PgPool::connect(&database_url)\n            .await\n            .expect(\"Failed to connect to test database\");\n        \n        // Run migrations\n        sqlx::migrate!(\"./migrations\")\n            .run(&pool)\n            .await\n            .expect(\"Failed to run migrations\");\n        \n        Self {\n            pool,\n            _container: container,\n        }\n    }\n    \n    async fn seed_test_data(&self) {\n        sqlx::query!(\n            \"INSERT INTO users (id, name, email) VALUES ($1, $2, $3)\",\n            1,\n            \"Test User\",\n            \"test@example.com\"\n        )\n        .execute(&self.pool)\n        .await\n        .expect(\"Failed to seed test data\");\n    }\n}\n\n#[tokio::test]\nasync fn test_database_repository_integration() {\n    let ctx = TestContext::new().await;\n    ctx.seed_test_data().await;\n    \n    let repo = SqlxDatabaseRepository::new(ctx.pool.clone());\n    \n    // Test successful retrieval\n    let user = repo.get_user(1).await.unwrap();\n    assert!(user.is_some());\n    assert_eq!(user.unwrap().name, \"Test User\");\n    \n    // Test not found\n    let user = repo.get_user(999).await.unwrap();\n    assert!(user.is_none());\n    \n    // Test creation\n    let new_user = repo.create_user(CreateUserRequest {\n        name: \"New User\".to_string(),\n        email: \"new@example.com\".to_string(),\n    }).await.unwrap();\n    \n    assert_eq!(new_user.name, \"New User\");\n    assert!(new_user.id > 1);\n}\n\n#[tokio::test]\nasync fn test_database_connection_failure_handling() {\n    let ctx = TestContext::new().await;\n    \n    // Close the pool to simulate connection failure\n    ctx.pool.close().await;\n    \n    let repo = SqlxDatabaseRepository::new(ctx.pool.clone());\n    \n    let result = repo.get_user(1).await;\n    assert!(result.is_err());\n    \n    // Verify it's the right kind of error\n    match result.unwrap_err() {\n        sqlx::Error::PoolClosed => {}, // Expected\n        other => panic!(\"Expected PoolClosed error, got {:?}\", other),\n    }\n}\n```\n\n## Testing Timeouts and Slow Operations\n\n```rust\n// tests/unit/timeout_test.rs\nuse tokio::time::{Duration, sleep, timeout};\nuse tokio_test::time::advance;\n\n#[tokio::test]\nasync fn test_operation_timeout() {\n    let mut mock_db = MockDatabaseRepository::new();\n    \n    // Simulate slow database operation\n    mock_db\n        .expect_get_user()\n        .returning(|_| async {\n            sleep(Duration::from_secs(10)).await; // Slow operation\n            Ok(Some(User {\n                id: 1,\n                name: \"Test\".to_string(),\n                email: \"test@example.com\".to_string(),\n            }))\n        }.boxed());\n    \n    let service = UserService::new(Box::new(mock_db), Box::new(MockExternalServiceClient::new()));\n    \n    // Test with timeout\n    let result = timeout(\n        Duration::from_secs(5),\n        service.get_user_profile(1)\n    ).await;\n    \n    assert!(result.is_err()); // Should timeout\n}\n\n#[tokio::test]\nasync fn test_concurrent_requests_under_load() {\n    let mut mock_db = MockDatabaseRepository::new();\n    \n    // Setup mock to handle multiple calls\n    mock_db\n        .expect_get_user()\n        .times(100)\n        .returning(|id| {\n            // Simulate variable response times\n            let delay = Duration::from_millis((id % 10) * 10);\n            async move {\n                sleep(delay).await;\n                Ok(Some(User {\n                    id,\n                    name: format!(\"User {}\", id),\n                    email: format!(\"user{}@example.com\", id),\n                }))\n            }.boxed()\n        });\n    \n    let service = UserService::new(Box::new(mock_db), Box::new(MockExternalServiceClient::new()));\n    \n    // Launch 100 concurrent requests\n    let futures: Vec<_> = (1..=100)\n        .map(|i| service.get_user_profile(i))\n        .collect();\n    \n    let results = futures::future::join_all(futures).await;\n    \n    // All should succeed\n    assert_eq!(results.len(), 100);\n    for (i, result) in results.into_iter().enumerate() {\n        assert!(result.is_ok(), \"Request {} failed: {:?}\", i + 1, result);\n    }\n}\n```\n\n## Mock External Services with WireMock\n\n```rust\n// tests/integration/external_service_test.rs\nuse wiremock::{\n    matchers::{method, path, query_param},\n    Mock, MockServer, ResponseTemplate,\n};\nuse reqwest::Client;\n\n#[tokio::test]\nasync fn test_external_service_success() {\n    let mock_server = MockServer::start().await;\n    \n    // Setup mock response\n    Mock::given(method(\"GET\"))\n        .and(path(\"/users/1/preferences\"))\n        .respond_with(\n            ResponseTemplate::new(200)\n                .set_body_json(serde_json::json!({\n                    \"theme\": \"dark\",\n                    \"notifications\": true\n                }))\n        )\n        .expect(1)\n        .mount(&mock_server)\n        .await;\n    \n    let client = ExternalServiceClientImpl::new(\n        Client::new(),\n        mock_server.uri()\n    );\n    \n    let preferences = client.get_user_preferences(1).await.unwrap();\n    assert_eq!(preferences.theme, \"dark\");\n    assert!(preferences.notifications);\n}\n\n#[tokio::test]\nasync fn test_external_service_timeout() {\n    let mock_server = MockServer::start().await;\n    \n    // Setup mock to delay response\n    Mock::given(method(\"GET\"))\n        .and(path(\"/users/1/preferences\"))\n        .respond_with(\n            ResponseTemplate::new(200)\n                .set_delay(Duration::from_secs(10)) // Longer than client timeout\n                .set_body_json(serde_json::json!({\n                    \"theme\": \"dark\",\n                    \"notifications\": true\n                }))\n        )\n        .mount(&mock_server)\n        .await;\n    \n    let client = ExternalServiceClientImpl::new_with_timeout(\n        Client::new(),\n        mock_server.uri(),\n        Duration::from_secs(1) // Short timeout\n    );\n    \n    let result = client.get_user_preferences(1).await;\n    assert!(result.is_err());\n    \n    // Verify it's a timeout error\n    assert!(result.unwrap_err().is_timeout());\n}\n\n#[tokio::test]\nasync fn test_external_service_500_error() {\n    let mock_server = MockServer::start().await;\n    \n    Mock::given(method(\"GET\"))\n        .and(path(\"/users/1/preferences\"))\n        .respond_with(ResponseTemplate::new(500))\n        .expect(1)\n        .mount(&mock_server)\n        .await;\n    \n    let client = ExternalServiceClientImpl::new(\n        Client::new(),\n        mock_server.uri()\n    );\n    \n    let result = client.get_user_preferences(1).await;\n    assert!(result.is_err());\n}\n```\n\n## Property-Based Testing\n\nTest edge cases automatically:\n\n```rust\n// tests/property/user_validation_test.rs\nuse proptest::prelude::*;\n\nproptest! {\n    #[test]\n    fn test_user_email_validation(email in \"[^@]*@[^@]*\\\\.[^@]*\") {\n        // Any string matching email pattern should be valid\n        assert!(validate_email(&email));\n    }\n    \n    #[test]\n    fn test_invalid_email_rejected(email in \"[^@]*\") {\n        // Strings without @ should be invalid\n        assert!(!validate_email(&email));\n    }\n    \n    #[test]\n    fn test_user_id_range(id in 1u32..=1000000u32) {\n        // All reasonable user IDs should be accepted\n        let request = GetUserRequest { id };\n        assert!(request.validate().is_ok());\n    }\n    \n    #[test]\n    fn test_bulk_operations_never_exceed_limits(\n        users in prop::collection::vec(\n            any::<UserUpdate>(),\n            0..200\n        )\n    ) {\n        let result = validate_bulk_update_request(&users);\n        \n        if users.len() <= 100 {\n            assert!(result.is_ok());\n        } else {\n            assert!(result.is_err());\n        }\n    }\n}\n```\n\n## Chaos Testing\n\nSimulate real-world failures:\n\n```rust\n// tests/chaos/failure_injection_test.rs\nuse std::sync::atomic::{AtomicBool, AtomicU32, Ordering};\nuse std::sync::Arc;\n\nstruct ChaosRepository {\n    inner: Box<dyn DatabaseRepository>,\n    failure_rate: f64, // 0.0 to 1.0\n    should_fail: Arc<AtomicBool>,\n    call_count: Arc<AtomicU32>,\n}\n\nimpl ChaosRepository {\n    fn new(inner: Box<dyn DatabaseRepository>, failure_rate: f64) -> Self {\n        Self {\n            inner,\n            failure_rate,\n            should_fail: Arc::new(AtomicBool::new(false)),\n            call_count: Arc::new(AtomicU32::new(0)),\n        }\n    }\n    \n    fn inject_failure(&self) {\n        self.should_fail.store(true, Ordering::Relaxed);\n    }\n    \n    fn stop_failure_injection(&self) {\n        self.should_fail.store(false, Ordering::Relaxed);\n    }\n}\n\n#[async_trait]\nimpl DatabaseRepository for ChaosRepository {\n    async fn get_user(&self, id: u32) -> Result<Option<User>, sqlx::Error> {\n        let call_num = self.call_count.fetch_add(1, Ordering::Relaxed);\n        \n        // Deterministic failure based on call count and rate\n        let should_fail = (call_num as f64 * self.failure_rate) % 1.0 < self.failure_rate;\n        \n        if should_fail || self.should_fail.load(Ordering::Relaxed) {\n            return Err(sqlx::Error::PoolClosed);\n        }\n        \n        self.inner.get_user(id).await\n    }\n    \n    // ... implement other methods similarly\n}\n\n#[tokio::test]\nasync fn test_system_resilience_under_chaos() {\n    let real_repo = create_test_database_repo().await;\n    let chaos_repo = ChaosRepository::new(Box::new(real_repo), 0.3); // 30% failure rate\n    \n    let service = UserService::new(\n        Box::new(chaos_repo),\n        Box::new(create_mock_external_service())\n    );\n    \n    let mut success_count = 0;\n    let mut failure_count = 0;\n    \n    // Run 100 operations with chaos\n    for i in 1..=100 {\n        match service.get_user_profile(i % 10).await {\n            Ok(_) => success_count += 1,\n            Err(_) => failure_count += 1,\n        }\n        \n        // Brief pause to simulate real usage\n        tokio::time::sleep(Duration::from_millis(10)).await;\n    }\n    \n    println!(\"Success: {}, Failures: {}\", success_count, failure_count);\n    \n    // System should handle failures gracefully\n    assert!(success_count > 50); // Should succeed most of the time\n    assert!(failure_count > 10); // But some failures are expected\n}\n```\n\n## Performance Testing\n\n```rust\n// benches/user_service_bench.rs\nuse criterion::{black_box, criterion_group, criterion_main, Criterion, BenchmarkId};\nuse tokio::runtime::Runtime;\n\nfn bench_concurrent_requests(c: &mut Criterion) {\n    let rt = Runtime::new().unwrap();\n    \n    let mut group = c.benchmark_group(\"concurrent_requests\");\n    \n    for concurrency in [1, 10, 50, 100, 200].iter() {\n        group.bench_with_input(\n            BenchmarkId::new(\"get_user_profile\", concurrency),\n            concurrency,\n            |b, &concurrency| {\n                b.to_async(&rt).iter(|| async {\n                    let service = create_test_service().await;\n                    \n                    let futures: Vec<_> = (1..=concurrency)\n                        .map(|i| service.get_user_profile(i % 10))\n                        .collect();\n                    \n                    let results = futures::future::join_all(futures).await;\n                    black_box(results);\n                });\n            },\n        );\n    }\n    \n    group.finish();\n}\n\ncriterion_group!(benches, bench_concurrent_requests);\ncriterion_main!(benches);\n```\n\n## Test Organization and Helpers\n\n```rust\n// tests/common/mod.rs\npub mod test_helpers {\n    use super::*;\n    \n    pub async fn create_test_app() -> Router {\n        let state = create_test_state().await;\n        create_app_with_state(state)\n    }\n    \n    pub async fn create_test_state() -> AppState {\n        AppState {\n            db: create_test_database_service().await,\n            circuit_breaker: Arc::new(CircuitBreaker::new(3, Duration::from_secs(60))),\n            external_client: create_mock_external_client(),\n        }\n    }\n    \n    pub fn assert_error_type(result: Result<impl std::fmt::Debug, AppError>, expected_error: &str) {\n        match result {\n            Ok(val) => panic!(\"Expected error '{}', but got success: {:?}\", expected_error, val),\n            Err(err) => {\n                let error_string = err.to_string();\n                assert!(\n                    error_string.contains(expected_error),\n                    \"Expected error containing '{}', got: {}\",\n                    expected_error,\n                    error_string\n                );\n            }\n        }\n    }\n    \n    pub async fn wait_for_condition<F, Fut>(\n        condition: F,\n        timeout: Duration,\n        check_interval: Duration,\n    ) -> bool\n    where\n        F: Fn() -> Fut,\n        Fut: std::future::Future<Output = bool>,\n    {\n        let start = tokio::time::Instant::now();\n        \n        while start.elapsed() < timeout {\n            if condition().await {\n                return true;\n            }\n            tokio::time::sleep(check_interval).await;\n        }\n        \n        false\n    }\n}\n```\n\n## Running Tests\n\nOrganize your test execution:\n\n```bash\n# Run unit tests (fast)\ncargo test --lib\n\n# Run integration tests (slower)\ncargo test --test '*'\n\n# Run specific test categories\ncargo test unit::\ncargo test integration::\ncargo test chaos::\n\n# Run with logging\nRUST_LOG=debug cargo test -- --nocapture\n\n# Run performance benchmarks\ncargo bench\n\n# Generate coverage report\ncargo tarpaulin --out html\n```\n\n## Key Testing Principles\n\n1. **Test Pyramid**: More unit tests, fewer integration tests, minimal end-to-end\n2. **Fail Fast**: Test error conditions as much as success cases\n3. **Isolation**: Each test should be independent\n4. **Realistic**: Use real databases for integration tests\n5. **Comprehensive**: Test timeouts, failures, and edge cases\n6. **Automated**: All tests should run in CI/CD\n\n## Testing Checklist\n\n\u2705 **Unit Tests**\n- Mock all external dependencies\n- Test success and failure paths\n- Test edge cases and validation\n- Test circuit breaker behavior\n\n\u2705 **Integration Tests**\n- Real database operations\n- External service integration\n- Timeout scenarios\n- Connection pool exhaustion\n\n\u2705 **Load Tests**\n- Concurrent request handling\n- Memory usage under load\n- Database connection limits\n- Response time distribution\n\n\u2705 **Chaos Tests**\n- Random failure injection\n- Network partitions\n- Resource exhaustion\n- Gradual degradation\n\nThis comprehensive testing strategy ensures your async Rust service is production-ready and can handle the chaos of real-world deployment!\n\nWant me to dive deeper into any specific testing pattern, or shall we explore monitoring and observability for production systems?",
    "tags": [
      "async-testing",
      "mocking",
      "integration-tests",
      "chaos-testing",
      "performance-testing",
      "testcontainers",
      "wiremock",
      "comprehensive",
      "long-conversation"
    ],
    "instruction": "Wow, this error handling stuff is incredibly detailed! I'm really getting the hang of it. But I have a follow-up question about testing all this async code. You mentioned testing error scenarios - how do I actually test things like database failures, timeouts, and circuit breakers? It seems like it would be really hard to simulate all these failure conditions."
  },
  {
    "output": "Fantastic question! Monitoring and observability are absolutely crucial for production Rust services. Let me walk you through a comprehensive monitoring strategy that will give you deep insights into your system's behavior.\n\n## The Three Pillars of Observability\n\n1. **Metrics** - Quantitative data about your system\n2. **Logs** - Detailed event information\n3. **Traces** - Request flow through your system\n\nLet's build a complete observability stack!\n\n## Setting Up Structured Logging\n\nFirst, let's implement comprehensive logging with `tracing`:\n\n```toml\n# Cargo.toml\n[dependencies]\ntracing = \"0.1\"\ntracing-subscriber = { version = \"0.3\", features = [\"env-filter\", \"json\"] }\ntracing-opentelemetry = \"0.21\"\nopentelemetry = { version = \"0.20\", features = [\"rt-tokio\"] }\nopentelemetry-jaeger = \"0.19\"\nopentelemetry-prometheus = \"0.13\"\nprometheus = \"0.13\"\naxum-tracing-opentelemetry = \"0.14\"\nserde_json = \"1.0\"\nchrono = { version = \"0.4\", features = [\"serde\"] }\nuuid = { version = \"1.0\", features = [\"v4\", \"serde\"] }\n```\n\n```rust\n// src/observability/mod.rs\nuse tracing::{info, warn, error, debug, Span};\nuse tracing_subscriber::{layer::SubscriberExt, util::SubscriberInitExt, EnvFilter};\nuse opentelemetry::KeyValue;\nuse std::collections::HashMap;\nuse uuid::Uuid;\n\npub fn init_observability() -> Result<(), Box<dyn std::error::Error>> {\n    // Create a jaeger tracer\n    let tracer = opentelemetry_jaeger::new_agent_pipeline()\n        .with_service_name(\"rust-web-api\")\n        .with_tags(vec![\n            KeyValue::new(\"version\", env!(\"CARGO_PKG_VERSION\")),\n            KeyValue::new(\"environment\", std::env::var(\"ENVIRONMENT\").unwrap_or_else(|_| \"development\".to_string())),\n        ])\n        .install_batch(opentelemetry::runtime::Tokio)?;\n\n    // Create OpenTelemetry layer\n    let telemetry = tracing_opentelemetry::layer().with_tracer(tracer);\n\n    // Environment filter for log levels\n    let env_filter = EnvFilter::try_from_default_env()\n        .unwrap_or_else(|_| EnvFilter::new(\"info\"));\n\n    // JSON formatter for structured logs\n    let json_layer = tracing_subscriber::fmt::layer()\n        .json()\n        .with_target(true)\n        .with_thread_ids(true)\n        .with_thread_names(true);\n\n    // Console layer for development\n    let console_layer = tracing_subscriber::fmt::layer()\n        .pretty()\n        .with_target(false);\n\n    // Initialize subscriber\n    tracing_subscriber::registry()\n        .with(env_filter)\n        .with(telemetry)\n        .with(json_layer)\n        .with(console_layer)\n        .init();\n\n    info!(\"Observability initialized\");\n    Ok(())\n}\n\n// Request ID middleware for tracing\n#[derive(Clone)]\npub struct RequestId(pub Uuid);\n\npub async fn request_id_middleware<B>(\n    mut request: axum::http::Request<B>,\n    next: axum::middleware::Next<B>,\n) -> axum::response::Response {\n    let request_id = Uuid::new_v4();\n    \n    // Add to request extensions\n    request.extensions_mut().insert(RequestId(request_id));\n    \n    // Create span for this request\n    let span = tracing::info_span!(\n        \"http_request\",\n        request_id = %request_id,\n        method = %request.method(),\n        uri = %request.uri(),\n        version = ?request.version(),\n    );\n    \n    let response = next.run(request).instrument(span).await;\n    \n    // Add request ID to response headers\n    let mut response = response;\n    response.headers_mut().insert(\n        \"x-request-id\",\n        request_id.to_string().parse().unwrap(),\n    );\n    \n    response\n}\n\n// Custom logging macros with context\n#[macro_export]\nmacro_rules! log_with_context {\n    ($level:ident, $request_id:expr, $message:expr, $($field:tt)*) => {\n        tracing::$level!(\n            request_id = %$request_id,\n            $message,\n            $($field)*\n        );\n    };\n}\n\n// Structured error logging\n#[derive(serde::Serialize)]\npub struct ErrorContext {\n    pub error_type: String,\n    pub error_message: String,\n    pub user_id: Option<u32>,\n    pub endpoint: String,\n    pub request_id: Uuid,\n    pub timestamp: chrono::DateTime<chrono::Utc>,\n    pub stack_trace: Option<String>,\n    pub additional_context: HashMap<String, serde_json::Value>,\n}\n\nimpl ErrorContext {\n    pub fn new(\n        error: &dyn std::error::Error,\n        endpoint: String,\n        request_id: Uuid,\n    ) -> Self {\n        Self {\n            error_type: error.to_string(),\n            error_message: format!(\"{}\", error),\n            user_id: None,\n            endpoint,\n            request_id,\n            timestamp: chrono::Utc::now(),\n            stack_trace: None,\n            additional_context: HashMap::new(),\n        }\n    }\n    \n    pub fn with_user_id(mut self, user_id: u32) -> Self {\n        self.user_id = Some(user_id);\n        self\n    }\n    \n    pub fn with_context<K: Into<String>, V: Into<serde_json::Value>>(\n        mut self,\n        key: K,\n        value: V,\n    ) -> Self {\n        self.additional_context.insert(key.into(), value.into());\n        self\n    }\n    \n    pub fn log(&self) {\n        error!(\n            error_type = %self.error_type,\n            error_message = %self.error_message,\n            user_id = ?self.user_id,\n            endpoint = %self.endpoint,\n            request_id = %self.request_id,\n            context = ?self.additional_context,\n            \"Application error occurred\"\n        );\n    }\n}\n```\n\n## Comprehensive Metrics Collection\n\nNow let's set up detailed metrics:\n\n```rust\n// src/observability/metrics.rs\nuse prometheus::{\n    Counter, Histogram, Gauge, IntCounter, IntGauge,\n    register_counter, register_histogram, register_gauge,\n    register_int_counter, register_int_gauge,\n    opts, histogram_opts,\n};\nuse std::sync::OnceLock;\nuse std::time::Instant;\n\n// Global metrics registry\npub struct Metrics {\n    // HTTP metrics\n    pub http_requests_total: IntCounter,\n    pub http_request_duration: Histogram,\n    pub http_requests_in_flight: IntGauge,\n    \n    // Database metrics\n    pub db_connections_active: IntGauge,\n    pub db_connections_idle: IntGauge,\n    pub db_query_duration: Histogram,\n    pub db_query_errors_total: IntCounter,\n    \n    // Business metrics\n    pub users_created_total: IntCounter,\n    pub users_active_sessions: IntGauge,\n    pub cache_hits_total: IntCounter,\n    pub cache_misses_total: IntCounter,\n    \n    // System metrics\n    pub memory_usage_bytes: Gauge,\n    pub cpu_usage_percent: Gauge,\n    pub goroutines_count: IntGauge,\n    \n    // Error metrics\n    pub errors_total: IntCounter,\n    pub circuit_breaker_state: IntGauge, // 0=closed, 1=open, 2=half-open\n    \n    // External service metrics\n    pub external_service_requests: IntCounter,\n    pub external_service_duration: Histogram,\n    pub external_service_errors: IntCounter,\n}\n\nstatic METRICS: OnceLock<Metrics> = OnceLock::new();\n\nimpl Metrics {\n    pub fn init() -> Result<(), prometheus::Error> {\n        let metrics = Metrics {\n            http_requests_total: register_int_counter!(\n                opts!(\"http_requests_total\", \"Total number of HTTP requests\")\n            )?,\n            \n            http_request_duration: register_histogram!(\n                histogram_opts!(\n                    \"http_request_duration_seconds\",\n                    \"HTTP request duration in seconds\",\n                    vec![0.001, 0.005, 0.01, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0, 10.0]\n                )\n            )?,\n            \n            http_requests_in_flight: register_int_gauge!(\n                opts!(\"http_requests_in_flight\", \"Number of HTTP requests being processed\")\n            )?,\n            \n            db_connections_active: register_int_gauge!(\n                opts!(\"db_connections_active\", \"Number of active database connections\")\n            )?,\n            \n            db_connections_idle: register_int_gauge!(\n                opts!(\"db_connections_idle\", \"Number of idle database connections\")\n            )?,\n            \n            db_query_duration: register_histogram!(\n                histogram_opts!(\n                    \"db_query_duration_seconds\",\n                    \"Database query duration in seconds\",\n                    vec![0.001, 0.005, 0.01, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0]\n                )\n            )?,\n            \n            db_query_errors_total: register_int_counter!(\n                opts!(\"db_query_errors_total\", \"Total number of database query errors\")\n            )?,\n            \n            users_created_total: register_int_counter!(\n                opts!(\"users_created_total\", \"Total number of users created\")\n            )?,\n            \n            users_active_sessions: register_int_gauge!(\n                opts!(\"users_active_sessions\", \"Number of active user sessions\")\n            )?,\n            \n            cache_hits_total: register_int_counter!(\n                opts!(\"cache_hits_total\", \"Total number of cache hits\")\n            )?,\n            \n            cache_misses_total: register_int_counter!(\n                opts!(\"cache_misses_total\", \"Total number of cache misses\")\n            )?,\n            \n            memory_usage_bytes: register_gauge!(\n                opts!(\"memory_usage_bytes\", \"Current memory usage in bytes\")\n            )?,\n            \n            cpu_usage_percent: register_gauge!(\n                opts!(\"cpu_usage_percent\", \"Current CPU usage percentage\")\n            )?,\n            \n            goroutines_count: register_int_gauge!(\n                opts!(\"goroutines_count\", \"Number of goroutines\")\n            )?,\n            \n            errors_total: register_int_counter!(\n                opts!(\"errors_total\", \"Total number of errors\")\n            )?,\n            \n            circuit_breaker_state: register_int_gauge!(\n                opts!(\"circuit_breaker_state\", \"Circuit breaker state (0=closed, 1=open, 2=half-open)\")\n            )?,\n            \n            external_service_requests: register_int_counter!(\n                opts!(\"external_service_requests_total\", \"Total requests to external services\")\n            )?,\n            \n            external_service_duration: register_histogram!(\n                histogram_opts!(\n                    \"external_service_duration_seconds\",\n                    \"External service request duration in seconds\",\n                    vec![0.01, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0, 10.0, 30.0]\n                )\n            )?,\n            \n            external_service_errors: register_int_counter!(\n                opts!(\"external_service_errors_total\", \"Total errors from external services\")\n            )?,\n        };\n        \n        METRICS.set(metrics).map_err(|_| {\n            prometheus::Error::Msg(\"Metrics already initialized\".to_string())\n        })?;\n        \n        Ok(())\n    }\n    \n    pub fn global() -> &'static Metrics {\n        METRICS.get().expect(\"Metrics not initialized\")\n    }\n}\n\n// Metrics middleware\npub async fn metrics_middleware<B>(\n    request: axum::http::Request<B>,\n    next: axum::middleware::Next<B>,\n) -> axum::response::Response {\n    let start_time = Instant::now();\n    let method = request.method().clone();\n    let uri = request.uri().clone();\n    \n    // Increment in-flight requests\n    Metrics::global().http_requests_in_flight.inc();\n    \n    // Process request\n    let response = next.run(request).await;\n    \n    // Record metrics\n    let duration = start_time.elapsed().as_secs_f64();\n    let status_code = response.status().as_u16();\n    \n    Metrics::global().http_requests_total.inc();\n    Metrics::global().http_request_duration.observe(duration);\n    Metrics::global().http_requests_in_flight.dec();\n    \n    // Log slow requests\n    if duration > 1.0 {\n        warn!(\n            method = %method,\n            uri = %uri,\n            status = status_code,\n            duration = duration,\n            \"Slow HTTP request detected\"\n        );\n    }\n    \n    response\n}\n\n// Database metrics helper\npub struct DatabaseMetricsCollector {\n    pool: sqlx::PgPool,\n}\n\nimpl DatabaseMetricsCollector {\n    pub fn new(pool: sqlx::PgPool) -> Self {\n        Self { pool }\n    }\n    \n    pub async fn collect_metrics(&self) {\n        let pool_status = self.pool.options();\n        \n        // Note: This is simplified - real implementation would use pool.status()\n        // when available in your sqlx version\n        Metrics::global().db_connections_active.set(0); // Would get from pool status\n        Metrics::global().db_connections_idle.set(0);   // Would get from pool status\n    }\n    \n    pub async fn start_background_collection(&self) {\n        let mut interval = tokio::time::interval(std::time::Duration::from_secs(10));\n        \n        loop {\n            interval.tick().await;\n            self.collect_metrics().await;\n        }\n    }\n}\n\n// Helper for timing operations\npub struct Timer {\n    start: Instant,\n    histogram: &'static Histogram,\n}\n\nimpl Timer {\n    pub fn new(histogram: &'static Histogram) -> Self {\n        Self {\n            start: Instant::now(),\n            histogram,\n        }\n    }\n}\n\nimpl Drop for Timer {\n    fn drop(&mut self) {\n        let duration = self.start.elapsed().as_secs_f64();\n        self.histogram.observe(duration);\n    }\n}\n\n// Macro for easy timing\n#[macro_export]\nmacro_rules! time_operation {\n    ($histogram:expr, $operation:expr) => {{\n        let _timer = Timer::new($histogram);\n        $operation\n    }};\n}\n```\n\n## Instrumented Service Implementation\n\nLet's update our services with comprehensive instrumentation:\n\n```rust\n// src/services/user_service.rs\nuse tracing::{info, warn, error, debug, instrument};\nuse crate::observability::{Metrics, ErrorContext, RequestId};\nuse crate::time_operation;\n\npub struct UserService {\n    db: Box<dyn DatabaseRepository>,\n    external_client: Box<dyn ExternalServiceClient>,\n    cache: Cache,\n}\n\nimpl UserService {\n    #[instrument(\n        skip(self),\n        fields(\n            user_id = %user_id,\n            service = \"user_service\",\n            operation = \"get_profile\"\n        )\n    )]\n    pub async fn get_user_profile(\n        &self,\n        user_id: u32,\n        request_id: RequestId,\n    ) -> Result<UserProfile, AppError> {\n        info!(\"Starting user profile retrieval\");\n        \n        // Check cache first\n        if let Some(cached_profile) = self.check_cache(user_id).await {\n            Metrics::global().cache_hits_total.inc();\n            info!(\"Cache hit for user profile\");\n            return Ok(cached_profile);\n        }\n        \n        Metrics::global().cache_misses_total.inc();\n        debug!(\"Cache miss, fetching from database\");\n        \n        // Fetch user from database with timing\n        let user = time_operation!(\n            &Metrics::global().db_query_duration,\n            self.fetch_user_with_retry(user_id, &request_id).await\n        )?;\n        \n        // Fetch additional data concurrently\n        let start_concurrent = std::time::Instant::now();\n        let (preferences_result, stats_result, activity_result) = tokio::join!(\n            self.fetch_user_preferences(user_id, &request_id),\n            self.fetch_user_stats(user_id, &request_id),\n            self.fetch_user_activity(user_id, &request_id)\n        );\n        \n        debug!(\n            concurrent_duration = ?start_concurrent.elapsed(),\n            \"Completed concurrent data fetching\"\n        );\n        \n        // Handle partial failures gracefully\n        let mut profile = UserProfile {\n            user,\n            preferences: None,\n            stats: None,\n            activity: None,\n        };\n        \n        // Process each result with detailed logging\n        match preferences_result {\n            Ok(prefs) => {\n                profile.preferences = Some(prefs);\n                debug!(\"Successfully fetched user preferences\");\n            }\n            Err(e) => {\n                warn!(\n                    error = %e,\n                    \"Failed to fetch user preferences, continuing with degraded profile\"\n                );\n                \n                ErrorContext::new(&*e, \"get_user_preferences\".to_string(), request_id.0)\n                    .with_user_id(user_id)\n                    .with_context(\"degraded_service\", \"preferences\")\n                    .log();\n                    \n                Metrics::global().external_service_errors.inc();\n            }\n        }\n        \n        match stats_result {\n            Ok(stats) => {\n                profile.stats = Some(stats);\n                debug!(\"Successfully fetched user stats\");\n            }\n            Err(e) => {\n                warn!(\n                    error = %e,\n                    \"Failed to fetch user stats, continuing with degraded profile\"\n                );\n                \n                ErrorContext::new(&*e, \"get_user_stats\".to_string(), request_id.0)\n                    .with_user_id(user_id)\n                    .with_context(\"degraded_service\", \"stats\")\n                    .log();\n            }\n        }\n        \n        match activity_result {\n            Ok(activity) => {\n                profile.activity = Some(activity);\n                debug!(\"Successfully fetched user activity\");\n            }\n            Err(e) => {\n                warn!(\n                    error = %e,\n                    \"Failed to fetch user activity, continuing with degraded profile\"\n                );\n            }\n        }\n        \n        // Cache the result (even if partially degraded)\n        if let Err(cache_error) = self.cache_profile(&profile).await {\n            warn!(\n                error = %cache_error,\n                \"Failed to cache user profile\"\n            );\n        }\n        \n        info!(\n            preferences_available = profile.preferences.is_some(),\n            stats_available = profile.stats.is_some(),\n            activity_available = profile.activity.is_some(),\n            \"Successfully retrieved user profile\"\n        );\n        \n        Ok(profile)\n    }\n    \n    #[instrument(skip(self), fields(user_id = %user_id))]\n    async fn fetch_user_with_retry(\n        &self,\n        user_id: u32,\n        request_id: &RequestId,\n    ) -> Result<User, AppError> {\n        let max_retries = 3;\n        let mut last_error = None;\n        \n        for attempt in 1..=max_retries {\n            debug!(attempt = attempt, \"Attempting database query\");\n            \n            match self.db.get_user(user_id).await {\n                Ok(Some(user)) => {\n                    debug!(\"Database query successful\");\n                    return Ok(user);\n                }\n                Ok(None) => {\n                    return Err(AppError::Validation {\n                        field: \"user_id\".to_string(),\n                        message: \"User not found\".to_string(),\n                    });\n                }\n                Err(e) => {\n                    last_error = Some(e);\n                    Metrics::global().db_query_errors_total.inc();\n                    \n                    if attempt < max_retries {\n                        let delay = std::time::Duration::from_millis(100 * attempt as u64);\n                        warn!(\n                            attempt = attempt,\n                            delay_ms = delay.as_millis(),\n                            error = %last_error.as_ref().unwrap(),\n                            \"Database query failed, retrying\"\n                        );\n                        tokio::time::sleep(delay).await;\n                    }\n                }\n            }\n        }\n        \n        let error = last_error.unwrap();\n        ErrorContext::new(&error, \"fetch_user_with_retry\".to_string(), request_id.0)\n            .with_user_id(user_id)\n            .with_context(\"max_retries\", max_retries)\n            .log();\n            \n        Err(AppError::Database(error))\n    }\n    \n    #[instrument(skip(self), fields(user_id = %user_id))]\n    async fn fetch_user_preferences(\n        &self,\n        user_id: u32,\n        request_id: &RequestId,\n    ) -> Result<UserPreferences, AppError> {\n        let _timer = crate::observability::metrics::Timer::new(\n            &Metrics::global().external_service_duration\n        );\n        \n        Metrics::global().external_service_requests.inc();\n        \n        debug!(\"Fetching user preferences from external service\");\n        \n        let timeout_duration = std::time::Duration::from_secs(5);\n        match tokio::time::timeout(\n            timeout_duration,\n            self.external_client.get_user_preferences(user_id)\n        ).await {\n            Ok(Ok(preferences)) => {\n                debug!(\"Successfully fetched user preferences\");\n                Ok(preferences)\n            }\n            Ok(Err(e)) => {\n                warn!(\n                    error = %e,\n                    \"External service returned error\"\n                );\n                Metrics::global().external_service_errors.inc();\n                Err(AppError::ServiceUnavailable {\n                    service: \"preferences-api\".to_string(),\n                })\n            }\n            Err(_) => {\n                warn!(\n                    timeout_seconds = timeout_duration.as_secs(),\n                    \"External service request timed out\"\n                );\n                Metrics::global().external_service_errors.inc();\n                Err(AppError::Timeout {\n                    timeout: timeout_duration,\n                })\n            }\n        }\n    }\n    \n    async fn check_cache(&self, user_id: u32) -> Option<UserProfile> {\n        match self.cache.get(&format!(\"user_profile:{}\", user_id)).await {\n            Ok(Some(cached)) => {\n                debug!(\"Found cached user profile\");\n                Some(cached)\n            }\n            Ok(None) => {\n                debug!(\"No cached user profile found\");\n                None\n            }\n            Err(e) => {\n                warn!(\n                    error = %e,\n                    \"Cache lookup failed, proceeding without cache\"\n                );\n                None\n            }\n        }\n    }\n    \n    async fn cache_profile(&self, profile: &UserProfile) -> Result<(), AppError> {\n        let cache_key = format!(\"user_profile:{}\", profile.user.id);\n        let ttl = std::time::Duration::from_secs(300); // 5 minutes\n        \n        self.cache.set(&cache_key, profile, ttl).await\n            .map_err(|e| {\n                warn!(\n                    error = %e,\n                    cache_key = %cache_key,\n                    \"Failed to cache user profile\"\n                );\n                AppError::Internal(Box::new(e))\n            })\n    }\n}\n```\n\n## Health Checks and Monitoring Endpoints\n\n```rust\n// src/handlers/monitoring.rs\nuse axum::{extract::State, response::Json, http::StatusCode};\nuse serde::{Serialize, Deserialize};\nuse std::collections::HashMap;\nuse crate::observability::Metrics;\n\n#[derive(Serialize)]\npub struct HealthResponse {\n    pub status: String,\n    pub timestamp: chrono::DateTime<chrono::Utc>,\n    pub version: String,\n    pub uptime_seconds: u64,\n    pub checks: HashMap<String, HealthCheck>,\n}\n\n#[derive(Serialize)]\npub struct HealthCheck {\n    pub status: String,\n    pub response_time_ms: u64,\n    pub details: Option<serde_json::Value>,\n}\n\n#[derive(Serialize)]\npub struct MetricsSnapshot {\n    pub http_requests_total: u64,\n    pub http_requests_in_flight: i64,\n    pub db_connections_active: i64,\n    pub errors_total: u64,\n    pub cache_hit_rate: f64,\n    pub memory_usage_mb: f64,\n    pub timestamp: chrono::DateTime<chrono::Utc>,\n}\n\nstatic START_TIME: std::sync::OnceLock<std::time::Instant> = std::sync::OnceLock::new();\n\npub fn init_start_time() {\n    START_TIME.set(std::time::Instant::now()).ok();\n}\n\npub async fn health_check(\n    State(state): State<AppState>,\n) -> Result<Json<HealthResponse>, StatusCode> {\n    let start_time = std::time::Instant::now();\n    let mut checks = HashMap::new();\n    \n    // Database health check\n    let db_start = std::time::Instant::now();\n    let db_status = match state.db.health_check().await {\n        Ok(_) => HealthCheck {\n            status: \"healthy\".to_string(),\n            response_time_ms: db_start.elapsed().as_millis() as u64,\n            details: Some(serde_json::json!({\n                \"connection_pool\": \"active\"\n            })),\n        },\n        Err(e) => HealthCheck {\n            status: \"unhealthy\".to_string(),\n            response_time_ms: db_start.elapsed().as_millis() as u64,\n            details: Some(serde_json::json!({\n                \"error\": e.to_string()\n            })),\n        },\n    };\n    checks.insert(\"database\".to_string(), db_status);\n    \n    // Cache health check\n    let cache_start = std::time::Instant::now();\n    let cache_status = match state.cache.ping().await {\n        Ok(_) => HealthCheck {\n            status: \"healthy\".to_string(),\n            response_time_ms: cache_start.elapsed().as_millis() as u64,\n            details: None,\n        },\n        Err(e) => HealthCheck {\n            status: \"unhealthy\".to_string(),\n            response_time_ms: cache_start.elapsed().as_millis() as u64,\n            details: Some(serde_json::json!({\n                \"error\": e.to_string()\n            })),\n        },\n    };\n    checks.insert(\"cache\".to_string(), cache_status);\n    \n    // External service health check\n    let external_start = std::time::Instant::now();\n    let external_status = match test_external_service_connectivity(&state).await {\n        Ok(_) => HealthCheck {\n            status: \"healthy\".to_string(),\n            response_time_ms: external_start.elapsed().as_millis() as u64,\n            details: None,\n        },\n        Err(e) => HealthCheck {\n            status: \"degraded\".to_string(), // Not critical for health\n            response_time_ms: external_start.elapsed().as_millis() as u64,\n            details: Some(serde_json::json!({\n                \"error\": e.to_string(),\n                \"impact\": \"Some features may be unavailable\"\n            })),\n        },\n    };\n    checks.insert(\"external_services\".to_string(), external_status);\n    \n    // Determine overall health\n    let overall_healthy = checks.values().all(|check| {\n        check.status == \"healthy\" || check.status == \"degraded\"\n    });\n    \n    let uptime = START_TIME.get()\n        .map(|start| start.elapsed().as_secs())\n        .unwrap_or(0);\n    \n    let response = HealthResponse {\n        status: if overall_healthy { \"healthy\" } else { \"unhealthy\" }.to_string(),\n        timestamp: chrono::Utc::now(),\n        version: env!(\"CARGO_PKG_VERSION\").to_string(),\n        uptime_seconds: uptime,\n        checks,\n    };\n    \n    if overall_healthy {\n        Ok(Json(response))\n    } else {\n        Err(StatusCode::SERVICE_UNAVAILABLE)\n    }\n}\n\npub async fn metrics_endpoint() -> String {\n    use prometheus::{Encoder, TextEncoder};\n    \n    let encoder = TextEncoder::new();\n    let metric_families = prometheus::gather();\n    \n    encoder.encode_to_string(&metric_families)\n        .unwrap_or_else(|e| {\n            error!(\"Failed to encode metrics: {}\", e);\n            \"# Failed to encode metrics\\n\".to_string()\n        })\n}\n\npub async fn metrics_json() -> Json<MetricsSnapshot> {\n    let metrics = Metrics::global();\n    \n    let cache_hits = metrics.cache_hits_total.get();\n    let cache_misses = metrics.cache_misses_total.get();\n    let cache_hit_rate = if cache_hits + cache_misses > 0 {\n        cache_hits as f64 / (cache_hits + cache_misses) as f64\n    } else {\n        0.0\n    };\n    \n    let snapshot = MetricsSnapshot {\n        http_requests_total: metrics.http_requests_total.get(),\n        http_requests_in_flight: metrics.http_requests_in_flight.get(),\n        db_connections_active: metrics.db_connections_active.get(),\n        errors_total: metrics.errors_total.get(),\n        cache_hit_rate,\n        memory_usage_mb: metrics.memory_usage_bytes.get() / 1024.0 / 1024.0,\n        timestamp: chrono::Utc::now(),\n    };\n    \n    Json(snapshot)\n}\n\n// Readiness probe (for Kubernetes)\npub async fn readiness_check(\n    State(state): State<AppState>,\n) -> Result<&'static str, StatusCode> {\n    // Quick checks for readiness\n    match state.db.health_check().await {\n        Ok(_) => Ok(\"ready\"),\n        Err(_) => Err(StatusCode::SERVICE_UNAVAILABLE),\n    }\n}\n\n// Liveness probe (for Kubernetes)\npub async fn liveness_check() -> &'static str {\n    // Simple check that the process is alive\n    \"alive\"\n}\n\nasync fn test_external_service_connectivity(\n    state: &AppState,\n) -> Result<(), Box<dyn std::error::Error>> {\n    // Test external service with a lightweight request\n    let timeout = std::time::Duration::from_secs(2);\n    \n    tokio::time::timeout(\n        timeout,\n        state.external_client.health_check()\n    ).await??;\n    \n    Ok(())\n}\n```\n\n## System Resource Monitoring\n\n```rust\n// src/observability/system_metrics.rs\nuse tokio::time::{interval, Duration};\nuse crate::observability::Metrics;\nuse tracing::{debug, warn, error};\n\npub struct SystemMetricsCollector {\n    process_id: u32,\n}\n\nimpl SystemMetricsCollector {\n    pub fn new() -> Self {\n        Self {\n            process_id: std::process::id(),\n        }\n    }\n    \n    pub async fn start_collection(&self) {\n        let mut interval = interval(Duration::from_secs(15));\n        \n        loop {\n            interval.tick().await;\n            \n            if let Err(e) = self.collect_system_metrics().await {\n                warn!(\"Failed to collect system metrics: {}\", e);\n            }\n        }\n    }\n    \n    async fn collect_system_metrics(&self) -> Result<(), Box<dyn std::error::Error>> {\n        // Memory usage\n        if let Ok(memory_usage) = self.get_memory_usage().await {\n            Metrics::global().memory_usage_bytes.set(memory_usage as f64);\n            debug!(\"Updated memory usage metric: {} bytes\", memory_usage);\n        }\n        \n        // CPU usage\n        if let Ok(cpu_usage) = self.get_cpu_usage().await {\n            Metrics::global().cpu_usage_percent.set(cpu_usage);\n            debug!(\"Updated CPU usage metric: {:.2}%\", cpu_usage);\n        }\n        \n        // Thread count (approximation of goroutines)\n        let thread_count = self.get_thread_count();\n        Metrics::global().goroutines_count.set(thread_count);\n        \n        Ok(())\n    }\n    \n    async fn get_memory_usage(&self) -> Result<u64, Box<dyn std::error::Error>> {\n        // On Linux, read from /proc/self/status\n        #[cfg(target_os = \"linux\")]\n        {\n            let status = tokio::fs::read_to_string(\"/proc/self/status\").await?;\n            for line in status.lines() {\n                if line.starts_with(\"VmRSS:\") {\n                    let parts: Vec<&str> = line.split_whitespace().collect();\n                    if parts.len() >= 2 {\n                        let kb: u64 = parts[1].parse()?;\n                        return Ok(kb * 1024); // Convert KB to bytes\n                    }\n                }\n            }\n        }\n        \n        // Fallback or other platforms\n        Ok(0)\n    }\n    \n    async fn get_cpu_usage(&self) -> Result<f64, Box<dyn std::error::Error>> {\n        // This is a simplified implementation\n        // In production, you'd want to use a proper system monitoring library\n        \n        #[cfg(target_os = \"linux\")]\n        {\n            // Read CPU stats from /proc/stat\n            let stat = tokio::fs::read_to_string(\"/proc/stat\").await?;\n            if let Some(cpu_line) = stat.lines().next() {\n                // Parse CPU usage - this is simplified\n                // Real implementation would track deltas over time\n                return Ok(0.0); // Placeholder\n            }\n        }\n        \n        Ok(0.0)\n    }\n    \n    fn get_thread_count(&self) -> i64 {\n        // Get current thread count\n        // This is simplified - real implementation would use system APIs\n        1 // Placeholder\n    }\n}\n```\n\n## Alert Configuration\n\n```rust\n// src/observability/alerts.rs\nuse tracing::{error, warn, info};\nuse serde::{Serialize, Deserialize};\nuse std::collections::HashMap;\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct AlertRule {\n    pub name: String,\n    pub condition: AlertCondition,\n    pub severity: AlertSeverity,\n    pub description: String,\n    pub runbook_url: Option<String>,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub enum AlertCondition {\n    MetricThreshold {\n        metric_name: String,\n        operator: ComparisonOperator,\n        threshold: f64,\n        duration_seconds: u64,\n    },\n    ErrorRate {\n        threshold_percent: f64,\n        window_seconds: u64,\n    },\n    ResponseTime {\n        percentile: f64,\n        threshold_ms: f64,\n        window_seconds: u64,\n    },\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub enum ComparisonOperator {\n    GreaterThan,\n    LessThan,\n    Equals,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub enum AlertSeverity {\n    Critical,\n    Warning,\n    Info,\n}\n\npub struct AlertManager {\n    rules: Vec<AlertRule>,\n    notification_channels: Vec<Box<dyn NotificationChannel>>,\n}\n\n#[async_trait::async_trait]\npub trait NotificationChannel: Send + Sync {\n    async fn send_alert(&self, alert: &Alert) -> Result<(), Box<dyn std::error::Error>>;\n}\n\n#[derive(Debug, Clone, Serialize)]\npub struct Alert {\n    pub rule_name: String,\n    pub severity: AlertSeverity,\n    pub message: String,\n    pub timestamp: chrono::DateTime<chrono::Utc>,\n    pub labels: HashMap<String, String>,\n    pub annotations: HashMap<String, String>,\n}\n\nimpl AlertManager {\n    pub fn new() -> Self {\n        Self {\n            rules: Self::default_rules(),\n            notification_channels: Vec::new(),\n        }\n    }\n    \n    fn default_rules() -> Vec<AlertRule> {\n        vec![\n            AlertRule {\n                name: \"HighErrorRate\".to_string(),\n                condition: AlertCondition::ErrorRate {\n                    threshold_percent: 5.0,\n                    window_seconds: 300,\n                },\n                severity: AlertSeverity::Critical,\n                description: \"Error rate is above 5% for 5 minutes\".to_string(),\n                runbook_url: Some(\"https://runbooks.example.com/high-error-rate\".to_string()),\n            },\n            AlertRule {\n                name: \"HighResponseTime\".to_string(),\n                condition: AlertCondition::ResponseTime {\n                    percentile: 95.0,\n                    threshold_ms: 2000.0,\n                    window_seconds: 300,\n                },\n                severity: AlertSeverity::Warning,\n                description: \"95th percentile response time is above 2s\".to_string(),\n                runbook_url: Some(\"https://runbooks.example.com/high-latency\".to_string()),\n            },\n            AlertRule {\n                name: \"DatabaseConnectionsHigh\".to_string(),\n                condition: AlertCondition::MetricThreshold {\n                    metric_name: \"db_connections_active\".to_string(),\n                    operator: ComparisonOperator::GreaterThan,\n                    threshold: 80.0,\n                    duration_seconds: 120,\n                },\n                severity: AlertSeverity::Warning,\n                description: \"Database connection usage is high\".to_string(),\n                runbook_url: None,\n            },\n        ]\n    }\n    \n    pub async fn evaluate_rules(&self) {\n        for rule in &self.rules {\n            if let Ok(should_alert) = self.evaluate_rule(rule).await {\n                if should_alert {\n                    let alert = Alert {\n                        rule_name: rule.name.clone(),\n                        severity: rule.severity.clone(),\n                        message: format!(\"Alert: {}\", rule.description),\n                        timestamp: chrono::Utc::now(),\n                        labels: HashMap::new(),\n                        annotations: [\n                            (\"description\".to_string(), rule.description.clone()),\n                            (\"runbook_url\".to_string(), rule.runbook_url.clone().unwrap_or_default()),\n                        ].into(),\n                    };\n                    \n                    self.send_alert(&alert).await;\n                }\n            }\n        }\n    }\n    \n    async fn evaluate_rule(&self, rule: &AlertRule) -> Result<bool, Box<dyn std::error::Error>> {\n        match &rule.condition {\n            AlertCondition::MetricThreshold { metric_name, operator, threshold, .. } => {\n                let current_value = self.get_metric_value(metric_name).await?;\n                \n                let triggered = match operator {\n                    ComparisonOperator::GreaterThan => current_value > *threshold,\n                    ComparisonOperator::LessThan => current_value < *threshold,\n                    ComparisonOperator::Equals => (current_value - threshold).abs() < 0.001,\n                };\n                \n                Ok(triggered)\n            }\n            AlertCondition::ErrorRate { threshold_percent, window_seconds } => {\n                // Calculate error rate over the window\n                let error_rate = self.calculate_error_rate(*window_seconds).await?;\n                Ok(error_rate > *threshold_percent)\n            }\n            AlertCondition::ResponseTime { percentile, threshold_ms, window_seconds } => {\n                // Calculate response time percentile\n                let response_time = self.calculate_response_time_percentile(\n                    *percentile,\n                    *window_seconds\n                ).await?;\n                Ok(response_time > *threshold_ms)\n            }\n        }\n    }\n    \n    async fn send_alert(&self, alert: &Alert) {\n        error!(\n            alert_name = %alert.rule_name,\n            severity = ?alert.severity,\n            message = %alert.message,\n            \"ALERT TRIGGERED\"\n        );\n        \n        for channel in &self.notification_channels {\n            if let Err(e) = channel.send_alert(alert).await {\n                error!(\"Failed to send alert via notification channel: {}\", e);\n            }\n        }\n    }\n    \n    async fn get_metric_value(&self, metric_name: &str) -> Result<f64, Box<dyn std::error::Error>> {\n        let metrics = crate::observability::Metrics::global();\n        \n        let value = match metric_name {\n            \"db_connections_active\" => metrics.db_connections_active.get() as f64,\n            \"memory_usage_bytes\" => metrics.memory_usage_bytes.get(),\n            \"cpu_usage_percent\" => metrics.cpu_usage_percent.get(),\n            _ => return Err(format!(\"Unknown metric: {}\", metric_name).into()),\n        };\n        \n        Ok(value)\n    }\n    \n    async fn calculate_error_rate(&self, window_seconds: u64) -> Result<f64, Box<dyn std::error::Error>> {\n        // Simplified calculation - in production you'd query time-series data\n        let total_requests = crate::observability::Metrics::global().http_requests_total.get();\n        let total_errors = crate::observability::Metrics::global().errors_total.get();\n        \n        if total_requests == 0 {\n            return Ok(0.0);\n        }\n        \n        let error_rate = (total_errors as f64 / total_requests as f64) * 100.0;\n        Ok(error_rate)\n    }\n    \n    async fn calculate_response_time_percentile(\n        &self,\n        percentile: f64,\n        window_seconds: u64,\n    ) -> Result<f64, Box<dyn std::error::Error>> {\n        // Simplified - in production you'd use histogram quantiles\n        // This would require storing time-series data\n        Ok(0.0)\n    }\n}\n```\n\n## Production Monitoring Checklist\n\n### Essential Metrics to Track:\n\n**Application Metrics:**\n- \u2705 Request rate (requests/second)\n- \u2705 Response time (p50, p95, p99)\n- \u2705 Error rate (4xx, 5xx)\n- \u2705 Concurrent requests\n- \u2705 Database query performance\n- \u2705 Cache hit/miss ratio\n- \u2705 External service dependency health\n\n**System Metrics:**\n- \u2705 CPU usage\n- \u2705 Memory usage\n- \u2705 Disk I/O\n- \u2705 Network I/O\n- \u2705 File descriptor usage\n- \u2705 Thread/goroutine count\n\n**Business Metrics:**\n- \u2705 User registrations\n- \u2705 Active sessions\n- \u2705 Feature usage\n- \u2705 Revenue impact\n\n### Alerting Strategy:\n\n1. **Critical Alerts** (Page immediately)\n   - Service completely down\n   - Error rate > 10%\n   - Database unreachable\n   - Memory usage > 90%\n\n2. **Warning Alerts** (Review during business hours)\n   - Response time > 2s (p95)\n   - Error rate > 5%\n   - Cache hit rate < 80%\n   - CPU usage > 80%\n\n3. **Info Alerts** (For trending)\n   - New deployments\n   - Configuration changes\n   - Scaling events\n\n### Dashboard Design:\n\n**Overview Dashboard:**\n- Service health status\n- Key performance indicators\n- Recent alerts\n- Deployment timeline\n\n**Detailed Dashboards:**\n- HTTP request analytics\n- Database performance\n- External dependencies\n- System resources\n- Error analysis\n\nThis monitoring setup gives you comprehensive visibility into your Rust service's behavior in production. You'll be able to detect issues before they impact users, understand performance characteristics, and debug problems quickly when they occur.\n\nWant me to dive deeper into any specific aspect, like setting up Grafana dashboards or implementing custom notification channels?",
    "tags": [
      "monitoring",
      "observability",
      "metrics",
      "logging",
      "tracing",
      "alerts",
      "production",
      "comprehensive",
      "long-conversation"
    ],
    "instruction": "This testing approach is incredibly thorough! I feel like I'm really getting a handle on building production-ready Rust services. But I'm curious - once I deploy this to production, how do I monitor it? What metrics should I track, and how do I debug issues when things go wrong in a live system?"
  },
  {
    "output": "I completely understand your frustration! You're absolutely not alone in feeling this way. Rust IS different from JavaScript and Python in fundamental ways, and that's actually what makes it powerful - but it also makes the learning curve steeper. Let me give you a realistic roadmap that will help you become productive step by step.\n\n## Why Rust Feels So Different\n\nFirst, let's acknowledge what you're experiencing:\n\n**JavaScript/Python mindset:**\n```javascript\n// JavaScript - everything is a reference, GC handles memory\nlet data = [1, 2, 3];\nlet copy = data;  // Both point to same array\ndata.push(4);     // Both see the change\nconsole.log(copy); // [1, 2, 3, 4]\n\nfunction processData(arr) {\n    arr.push(999);  // Modifies original\n    return arr.length;\n}\n```\n\n**Rust forces you to think differently:**\n```rust\n// Rust - explicit ownership and borrowing\nlet data = vec![1, 2, 3];\nlet moved_data = data;  // data is MOVED, no longer accessible\n// data.push(4);        // ERROR! data was moved\n\nfn process_data(arr: &mut Vec<i32>) -> usize {\n    arr.push(999);  // Need explicit mutable borrow\n    arr.len()\n}\n```\n\nThe difference isn't just syntax - it's a completely different mental model!\n\n## Learning Path: From Overwhelming to Productive\n\n### Phase 1: Get Something Working (Week 1-2)\n**Goal: Build confidence with simple programs**\n\nStart with basic Rust without worrying about the \"hard parts\":\n\n```rust\n// Day 1: Basic syntax and types\nfn main() {\n    let name = \"Alice\";\n    let age = 30;\n    let is_student = false;\n    \n    println!(\"Hello, {}! You are {} years old.\", name, age);\n    \n    if age >= 18 {\n        println!(\"You're an adult!\");\n    }\n}\n\n// Day 2: Functions and basic control flow\nfn greet(name: &str, age: u32) {\n    println!(\"Hi {}, you're {} years old!\", name, age);\n}\n\nfn is_even(n: i32) -> bool {\n    n % 2 == 0\n}\n\nfn main() {\n    for i in 1..=10 {\n        if is_even(i) {\n            println!(\"{} is even\", i);\n        }\n    }\n    \n    greet(\"Bob\", 25);\n}\n```\n\n**Focus on:**\n- Variables and basic types (`i32`, `String`, `bool`)\n- Functions with simple parameters\n- `if/else`, `for` loops, `match` on simple values\n- `println!` macro\n- **Don't worry about**: borrowing, lifetimes, complex ownership\n\n**Mini-projects to try:**\n- Calculator that takes two numbers and adds them\n- FizzBuzz implementation\n- Simple number guessing game\n- Temperature converter\n\n### Phase 2: Understanding Ownership (Week 3-4)\n**Goal: Make peace with the borrow checker**\n\nThis is where most people get stuck. Take it slow:\n\n```rust\n// Start with owned values (no borrowing yet)\nfn main() {\n    let greeting = String::from(\"Hello\");\n    let full_greeting = add_world(greeting);\n    println!(\"{}\", full_greeting);\n    // Note: greeting is no longer accessible here\n}\n\nfn add_world(mut text: String) -> String {\n    text.push_str(\", World!\");\n    text  // Return the owned string\n}\n```\n\nThen gradually introduce borrowing:\n\n```rust\n// Now with borrowing\nfn main() {\n    let greeting = String::from(\"Hello\");\n    let length = get_length(&greeting);  // Borrow, don't move\n    println!(\"{} has {} characters\", greeting, length);\n    // greeting is still accessible!\n}\n\nfn get_length(text: &String) -> usize {\n    text.len()  // Just reading, no ownership needed\n}\n```\n\n**The Key Insight:** Start by accepting moves, then learn when borrowing helps.\n\n**Practice exercises:**\n- Build functions that take ownership vs. borrow\n- Experiment with `clone()` when you get stuck\n- Make a simple struct and practice moving vs. borrowing it\n\n### Phase 3: Collections and Error Handling (Week 5-6)\n**Goal: Handle real-world data**\n\n```rust\n// Working with Vec and basic error handling\nfn main() {\n    let numbers = vec![1, 2, 3, 4, 5];\n    \n    match find_largest(&numbers) {\n        Some(largest) => println!(\"Largest number: {}\", largest),\n        None => println!(\"No numbers provided\"),\n    }\n    \n    // Practice with strings\n    let words = vec![\"hello\", \"world\", \"rust\"];\n    let combined = join_words(&words, \" \");\n    println!(\"{}\", combined);\n}\n\nfn find_largest(numbers: &[i32]) -> Option<i32> {\n    if numbers.is_empty() {\n        None\n    } else {\n        Some(*numbers.iter().max().unwrap())\n    }\n}\n\nfn join_words(words: &[&str], separator: &str) -> String {\n    words.join(separator)\n}\n```\n\n**Focus on:**\n- `Vec<T>` operations\n- `Option<T>` for handling missing values\n- Basic `Result<T, E>` for errors\n- String vs `&str` (start with \"use `&str` for parameters, `String` for owned data\")\n\n### Phase 4: Structs and Methods (Week 7-8)\n**Goal: Organize code like you would in other languages**\n\n```rust\n// Build something familiar - a simple struct\n#[derive(Debug)]\nstruct User {\n    name: String,\n    email: String,\n    age: u32,\n    active: bool,\n}\n\nimpl User {\n    fn new(name: String, email: String, age: u32) -> User {\n        User {\n            name,\n            email,\n            age,\n            active: true,\n        }\n    }\n    \n    fn deactivate(&mut self) {\n        self.active = false;\n    }\n    \n    fn is_adult(&self) -> bool {\n        self.age >= 18\n    }\n    \n    fn summary(&self) -> String {\n        format!(\"{} ({}) - Active: {}\", self.name, self.email, self.active)\n    }\n}\n\nfn main() {\n    let mut user = User::new(\n        \"Alice\".to_string(),\n        \"alice@example.com\".to_string(),\n        25\n    );\n    \n    println!(\"{}\", user.summary());\n    \n    if user.is_adult() {\n        println!(\"{} is an adult\", user.name);\n    }\n    \n    user.deactivate();\n    println!(\"After deactivation: {}\", user.summary());\n}\n```\n\n**This should feel familiar!** You're building objects with methods, just like in JavaScript/Python.\n\n### Phase 5: Traits and Generics (Week 9-10)\n**Goal: Write reusable code**\n\n```rust\n// Traits are like interfaces in other languages\ntrait Summarizable {\n    fn summary(&self) -> String;\n}\n\nstruct Article {\n    title: String,\n    content: String,\n    author: String,\n}\n\nstruct Tweet {\n    username: String,\n    content: String,\n    reply_to: Option<String>,\n}\n\nimpl Summarizable for Article {\n    fn summary(&self) -> String {\n        format!(\"{} by {}\", self.title, self.author)\n    }\n}\n\nimpl Summarizable for Tweet {\n    fn summary(&self) -> String {\n        format!(\"{}: {}\", self.username, self.content)\n    }\n}\n\n// Generic function that works with any Summarizable type\nfn print_summary<T: Summarizable>(item: &T) {\n    println!(\"Summary: {}\", item.summary());\n}\n\nfn main() {\n    let article = Article {\n        title: \"Rust is Great\".to_string(),\n        content: \"Here's why...\".to_string(),\n        author: \"Alice\".to_string(),\n    };\n    \n    let tweet = Tweet {\n        username: \"bob\".to_string(),\n        content: \"Learning Rust!\".to_string(),\n        reply_to: None,\n    };\n    \n    print_summary(&article);\n    print_summary(&tweet);\n}\n```\n\n## Practical Tips for JavaScript/Python Developers\n\n### 1. **Start with `clone()` and `.to_string()`**\n\nWhen you get ownership errors, these are your friends:\n\n```rust\n// Instead of fighting the borrow checker, clone when learning\nlet original = vec![1, 2, 3];\nlet copy = original.clone();  // Explicit copy\n// Now both original and copy can be used\n\n// Convert &str to String when needed\nlet name: &str = \"Alice\";\nlet owned_name: String = name.to_string();\n```\n\nYes, cloning can be inefficient, but it's better to have working code than no code!\n\n### 2. **Use `unwrap()` While Learning**\n\n```rust\n// While learning, use unwrap() to focus on main logic\nlet number: i32 = \"42\".parse().unwrap();\nlet first_item = my_vec.first().unwrap();\n\n// Later, you'll learn proper error handling:\nlet number: i32 = match \"42\".parse() {\n    Ok(n) => n,\n    Err(_) => {\n        println!(\"Invalid number\");\n        return;\n    }\n};\n```\n\n### 3. **Think \"Who Owns This Data?\"**\n\nThis is the key mental shift:\n\n```rust\n// JavaScript: everything is shared references\nfunction processUser(user) {\n    user.name = \"Updated\";  // Modifies original\n    return user;\n}\n\n// Rust: be explicit about ownership\nfn process_user_owned(mut user: User) -> User {\n    user.name = \"Updated\".to_string();\n    user  // Give ownership back\n}\n\nfn process_user_borrowed(user: &mut User) {\n    user.name = \"Updated\".to_string();\n    // Borrow ends here, caller keeps ownership\n}\n```\n\n### 4. **Learn to Read Compiler Errors**\n\nRust's compiler errors are actually helpful! They tell you exactly what's wrong:\n\n```rust\n// This code:\nlet s = String::from(\"hello\");\nlet s2 = s;\nprintln!(\"{}\", s);  // Error!\n\n// Compiler says:\n// \"borrow of moved value: `s`\"\n// \"value borrowed here after move\"\n\n// Solution:\nlet s = String::from(\"hello\");\nlet s2 = s.clone();  // Clone instead of move\nprintln!(\"{}\", s);   // Now this works!\n```\n\n## Building Your First Real Project\n\nOnce you're comfortable with the basics, build something practical:\n\n**Project Ideas (in order of difficulty):**\n\n1. **Command-line calculator**\n   ```bash\n   cargo new calculator\n   # Practice: parsing input, match expressions, error handling\n   ```\n\n2. **To-do list CLI**\n   ```bash\n   cargo new todo-cli\n   # Practice: structs, Vec, file I/O, command parsing\n   ```\n\n3. **Simple web server**\n   ```bash\n   cargo new web-server\n   # Add: axum = \"0.7\", tokio = { version = \"1\", features = [\"full\"] }\n   # Practice: async/await, HTTP handling, JSON\n   ```\n\n4. **REST API with database**\n   ```bash\n   cargo new api-server\n   # Add: sqlx, serde, more complex error handling\n   ```\n\n## Learning Resources (Prioritized)\n\n### Essential (Read First):\n1. **\"The Rust Book\" Chapters 1-10** - Skip the hard parts initially\n2. **Rust by Example** - For hands-on practice\n3. **Rustlings** - Interactive exercises\n\n### When You're Ready for More:\n4. **\"Programming Rust\" by O'Reilly** - Deeper understanding\n5. **\"Rust in Action\"** - Practical projects\n6. **Jon Gjengset's YouTube channel** - Advanced concepts\n\n## Common Struggles and Solutions\n\n### \"The Borrow Checker is Driving Me Crazy!\"\n\n**Solution:** Start with owned values, add borrowing gradually:\n\n```rust\n// Phase 1: Use owned values everywhere\nfn process_name(name: String) -> String {\n    format!(\"Hello, {}!\", name)\n}\n\nlet name = \"Alice\".to_string();\nlet greeting = process_name(name.clone());  // Clone to keep ownership\n\n// Phase 2: Add borrowing when you understand ownership\nfn process_name_borrowed(name: &str) -> String {\n    format!(\"Hello, {}!\", name)\n}\n\nlet greeting = process_name_borrowed(&name);  // Borrow instead\n```\n\n### \"Everything is So Verbose!\"\n\n**Remember:** Explicitness prevents bugs. In JavaScript/Python, many errors happen at runtime. Rust catches them at compile time.\n\n```rust\n// Yes, this is more verbose than Python:\nlet mut users: Vec<User> = Vec::new();\nusers.push(User::new(\"Alice\".to_string(), \"alice@example.com\".to_string(), 30));\n\n// But it prevents runtime errors like:\n// users.push(42)  # Python would crash at runtime\n// Rust prevents this at compile time!\n```\n\n### \"I Miss Dynamic Typing!\"\n\n**Strategy:** Use `String` and basic types initially, learn enums for flexibility:\n\n```rust\n// Instead of Python's dynamic values:\n# value = \"hello\"  # str\n# value = 42       # int\n# value = [1,2,3]  # list\n\n// Use Rust enums for variant data:\nenum Value {\n    Text(String),\n    Number(i32),\n    List(Vec<i32>),\n}\n\nlet data = vec![\n    Value::Text(\"hello\".to_string()),\n    Value::Number(42),\n    Value::List(vec![1, 2, 3]),\n];\n```\n\n## The \"Aha!\" Moment\n\nMost people have their breakthrough around week 6-8, when they realize:\n\n1. **The compiler is helping, not hindering** - It prevents bugs you'd spend hours debugging in other languages\n2. **Ownership makes sense** - You start thinking \"who should own this data?\" naturally\n3. **Performance comes for free** - No garbage collection, no unexpected pauses\n4. **Refactoring is fearless** - The compiler catches breaking changes\n\n## Your 10-Week Plan\n\n**Weeks 1-2:** Basic syntax, simple programs, build confidence\n**Weeks 3-4:** Ownership and borrowing (expect frustration, that's normal!)\n**Weeks 5-6:** Collections, error handling, first useful programs\n**Weeks 7-8:** Structs, methods, organizing code\n**Weeks 9-10:** Traits, generics, first real project\n\n**After 10 weeks:** You should be productive enough to build real applications!\n\n## Final Encouragement\n\nRemember:\n- **Every Rust developer struggled initially** - You're not alone\n- **The learning curve is steep but worth it** - Once you \"get it\", Rust is incredibly productive\n- **Start small and build up** - Don't try to learn everything at once\n- **Use `.clone()` liberally while learning** - Optimization comes later\n- **Read the compiler errors** - They're usually helpful\n- **Ask for help** - The Rust community is very welcoming\n\nThe fact that you're asking about learning paths shows you're thinking strategically. That's exactly the right approach for Rust. Take it one concept at a time, build lots of small programs, and be patient with yourself.\n\nYou've got this! Want me to elaborate on any part of this roadmap or help you get started with your first project?",
    "tags": [
      "learning-path",
      "beginner-friendly",
      "javascript-python-background",
      "roadmap",
      "encouragement",
      "practical-advice",
      "long-conversation"
    ],
    "instruction": "I'm getting really overwhelmed trying to learn Rust. Everyone says it's hard because of the borrow checker, but I feel like I'm struggling with much more basic things. I come from JavaScript and Python, and everything in Rust feels so different. Can you help me understand what I should focus on learning first? What's the best path to actually become productive in Rust?"
  },
  {
    "output": "Absolutely! Memory management is one of Rust's superpowers, but it requires understanding several key patterns. Let me walk you through a comprehensive approach to memory optimization in web services.\n\n## Stack vs Heap Allocation\n\nFirst, let's understand when data goes on the stack vs heap:\n\n```rust\nuse std::collections::HashMap;\nuse serde::{Deserialize, Serialize};\n\n#[derive(Serialize, Deserialize, Clone)]\nstruct UserProfile {\n    id: u64,\n    name: String,        // Heap allocated\n    email: String,       // Heap allocated\n    preferences: HashMap<String, String>, // Heap allocated\n}\n\n// Stack allocated - very fast\nfn process_user_id(user_id: u64) -> bool {\n    user_id > 0  // u64 is Copy, lives on stack\n}\n\n// Heap allocated - use wisely\nfn create_user_profile(id: u64, name: String, email: String) -> UserProfile {\n    UserProfile {\n        id,\n        name,        // Moves into struct\n        email,       // Moves into struct\n        preferences: HashMap::new(), // New heap allocation\n    }\n}\n```\n\n## String Optimization Patterns\n\nStrings are often the biggest memory consumers in web services:\n\n```rust\nuse std::borrow::Cow;\nuse std::sync::Arc;\n\n// Pattern 1: Use &str when possible (no allocation)\nfn validate_email(email: &str) -> bool {\n    email.contains('@') && email.contains('.')\n}\n\n// Pattern 2: Use Cow for conditional ownership\nfn normalize_username(input: &str) -> Cow<str> {\n    if input.chars().any(|c| c.is_uppercase()) {\n        Cow::Owned(input.to_lowercase()) // Allocate only when needed\n    } else {\n        Cow::Borrowed(input) // No allocation\n    }\n}\n\n// Pattern 3: Arc<str> for shared immutable strings\n#[derive(Clone)]\nstruct CachedResponse {\n    content_type: Arc<str>,  // Shared across many responses\n    body: Vec<u8>,\n}\n\nimpl CachedResponse {\n    fn new(content_type: &str, body: Vec<u8>) -> Self {\n        Self {\n            content_type: Arc::from(content_type),\n            body,\n        }\n    }\n}\n\n// Pattern 4: String interning for repeated values\nuse std::collections::HashSet;\nuse std::sync::Mutex;\n\nlazy_static::lazy_static! {\n    static ref STRING_INTERNER: Mutex<HashSet<Arc<str>>> = Mutex::new(HashSet::new());\n}\n\nfn intern_string(s: &str) -> Arc<str> {\n    let mut interner = STRING_INTERNER.lock().unwrap();\n    if let Some(interned) = interner.get(s) {\n        Arc::clone(interned)\n    } else {\n        let arc_str: Arc<str> = Arc::from(s);\n        interner.insert(Arc::clone(&arc_str));\n        arc_str\n    }\n}\n```",
    "tags": [
      "memory-management",
      "performance",
      "web-services",
      "optimization",
      "strings",
      "heap-allocation"
    ],
    "instruction": "I'm building a high-performance web service in Rust and need to understand memory management patterns. Can you walk me through how to optimize memory usage and avoid common pitfalls?"
  },
  {
    "output": "Great question! Object pooling is crucial for high-performance web services. Let me show you several pooling strategies, from simple to sophisticated.\n\n## Basic Object Pool Implementation\n\n```rust\nuse std::sync::{Arc, Mutex};\nuse std::collections::VecDeque;\nuse serde::{Serialize, Deserialize};\n\n#[derive(Debug, Default, Serialize, Deserialize)]\nstruct RequestBuffer {\n    headers: Vec<(String, String)>,\n    body: Vec<u8>,\n    query_params: Vec<(String, String)>,\n}\n\nimpl RequestBuffer {\n    fn clear(&mut self) {\n        self.headers.clear();\n        self.body.clear();\n        self.query_params.clear();\n        // Note: clear() doesn't deallocate, keeping capacity\n    }\n    \n    fn reset_with_capacity(&mut self, header_cap: usize, body_cap: usize, query_cap: usize) {\n        self.headers.clear();\n        self.headers.reserve(header_cap);\n        \n        self.body.clear();\n        self.body.reserve(body_cap);\n        \n        self.query_params.clear();\n        self.query_params.reserve(query_cap);\n    }\n}\n\n// Simple thread-safe object pool\nstruct ObjectPool<T> {\n    objects: Arc<Mutex<VecDeque<T>>>,\n    factory: Box<dyn Fn() -> T + Send + Sync>,\n    max_size: usize,\n}\n\nimpl<T> ObjectPool<T> {\n    fn new<F>(factory: F, max_size: usize) -> Self \n    where \n        F: Fn() -> T + Send + Sync + 'static\n    {\n        Self {\n            objects: Arc::new(Mutex::new(VecDeque::new())),\n            factory: Box::new(factory),\n            max_size,\n        }\n    }\n    \n    fn acquire(&self) -> PooledObject<T> {\n        let mut objects = self.objects.lock().unwrap();\n        let object = objects.pop_front().unwrap_or_else(|| (self.factory)());\n        \n        PooledObject {\n            object: Some(object),\n            pool: Arc::clone(&self.objects),\n            max_size: self.max_size,\n        }\n    }\n}\n\n// RAII wrapper that returns object to pool on drop\nstruct PooledObject<T> {\n    object: Option<T>,\n    pool: Arc<Mutex<VecDeque<T>>>,\n    max_size: usize,\n}\n\nimpl<T> PooledObject<T> {\n    fn get_mut(&mut self) -> &mut T {\n        self.object.as_mut().unwrap()\n    }\n}\n\nimpl<T> Drop for PooledObject<T> {\n    fn drop(&mut self) {\n        if let Some(mut object) = self.object.take() {\n            // Reset object state if it implements a reset trait\n            if let Ok(mut pool) = self.pool.lock() {\n                if pool.len() < self.max_size {\n                    pool.push_back(object);\n                }\n                // If pool is full, object will be dropped (good for memory pressure)\n            }\n        }\n    }\n}\n\n// Usage in web service\nstatic REQUEST_POOL: std::sync::OnceLock<ObjectPool<RequestBuffer>> = std::sync::OnceLock::new();\n\nfn get_request_pool() -> &'static ObjectPool<RequestBuffer> {\n    REQUEST_POOL.get_or_init(|| {\n        ObjectPool::new(\n            || RequestBuffer::default(),\n            100  // Max 100 pooled objects\n        )\n    })\n}\n\nasync fn handle_request(raw_request: &[u8]) -> Result<Vec<u8>, Box<dyn std::error::Error>> {\n    // Acquire pooled buffer\n    let mut pooled_buffer = get_request_pool().acquire();\n    let buffer = pooled_buffer.get_mut();\n    \n    // Reset with appropriate capacities based on typical request sizes\n    buffer.reset_with_capacity(20, 4096, 10);\n    \n    // Parse request into buffer\n    parse_request(raw_request, buffer)?;\n    \n    // Process request\n    let response = process_parsed_request(buffer).await?;\n    \n    Ok(response)\n    // Buffer automatically returns to pool when pooled_buffer drops\n}\n\nfn parse_request(raw: &[u8], buffer: &mut RequestBuffer) -> Result<(), Box<dyn std::error::Error>> {\n    // Simulate parsing HTTP request\n    buffer.headers.push((\"content-type\".to_string(), \"application/json\".to_string()));\n    buffer.body.extend_from_slice(raw);\n    Ok(())\n}\n\nasync fn process_parsed_request(buffer: &RequestBuffer) -> Result<Vec<u8>, Box<dyn std::error::Error>> {\n    // Simulate request processing\n    Ok(b\"HTTP/1.1 200 OK\\r\\n\\r\\n{\\\"status\\\": \\\"ok\\\"}\".to_vec())\n}\n```\n\n## Advanced: Per-Thread Pools with crossbeam\n\nFor even better performance, use per-thread pools to avoid lock contention:\n\n```rust\nuse crossbeam_utils::thread;\nuse std::cell::RefCell;\nuse std::collections::VecDeque;\n\n// Thread-local pool (no locks needed!)\nthread_local! {\n    static THREAD_LOCAL_POOL: RefCell<VecDeque<RequestBuffer>> = RefCell::new(VecDeque::new());\n}\n\nstruct ThreadLocalPool;\n\nimpl ThreadLocalPool {\n    fn acquire() -> ThreadLocalPooled {\n        THREAD_LOCAL_POOL.with(|pool| {\n            let buffer = pool.borrow_mut()\n                .pop_front()\n                .unwrap_or_else(|| RequestBuffer::default());\n            \n            ThreadLocalPooled {\n                buffer: Some(buffer),\n            }\n        })\n    }\n}\n\nstruct ThreadLocalPooled {\n    buffer: Option<RequestBuffer>,\n}\n\nimpl ThreadLocalPooled {\n    fn get_mut(&mut self) -> &mut RequestBuffer {\n        self.buffer.as_mut().unwrap()\n    }\n}\n\nimpl Drop for ThreadLocalPooled {\n    fn drop(&mut self) {\n        if let Some(mut buffer) = self.buffer.take() {\n            buffer.clear(); // Reset state\n            \n            THREAD_LOCAL_POOL.with(|pool| {\n                let mut pool = pool.borrow_mut();\n                if pool.len() < 50 { // Limit per-thread pool size\n                    pool.push_back(buffer);\n                }\n            });\n        }\n    }\n}\n\n// Ultra-fast request handling with thread-local pools\nasync fn fast_handle_request(raw_request: &[u8]) -> Result<Vec<u8>, Box<dyn std::error::Error>> {\n    let mut pooled = ThreadLocalPool::acquire();\n    let buffer = pooled.get_mut();\n    \n    buffer.reset_with_capacity(20, 4096, 10);\n    parse_request(raw_request, buffer)?;\n    \n    let response = process_parsed_request(buffer).await?;\n    Ok(response)\n}\n```\n\n## Memory Pool for Dynamic Allocations\n\nFor very high-performance scenarios, you might want a custom allocator:\n\n```rust\nuse std::alloc::{GlobalAlloc, Layout};\nuse std::ptr::NonNull;\nuse std::sync::atomic::{AtomicPtr, Ordering};\n\n// Simple bump allocator for short-lived allocations\nstruct BumpAllocator {\n    start: *mut u8,\n    current: AtomicPtr<u8>,\n    end: *mut u8,\n}\n\nunsafe impl GlobalAlloc for BumpAllocator {\n    unsafe fn alloc(&self, layout: Layout) -> *mut u8 {\n        let size = layout.size();\n        let align = layout.align();\n        \n        loop {\n            let current = self.current.load(Ordering::Relaxed);\n            let aligned = (current as usize + align - 1) & !(align - 1);\n            let new_current = aligned + size;\n            \n            if new_current as *mut u8 > self.end {\n                return std::ptr::null_mut(); // Out of memory\n            }\n            \n            if self.current.compare_exchange_weak(\n                current,\n                new_current as *mut u8,\n                Ordering::Relaxed,\n                Ordering::Relaxed\n            ).is_ok() {\n                return aligned as *mut u8;\n            }\n        }\n    }\n    \n    unsafe fn dealloc(&self, _ptr: *mut u8, _layout: Layout) {\n        // Bump allocator doesn't support individual deallocation\n        // Memory is reclaimed when the entire allocator is reset\n    }\n}\n\nimpl BumpAllocator {\n    fn reset(&self) {\n        self.current.store(self.start, Ordering::Relaxed);\n    }\n}\n```\n\nThese patterns will significantly reduce allocation pressure in your web service. The key insights are:\n\n1. **Object pooling** eliminates allocation/deallocation overhead\n2. **Thread-local pools** avoid lock contention\n3. **Capacity management** prevents repeated Vec reallocations\n4. **RAII patterns** ensure automatic cleanup\n5. **Custom allocators** for extreme performance scenarios\n\nStart with the basic object pool and measure performance - you might be surprised how much difference it makes!",
    "tags": [
      "memory-pooling",
      "object-pools",
      "performance",
      "web-services",
      "thread-local",
      "allocators",
      "raii"
    ],
    "instruction": "This is really helpful! Can you show me how to implement memory pooling for frequently allocated objects? I'm dealing with a lot of request/response objects that get created and destroyed rapidly."
  },
  {
    "output": "Excellent question! Rust's concurrency model is designed to prevent data races at compile time while still allowing flexible concurrent programming. Let me walk you through the key concepts and practical patterns.\n\n## Rust's Concurrency Guarantees\n\nRust enforces two key rules that prevent data races:\n1. **Aliasing XOR Mutability**: You can have many immutable references OR one mutable reference, but not both\n2. **Send + Sync Traits**: Types must explicitly opt into thread safety\n\n```rust\nuse std::sync::{Arc, Mutex, RwLock};\nuse std::thread;\nuse std::time::Duration;\n\n// Send: Can be transferred between threads\n// Sync: Can be accessed from multiple threads simultaneously\n\n#[derive(Debug)]\nstruct Counter {\n    value: u64,\n}\n\n// Counter is automatically Send + Sync because u64 is Send + Sync\n// But we need synchronization for mutation\n\n// Pattern 1: Mutex for exclusive access\nfn mutex_example() {\n    let counter = Arc::new(Mutex::new(Counter { value: 0 }));\n    let mut handles = vec![];\n    \n    for i in 0..10 {\n        let counter_clone = Arc::clone(&counter);\n        let handle = thread::spawn(move || {\n            for _ in 0..1000 {\n                // Lock acquisition is explicit and scoped\n                let mut guard = counter_clone.lock().unwrap();\n                guard.value += 1;\n                // Lock automatically released when guard drops\n            }\n            println!(\"Thread {} finished\", i);\n        });\n        handles.push(handle);\n    }\n    \n    // Wait for all threads\n    for handle in handles {\n        handle.join().unwrap();\n    }\n    \n    let final_value = counter.lock().unwrap().value;\n    println!(\"Final counter value: {}\", final_value); // Should be 10,000\n}\n\n// Pattern 2: RwLock for reader-writer scenarios\nuse std::collections::HashMap;\n\nstruct Cache {\n    data: RwLock<HashMap<String, String>>,\n}\n\nimpl Cache {\n    fn new() -> Self {\n        Self {\n            data: RwLock::new(HashMap::new()),\n        }\n    }\n    \n    // Many readers can access simultaneously\n    fn get(&self, key: &str) -> Option<String> {\n        let reader = self.data.read().unwrap();\n        reader.get(key).cloned()\n    }\n    \n    // Only one writer at a time\n    fn insert(&self, key: String, value: String) {\n        let mut writer = self.data.write().unwrap();\n        writer.insert(key, value);\n    }\n    \n    // Upgrade read to write (careful with deadlocks!)\n    fn get_or_insert(&self, key: String, default_value: String) -> String {\n        // First try reading\n        {\n            let reader = self.data.read().unwrap();\n            if let Some(value) = reader.get(&key) {\n                return value.clone();\n            }\n        } // Release read lock before acquiring write lock\n        \n        // If not found, acquire write lock\n        let mut writer = self.data.write().unwrap();\n        // Double-check pattern (another thread might have inserted)\n        if let Some(value) = writer.get(&key) {\n            value.clone()\n        } else {\n            writer.insert(key.clone(), default_value.clone());\n            default_value\n        }\n    }\n}\n\nfn rwlock_example() {\n    let cache = Arc::new(Cache::new());\n    let mut handles = vec![];\n    \n    // Spawn reader threads\n    for i in 0..5 {\n        let cache_clone = Arc::clone(&cache);\n        let handle = thread::spawn(move || {\n            for j in 0..100 {\n                let key = format!(\"key_{}\", j % 10);\n                if let Some(value) = cache_clone.get(&key) {\n                    println!(\"Reader {}: {} = {}\", i, key, value);\n                }\n                thread::sleep(Duration::from_millis(1));\n            }\n        });\n        handles.push(handle);\n    }\n    \n    // Spawn writer threads\n    for i in 0..2 {\n        let cache_clone = Arc::clone(&cache);\n        let handle = thread::spawn(move || {\n            for j in 0..50 {\n                let key = format!(\"key_{}\", j % 10);\n                let value = format!(\"value_{}_{}\", i, j);\n                cache_clone.insert(key, value);\n                thread::sleep(Duration::from_millis(10));\n            }\n        });\n        handles.push(handle);\n    }\n    \n    for handle in handles {\n        handle.join().unwrap();\n    }\n}\n```\n\n## Avoiding Deadlocks\n\nDeadlocks happen when threads wait for each other in a cycle. Here are key prevention strategies:\n\n```rust\nuse std::sync::{Arc, Mutex};\nuse std::thread;\nuse std::time::Duration;\n\n// BAD: Potential deadlock\nfn deadlock_example() {\n    let resource_a = Arc::new(Mutex::new(\"Resource A\"));\n    let resource_b = Arc::new(Mutex::new(\"Resource B\"));\n    \n    let resource_a_clone = Arc::clone(&resource_a);\n    let resource_b_clone = Arc::clone(&resource_b);\n    \n    let thread1 = thread::spawn(move || {\n        let _a = resource_a_clone.lock().unwrap();\n        println!(\"Thread 1: Acquired A\");\n        thread::sleep(Duration::from_millis(100));\n        \n        let _b = resource_b_clone.lock().unwrap(); // Might deadlock here\n        println!(\"Thread 1: Acquired B\");\n    });\n    \n    let thread2 = thread::spawn(move || {\n        let _b = resource_b.lock().unwrap();\n        println!(\"Thread 2: Acquired B\");\n        thread::sleep(Duration::from_millis(100));\n        \n        let _a = resource_a.lock().unwrap(); // Might deadlock here\n        println!(\"Thread 2: Acquired A\");\n    });\n    \n    thread1.join().unwrap();\n    thread2.join().unwrap();\n}\n\n// GOOD: Consistent lock ordering prevents deadlocks\nfn deadlock_prevention() {\n    let resource_a = Arc::new(Mutex::new(\"Resource A\"));\n    let resource_b = Arc::new(Mutex::new(\"Resource B\"));\n    \n    let resource_a_clone = Arc::clone(&resource_a);\n    let resource_b_clone = Arc::clone(&resource_b);\n    \n    let thread1 = thread::spawn(move || {\n        // Always acquire locks in the same order: A then B\n        let _a = resource_a_clone.lock().unwrap();\n        println!(\"Thread 1: Acquired A\");\n        \n        let _b = resource_b_clone.lock().unwrap();\n        println!(\"Thread 1: Acquired B\");\n        \n        // Do work...\n        thread::sleep(Duration::from_millis(100));\n    });\n    \n    let thread2 = thread::spawn(move || {\n        // Same order: A then B\n        let _a = resource_a.lock().unwrap();\n        println!(\"Thread 2: Acquired A\");\n        \n        let _b = resource_b.lock().unwrap();\n        println!(\"Thread 2: Acquired B\");\n        \n        // Do work...\n        thread::sleep(Duration::from_millis(100));\n    });\n    \n    thread1.join().unwrap();\n    thread2.join().unwrap();\n}\n\n// Even better: Use try_lock with timeout\nuse std::sync::TryLockError;\n\nfn deadlock_prevention_with_timeout() {\n    let resource_a = Arc::new(Mutex::new(\"Resource A\"));\n    let resource_b = Arc::new(Mutex::new(\"Resource B\"));\n    \n    let resource_a_clone = Arc::clone(&resource_a);\n    let resource_b_clone = Arc::clone(&resource_b);\n    \n    let thread1 = thread::spawn(move || {\n        let _a = resource_a_clone.lock().unwrap();\n        println!(\"Thread 1: Acquired A\");\n        \n        // Try to acquire B with timeout logic\n        for attempt in 0..5 {\n            match resource_b_clone.try_lock() {\n                Ok(_b) => {\n                    println!(\"Thread 1: Acquired B on attempt {}\", attempt);\n                    return; // Success!\n                }\n                Err(TryLockError::WouldBlock) => {\n                    println!(\"Thread 1: B is busy, waiting...\");\n                    thread::sleep(Duration::from_millis(50));\n                }\n                Err(TryLockError::Poisoned(_)) => {\n                    panic!(\"Mutex poisoned!\");\n                }\n            }\n        }\n        println!(\"Thread 1: Failed to acquire B after retries\");\n    });\n    \n    thread1.join().unwrap();\n}\n```",
    "tags": [
      "concurrency",
      "threading",
      "mutex",
      "rwlock",
      "deadlocks",
      "data-races",
      "arc",
      "sync-send"
    ],
    "instruction": "I'm working on a multi-threaded application and running into some tricky concurrency issues. Can you explain Rust's approach to concurrent programming and show me how to avoid data races and deadlocks?"
  },
  {
    "output": "Absolutely! Let's dive into advanced concurrency patterns. Lock-free programming and message passing are powerful tools for high-performance concurrent systems.\n\n## Atomic Operations and Lock-Free Data Structures\n\nAtomic operations are the foundation of lock-free programming:\n\n```rust\nuse std::sync::atomic::{AtomicU64, AtomicBool, AtomicPtr, Ordering};\nuse std::sync::Arc;\nuse std::thread;\nuse std::ptr;\n\n// Lock-free counter using compare-and-swap\nstruct LockFreeCounter {\n    value: AtomicU64,\n}\n\nimpl LockFreeCounter {\n    fn new() -> Self {\n        Self {\n            value: AtomicU64::new(0),\n        }\n    }\n    \n    // Increment and return old value\n    fn increment(&self) -> u64 {\n        self.value.fetch_add(1, Ordering::SeqCst)\n    }\n    \n    // Conditional increment (only if current value is even)\n    fn increment_if_even(&self) -> Result<u64, u64> {\n        let mut current = self.value.load(Ordering::SeqCst);\n        loop {\n            if current % 2 != 0 {\n                return Err(current); // Odd number, don't increment\n            }\n            \n            match self.value.compare_exchange_weak(\n                current,\n                current + 1,\n                Ordering::SeqCst,\n                Ordering::SeqCst,\n            ) {\n                Ok(old_value) => return Ok(old_value),\n                Err(actual) => current = actual, // Retry with new value\n            }\n        }\n    }\n    \n    fn get(&self) -> u64 {\n        self.value.load(Ordering::SeqCst)\n    }\n}\n\n// Lock-free stack using atomic pointers\nstruct Node<T> {\n    data: T,\n    next: *mut Node<T>,\n}\n\nstruct LockFreeStack<T> {\n    head: AtomicPtr<Node<T>>,\n}\n\nimpl<T> LockFreeStack<T> {\n    fn new() -> Self {\n        Self {\n            head: AtomicPtr::new(ptr::null_mut()),\n        }\n    }\n    \n    fn push(&self, data: T) {\n        let new_node = Box::into_raw(Box::new(Node {\n            data,\n            next: ptr::null_mut(),\n        }));\n        \n        let mut head = self.head.load(Ordering::Acquire);\n        loop {\n            unsafe {\n                (*new_node).next = head;\n            }\n            \n            match self.head.compare_exchange_weak(\n                head,\n                new_node,\n                Ordering::Release,\n                Ordering::Relaxed,\n            ) {\n                Ok(_) => break,\n                Err(actual) => head = actual,\n            }\n        }\n    }\n    \n    fn pop(&self) -> Option<T> {\n        let mut head = self.head.load(Ordering::Acquire);\n        loop {\n            if head.is_null() {\n                return None;\n            }\n            \n            let next = unsafe { (*head).next };\n            \n            match self.head.compare_exchange_weak(\n                head,\n                next,\n                Ordering::Release,\n                Ordering::Relaxed,\n            ) {\n                Ok(_) => {\n                    let boxed = unsafe { Box::from_raw(head) };\n                    return Some(boxed.data);\n                }\n                Err(actual) => head = actual,\n            }\n        }\n    }\n}\n\n// Memory ordering is crucial for correctness\nfn memory_ordering_example() {\n    let flag = Arc::new(AtomicBool::new(false));\n    let data = Arc::new(AtomicU64::new(0));\n    \n    let flag_clone = Arc::clone(&flag);\n    let data_clone = Arc::clone(&data);\n    \n    // Writer thread\n    let writer = thread::spawn(move || {\n        data_clone.store(42, Ordering::Relaxed);\n        flag_clone.store(true, Ordering::Release); // Release ensures data write happens before flag\n    });\n    \n    // Reader thread\n    let reader = thread::spawn(move || {\n        while !flag.load(Ordering::Acquire) { // Acquire ensures flag read happens before data read\n            thread::yield_now();\n        }\n        let value = data.load(Ordering::Relaxed);\n        println!(\"Read value: {}\", value); // Guaranteed to be 42\n    });\n    \n    writer.join().unwrap();\n    reader.join().unwrap();\n}\n```\n\n## Channel-Based Message Passing\n\nChannels provide a safer alternative to shared memory:\n\n```rust\nuse std::sync::mpsc::{self, Receiver, Sender};\nuse std::thread;\nuse std::time::Duration;\n\n// Basic producer-consumer pattern\n#[derive(Debug)]\nstruct WorkItem {\n    id: u32,\n    data: String,\n}\n\nfn basic_channel_example() {\n    let (tx, rx): (Sender<WorkItem>, Receiver<WorkItem>) = mpsc::channel();\n    \n    // Producer thread\n    let producer = thread::spawn(move || {\n        for i in 0..10 {\n            let item = WorkItem {\n                id: i,\n                data: format!(\"Work item {}\", i),\n            };\n            \n            match tx.send(item) {\n                Ok(_) => println!(\"Sent work item {}\", i),\n                Err(e) => println!(\"Failed to send: {}\", e),\n            }\n            \n            thread::sleep(Duration::from_millis(100));\n        }\n        println!(\"Producer finished\");\n    });\n    \n    // Consumer thread\n    let consumer = thread::spawn(move || {\n        while let Ok(item) = rx.recv() {\n            println!(\"Processing: {:?}\", item);\n            thread::sleep(Duration::from_millis(200)); // Simulate work\n        }\n        println!(\"Consumer finished\");\n    });\n    \n    producer.join().unwrap();\n    consumer.join().unwrap();\n}\n\n// Multi-producer, single-consumer with work distribution\nfn mpsc_example() {\n    let (tx, rx) = mpsc::channel();\n    let mut producers = vec![];\n    \n    // Create multiple producers\n    for producer_id in 0..3 {\n        let tx_clone = tx.clone();\n        let producer = thread::spawn(move || {\n            for i in 0..5 {\n                let item = WorkItem {\n                    id: producer_id * 100 + i,\n                    data: format!(\"Producer {} - Item {}\", producer_id, i),\n                };\n                tx_clone.send(item).unwrap();\n                thread::sleep(Duration::from_millis(50));\n            }\n            println!(\"Producer {} finished\", producer_id);\n        });\n        producers.push(producer);\n    }\n    \n    // Drop the original sender so receiver knows when all producers are done\n    drop(tx);\n    \n    // Single consumer\n    let consumer = thread::spawn(move || {\n        let mut count = 0;\n        while let Ok(item) = rx.recv() {\n            count += 1;\n            println!(\"[{}] Processing: {:?}\", count, item);\n        }\n        println!(\"Processed {} items total\", count);\n    });\n    \n    // Wait for all threads\n    for producer in producers {\n        producer.join().unwrap();\n    }\n    consumer.join().unwrap();\n}\n\n// Bounded channels for backpressure\nfn bounded_channel_example() {\n    let (tx, rx) = mpsc::sync_channel(3); // Buffer size of 3\n    \n    let producer = thread::spawn(move || {\n        for i in 0..10 {\n            let item = WorkItem {\n                id: i,\n                data: format!(\"Bounded item {}\", i),\n            };\n            \n            println!(\"Attempting to send item {}\", i);\n            match tx.send(item) {\n                Ok(_) => println!(\"Sent item {}\", i),\n                Err(e) => println!(\"Failed to send item {}: {}\", i, e),\n            }\n        }\n    });\n    \n    // Slow consumer creates backpressure\n    let consumer = thread::spawn(move || {\n        thread::sleep(Duration::from_secs(1)); // Start slow\n        \n        while let Ok(item) = rx.recv() {\n            println!(\"Processing: {:?}\", item);\n            thread::sleep(Duration::from_millis(500)); // Slow processing\n        }\n    });\n    \n    producer.join().unwrap();\n    consumer.join().unwrap();\n}\n```\n\n## Advanced Patterns: Actor Model and Work Stealing\n\n```rust\nuse std::sync::mpsc;\nuse std::collections::VecDeque;\nuse std::sync::{Arc, Mutex};\n\n// Simple actor model implementation\nstruct Actor<State, Message> {\n    state: State,\n    receiver: Receiver<Message>,\n}\n\nstruct ActorHandle<Message> {\n    sender: Sender<Message>,\n}\n\nstruct ActorSystem;\n\nimpl ActorSystem {\n    fn spawn_actor<State, Message, F>(\n        initial_state: State,\n        mut handler: F,\n    ) -> ActorHandle<Message>\n    where\n        State: Send + 'static,\n        Message: Send + 'static,\n        F: FnMut(&mut State, Message) + Send + 'static,\n    {\n        let (tx, rx) = mpsc::channel();\n        \n        thread::spawn(move || {\n            let mut actor = Actor {\n                state: initial_state,\n                receiver: rx,\n            };\n            \n            while let Ok(message) = actor.receiver.recv() {\n                handler(&mut actor.state, message);\n            }\n        });\n        \n        ActorHandle { sender: tx }\n    }\n}\n\nimpl<Message> ActorHandle<Message> {\n    fn send(&self, message: Message) -> Result<(), mpsc::SendError<Message>> {\n        self.sender.send(message)\n    }\n}\n\n// Counter actor example\n#[derive(Debug)]\nenum CounterMessage {\n    Increment,\n    Decrement,\n    GetValue(Sender<i32>),\n}\n\nfn actor_example() {\n    let counter_actor = ActorSystem::spawn_actor(\n        0i32, // Initial state\n        |state: &mut i32, message: CounterMessage| {\n            match message {\n                CounterMessage::Increment => {\n                    *state += 1;\n                    println!(\"Counter incremented to {}\", state);\n                }\n                CounterMessage::Decrement => {\n                    *state -= 1;\n                    println!(\"Counter decremented to {}\", state);\n                }\n                CounterMessage::GetValue(response_tx) => {\n                    let _ = response_tx.send(*state);\n                }\n            }\n        },\n    );\n    \n    // Use the actor\n    counter_actor.send(CounterMessage::Increment).unwrap();\n    counter_actor.send(CounterMessage::Increment).unwrap();\n    counter_actor.send(CounterMessage::Decrement).unwrap();\n    \n    // Query the value\n    let (response_tx, response_rx) = mpsc::channel();\n    counter_actor.send(CounterMessage::GetValue(response_tx)).unwrap();\n    \n    if let Ok(value) = response_rx.recv() {\n        println!(\"Final counter value: {}\", value);\n    }\n    \n    thread::sleep(Duration::from_millis(100)); // Let actor finish\n}\n\n// Work-stealing queue for load balancing\nstruct WorkStealingQueue<T> {\n    local_queue: Mutex<VecDeque<T>>,\n    stealers: Vec<Arc<Mutex<VecDeque<T>>>>,\n}\n\nimpl<T> WorkStealingQueue<T> {\n    fn new(worker_count: usize) -> Vec<Arc<Self>> {\n        let mut queues = Vec::new();\n        \n        for _ in 0..worker_count {\n            queues.push(Arc::new(WorkStealingQueue {\n                local_queue: Mutex::new(VecDeque::new()),\n                stealers: Vec::new(),\n            }));\n        }\n        \n        // Set up stealing relationships\n        for i in 0..worker_count {\n            for j in 0..worker_count {\n                if i != j {\n                    let stealer = Arc::clone(&queues[j].local_queue);\n                    Arc::get_mut(&mut queues[i]).unwrap().stealers.push(stealer);\n                }\n            }\n        }\n        \n        queues\n    }\n    \n    fn push(&self, item: T) {\n        self.local_queue.lock().unwrap().push_back(item);\n    }\n    \n    fn pop(&self) -> Option<T> {\n        // Try local queue first\n        if let Some(item) = self.local_queue.lock().unwrap().pop_back() {\n            return Some(item);\n        }\n        \n        // Try stealing from other queues\n        for stealer in &self.stealers {\n            if let Some(item) = stealer.lock().unwrap().pop_front() {\n                return Some(item);\n            }\n        }\n        \n        None\n    }\n}\n```\n\nThese patterns give you powerful tools for building highly concurrent systems:\n\n1. **Lock-free data structures** eliminate contention but require careful memory ordering\n2. **Channels** provide safe message passing and natural backpressure\n3. **Actor model** encapsulates state and provides clear communication patterns\n4. **Work stealing** automatically balances load across threads\n\nThe key is choosing the right pattern for your use case - channels for loose coupling, atomics for high-performance counters, and actors for complex state management!",
    "tags": [
      "lock-free",
      "atomics",
      "channels",
      "message-passing",
      "actor-model",
      "work-stealing",
      "memory-ordering",
      "concurrent-data-structures"
    ],
    "instruction": "This is really comprehensive! Can you show me some more advanced concurrency patterns? I'm particularly interested in lock-free programming and channels for message passing."
  },
  {
    "output": "Fantastic question! Rust's type system is incredibly powerful for systems programming like database engines. Let me walk you through the advanced type patterns that will help you build safe, fast, and expressive database abstractions.\n\n## Generic Associated Types (GATs)\n\nGATs allow associated types to be generic, enabling more flexible trait designs:\n\n```rust\nuse std::marker::PhantomData;\nuse std::collections::HashMap;\n\n// Traditional associated types are limited\ntrait Iterator {\n    type Item;\n    fn next(&mut self) -> Option<Self::Item>;\n}\n\n// GATs allow parameterized associated types\ntrait Database {\n    type Connection<'conn>;\n    type Transaction<'txn>;\n    type Query<'q, T>;\n    \n    fn connect(&self) -> Self::Connection<'_>;\n    fn begin_transaction<'conn>(\n        conn: &'conn mut Self::Connection<'conn>\n    ) -> Self::Transaction<'conn>;\n    \n    fn query<'q, T>(\n        query_str: &'q str\n    ) -> Self::Query<'q, T>\n    where \n        T: DatabaseType;\n}\n\n// Database type trait for serialization/deserialization\ntrait DatabaseType: Sized {\n    fn from_bytes(bytes: &[u8]) -> Result<Self, DecodeError>;\n    fn to_bytes(&self) -> Vec<u8>;\n    fn type_name() -> &'static str;\n}\n\n#[derive(Debug)]\nstruct DecodeError(String);\n\n// Implement for basic types\nimpl DatabaseType for i32 {\n    fn from_bytes(bytes: &[u8]) -> Result<Self, DecodeError> {\n        if bytes.len() != 4 {\n            return Err(DecodeError(\"Invalid i32 length\".to_string()));\n        }\n        Ok(i32::from_le_bytes([bytes[0], bytes[1], bytes[2], bytes[3]]))\n    }\n    \n    fn to_bytes(&self) -> Vec<u8> {\n        self.to_le_bytes().to_vec()\n    }\n    \n    fn type_name() -> &'static str {\n        \"INTEGER\"\n    }\n}\n\nimpl DatabaseType for String {\n    fn from_bytes(bytes: &[u8]) -> Result<Self, DecodeError> {\n        String::from_utf8(bytes.to_vec())\n            .map_err(|e| DecodeError(format!(\"UTF-8 error: {}\", e)))\n    }\n    \n    fn to_bytes(&self) -> Vec<u8> {\n        self.as_bytes().to_vec()\n    }\n    \n    fn type_name() -> &'static str {\n        \"VARCHAR\"\n    }\n}\n\n// In-memory database implementation using GATs\nstruct InMemoryDatabase {\n    tables: HashMap<String, Table>,\n}\n\nstruct Table {\n    columns: Vec<Column>,\n    rows: Vec<Row>,\n}\n\nstruct Column {\n    name: String,\n    type_name: String,\n}\n\nstruct Row {\n    data: Vec<Vec<u8>>,\n}\n\nstruct InMemoryConnection<'db> {\n    db: &'db mut InMemoryDatabase,\n}\n\nstruct InMemoryTransaction<'conn> {\n    conn: &'conn mut InMemoryConnection<'conn>,\n    changes: Vec<Change>,\n}\n\n#[derive(Clone)]\nenum Change {\n    Insert { table: String, row: Row },\n    Update { table: String, row_id: usize, row: Row },\n    Delete { table: String, row_id: usize },\n}\n\nstruct InMemoryQuery<'q, T> {\n    query: &'q str,\n    _phantom: PhantomData<T>,\n}\n\nimpl Database for InMemoryDatabase {\n    type Connection<'conn> = InMemoryConnection<'conn>;\n    type Transaction<'txn> = InMemoryTransaction<'txn>;\n    type Query<'q, T> = InMemoryQuery<'q, T>;\n    \n    fn connect(&mut self) -> Self::Connection<'_> {\n        InMemoryConnection { db: self }\n    }\n    \n    fn begin_transaction<'conn>(\n        conn: &'conn mut Self::Connection<'conn>\n    ) -> Self::Transaction<'conn> {\n        InMemoryTransaction {\n            conn,\n            changes: Vec::new(),\n        }\n    }\n    \n    fn query<'q, T>(query_str: &'q str) -> Self::Query<'q, T>\n    where \n        T: DatabaseType\n    {\n        InMemoryQuery {\n            query: query_str,\n            _phantom: PhantomData,\n        }\n    }\n}\n```\n\n## Higher-Kinded Types (HKT) Simulation\n\nRust doesn't have true HKTs, but we can simulate them with associated types:\n\n```rust\n// Simulate HKT with type constructors\ntrait TypeConstructor {\n    type Applied<T>;\n}\n\n// Option as a type constructor\nstruct OptionConstructor;\nimpl TypeConstructor for OptionConstructor {\n    type Applied<T> = Option<T>;\n}\n\n// Vec as a type constructor\nstruct VecConstructor;\nimpl TypeConstructor for VecConstructor {\n    type Applied<T> = Vec<T>;\n}\n\n// Result as a type constructor (with fixed error type)\nstruct ResultConstructor<E> {\n    _phantom: PhantomData<E>,\n}\nimpl<E> TypeConstructor for ResultConstructor<E> {\n    type Applied<T> = Result<T, E>;\n}\n\n// Functor-like trait using our HKT simulation\ntrait Mappable<F: TypeConstructor> {\n    fn map<A, B, G>(self, f: G) -> F::Applied<B>\n    where\n        G: FnOnce(A) -> B,\n        Self: Into<F::Applied<A>>;\n}\n\n// Query result abstraction using HKT patterns\ntrait QueryResult<F: TypeConstructor> {\n    type Error;\n    \n    fn collect<T>(self) -> F::Applied<T>\n    where\n        T: DatabaseType;\n        \n    fn map_rows<T, U, G>(self, f: G) -> F::Applied<U>\n    where\n        T: DatabaseType,\n        U: DatabaseType,\n        G: FnMut(T) -> U;\n}\n\n// Implementation for different result types\nstruct StreamingResult<T> {\n    data: Vec<T>,\n}\n\nimpl<T> QueryResult<VecConstructor> for StreamingResult<T>\nwhere\n    T: DatabaseType\n{\n    type Error = DecodeError;\n    \n    fn collect<U>(self) -> Vec<U>\n    where\n        U: DatabaseType\n    {\n        // In real implementation, this would decode bytes to U\n        Vec::new() // Simplified\n    }\n    \n    fn map_rows<U, V, G>(self, mut f: G) -> Vec<V>\n    where\n        U: DatabaseType,\n        V: DatabaseType,\n        G: FnMut(U) -> V\n    {\n        // In real implementation, this would apply f to each decoded row\n        Vec::new() // Simplified\n    }\n}\n```\n\n## Type-Level Programming with Const Generics\n\nConst generics enable compile-time computation and type safety:\n\n```rust\nuse std::mem;\n\n// Fixed-size pages for database storage\n#[derive(Debug)]\nstruct Page<const SIZE: usize> {\n    data: [u8; SIZE],\n    used: usize,\n}\n\nimpl<const SIZE: usize> Page<SIZE> {\n    fn new() -> Self {\n        Self {\n            data: [0; SIZE],\n            used: 0,\n        }\n    }\n    \n    fn write<T>(&mut self, value: &T) -> Result<usize, &'static str>\n    where\n        T: DatabaseType\n    {\n        let bytes = value.to_bytes();\n        let size_needed = bytes.len() + mem::size_of::<u32>(); // Length prefix\n        \n        if self.used + size_needed > SIZE {\n            return Err(\"Page full\");\n        }\n        \n        let offset = self.used;\n        \n        // Write length prefix\n        let len_bytes = (bytes.len() as u32).to_le_bytes();\n        self.data[self.used..self.used + 4].copy_from_slice(&len_bytes);\n        self.used += 4;\n        \n        // Write data\n        self.data[self.used..self.used + bytes.len()].copy_from_slice(&bytes);\n        self.used += bytes.len();\n        \n        Ok(offset)\n    }\n    \n    fn read<T>(&self, offset: usize) -> Result<T, DecodeError>\n    where\n        T: DatabaseType\n    {\n        if offset + 4 > self.used {\n            return Err(DecodeError(\"Offset out of bounds\".to_string()));\n        }\n        \n        // Read length prefix\n        let len_bytes = [self.data[offset], self.data[offset + 1], \n                        self.data[offset + 2], self.data[offset + 3]];\n        let len = u32::from_le_bytes(len_bytes) as usize;\n        \n        if offset + 4 + len > self.used {\n            return Err(DecodeError(\"Data truncated\".to_string()));\n        }\n        \n        // Read data\n        let data_slice = &self.data[offset + 4..offset + 4 + len];\n        T::from_bytes(data_slice)\n    }\n    \n    // Type-level constraint: ensure page size is power of 2\n    const fn assert_power_of_two() -> bool {\n        SIZE > 0 && (SIZE & (SIZE - 1)) == 0\n    }\n}\n\n// Compile-time assertion using const generics\nstruct PowerOfTwoPage<const SIZE: usize>\nwhere\n    [(); Self::ASSERT]: // This creates a compile-time check\n{\n    page: Page<SIZE>,\n}\n\nimpl<const SIZE: usize> PowerOfTwoPage<SIZE>\nwhere\n    [(); Self::ASSERT]:\n{\n    const ASSERT: usize = {\n        assert!(SIZE > 0 && (SIZE & (SIZE - 1)) == 0, \"Size must be power of 2\");\n        0\n    };\n    \n    fn new() -> Self {\n        Self {\n            page: Page::new(),\n        }\n    }\n}\n\n// Type-level list for compile-time schema validation\ntrait TypeList {\n    const LEN: usize;\n    fn type_names() -> Vec<&'static str>;\n}\n\nstruct Nil;\nimpl TypeList for Nil {\n    const LEN: usize = 0;\n    fn type_names() -> Vec<&'static str> {\n        Vec::new()\n    }\n}\n\nstruct Cons<H, T> {\n    _phantom: PhantomData<(H, T)>,\n}\n\nimpl<H, T> TypeList for Cons<H, T>\nwhere\n    H: DatabaseType,\n    T: TypeList,\n{\n    const LEN: usize = 1 + T::LEN;\n    \n    fn type_names() -> Vec<&'static str> {\n        let mut names = vec![H::type_name()];\n        names.extend(T::type_names());\n        names\n    }\n}\n\n// Schema validation at compile time\nstruct Schema<T: TypeList> {\n    _phantom: PhantomData<T>,\n}\n\nimpl<T: TypeList> Schema<T> {\n    fn new() -> Self {\n        Self {\n            _phantom: PhantomData,\n        }\n    }\n    \n    fn column_count() -> usize {\n        T::LEN\n    }\n    \n    fn column_types() -> Vec<&'static str> {\n        T::type_names()\n    }\n    \n    // Only allow schemas with reasonable column counts\n    fn validate() -> Result<(), &'static str>\n    where\n        [(); Self::check_column_count()]: // Compile-time check\n    {\n        Ok(())\n    }\n    \n    const fn check_column_count() -> usize {\n        assert!(T::LEN <= 64, \"Too many columns\");\n        assert!(T::LEN > 0, \"Must have at least one column\");\n        0\n    }\n}\n\n// Usage examples\ntype UserSchema = Schema<Cons<i32, Cons<String, Cons<String, Nil>>>>; // id, name, email\ntype ProductSchema = Schema<Cons<i32, Cons<String, Cons<i32, Nil>>>>; // id, name, price\n\nfn type_level_example() {\n    // These work fine\n    let page_4k: Page<4096> = Page::new();\n    let page_8k: Page<8192> = Page::new();\n    \n    // This would compile-time error if uncommented:\n    // let bad_page: PowerOfTwoPage<1000> = PowerOfTwoPage::new(); // Not power of 2\n    \n    let user_schema = UserSchema::new();\n    println!(\"User schema has {} columns: {:?}\", \n             UserSchema::column_count(), \n             UserSchema::column_types());\n    \n    // This would compile-time error if we tried:\n    // type TooManyColumns = Schema<Cons<i32, Cons<i32, ...>>> // > 64 columns\n}\n```\n\n## Phantom Types for State Machines\n\nPhantom types provide zero-cost state tracking:\n\n```rust\nuse std::marker::PhantomData;\n\n// Database connection states\nstruct Disconnected;\nstruct Connected;\nstruct InTransaction;\n\n// Connection with compile-time state tracking\nstruct Connection<State> {\n    handle: usize, // Simplified connection handle\n    _state: PhantomData<State>,\n}\n\nimpl Connection<Disconnected> {\n    fn new() -> Self {\n        Self {\n            handle: 0,\n            _state: PhantomData,\n        }\n    }\n    \n    fn connect(self) -> Result<Connection<Connected>, ConnectionError> {\n        // Simulate connection logic\n        Ok(Connection {\n            handle: 42, // Mock connected handle\n            _state: PhantomData,\n        })\n    }\n}\n\nimpl Connection<Connected> {\n    fn begin_transaction(self) -> Connection<InTransaction> {\n        Connection {\n            handle: self.handle,\n            _state: PhantomData,\n        }\n    }\n    \n    fn execute_query<T>(&self, _query: &str) -> QueryResult<T>\n    where\n        T: DatabaseType\n    {\n        // Can execute queries when connected\n        todo!()\n    }\n    \n    fn disconnect(self) -> Connection<Disconnected> {\n        Connection {\n            handle: 0,\n            _state: PhantomData,\n        }\n    }\n}\n\nimpl Connection<InTransaction> {\n    fn commit(self) -> Connection<Connected> {\n        Connection {\n            handle: self.handle,\n            _state: PhantomData,\n        }\n    }\n    \n    fn rollback(self) -> Connection<Connected> {\n        Connection {\n            handle: self.handle,\n            _state: PhantomData,\n        }\n    }\n    \n    fn execute_transactional_query<T>(&self, _query: &str) -> QueryResult<T>\n    where\n        T: DatabaseType\n    {\n        // Can execute queries within transaction\n        todo!()\n    }\n}\n\n#[derive(Debug)]\nstruct ConnectionError(&'static str);\n\n// Zero-cost state machine usage\nfn phantom_type_example() -> Result<(), ConnectionError> {\n    let conn = Connection::new();\n    let conn = conn.connect()?;\n    \n    // This compiles\n    let _result = conn.execute_query::<i32>(\"SELECT 1\");\n    \n    let conn = conn.begin_transaction();\n    let _txn_result = conn.execute_transactional_query::<String>(\"INSERT ...\");\n    let conn = conn.commit();\n    \n    let _conn = conn.disconnect();\n    \n    // These would be compile errors:\n    // conn.execute_query(...); // Can't use moved connection\n    // disconnected_conn.execute_query(...); // Can't query when disconnected\n    \n    Ok(())\n}\n```\n\nThese advanced type patterns give you:\n\n1. **GATs** enable flexible, lifetime-aware database abstractions\n2. **HKT simulation** allows generic container operations\n3. **Const generics** provide compile-time optimization and validation\n4. **Phantom types** ensure correct API usage at zero runtime cost\n\nThese patterns are essential for building high-performance, type-safe database engines where correctness and performance are paramount!",
    "tags": [
      "type-system",
      "gats",
      "hkt",
      "const-generics",
      "phantom-types",
      "type-level-programming",
      "database",
      "advanced-types"
    ],
    "instruction": "I'm building a high-performance database engine and need to understand Rust's type system deeply. Can you explain advanced type patterns like GATs, HKTs, and type-level programming?"
  },
  {
    "output": "Absolutely! Rust's macro system is incredibly powerful for distributed systems where you often need to generate repetitive networking, serialization, and RPC code. Let me show you how to build sophisticated macros from simple to advanced.\n\n## Declarative Macros (macro_rules!)\n\nLet's start with practical examples for distributed systems:\n\n```rust\n// Simple macro for creating RPC service definitions\nmacro_rules! define_service {\n    (\n        service $service_name:ident {\n            $($method_name:ident($($param:ident: $param_type:ty),*) -> $return_type:ty;)*\n        }\n    ) => {\n        // Generate trait definition\n        pub trait $service_name {\n            $(\n                fn $method_name(&self, $($param: $param_type),*) -> Result<$return_type, ServiceError>;\n            )*\n        }\n        \n        // Generate client stub\n        paste::paste! {\n            pub struct [<$service_name Client>] {\n                endpoint: String,\n                client: reqwest::Client,\n            }\n            \n            impl [<$service_name Client>] {\n                pub fn new(endpoint: String) -> Self {\n                    Self {\n                        endpoint,\n                        client: reqwest::Client::new(),\n                    }\n                }\n                \n                $(\n                    pub async fn $method_name(&self, $($param: $param_type),*) -> Result<$return_type, ServiceError> {\n                        let url = format!(\"{}/{}\"., self.endpoint, stringify!($method_name));\n                        let payload = serde_json::json!({\n                            $(stringify!($param): $param),*\n                        });\n                        \n                        let response = self.client\n                            .post(&url)\n                            .json(&payload)\n                            .send()\n                            .await\n                            .map_err(|e| ServiceError::Network(e.to_string()))?;\n                            \n                        let result: $return_type = response\n                            .json()\n                            .await\n                            .map_err(|e| ServiceError::Deserialization(e.to_string()))?;\n                            \n                        Ok(result)\n                    }\n                )*\n            }\n            \n            // Generate server handler registration\n            pub fn [<register_ $service_name:snake _handlers>]<T: $service_name + Send + Sync + 'static>(\n                router: axum::Router,\n                service: std::sync::Arc<T>\n            ) -> axum::Router {\n                router\n                    $(\n                        .route(&format!(\"/{}\", stringify!($method_name)), \n                               axum::routing::post({\n                                   let service = service.clone();\n                                   move |payload: axum::Json<serde_json::Value>| async move {\n                                       // Extract parameters and call service method\n                                       // This is simplified - real implementation would handle parameter extraction\n                                       let result = service.$method_name(\n                                           // Parameter extraction would go here\n                                       );\n                                       axum::Json(result)\n                                   }\n                               }))\n                    )*\n            }\n        }\n    };\n}\n\n// Usage of the service macro\ndefine_service! {\n    service UserService {\n        get_user(user_id: u64) -> User;\n        create_user(name: String, email: String) -> User;\n        delete_user(user_id: u64) -> bool;\n    }\n}\n\n// Define error types and User struct\n#[derive(Debug, serde::Serialize, serde::Deserialize)]\nstruct User {\n    id: u64,\n    name: String,\n    email: String,\n}\n\n#[derive(Debug)]\nenum ServiceError {\n    Network(String),\n    Deserialization(String),\n    NotFound,\n}\n\n// Advanced macro for generating configuration structs\nmacro_rules! config_struct {\n    (\n        $name:ident {\n            $(\n                $field:ident: $field_type:ty = $default:expr,\n                doc = $doc:expr,\n                env = $env_var:expr\n            ),* $(,)?\n        }\n    ) => {\n        #[derive(Debug, Clone, serde::Deserialize)]\n        pub struct $name {\n            $(\n                #[doc = $doc]\n                pub $field: $field_type,\n            )*\n        }\n        \n        impl Default for $name {\n            fn default() -> Self {\n                Self {\n                    $(\n                        $field: $default,\n                    )*\n                }\n            }\n        }\n        \n        impl $name {\n            pub fn from_env() -> Result<Self, ConfigError> {\n                let mut config = Self::default();\n                \n                $(\n                    if let Ok(val) = std::env::var($env_var) {\n                        config.$field = val.parse()\n                            .map_err(|_| ConfigError::InvalidValue {\n                                field: stringify!($field),\n                                value: val,\n                            })?;\n                    }\n                )*\n                \n                Ok(config)\n            }\n            \n            pub fn load_from_file<P: AsRef<std::path::Path>>(path: P) -> Result<Self, ConfigError> {\n                let content = std::fs::read_to_string(path)\n                    .map_err(ConfigError::Io)?;\n                    \n                toml::from_str(&content)\n                    .map_err(ConfigError::Parse)\n            }\n        }\n    };\n}\n\n#[derive(Debug)]\nenum ConfigError {\n    Io(std::io::Error),\n    Parse(toml::de::Error),\n    InvalidValue { field: &'static str, value: String },\n}\n\n// Usage of config macro\nconfig_struct! {\n    ServerConfig {\n        host: String = \"127.0.0.1\".to_string(),\n        doc = \"Server host address\",\n        env = \"SERVER_HOST\",\n        \n        port: u16 = 8080,\n        doc = \"Server port number\",\n        env = \"SERVER_PORT\",\n        \n        max_connections: usize = 1000,\n        doc = \"Maximum concurrent connections\",\n        env = \"MAX_CONNECTIONS\",\n        \n        timeout_ms: u64 = 30000,\n        doc = \"Request timeout in milliseconds\",\n        env = \"TIMEOUT_MS\",\n    }\n}\n```\n\n## Procedural Macros for Complex Code Generation\n\nFor more sophisticated code generation, procedural macros are the way to go:\n\n```rust\n// This would be in a separate crate (proc-macro = true in Cargo.toml)\nuse proc_macro::TokenStream;\nuse quote::quote;\nuse syn::{parse_macro_input, DeriveInput, Data, Fields};\n\n// Derive macro for automatic serialization with versioning\n#[proc_macro_derive(VersionedSerialize, attributes(version))]\npub fn versioned_serialize_derive(input: TokenStream) -> TokenStream {\n    let input = parse_macro_input!(input as DeriveInput);\n    let name = &input.ident;\n    \n    // Extract version from attributes\n    let version = input.attrs.iter()\n        .find(|attr| attr.path.is_ident(\"version\"))\n        .and_then(|attr| attr.parse_args::<syn::LitInt>().ok())\n        .map(|lit| lit.base10_parse::<u32>().unwrap())\n        .unwrap_or(1);\n    \n    let fields = match &input.data {\n        Data::Struct(data) => match &data.fields {\n            Fields::Named(fields) => &fields.named,\n            _ => panic!(\"Only named fields are supported\"),\n        },\n        _ => panic!(\"Only structs are supported\"),\n    };\n    \n    let field_serialization = fields.iter().map(|field| {\n        let field_name = &field.ident;\n        let field_name_str = field_name.as_ref().unwrap().to_string();\n        quote! {\n            map.insert(#field_name_str.to_string(), serde_json::to_value(&self.#field_name)?);\n        }\n    });\n    \n    let field_deserialization = fields.iter().map(|field| {\n        let field_name = &field.ident;\n        let field_name_str = field_name.as_ref().unwrap().to_string();\n        let field_type = &field.ty;\n        quote! {\n            #field_name: {\n                let value = map.get(#field_name_str)\n                    .ok_or_else(|| VersionedError::MissingField(#field_name_str.to_string()))?;\n                serde_json::from_value::<#field_type>(value.clone())?\n            },\n        }\n    });\n    \n    let expanded = quote! {\n        impl VersionedSerialize for #name {\n            const VERSION: u32 = #version;\n            \n            fn serialize_versioned(&self) -> Result<Vec<u8>, VersionedError> {\n                let mut map = std::collections::HashMap::new();\n                \n                // Add version header\n                map.insert(\"__version\".to_string(), serde_json::Value::Number(\n                    serde_json::Number::from(Self::VERSION)\n                ));\n                \n                // Serialize fields\n                #(#field_serialization)*\n                \n                let json = serde_json::to_vec(&map)?;\n                Ok(json)\n            }\n            \n            fn deserialize_versioned(data: &[u8]) -> Result<Self, VersionedError> {\n                let map: std::collections::HashMap<String, serde_json::Value> = \n                    serde_json::from_slice(data)?;\n                \n                // Check version compatibility\n                let version = map.get(\"__version\")\n                    .and_then(|v| v.as_u64())\n                    .ok_or(VersionedError::InvalidVersion)? as u32;\n                    \n                if version > Self::VERSION {\n                    return Err(VersionedError::VersionTooNew { \n                        expected: Self::VERSION, \n                        actual: version \n                    });\n                }\n                \n                Ok(Self {\n                    #(#field_deserialization)*\n                })\n            }\n        }\n    };\n    \n    TokenStream::from(expanded)\n}\n\n// Trait for versioned serialization\ntrait VersionedSerialize: Sized {\n    const VERSION: u32;\n    fn serialize_versioned(&self) -> Result<Vec<u8>, VersionedError>;\n    fn deserialize_versioned(data: &[u8]) -> Result<Self, VersionedError>;\n}\n\n#[derive(Debug)]\nenum VersionedError {\n    Serialization(serde_json::Error),\n    MissingField(String),\n    InvalidVersion,\n    VersionTooNew { expected: u32, actual: u32 },\n}\n\nimpl From<serde_json::Error> for VersionedError {\n    fn from(err: serde_json::Error) -> Self {\n        VersionedError::Serialization(err)\n    }\n}\n\n// Function-like macro for generating distributed consensus protocols\n#[proc_macro]\npub fn consensus_protocol(input: TokenStream) -> TokenStream {\n    let input = parse_macro_input!(input as syn::LitStr);\n    let protocol_name = input.value();\n    \n    let struct_name = syn::Ident::new(&format!(\"{}Protocol\", protocol_name), proc_macro2::Span::call_site());\n    let message_enum = syn::Ident::new(&format!(\"{}Message\", protocol_name), proc_macro2::Span::call_site());\n    \n    let expanded = quote! {\n        #[derive(Debug, Clone, serde::Serialize, serde::Deserialize)]\n        pub enum #message_enum {\n            Propose { term: u64, value: Vec<u8> },\n            Vote { term: u64, node_id: String, accept: bool },\n            Commit { term: u64, value: Vec<u8> },\n            Heartbeat { term: u64, leader_id: String },\n        }\n        \n        pub struct #struct_name {\n            node_id: String,\n            current_term: std::sync::atomic::AtomicU64,\n            peers: Vec<String>,\n            message_sender: tokio::sync::mpsc::UnboundedSender<#message_enum>,\n            message_receiver: std::sync::Mutex<Option<tokio::sync::mpsc::UnboundedReceiver<#message_enum>>>,\n        }\n        \n        impl #struct_name {\n            pub fn new(node_id: String, peers: Vec<String>) -> Self {\n                let (tx, rx) = tokio::sync::mpsc::unbounded_channel();\n                Self {\n                    node_id,\n                    current_term: std::sync::atomic::AtomicU64::new(0),\n                    peers,\n                    message_sender: tx,\n                    message_receiver: std::sync::Mutex::new(Some(rx)),\n                }\n            }\n            \n            pub async fn propose(&self, value: Vec<u8>) -> Result<(), ConsensusError> {\n                let term = self.current_term.fetch_add(1, std::sync::atomic::Ordering::SeqCst);\n                let message = #message_enum::Propose { term, value };\n                \n                // Broadcast to all peers\n                for peer in &self.peers {\n                    self.send_to_peer(peer, &message).await?;\n                }\n                \n                Ok(())\n            }\n            \n            pub async fn handle_message(&self, message: #message_enum) -> Result<(), ConsensusError> {\n                match message {\n                    #message_enum::Propose { term, value } => {\n                        // Handle proposal logic\n                        let current_term = self.current_term.load(std::sync::atomic::Ordering::SeqCst);\n                        if term > current_term {\n                            self.current_term.store(term, std::sync::atomic::Ordering::SeqCst);\n                            // Send vote\n                            let vote = #message_enum::Vote {\n                                term,\n                                node_id: self.node_id.clone(),\n                                accept: true,\n                            };\n                            // Would send vote back to proposer\n                        }\n                    }\n                    #message_enum::Vote { term, node_id, accept } => {\n                        // Handle vote logic\n                        println!(\"Received vote from {}: {}\", node_id, accept);\n                    }\n                    #message_enum::Commit { term, value } => {\n                        // Handle commit logic\n                        println!(\"Committing value at term {}\", term);\n                    }\n                    #message_enum::Heartbeat { term, leader_id } => {\n                        // Handle heartbeat logic\n                        println!(\"Heartbeat from leader {} at term {}\", leader_id, term);\n                    }\n                }\n                Ok(())\n            }\n            \n            async fn send_to_peer(&self, peer: &str, message: &#message_enum) -> Result<(), ConsensusError> {\n                // Simplified - would use actual network communication\n                println!(\"Sending to {}: {:?}\", peer, message);\n                Ok(())\n            }\n        }\n        \n        #[derive(Debug)]\n        pub enum ConsensusError {\n            NetworkError(String),\n            SerializationError(String),\n            InvalidState,\n        }\n    };\n    \n    TokenStream::from(expanded)\n}\n```\n\n## Advanced Macro Techniques\n\n```rust\n// Macro for generating state machines with compile-time validation\nmacro_rules! state_machine {\n    (\n        machine $name:ident;\n        \n        states { $($state:ident),* }\n        \n        transitions {\n            $(\n                $from:ident -> $to:ident on $event:ident $(\n                    if $guard:expr\n                )? $(\n                    / $action:expr\n                )?;\n            )*\n        }\n    ) => {\n        // Generate state enum\n        #[derive(Debug, Clone, Copy, PartialEq, Eq)]\n        pub enum State {\n            $($state),*\n        }\n        \n        // Generate event enum\n        #[derive(Debug, Clone)]\n        pub enum Event {\n            $($event),*\n        }\n        \n        // Generate state machine struct\n        pub struct $name {\n            current_state: State,\n        }\n        \n        impl $name {\n            pub fn new(initial_state: State) -> Self {\n                Self {\n                    current_state: initial_state,\n                }\n            }\n            \n            pub fn current_state(&self) -> State {\n                self.current_state\n            }\n            \n            pub fn handle_event(&mut self, event: Event) -> Result<State, StateMachineError> {\n                let new_state = match (self.current_state, &event) {\n                    $(\n                        (State::$from, Event::$event) => {\n                            // Check guard condition if present\n                            $(\n                                if !($guard) {\n                                    return Err(StateMachineError::GuardFailed);\n                                }\n                            )?\n                            \n                            // Execute action if present\n                            $(\n                                ($action);\n                            )?\n                            \n                            State::$to\n                        }\n                    )*\n                    _ => return Err(StateMachineError::InvalidTransition {\n                        from: self.current_state,\n                        event,\n                    }),\n                };\n                \n                self.current_state = new_state;\n                Ok(new_state)\n            }\n        }\n        \n        #[derive(Debug)]\n        pub enum StateMachineError {\n            InvalidTransition { from: State, event: Event },\n            GuardFailed,\n        }\n    };\n}\n\n// Usage: Connection state machine\nstate_machine! {\n    machine ConnectionStateMachine;\n    \n    states { Disconnected, Connecting, Connected, Error }\n    \n    transitions {\n        Disconnected -> Connecting on Connect;\n        Connecting -> Connected on ConnectionEstablished;\n        Connecting -> Error on ConnectionFailed;\n        Connected -> Disconnected on Disconnect / println!(\"Cleaning up connection\");\n        Connected -> Error on ConnectionLost;\n        Error -> Disconnected on Reset;\n    }\n}\n\n// Advanced: Macro that generates compile-time verified SQL queries\nmacro_rules! sql_query {\n    (\n        $query:literal,\n        params: { $($param:ident: $param_type:ty),* },\n        returns: $return_type:ty\n    ) => {\n        {\n            // At compile time, we could validate SQL syntax\n            // For now, this is a simplified example\n            struct Query {\n                sql: &'static str,\n                _phantom: std::marker::PhantomData<($($param_type,)* $return_type)>,\n            }\n            \n            impl Query {\n                fn execute(&self, $($param: $param_type),*) -> Result<Vec<$return_type>, DatabaseError> {\n                    // Execute query with parameters\n                    println!(\"Executing: {}\", self.sql);\n                    $(println!(\"Param {}: {:?}\", stringify!($param), $param);)*\n                    \n                    // Return mock result\n                    Ok(Vec::new())\n                }\n            }\n            \n            Query {\n                sql: $query,\n                _phantom: std::marker::PhantomData,\n            }\n        }\n    };\n}\n\n#[derive(Debug)]\nstruct DatabaseError(String);\n\n// Usage of SQL query macro\nfn query_example() {\n    let query = sql_query!(\n        \"SELECT id, name FROM users WHERE age > ? AND city = ?\",\n        params: { min_age: i32, city: String },\n        returns: User\n    );\n    \n    let results = query.execute(25, \"San Francisco\".to_string());\n    println!(\"Query results: {:?}\", results);\n}\n```\n\nThese macro patterns give you:\n\n1. **Boilerplate elimination** for RPC services and configuration\n2. **Compile-time validation** for state machines and protocols\n3. **Code generation** for serialization and networking\n4. **Type safety** with minimal runtime overhead\n5. **Domain-specific languages** embedded in Rust\n\nMacros are particularly powerful in distributed systems where you need to generate consistent serialization, networking, and protocol handling code across many services!",
    "tags": [
      "macros",
      "code-generation",
      "distributed-systems",
      "rpc",
      "procedural-macros",
      "compile-time",
      "boilerplate-reduction",
      "dsl"
    ],
    "instruction": "I'm working on a complex distributed system and need to understand Rust's macro system. Can you show me how to build powerful compile-time code generation for reducing boilerplate?"
  },
  {
    "output": "Excellent question! Custom derive macros are perfect for domain objects where you need consistent behavior across many types. Let me show you how to build a comprehensive derive macro system for your domain.\n\n## Setting Up the Proc Macro Crate\n\nFirst, you'll need a separate crate for your proc macros:\n\n```toml\n# Cargo.toml for your proc-macro crate\n[package]\nname = \"domain-macros\"\nversion = \"0.1.0\"\nedition = \"2021\"\n\n[lib]\nproc-macro = true\n\n[dependencies]\nproc-macro2 = \"1.0\"\nquote = \"1.0\"\nsyn = { version = \"2.0\", features = [\"full\", \"extra-traits\"] }\nserde = { version = \"1.0\", features = [\"derive\"] }\nserde_json = \"1.0\"\n```\n\nNow let's build sophisticated derive macros:\n\n```rust\n// lib.rs in your proc-macro crate\nuse proc_macro::TokenStream;\nuse quote::{quote, format_ident};\nuse syn::{\n    parse_macro_input, DeriveInput, Data, Fields, Field, Attribute, Meta, Lit,\n    Type, PathArguments, GenericArgument, punctuated::Punctuated, Token\n};\n\n// Main derive macro that generates multiple traits\n#[proc_macro_derive(DomainObject, attributes(validate, db_field, display_name))]\npub fn domain_object_derive(input: TokenStream) -> TokenStream {\n    let input = parse_macro_input!(input as DeriveInput);\n    \n    let name = &input.ident;\n    let (impl_generics, ty_generics, where_clause) = input.generics.split_for_impl();\n    \n    // Parse struct fields\n    let fields = match &input.data {\n        Data::Struct(data) => match &data.fields {\n            Fields::Named(fields) => &fields.named,\n            _ => panic!(\"DomainObject only supports structs with named fields\"),\n        },\n        _ => panic!(\"DomainObject only supports structs\"),\n    };\n    \n    // Generate different trait implementations\n    let validation_impl = generate_validation_impl(name, fields, &impl_generics, &ty_generics, &where_clause);\n    let serialization_impl = generate_serialization_impl(name, fields, &impl_generics, &ty_generics, &where_clause);\n    let database_impl = generate_database_impl(name, fields, &impl_generics, &ty_generics, &where_clause);\n    let display_impl = generate_display_impl(name, fields, &impl_generics, &ty_generics, &where_clause);\n    \n    let expanded = quote! {\n        #validation_impl\n        #serialization_impl\n        #database_impl\n        #display_impl\n    };\n    \n    TokenStream::from(expanded)\n}\n\n// Generate validation implementation\nfn generate_validation_impl(\n    name: &syn::Ident,\n    fields: &Punctuated<Field, Token![,]>,\n    impl_generics: &syn::ImplGenerics,\n    ty_generics: &syn::TypeGenerics,\n    where_clause: &Option<&syn::WhereClause>,\n) -> proc_macro2::TokenStream {\n    let validation_checks = fields.iter().map(|field| {\n        let field_name = &field.ident;\n        let field_name_str = field_name.as_ref().unwrap().to_string();\n        \n        // Parse validation attributes\n        let validations = parse_validation_attributes(&field.attrs);\n        \n        let checks = validations.iter().map(|validation| {\n            match validation {\n                ValidationRule::Required => {\n                    if is_option_type(&field.ty) {\n                        quote! {\n                            if self.#field_name.is_none() {\n                                errors.push(ValidationError::Required(#field_name_str.to_string()));\n                            }\n                        }\n                    } else {\n                        quote! {} // Non-option types are always \"present\"\n                    }\n                }\n                ValidationRule::MinLength(min) => {\n                    if is_string_type(&field.ty) {\n                        quote! {\n                            if let Some(ref value) = self.#field_name {\n                                if value.len() < #min {\n                                    errors.push(ValidationError::MinLength {\n                                        field: #field_name_str.to_string(),\n                                        min: #min,\n                                        actual: value.len(),\n                                    });\n                                }\n                            }\n                        }\n                    } else {\n                        quote! {\n                            if self.#field_name.len() < #min {\n                                errors.push(ValidationError::MinLength {\n                                    field: #field_name_str.to_string(),\n                                    min: #min,\n                                    actual: self.#field_name.len(),\n                                });\n                            }\n                        }\n                    }\n                }\n                ValidationRule::Email => {\n                    quote! {\n                        if !is_valid_email(&self.#field_name) {\n                            errors.push(ValidationError::InvalidEmail(#field_name_str.to_string()));\n                        }\n                    }\n                }\n                ValidationRule::Custom(fn_name) => {\n                    let fn_ident = format_ident!(\"{}\", fn_name);\n                    quote! {\n                        if let Err(e) = #fn_ident(&self.#field_name) {\n                            errors.push(ValidationError::Custom {\n                                field: #field_name_str.to_string(),\n                                message: e,\n                            });\n                        }\n                    }\n                }\n            }\n        });\n        \n        quote! {\n            #(#checks)*\n        }\n    });\n    \n    quote! {\n        impl #impl_generics Validatable for #name #ty_generics #where_clause {\n            fn validate(&self) -> Result<(), Vec<ValidationError>> {\n                let mut errors = Vec::new();\n                \n                #(#validation_checks)*\n                \n                if errors.is_empty() {\n                    Ok(())\n                } else {\n                    Err(errors)\n                }\n            }\n        }\n    }\n}\n\n// Generate database mapping implementation\nfn generate_database_impl(\n    name: &syn::Ident,\n    fields: &Punctuated<Field, Token![,]>,\n    impl_generics: &syn::ImplGenerics,\n    ty_generics: &syn::TypeGenerics,\n    where_clause: &Option<&syn::WhereClause>,\n) -> proc_macro2::TokenStream {\n    let table_name = name.to_string().to_lowercase();\n    \n    // Generate column mappings\n    let column_mappings = fields.iter().map(|field| {\n        let field_name = &field.ident;\n        let field_name_str = field_name.as_ref().unwrap().to_string();\n        \n        // Check for custom db_field attribute\n        let db_column = get_db_field_name(&field.attrs)\n            .unwrap_or_else(|| field_name_str.clone());\n        \n        quote! {\n            (#db_column.to_string(), stringify!(#field_name).to_string())\n        }\n    });\n    \n    // Generate INSERT values\n    let insert_values = fields.iter().map(|field| {\n        let field_name = &field.ident;\n        quote! {\n            serde_json::to_value(&self.#field_name)?\n        }\n    });\n    \n    // Generate field extraction from database row\n    let field_extractions = fields.iter().map(|field| {\n        let field_name = &field.ident;\n        let field_type = &field.ty;\n        let db_column = get_db_field_name(&field.attrs)\n            .unwrap_or_else(|| field_name.as_ref().unwrap().to_string());\n        \n        quote! {\n            #field_name: {\n                let value = row.get(#db_column)\n                    .ok_or_else(|| DatabaseError::MissingColumn(#db_column.to_string()))?;\n                serde_json::from_value::<#field_type>(value.clone())?\n            }\n        }\n    });\n    \n    quote! {\n        impl #impl_generics DatabaseMappable for #name #ty_generics #where_clause {\n            fn table_name() -> &'static str {\n                #table_name\n            }\n            \n            fn column_mappings() -> Vec<(String, String)> {\n                vec![\n                    #(#column_mappings),*\n                ]\n            }\n            \n            fn to_insert_query(&self) -> Result<(String, Vec<serde_json::Value>), DatabaseError> {\n                let values = vec![#(#insert_values),*];\n                let query = format!(\n                    \"INSERT INTO {} VALUES ({})\", \n                    Self::table_name(),\n                    (0..values.len()).map(|i| format!(\"?{}\", i + 1)).collect::<Vec<_>>().join(\", \")\n                );\n                Ok((query, values))\n            }\n            \n            fn from_row(row: &std::collections::HashMap<String, serde_json::Value>) -> Result<Self, DatabaseError> {\n                Ok(Self {\n                    #(#field_extractions),*\n                })\n            }\n        }\n    }\n}\n\n// Generate custom serialization with metadata\nfn generate_serialization_impl(\n    name: &syn::Ident,\n    fields: &Punctuated<Field, Token![,]>,\n    impl_generics: &syn::ImplGenerics,\n    ty_generics: &syn::TypeGenerics,\n    where_clause: &Option<&syn::WhereClause>,\n) -> proc_macro2::TokenStream {\n    let serialize_fields = fields.iter().map(|field| {\n        let field_name = &field.ident;\n        let field_name_str = field_name.as_ref().unwrap().to_string();\n        \n        quote! {\n            map.insert(#field_name_str.to_string(), serde_json::to_value(&self.#field_name)?);\n        }\n    });\n    \n    let deserialize_fields = fields.iter().map(|field| {\n        let field_name = &field.ident;\n        let field_name_str = field_name.as_ref().unwrap().to_string();\n        let field_type = &field.ty;\n        \n        quote! {\n            #field_name: {\n                let value = data.get(#field_name_str)\n                    .ok_or_else(|| SerializationError::MissingField(#field_name_str.to_string()))?;\n                serde_json::from_value::<#field_type>(value.clone())?\n            }\n        }\n    });\n    \n    quote! {\n        impl #impl_generics DomainSerializable for #name #ty_generics #where_clause {\n            fn serialize_with_metadata(&self) -> Result<Vec<u8>, SerializationError> {\n                let mut map = std::collections::HashMap::new();\n                \n                // Add type metadata\n                map.insert(\"__type\".to_string(), serde_json::Value::String(stringify!(#name).to_string()));\n                map.insert(\"__version\".to_string(), serde_json::Value::Number(serde_json::Number::from(1)));\n                map.insert(\"__timestamp\".to_string(), serde_json::Value::Number(\n                    serde_json::Number::from(\n                        std::time::SystemTime::now()\n                            .duration_since(std::time::UNIX_EPOCH)\n                            .unwrap()\n                            .as_secs()\n                    )\n                ));\n                \n                // Serialize fields\n                #(#serialize_fields)*\n                \n                let json = serde_json::to_vec(&map)?;\n                Ok(json)\n            }\n            \n            fn deserialize_with_validation(data: &[u8]) -> Result<Self, SerializationError> {\n                let data: std::collections::HashMap<String, serde_json::Value> = \n                    serde_json::from_slice(data)?;\n                \n                // Validate type\n                let type_name = data.get(\"__type\")\n                    .and_then(|v| v.as_str())\n                    .ok_or(SerializationError::InvalidType)?;\n                    \n                if type_name != stringify!(#name) {\n                    return Err(SerializationError::TypeMismatch {\n                        expected: stringify!(#name).to_string(),\n                        actual: type_name.to_string(),\n                    });\n                }\n                \n                let obj = Self {\n                    #(#deserialize_fields),*\n                };\n                \n                // Validate the deserialized object\n                obj.validate().map_err(SerializationError::ValidationFailed)?;\n                \n                Ok(obj)\n            }\n        }\n    }\n}\n\n// Generate user-friendly display implementation\nfn generate_display_impl(\n    name: &syn::Ident,\n    fields: &Punctuated<Field, Token![,]>,\n    impl_generics: &syn::ImplGenerics,\n    ty_generics: &syn::TypeGenerics,\n    where_clause: &Option<&syn::WhereClause>,\n) -> proc_macro2::TokenStream {\n    let display_fields = fields.iter().map(|field| {\n        let field_name = &field.ident;\n        let display_name = get_display_name(&field.attrs)\n            .unwrap_or_else(|| field_name.as_ref().unwrap().to_string());\n        \n        quote! {\n            writeln!(f, \"{}: {:?}\", #display_name, self.#field_name)?;\n        }\n    });\n    \n    quote! {\n        impl #impl_generics std::fmt::Display for #name #ty_generics #where_clause {\n            fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n                writeln!(f, \"{}:\", stringify!(#name))?;\n                #(#display_fields)*\n                Ok(())\n            }\n        }\n    }\n}\n\n// Helper functions and types\n#[derive(Debug, Clone)]\nenum ValidationRule {\n    Required,\n    MinLength(usize),\n    Email,\n    Custom(String),\n}\n\nfn parse_validation_attributes(attrs: &[Attribute]) -> Vec<ValidationRule> {\n    let mut rules = Vec::new();\n    \n    for attr in attrs {\n        if attr.path().is_ident(\"validate\") {\n            if let Ok(Meta::List(meta_list)) = attr.meta {\n                let tokens = meta_list.tokens.to_string();\n                if tokens.contains(\"required\") {\n                    rules.push(ValidationRule::Required);\n                }\n                if tokens.contains(\"email\") {\n                    rules.push(ValidationRule::Email);\n                }\n            }\n        }\n    }\n    \n    rules\n}\n\nfn get_db_field_name(attrs: &[Attribute]) -> Option<String> {\n    for attr in attrs {\n        if attr.path().is_ident(\"db_field\") {\n            if let Ok(Meta::NameValue(meta)) = attr.meta {\n                if let syn::Expr::Lit(syn::ExprLit { lit: Lit::Str(lit_str), .. }) = meta.value {\n                    return Some(lit_str.value());\n                }\n            }\n        }\n    }\n    None\n}\n\nfn get_display_name(attrs: &[Attribute]) -> Option<String> {\n    for attr in attrs {\n        if attr.path().is_ident(\"display_name\") {\n            if let Ok(Meta::NameValue(meta)) = attr.meta {\n                if let syn::Expr::Lit(syn::ExprLit { lit: Lit::Str(lit_str), .. }) = meta.value {\n                    return Some(lit_str.value());\n                }\n            }\n        }\n    }\n    None\n}\n\nfn is_option_type(ty: &Type) -> bool {\n    if let Type::Path(type_path) = ty {\n        type_path.path.segments.last()\n            .map(|seg| seg.ident == \"Option\")\n            .unwrap_or(false)\n    } else {\n        false\n    }\n}\n\nfn is_string_type(ty: &Type) -> bool {\n    if let Type::Path(type_path) = ty {\n        type_path.path.segments.last()\n            .map(|seg| seg.ident == \"String\")\n            .unwrap_or(false)\n    } else {\n        false\n    }\n}\n\n// Supporting trait definitions\npub trait Validatable {\n    fn validate(&self) -> Result<(), Vec<ValidationError>>;\n}\n\npub trait DatabaseMappable {\n    fn table_name() -> &'static str;\n    fn column_mappings() -> Vec<(String, String)>;\n    fn to_insert_query(&self) -> Result<(String, Vec<serde_json::Value>), DatabaseError>;\n    fn from_row(row: &std::collections::HashMap<String, serde_json::Value>) -> Result<Self, DatabaseError>\n    where\n        Self: Sized;\n}\n\npub trait DomainSerializable {\n    fn serialize_with_metadata(&self) -> Result<Vec<u8>, SerializationError>;\n    fn deserialize_with_validation(data: &[u8]) -> Result<Self, SerializationError>\n    where\n        Self: Sized;\n}\n\n#[derive(Debug)]\npub enum ValidationError {\n    Required(String),\n    MinLength { field: String, min: usize, actual: usize },\n    InvalidEmail(String),\n    Custom { field: String, message: String },\n}\n\n#[derive(Debug)]\npub enum DatabaseError {\n    MissingColumn(String),\n    SerializationError(serde_json::Error),\n}\n\n#[derive(Debug)]\npub enum SerializationError {\n    Json(serde_json::Error),\n    MissingField(String),\n    InvalidType,\n    TypeMismatch { expected: String, actual: String },\n    ValidationFailed(Vec<ValidationError>),\n}\n\n// Helper function for email validation\nfn is_valid_email(email: &str) -> bool {\n    email.contains('@') && email.contains('.')\n}\n```\n\n## Usage of the Custom Derive Macros\n\n```rust\n// In your main application crate\nuse domain_macros::DomainObject;\n\n#[derive(Debug, DomainObject)]\nstruct User {\n    #[validate(required)]\n    #[db_field = \"user_id\"]\n    id: Option<u64>,\n    \n    #[validate(required)]\n    #[display_name = \"Full Name\"]\n    name: String,\n    \n    #[validate(required, email)]\n    #[db_field = \"email_address\"]\n    email: String,\n    \n    age: u32,\n    \n    #[validate(custom = \"validate_phone_number\")]\n    #[display_name = \"Phone Number\"]\n    phone: Option<String>,\n}\n\n// Custom validation function\nfn validate_phone_number(phone: &Option<String>) -> Result<(), String> {\n    if let Some(phone) = phone {\n        if phone.len() < 10 {\n            return Err(\"Phone number must be at least 10 digits\".to_string());\n        }\n    }\n    Ok(())\n}\n\n// Usage examples\nfn domain_object_examples() {\n    let user = User {\n        id: Some(1),\n        name: \"John Doe\".to_string(),\n        email: \"john@example.com\".to_string(),\n        age: 30,\n        phone: Some(\"1234567890\".to_string()),\n    };\n    \n    // Validation\n    match user.validate() {\n        Ok(()) => println!(\"User is valid\"),\n        Err(errors) => {\n            for error in errors {\n                println!(\"Validation error: {:?}\", error);\n            }\n        }\n    }\n    \n    // Database operations\n    match user.to_insert_query() {\n        Ok((query, values)) => {\n            println!(\"Insert query: {}\", query);\n            println!(\"Values: {:?}\", values);\n        }\n        Err(e) => println!(\"Database error: {:?}\", e),\n    }\n    \n    // Serialization with metadata\n    match user.serialize_with_metadata() {\n        Ok(data) => {\n            println!(\"Serialized user: {} bytes\", data.len());\n            \n            // Deserialize back\n            match User::deserialize_with_validation(&data) {\n                Ok(deserialized) => println!(\"Deserialized: {:?}\", deserialized),\n                Err(e) => println!(\"Deserialization error: {:?}\", e),\n            }\n        }\n        Err(e) => println!(\"Serialization error: {:?}\", e),\n    }\n    \n    // Display\n    println!(\"{}\", user);\n    \n    // Table info\n    println!(\"Table: {}\", User::table_name());\n    println!(\"Columns: {:?}\", User::column_mappings());\n}\n```\n\nThis comprehensive derive macro system provides:\n\n1. **Automatic validation** based on field attributes\n2. **Database mapping** with custom column names\n3. **Type-safe serialization** with metadata\n4. **User-friendly display** formatting\n5. **Compile-time generation** of all boilerplate code\n6. **Flexible attribute system** for customization\n\nThe beauty is that you write the domain logic once in attributes, and get consistent behavior across all your domain objects!",
    "tags": [
      "custom-derive",
      "domain-objects",
      "validation",
      "serialization",
      "database-mapping",
      "proc-macros",
      "attributes",
      "code-generation"
    ],
    "instruction": "This macro system is incredible! Can you show me how to implement custom derive macros for my domain objects? I need automatic serialization, validation, and database mapping."
  },
  {
    "output": "Great question! This is a classic Rust ownership issue that trips up many developers. Let me walk you through exactly what's happening and how to fix it.\n\n## The Problem: Use After Move\n\nThe error you're seeing is:\n```\nerror[E0382]: borrow of moved value: `users`\n   --> src/main.rs:18:17\n    |\n13  |     let alice = users.get(&1).unwrap();\n    |                 ----- borrow of `users` occurs here\n17  |     let bob = users.remove(&2).unwrap();\n    |               ^^^^^ value borrowed here after move\n18  |     println!(\"Alice again: {}\", alice.name);\n    |                                 ^^^^^^^^^^ value used here after move\n```\n\nHere's what's happening step by step:\n\n1. `users.get(&1)` returns a **reference** to the User (`&User`)\n2. `alice` holds this reference - it's borrowing the User from the HashMap\n3. `users.remove(&2)` requires a **mutable borrow** of the entire HashMap\n4. Rust won't allow a mutable borrow while an immutable borrow (`alice`) is still active\n5. When you try to use `alice.name`, the compiler catches this violation\n\n## Understanding the Borrow Checker\n\nLet me show you what the borrow checker sees:\n\n```rust\nuse std::collections::HashMap;\n\nstruct User {\n    name: String,\n    age: u32,\n}\n\nfn main() {\n    let mut users = HashMap::new();\n    let user1 = User { name: \"Alice\".to_string(), age: 25 };\n    let user2 = User { name: \"Bob\".to_string(), age: 30 };\n    \n    users.insert(1, user1);\n    users.insert(2, user2);\n    \n    // alice borrows from users - immutable borrow starts here\n    let alice = users.get(&1).unwrap(); // &User\n    println!(\"User: {} is {} years old\", alice.name, alice.age);\n    \n    // ERROR: Can't mutably borrow users while alice still exists\n    let bob = users.remove(&2).unwrap(); // requires &mut HashMap\n    \n    // alice is still in scope here, so the immutable borrow is active\n    println!(\"Alice again: {}\", alice.name); // tries to use the borrow\n}\n```\n\n## Solution 1: Scope Management\n\nThe simplest fix is to limit the scope of the borrow:\n\n```rust\nuse std::collections::HashMap;\n\nstruct User {\n    name: String,\n    age: u32,\n}\n\nfn main() {\n    let mut users = HashMap::new();\n    let user1 = User { name: \"Alice\".to_string(), age: 25 };\n    let user2 = User { name: \"Bob\".to_string(), age: 30 };\n    \n    users.insert(1, user1);\n    users.insert(2, user2);\n    \n    // Use the borrow and let it end\n    {\n        let alice = users.get(&1).unwrap();\n        println!(\"User: {} is {} years old\", alice.name, alice.age);\n    } // alice goes out of scope here, borrow ends\n    \n    // Now we can mutably borrow\n    let bob = users.remove(&2).unwrap();\n    println!(\"Removed user: {}\", bob.name);\n    \n    // Get alice again if needed\n    let alice_again = users.get(&1).unwrap();\n    println!(\"Alice again: {}\", alice_again.name);\n}\n```\n\n## Solution 2: Clone the Data\n\nIf you need to keep the data around, clone it:\n\n```rust\nuse std::collections::HashMap;\n\n#[derive(Clone)] // Add Clone trait\nstruct User {\n    name: String,\n    age: u32,\n}\n\nfn main() {\n    let mut users = HashMap::new();\n    let user1 = User { name: \"Alice\".to_string(), age: 25 };\n    let user2 = User { name: \"Bob\".to_string(), age: 30 };\n    \n    users.insert(1, user1);\n    users.insert(2, user2);\n    \n    // Clone the user instead of borrowing\n    let alice = users.get(&1).unwrap().clone();\n    println!(\"User: {} is {} years old\", alice.name, alice.age);\n    \n    // Now this works because we own alice, not borrowing from users\n    let bob = users.remove(&2).unwrap();\n    println!(\"Removed user: {}\", bob.name);\n    \n    // alice is owned data, so this works\n    println!(\"Alice again: {}\", alice.name);\n}\n```\n\n## Solution 3: Restructure the Logic\n\nOften the best solution is to rethink the order of operations:\n\n```rust\nuse std::collections::HashMap;\n\nstruct User {\n    name: String,\n    age: u32,\n}\n\nfn main() {\n    let mut users = HashMap::new();\n    let user1 = User { name: \"Alice\".to_string(), age: 25 };\n    let user2 = User { name: \"Bob\".to_string(), age: 30 };\n    \n    users.insert(1, user1);\n    users.insert(2, user2);\n    \n    // Do all the reads first\n    if let Some(alice) = users.get(&1) {\n        println!(\"User: {} is {} years old\", alice.name, alice.age);\n        println!(\"Alice first time: {}\", alice.name);\n    }\n    \n    // Then do the mutations\n    if let Some(bob) = users.remove(&2) {\n        println!(\"Removed user: {}\", bob.name);\n    }\n    \n    // Then read again if needed\n    if let Some(alice) = users.get(&1) {\n        println!(\"Alice again: {}\", alice.name);\n    }\n}\n```\n\n## Debugging Tips for Borrow Checker Issues\n\n1. **Look for the borrow scope**: Use `cargo check` to see exactly where borrows start and end\n2. **Use explicit scopes**: Add `{}` blocks to limit borrow lifetimes\n3. **Consider ownership**: Ask \"Do I need to own this data or just read it?\"\n4. **Check method signatures**: `get()` returns `Option<&T>`, `remove()` returns `Option<T>`\n5. **Use `clone()` strategically**: It's often better to clone small data than fight the borrow checker\n\nThe key insight is that Rust prevents data races by ensuring you can't modify something while it's being read elsewhere. Once you understand this principle, these errors become much easier to debug!",
    "tags": [
      "debugging",
      "borrow-checker",
      "ownership",
      "compiler-errors",
      "troubleshooting",
      "lifetimes"
    ],
    "instruction": "I'm getting some really confusing compiler errors in my Rust code. Can you help me debug this? Here's what I'm seeing:\n\n```rust\nuse std::collections::HashMap;\n\nstruct User {\n    name: String,\n    age: u32,\n}\n\nfn main() {\n    let mut users = HashMap::new();\n    let user1 = User { name: \"Alice\".to_string(), age: 25 };\n    let user2 = User { name: \"Bob\".to_string(), age: 30 };\n    \n    users.insert(1, user1);\n    users.insert(2, user2);\n    \n    let alice = users.get(&1).unwrap();\n    println!(\"User: {} is {} years old\", alice.name, alice.age);\n    \n    let bob = users.remove(&2).unwrap();\n    println!(\"Removed user: {}\", bob.name);\n    \n    // This is where I'm getting errors\n    println!(\"Alice again: {}\", alice.name);\n}\n```\n\nThe error says something about 'alice' being borrowed after move. I don't understand what's happening!"
  },
  {
    "output": "Excellent follow-up question! You've hit another classic Rust concept - lifetime parameters. The compiler is actually protecting you from a potential use-after-free bug. Let me explain what's happening and show you how to fix it.\n\n## The Problem: Missing Lifetime Annotations\n\nThe exact error you're seeing is:\n```\nerror[E0106]: missing lifetime parameter\n --> src/main.rs:1:46\n  |\n1 | fn find_longest_string(strings: Vec<&str>) -> &str {\n  |                                     ----     ^ expected named lifetime parameter\n  |\n  = help: this function's return type contains a borrowed value, but the signature does not say whether it is borrowed from `strings`\n```\n\n## Understanding the Issue\n\nRust needs to know: **How long will the returned reference be valid?**\n\nYour function takes references as input and returns a reference as output. The compiler needs to understand the relationship between the input and output lifetimes to prevent dangling pointers.\n\nHere's what could go wrong without lifetime checking:\n\n```rust\n// This would be dangerous if Rust allowed it\nfn dangerous_example() {\n    let result;\n    {\n        let temp_vec = vec![\"short\", \"longer\", \"longest\"];\n        result = find_longest_string(temp_vec); // hypothetical broken version\n    } // temp_vec is dropped here!\n    \n    println!(\"{}\", result); // result points to freed memory!\n}\n```\n\n## Solution 1: Add Lifetime Parameters\n\nTell Rust that the output lifetime is tied to the input:\n\n```rust\n// The lifetime 'a says: \"the returned reference lives as long as the input references\"\nfn find_longest_string<'a>(strings: Vec<&'a str>) -> &'a str {\n    let mut longest = \"\";\n    for s in strings {\n        if s.len() > longest.len() {\n            longest = s;\n        }\n    }\n    longest\n}\n\nfn main() {\n    let words = vec![\"hello\", \"world\", \"rust\", \"programming\"];\n    let result = find_longest_string(words);\n    println!(\"Longest: {}\", result);\n}\n```\n\n## But Wait - There's Still a Problem!\n\nEven with lifetimes, your code has a subtle bug. Let me show you:\n\n```rust\nfn find_longest_string<'a>(strings: Vec<&'a str>) -> &'a str {\n    let mut longest = \"\"; // This is a string literal with 'static lifetime\n    for s in strings {\n        if s.len() > longest.len() {\n            longest = s;\n        }\n    }\n    longest // Could return the 'static \"\" if all input strings are empty!\n}\n\nfn main() {\n    let empty_strings = vec![\"\", \"\", \"\"];\n    let result = find_longest_string(empty_strings);\n    println!(\"Longest: '{}'\", result); // Returns empty string, but from wrong lifetime!\n}\n```\n\n## Solution 2: Handle Empty Input Properly\n\n```rust\nfn find_longest_string<'a>(strings: Vec<&'a str>) -> Option<&'a str> {\n    if strings.is_empty() {\n        return None;\n    }\n    \n    let mut longest = strings[0]; // Start with first string, not empty literal\n    for s in strings.iter().skip(1) {\n        if s.len() > longest.len() {\n            longest = s;\n        }\n    }\n    Some(longest)\n}\n\nfn main() {\n    let words = vec![\"hello\", \"world\", \"rust\", \"programming\"];\n    \n    match find_longest_string(words) {\n        Some(result) => println!(\"Longest: {}\", result),\n        None => println!(\"No strings provided\"),\n    }\n    \n    // Test edge cases\n    let empty: Vec<&str> = vec![];\n    println!(\"Empty result: {:?}\", find_longest_string(empty));\n    \n    let single = vec![\"only\"];\n    println!(\"Single result: {:?}\", find_longest_string(single));\n}\n```\n\n## Solution 3: Take a Slice Instead (More Idiomatic)\n\n```rust\n// Taking &[&str] is more flexible than Vec<&str>\nfn find_longest_string<'a>(strings: &[&'a str]) -> Option<&'a str> {\n    strings.iter()\n        .max_by_key(|s| s.len())\n        .copied() // Convert &&str to &str\n}\n\n// Alternative: using fold for explicit logic\nfn find_longest_string_explicit<'a>(strings: &[&'a str]) -> Option<&'a str> {\n    if strings.is_empty() {\n        return None;\n    }\n    \n    Some(strings.iter().fold(strings[0], |longest, &current| {\n        if current.len() > longest.len() {\n            current\n        } else {\n            longest\n        }\n    }))\n}\n\nfn main() {\n    let words = vec![\"hello\", \"world\", \"rust\", \"programming\"];\n    \n    // Can pass vec as slice\n    if let Some(result) = find_longest_string(&words) {\n        println!(\"Longest: {}\", result);\n    }\n    \n    // Can also pass array slice directly\n    let array = [\"short\", \"medium\", \"longest_string\"];\n    if let Some(result) = find_longest_string(&array) {\n        println!(\"Longest from array: {}\", result);\n    }\n    \n    // Test the explicit version\n    if let Some(result) = find_longest_string_explicit(&words) {\n        println!(\"Longest (explicit): {}\", result);\n    }\n}\n```\n\n## Solution 4: Return Owned Data (No Lifetimes Needed)\n\nIf lifetime management is too complex, return owned data:\n\n```rust\nfn find_longest_string_owned(strings: Vec<&str>) -> Option<String> {\n    strings.iter()\n        .max_by_key(|s| s.len())\n        .map(|s| s.to_string()) // Convert to owned String\n}\n\nfn main() {\n    let words = vec![\"hello\", \"world\", \"rust\", \"programming\"];\n    \n    if let Some(result) = find_longest_string_owned(words) {\n        println!(\"Longest (owned): {}\", result);\n        // result is a String, so no lifetime issues\n    }\n}\n```\n\n## Key Debugging Insights\n\n1. **Lifetime errors usually mean**: \"You're trying to return a reference, but Rust can't guarantee what it points to will live long enough\"\n\n2. **Common fixes**:\n   - Add lifetime parameters to connect input and output lifetimes\n   - Return owned data instead of references\n   - Restructure to avoid returning references\n\n3. **Read the error carefully**: The compiler often suggests the exact fix (\"expected named lifetime parameter\")\n\n4. **Test edge cases**: Empty inputs, single elements, all elements the same length\n\n5. **When in doubt, return `Option`**: It's more honest about failure cases\n\nLifetimes can be tricky at first, but they're Rust's way of preventing memory safety bugs that would crash your program in other languages!",
    "tags": [
      "debugging",
      "lifetimes",
      "compiler-errors",
      "references",
      "function-signatures",
      "memory-safety"
    ],
    "instruction": "Thanks! That makes much more sense now. I'm running into another issue though. I'm trying to create a function that returns the longest string from a vector, but I'm getting lifetime errors. Here's my code:\n\n```rust\nfn find_longest_string(strings: Vec<&str>) -> &str {\n    let mut longest = \"\";\n    for s in strings {\n        if s.len() > longest.len() {\n            longest = s;\n        }\n    }\n    longest\n}\n\nfn main() {\n    let words = vec![\"hello\", \"world\", \"rust\", \"programming\"];\n    let result = find_longest_string(words);\n    println!(\"Longest: {}\", result);\n}\n```\n\nThe compiler says 'cannot return value referencing local variable'. What's going wrong here?"
  },
  {
    "output": "Absolutely! Setting up a Rust web API project can feel overwhelming with all the options available. Let me walk you through a practical, opinionated setup that will get you productive quickly.\n\n## Step 1: Create the Project\n\n```bash\n# Create new project\ncargo new my-web-api --bin\ncd my-web-api\n\n# Initialize git if you want version control\ngit init\n```\n\n## Step 2: Choose Your Dependencies (Opinionated Recommendations)\n\nHere's a solid dependency stack for a modern web API:\n\n```toml\n# Cargo.toml\n[package]\nname = \"my-web-api\"\nversion = \"0.1.0\"\nedition = \"2021\"\n\n[dependencies]\n# Web framework - Axum is modern, fast, and well-designed\naxum = { version = \"0.7\", features = [\"macros\"] }\ntokio = { version = \"1.0\", features = [\"full\"] }\ntower = \"0.4\"\ntower-http = { version = \"0.5\", features = [\"fs\", \"trace\", \"cors\"] }\n\n# Serialization - serde is the standard\nserde = { version = \"1.0\", features = [\"derive\"] }\nserde_json = \"1.0\"\n\n# Database - sqlx is excellent for async\nsqlx = { version = \"0.7\", features = [\"runtime-tokio-rustls\", \"postgres\", \"uuid\", \"chrono\"] }\n\n# Utilities\nuuid = { version = \"1.0\", features = [\"v4\", \"serde\"] }\nchrono = { version = \"0.4\", features = [\"serde\"] }\nanyhow = \"1.0\"  # Error handling\nthiserror = \"1.0\"  # Custom error types\n\n# Logging\ntracing = \"0.1\"\ntracing-subscriber = { version = \"0.3\", features = [\"env-filter\"] }\n\n# Configuration\nconfig = \"0.14\"\ndotenvy = \"0.15\"  # .env file support\n\n# Development dependencies\n[dev-dependencies]\ntokio-test = \"0.4\"\nhttpc-test = \"0.1\"\n```\n\n## Step 3: Project Structure\n\nCreate this directory structure:\n\n```\nmy-web-api/\n\u251c\u2500\u2500 Cargo.toml\n\u251c\u2500\u2500 .env                    # Environment variables\n\u251c\u2500\u2500 .gitignore             # Git ignore file\n\u251c\u2500\u2500 README.md              # Project documentation\n\u251c\u2500\u2500 src/\n\u2502   \u251c\u2500\u2500 main.rs           # Application entry point\n\u2502   \u251c\u2500\u2500 lib.rs            # Library code\n\u2502   \u251c\u2500\u2500 config.rs         # Configuration management\n\u2502   \u251c\u2500\u2500 error.rs          # Error types\n\u2502   \u251c\u2500\u2500 handlers/         # HTTP handlers\n\u2502   \u2502   \u251c\u2500\u2500 mod.rs\n\u2502   \u2502   \u251c\u2500\u2500 health.rs\n\u2502   \u2502   \u2514\u2500\u2500 users.rs\n\u2502   \u251c\u2500\u2500 models/           # Data models\n\u2502   \u2502   \u251c\u2500\u2500 mod.rs\n\u2502   \u2502   \u2514\u2500\u2500 user.rs\n\u2502   \u251c\u2500\u2500 db/               # Database code\n\u2502   \u2502   \u251c\u2500\u2500 mod.rs\n\u2502   \u2502   \u2514\u2500\u2500 migrations/\n\u2502   \u2514\u2500\u2500 routes.rs         # Route definitions\n\u251c\u2500\u2500 migrations/           # Database migrations\n\u2514\u2500\u2500 tests/               # Integration tests\n    \u2514\u2500\u2500 api_tests.rs\n```\n\nLet's create these files:\n\n```bash\n# Create the directory structure\nmkdir -p src/{handlers,models,db/migrations} tests migrations\n\n# Create module files\ntouch src/{lib.rs,config.rs,error.rs,routes.rs}\ntouch src/handlers/{mod.rs,health.rs,users.rs}\ntouch src/models/{mod.rs,user.rs}\ntouch src/db/mod.rs\ntouch tests/api_tests.rs\n```\n\n## Step 4: Environment Configuration\n\nCreate `.env` file:\n\n```bash\n# .env\nDATABASE_URL=postgresql://username:password@localhost/my_web_api_db\nRUST_LOG=debug\nSERVER_HOST=127.0.0.1\nSERVER_PORT=3000\n```\n\nCreate `.gitignore`:\n\n```bash\n# .gitignore\n/target\nCargo.lock\n.env\n.DS_Store\n*.log\n```\n\n## Step 5: Configuration Module\n\n```rust\n// src/config.rs\nuse serde::Deserialize;\nuse std::env;\n\n#[derive(Debug, Deserialize, Clone)]\npub struct Config {\n    pub database_url: String,\n    pub server_host: String,\n    pub server_port: u16,\n    pub rust_log: String,\n}\n\nimpl Config {\n    pub fn from_env() -> Result<Self, config::ConfigError> {\n        dotenvy::dotenv().ok(); // Load .env file\n        \n        let config = config::Config::builder()\n            .add_source(config::Environment::default())\n            .build()?;\n        \n        config.try_deserialize()\n    }\n    \n    pub fn server_address(&self) -> String {\n        format!(\"{}:{}\", self.server_host, self.server_port)\n    }\n}\n```\n\n## Step 6: Error Handling\n\n```rust\n// src/error.rs\nuse axum::{\n    http::StatusCode,\n    response::{IntoResponse, Response},\n    Json,\n};\nuse serde_json::json;\nuse thiserror::Error;\n\n#[derive(Error, Debug)]\npub enum AppError {\n    #[error(\"Database error: {0}\")]\n    Database(#[from] sqlx::Error),\n    \n    #[error(\"Configuration error: {0}\")]\n    Config(#[from] config::ConfigError),\n    \n    #[error(\"User not found\")]\n    UserNotFound,\n    \n    #[error(\"Validation error: {0}\")]\n    Validation(String),\n    \n    #[error(\"Internal server error\")]\n    Internal(#[from] anyhow::Error),\n}\n\nimpl IntoResponse for AppError {\n    fn into_response(self) -> Response {\n        let (status, error_message) = match &self {\n            AppError::Database(_) => (StatusCode::INTERNAL_SERVER_ERROR, \"Database error\"),\n            AppError::Config(_) => (StatusCode::INTERNAL_SERVER_ERROR, \"Configuration error\"),\n            AppError::UserNotFound => (StatusCode::NOT_FOUND, \"User not found\"),\n            AppError::Validation(_) => (StatusCode::BAD_REQUEST, \"Validation error\"),\n            AppError::Internal(_) => (StatusCode::INTERNAL_SERVER_ERROR, \"Internal server error\"),\n        };\n        \n        let body = Json(json!({\n            \"error\": error_message,\n            \"details\": self.to_string()\n        }));\n        \n        (status, body).into_response()\n    }\n}\n\npub type Result<T> = std::result::Result<T, AppError>;\n```\n\n## Step 7: Data Models\n\n```rust\n// src/models/user.rs\nuse serde::{Deserialize, Serialize};\nuse sqlx::FromRow;\nuse uuid::Uuid;\nuse chrono::{DateTime, Utc};\n\n#[derive(Debug, Serialize, Deserialize, FromRow)]\npub struct User {\n    pub id: Uuid,\n    pub name: String,\n    pub email: String,\n    pub created_at: DateTime<Utc>,\n    pub updated_at: DateTime<Utc>,\n}\n\n#[derive(Debug, Deserialize)]\npub struct CreateUserRequest {\n    pub name: String,\n    pub email: String,\n}\n\n#[derive(Debug, Deserialize)]\npub struct UpdateUserRequest {\n    pub name: Option<String>,\n    pub email: Option<String>,\n}\n\n// src/models/mod.rs\npub mod user;\npub use user::*;\n```\n\n## Step 8: Database Module\n\n```rust\n// src/db/mod.rs\nuse sqlx::{PgPool, Pool, Postgres};\nuse crate::config::Config;\n\npub type DbPool = Pool<Postgres>;\n\npub async fn create_pool(config: &Config) -> Result<DbPool, sqlx::Error> {\n    PgPool::connect(&config.database_url).await\n}\n\npub async fn run_migrations(pool: &DbPool) -> Result<(), sqlx::migrate::MigrateError> {\n    sqlx::migrate!(\"./migrations\").run(pool).await\n}\n```\n\n## Step 9: HTTP Handlers\n\n```rust\n// src/handlers/health.rs\nuse axum::Json;\nuse serde_json::{json, Value};\n\npub async fn health_check() -> Json<Value> {\n    Json(json!({\n        \"status\": \"healthy\",\n        \"timestamp\": chrono::Utc::now()\n    }))\n}\n\n// src/handlers/users.rs\nuse axum::{\n    extract::{Path, State},\n    Json,\n};\nuse uuid::Uuid;\nuse crate::{\n    db::DbPool,\n    error::Result,\n    models::{User, CreateUserRequest, UpdateUserRequest},\n};\n\npub async fn get_users(State(pool): State<DbPool>) -> Result<Json<Vec<User>>> {\n    let users = sqlx::query_as::<_, User>(\"SELECT * FROM users ORDER BY created_at DESC\")\n        .fetch_all(&pool)\n        .await?;\n    \n    Ok(Json(users))\n}\n\npub async fn get_user(State(pool): State<DbPool>, Path(id): Path<Uuid>) -> Result<Json<User>> {\n    let user = sqlx::query_as::<_, User>(\"SELECT * FROM users WHERE id = $1\")\n        .bind(id)\n        .fetch_optional(&pool)\n        .await?\n        .ok_or(crate::error::AppError::UserNotFound)?;\n    \n    Ok(Json(user))\n}\n\npub async fn create_user(\n    State(pool): State<DbPool>,\n    Json(req): Json<CreateUserRequest>,\n) -> Result<Json<User>> {\n    let user = sqlx::query_as::<_, User>(\n        r#\"\n        INSERT INTO users (id, name, email, created_at, updated_at)\n        VALUES ($1, $2, $3, $4, $5)\n        RETURNING *\n        \"#,\n    )\n    .bind(Uuid::new_v4())\n    .bind(&req.name)\n    .bind(&req.email)\n    .bind(chrono::Utc::now())\n    .bind(chrono::Utc::now())\n    .fetch_one(&pool)\n    .await?;\n    \n    Ok(Json(user))\n}\n\n// src/handlers/mod.rs\npub mod health;\npub mod users;\n```\n\n## Step 10: Routes\n\n```rust\n// src/routes.rs\nuse axum::{\n    routing::{get, post},\n    Router,\n};\nuse crate::{\n    db::DbPool,\n    handlers::{health, users},\n};\n\npub fn create_routes(pool: DbPool) -> Router {\n    Router::new()\n        .route(\"/health\", get(health::health_check))\n        .route(\"/users\", get(users::get_users).post(users::create_user))\n        .route(\"/users/:id\", get(users::get_user))\n        .with_state(pool)\n}\n```\n\n## Step 11: Main Application\n\n```rust\n// src/lib.rs\npub mod config;\npub mod error;\npub mod handlers;\npub mod models;\npub mod db;\npub mod routes;\n\n// src/main.rs\nuse my_web_api::{\n    config::Config,\n    db::{create_pool, run_migrations},\n    routes::create_routes,\n};\nuse tower_http::{\n    trace::TraceLayer,\n    cors::CorsLayer,\n};\nuse tracing_subscriber;\n\n#[tokio::main]\nasync fn main() -> anyhow::Result<()> {\n    // Initialize tracing\n    tracing_subscriber::fmt::init();\n    \n    // Load configuration\n    let config = Config::from_env()?;\n    tracing::info!(\"Starting server with config: {:?}\", config);\n    \n    // Create database connection pool\n    let pool = create_pool(&config).await?;\n    tracing::info!(\"Database pool created successfully\");\n    \n    // Run migrations\n    run_migrations(&pool).await?;\n    tracing::info!(\"Database migrations completed\");\n    \n    // Create router\n    let app = create_routes(pool)\n        .layer(TraceLayer::new_for_http())\n        .layer(CorsLayer::permissive());\n    \n    // Start server\n    let listener = tokio::net::TcpListener::bind(&config.server_address()).await?;\n    tracing::info!(\"Server listening on {}\", config.server_address());\n    \n    axum::serve(listener, app).await?;\n    \n    Ok(())\n}\n```\n\n## Step 12: Database Migration\n\nCreate your first migration:\n\n```bash\n# Install sqlx-cli if you haven't\ncargo install sqlx-cli\n\n# Create migration\nsqlx migrate add create_users_table\n```\n\nThis creates a file in `migrations/` - edit it:\n\n```sql\n-- migrations/001_create_users_table.up.sql\nCREATE EXTENSION IF NOT EXISTS \"uuid-ossp\";\n\nCREATE TABLE users (\n    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n    name VARCHAR NOT NULL,\n    email VARCHAR UNIQUE NOT NULL,\n    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),\n    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW()\n);\n\nCREATE INDEX idx_users_email ON users(email);\nCREATE INDEX idx_users_created_at ON users(created_at);\n```\n\n## Step 13: Run Your API\n\n```bash\n# Make sure PostgreSQL is running and create your database\ncreatedb my_web_api_db\n\n# Run the application\ncargo run\n\n# Test it\ncurl http://localhost:3000/health\ncurl -X POST http://localhost:3000/users \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"name\": \"John Doe\", \"email\": \"john@example.com\"}'\n```\n\nThis setup gives you:\n- \u2705 Modern async web framework (Axum)\n- \u2705 Database integration (SQLx + PostgreSQL)\n- \u2705 Proper error handling\n- \u2705 Configuration management\n- \u2705 Logging and tracing\n- \u2705 Clean project structure\n- \u2705 Development-ready setup\n\nYou can now build upon this foundation by adding authentication, more endpoints, testing, etc.!",
    "tags": [
      "project-setup",
      "web-api",
      "dependencies",
      "project-structure",
      "axum",
      "database",
      "configuration",
      "practical-workflow"
    ],
    "instruction": "I'm trying to set up a new Rust project for a web API and I'm completely overwhelmed by all the choices. What dependencies should I use? How do I structure the project? Can you walk me through the whole setup process?"
  },
  {
    "output": "Great question! These are super common issues when setting up a new Rust project. Let me walk you through debugging each of these problems systematically.\n\n## Problem 1: Missing Modules\n\nThe \"missing modules\" error usually looks like:\n```\nerror[E0583]: file not found for module `handlers`\n --> src/lib.rs:3:5\n  |\n3 | pub mod handlers;\n  |     ^^^^^^^^^^^^^\n  |\n  = help: to create the module `handlers`, create file \"src/handlers.rs\" or \"src/handlers/mod.rs\"\n```\n\n**Debug Steps:**\n\n1. **Check your file structure exactly:**\n```bash\n# Run this to see your actual structure\nfind src -type f -name \"*.rs\" | sort\n```\n\nYou should see:\n```\nsrc/config.rs\nsrc/db/mod.rs\nsrc/error.rs\nsrc/handlers/health.rs\nsrc/handlers/mod.rs\nsrc/handlers/users.rs\nsrc/lib.rs\nsrc/main.rs\nsrc/models/mod.rs\nsrc/models/user.rs\nsrc/routes.rs\n```\n\n2. **Fix missing mod.rs files:**\n\nIf you're missing `src/handlers/mod.rs`, create it:\n```rust\n// src/handlers/mod.rs\npub mod health;\npub mod users;\n```\n\nSame for `src/models/mod.rs`:\n```rust\n// src/models/mod.rs\npub mod user;\npub use user::*;\n```\n\n3. **Check your lib.rs declarations:**\n```rust\n// src/lib.rs - make sure all modules are declared\npub mod config;\npub mod error;\npub mod handlers;\npub mod models;\npub mod db;\npub mod routes;\n```\n\n## Problem 2: Trait Bound Issues\n\nThese often look like:\n```\nerror[E0277]: the trait bound `DbPool: Clone` is not satisfied\n --> src/routes.rs:XX:XX\n```\n\n**Common fixes:**\n\n1. **Add missing derives:**\n```rust\n// Make sure your structs have the right derives\n#[derive(Debug, Clone)] // Add Clone if needed\npub struct Config {\n    // ...\n}\n```\n\n2. **Fix the router state issue:**\n\nIf you get an error about `DbPool` not implementing `Clone`, update your routes:\n\n```rust\n// src/routes.rs - Fix the state management\nuse axum::{\n    routing::{get, post},\n    Router,\n};\nuse std::sync::Arc;\nuse crate::{\n    db::DbPool,\n    handlers::{health, users},\n};\n\n// Use Arc to make the pool cloneable\npub fn create_routes(pool: DbPool) -> Router {\n    let shared_pool = Arc::new(pool);\n    \n    Router::new()\n        .route(\"/health\", get(health::health_check))\n        .route(\"/users\", get(users::get_users).post(users::create_user))\n        .route(\"/users/:id\", get(users::get_user))\n        .with_state(shared_pool)\n}\n```\n\nAnd update your handlers:\n```rust\n// src/handlers/users.rs - Update to use Arc<DbPool>\nuse axum::{\n    extract::{Path, State},\n    Json,\n};\nuse std::sync::Arc;\nuse uuid::Uuid;\nuse crate::{\n    db::DbPool,\n    error::Result,\n    models::{User, CreateUserRequest},\n};\n\npub async fn get_users(State(pool): State<Arc<DbPool>>) -> Result<Json<Vec<User>>> {\n    let users = sqlx::query_as::<_, User>(\"SELECT * FROM users ORDER BY created_at DESC\")\n        .fetch_all(pool.as_ref()) // Use as_ref() to get &DbPool\n        .await?;\n    \n    Ok(Json(users))\n}\n\npub async fn get_user(\n    State(pool): State<Arc<DbPool>>, \n    Path(id): Path<Uuid>\n) -> Result<Json<User>> {\n    let user = sqlx::query_as::<_, User>(\"SELECT * FROM users WHERE id = $1\")\n        .bind(id)\n        .fetch_optional(pool.as_ref())\n        .await?\n        .ok_or(crate::error::AppError::UserNotFound)?;\n    \n    Ok(Json(user))\n}\n\npub async fn create_user(\n    State(pool): State<Arc<DbPool>>,\n    Json(req): Json<CreateUserRequest>,\n) -> Result<Json<User>> {\n    let user = sqlx::query_as::<_, User>(\n        r#\"\n        INSERT INTO users (id, name, email, created_at, updated_at)\n        VALUES ($1, $2, $3, $4, $5)\n        RETURNING *\n        \"#,\n    )\n    .bind(Uuid::new_v4())\n    .bind(&req.name)\n    .bind(&req.email)\n    .bind(chrono::Utc::now())\n    .bind(chrono::Utc::now())\n    .fetch_one(pool.as_ref())\n    .await?;\n    \n    Ok(Json(user))\n}\n```\n\n## Problem 3: SQLx Compile-Time Verification\n\nThe error looks like:\n```\nerror: sqlx-data.json not found; please run `cargo sqlx prepare` or set `SQLX_OFFLINE=true`\n```\n\n**Solution options:**\n\n**Option A: Generate query metadata (Recommended for CI/CD):**\n```bash\n# First, make sure your database is running and migrated\ncargo install sqlx-cli\nexport DATABASE_URL=\"postgresql://username:password@localhost/my_web_api_db\"\nsqlx database create\nsqlx migrate run\n\n# Generate the metadata\ncargo sqlx prepare\n```\n\nThis creates a `.sqlx/` directory with query metadata that SQLx uses for compile-time verification.\n\n**Option B: Disable compile-time checking (Quick fix for development):**\n\nAdd this to your environment or `.env`:\n```bash\n# .env\nSQLX_OFFLINE=true\n```\n\nOr in your `Cargo.toml`:\n```toml\n[dependencies]\nsqlx = { version = \"0.7\", features = [\"runtime-tokio-rustls\", \"postgres\", \"uuid\", \"chrono\"], default-features = false }\n```\n\n**Option C: Use the query! macro for better error messages:**\n\nReplace your raw SQL with the `query!` macro for better error reporting:\n\n```rust\n// Instead of sqlx::query_as\nuse sqlx::query_as;\n\n// Use this for better compile-time checking:\nuse sqlx::query;\n\npub async fn get_users(State(pool): State<Arc<DbPool>>) -> Result<Json<Vec<User>>> {\n    let rows = query!(\"SELECT id, name, email, created_at, updated_at FROM users ORDER BY created_at DESC\")\n        .fetch_all(pool.as_ref())\n        .await?;\n    \n    let users: Vec<User> = rows.into_iter().map(|row| User {\n        id: row.id,\n        name: row.name,\n        email: row.email,\n        created_at: row.created_at,\n        updated_at: row.updated_at,\n    }).collect();\n    \n    Ok(Json(users))\n}\n```\n\n## Problem 4: Dependency Version Conflicts\n\nIf you get errors like:\n```\nerror: failed to select a version for `tokio`\n```\n\n**Debug with:**\n```bash\n# Check for conflicts\ncargo tree\n\n# Update to latest compatible versions\ncargo update\n\n# Check what's actually available\ncargo search tokio\n```\n\n**Fix by pinning compatible versions:**\n```toml\n[dependencies]\n# Make sure versions are compatible\ntokio = { version = \"1.35\", features = [\"full\"] }\naxum = { version = \"0.7\", features = [\"macros\"] }\nsqlx = { version = \"0.7\", features = [\"runtime-tokio-rustls\", \"postgres\", \"uuid\", \"chrono\"] }\n```\n\n## Systematic Debugging Approach\n\n1. **Start simple:**\n```bash\n# Check basic compilation\ncargo check\n\n# If that fails, try individual modules\ncargo check --lib\ncargo check --bin my-web-api\n```\n\n2. **Read errors from top to bottom:**\nRust compiler errors cascade - fix the first error first.\n\n3. **Use verbose output:**\n```bash\ncargo check --verbose\n```\n\n4. **Test module by module:**\nComment out module declarations in `lib.rs` one by one to isolate the problem.\n\n5. **Check your .env file:**\n```bash\n# Make sure it's properly formatted\ncat .env\n```\n\n## Quick Verification Script\n\nCreate this script to verify your setup:\n\n```bash\n#!/bin/bash\n# verify-setup.sh\n\necho \"\ud83d\udd0d Checking project structure...\"\nfind src -name \"*.rs\" | head -10\n\necho \"\ud83d\udd0d Checking dependencies...\"\ncargo tree --depth 1\n\necho \"\ud83d\udd0d Checking environment...\"\nif [ -f .env ]; then\n    echo \"\u2705 .env file exists\"\nelse\n    echo \"\u274c .env file missing\"\nfi\n\necho \"\ud83d\udd0d Checking database connection...\"\nif command -v psql &> /dev/null; then\n    echo \"\u2705 PostgreSQL client available\"\nelse\n    echo \"\u274c PostgreSQL client not found\"\nfi\n\necho \"\ud83d\udd0d Attempting compilation...\"\ncargo check --quiet && echo \"\u2705 Compilation successful\" || echo \"\u274c Compilation failed\"\n```\n\nRun it with:\n```bash\nchmod +x verify-setup.sh\n./verify-setup.sh\n```\n\nThis systematic approach should help you identify and fix the most common setup issues!",
    "tags": [
      "debugging",
      "compilation-errors",
      "project-setup",
      "sqlx",
      "module-system",
      "troubleshooting",
      "dependency-management"
    ],
    "instruction": "This is really helpful! I'm following your setup but I'm getting some weird compilation errors. When I try to run `cargo check`, I get errors about missing modules and some trait bound issues. Also, SQLx is complaining about not being able to verify queries at compile time. How do I debug these kinds of setup issues?"
  },
  {
    "output": "Great question! Code review is crucial for learning good Rust practices. This code has several issues that are common in beginner Rust code. Let me walk through the problems and show you how to fix them.\n\n## Issues Identified\n\n1. **Excessive use of `unwrap()` - will panic on errors**\n2. **Poor error handling - no graceful error recovery**\n3. **Inefficient string usage - unnecessary allocations**\n4. **Missing input validation - will crash on malformed data**\n5. **No error types defined - hard to handle specific errors**\n6. **Unsafe assumptions about data format**\n7. **Missing documentation**\n\n## Improved Version with Detailed Explanations\n\n```rust\nuse std::collections::HashMap;\nuse std::fs::File;\nuse std::io::{BufRead, BufReader, Write};\nuse std::path::Path;\nuse thiserror::Error;\n\n// Define proper error types instead of panicking\n#[derive(Error, Debug)]\npub enum UserManagerError {\n    #[error(\"File I/O error: {0}\")]\n    Io(#[from] std::io::Error),\n    \n    #[error(\"User '{0}' not found\")]\n    UserNotFound(String),\n    \n    #[error(\"Invalid data format in line: '{0}'\")]\n    InvalidFormat(String),\n    \n    #[error(\"Invalid email format: '{0}'\")]\n    InvalidEmail(String),\n}\n\npub type Result<T> = std::result::Result<T, UserManagerError>;\n\n// Better data model with validation\n#[derive(Debug, Clone, PartialEq)]\npub struct User {\n    pub name: String,\n    pub email: String,\n}\n\nimpl User {\n    pub fn new(name: String, email: String) -> Result<Self> {\n        // Basic email validation\n        if !email.contains('@') || !email.contains('.') {\n            return Err(UserManagerError::InvalidEmail(email));\n        }\n        \n        if name.is_empty() {\n            return Err(UserManagerError::InvalidFormat(\"Name cannot be empty\".to_string()));\n        }\n        \n        Ok(User { name, email })\n    }\n    \n    // Parse from CSV line with proper error handling\n    pub fn from_csv_line(line: &str) -> Result<Self> {\n        let parts: Vec<&str> = line.split(',').collect();\n        \n        if parts.len() != 2 {\n            return Err(UserManagerError::InvalidFormat(line.to_string()));\n        }\n        \n        // Trim whitespace and validate\n        let name = parts[0].trim();\n        let email = parts[1].trim();\n        \n        if name.is_empty() || email.is_empty() {\n            return Err(UserManagerError::InvalidFormat(line.to_string()));\n        }\n        \n        Self::new(name.to_string(), email.to_string())\n    }\n    \n    // Convert to CSV format\n    pub fn to_csv_line(&self) -> String {\n        format!(\"{},{}\", self.name, self.email)\n    }\n}\n\n/// Manages a collection of users with file persistence\n/// \n/// # Examples\n/// \n/// ```\n/// use your_crate::UserManager;\n/// \n/// let mut manager = UserManager::new(\"users.txt\");\n/// manager.load_users().expect(\"Failed to load users\");\n/// manager.add_user(\"John\", \"john@example.com\").expect(\"Failed to add user\");\n/// ```\npub struct UserManager {\n    users: HashMap<String, User>,\n    file_path: String,\n}\n\nimpl UserManager {\n    /// Creates a new UserManager with the specified file path\n    pub fn new<P: AsRef<Path>>(path: P) -> Self {\n        Self {\n            users: HashMap::new(),\n            file_path: path.as_ref().to_string_lossy().to_string(),\n        }\n    }\n    \n    /// Loads users from the file, with proper error handling\n    pub fn load_users(&mut self) -> Result<usize> {\n        // Check if file exists first\n        if !Path::new(&self.file_path).exists() {\n            // File doesn't exist yet, that's ok for a new manager\n            return Ok(0);\n        }\n        \n        let file = File::open(&self.file_path)?;\n        let reader = BufReader::new(file);\n        let mut loaded_count = 0;\n        \n        // Process line by line for better memory usage\n        for (line_number, line_result) in reader.lines().enumerate() {\n            let line = line_result?;\n            \n            // Skip empty lines\n            if line.trim().is_empty() {\n                continue;\n            }\n            \n            match User::from_csv_line(&line) {\n                Ok(user) => {\n                    self.users.insert(user.name.clone(), user);\n                    loaded_count += 1;\n                }\n                Err(e) => {\n                    eprintln!(\"Warning: Skipping invalid line {}: {} (error: {})\", \n                             line_number + 1, line, e);\n                    // Continue processing other lines instead of failing completely\n                }\n            }\n        }\n        \n        Ok(loaded_count)\n    }\n    \n    /// Adds a new user with validation\n    pub fn add_user(&mut self, name: &str, email: &str) -> Result<()> {\n        let user = User::new(name.to_string(), email.to_string())?;\n        self.users.insert(user.name.clone(), user);\n        Ok(())\n    }\n    \n    /// Gets a user by name, returning a reference to avoid cloning\n    pub fn get_user(&self, name: &str) -> Result<&User> {\n        self.users\n            .get(name)\n            .ok_or_else(|| UserManagerError::UserNotFound(name.to_string()))\n    }\n    \n    /// Gets a mutable reference to a user\n    pub fn get_user_mut(&mut self, name: &str) -> Result<&mut User> {\n        self.users\n            .get_mut(name)\n            .ok_or_else(|| UserManagerError::UserNotFound(name.to_string()))\n    }\n    \n    /// Removes a user and returns it\n    pub fn remove_user(&mut self, name: &str) -> Result<User> {\n        self.users\n            .remove(name)\n            .ok_or_else(|| UserManagerError::UserNotFound(name.to_string()))\n    }\n    \n    /// Lists all users\n    pub fn list_users(&self) -> Vec<&User> {\n        self.users.values().collect()\n    }\n    \n    /// Returns the number of users\n    pub fn user_count(&self) -> usize {\n        self.users.len()\n    }\n    \n    /// Saves users to file with atomic write (safer)\n    pub fn save_users(&self) -> Result<()> {\n        // Use a temporary file for atomic writes\n        let temp_path = format!(\"{}.tmp\", self.file_path);\n        \n        {\n            let mut file = File::create(&temp_path)?;\n            \n            // Sort users by name for consistent output\n            let mut users: Vec<_> = self.users.values().collect();\n            users.sort_by(|a, b| a.name.cmp(&b.name));\n            \n            for user in users {\n                writeln!(file, \"{}\", user.to_csv_line())?;\n            }\n            \n            // Ensure data is written to disk\n            file.sync_all()?;\n        }\n        \n        // Atomically replace the original file\n        std::fs::rename(temp_path, &self.file_path)?;\n        \n        Ok(())\n    }\n    \n    /// Updates an existing user's email\n    pub fn update_user_email(&mut self, name: &str, new_email: &str) -> Result<()> {\n        // Validate email format first\n        if !new_email.contains('@') || !new_email.contains('.') {\n            return Err(UserManagerError::InvalidEmail(new_email.to_string()));\n        }\n        \n        let user = self.get_user_mut(name)?;\n        user.email = new_email.to_string();\n        Ok(())\n    }\n}\n\n// Implement Drop to auto-save on destruction (optional)\nimpl Drop for UserManager {\n    fn drop(&mut self) {\n        if let Err(e) = self.save_users() {\n            eprintln!(\"Warning: Failed to auto-save users on drop: {}\", e);\n        }\n    }\n}\n\nfn main() -> Result<()> {\n    let mut manager = UserManager::new(\"users.txt\");\n    \n    // Load existing users (won't panic if file doesn't exist)\n    match manager.load_users() {\n        Ok(count) => println!(\"Loaded {} users\", count),\n        Err(e) => {\n            eprintln!(\"Warning: Could not load users: {}\", e);\n            println!(\"Starting with empty user list\");\n        }\n    }\n    \n    // Add users with proper error handling\n    match manager.add_user(\"John\", \"john@example.com\") {\n        Ok(()) => println!(\"Added John successfully\"),\n        Err(e) => eprintln!(\"Failed to add John: {}\", e),\n    }\n    \n    // Try to add invalid user\n    match manager.add_user(\"Jane\", \"invalid-email\") {\n        Ok(()) => println!(\"Added Jane successfully\"),\n        Err(e) => eprintln!(\"Failed to add Jane: {}\", e),\n    }\n    \n    // Get user safely\n    match manager.get_user(\"John\") {\n        Ok(user) => println!(\"John's email: {}\", user.email),\n        Err(e) => eprintln!(\"Could not find John: {}\", e),\n    }\n    \n    // List all users\n    println!(\"All users:\");\n    for user in manager.list_users() {\n        println!(\"  {} - {}\", user.name, user.email);\n    }\n    \n    // Save users\n    match manager.save_users() {\n        Ok(()) => println!(\"Users saved successfully\"),\n        Err(e) => eprintln!(\"Failed to save users: {}\", e),\n    }\n    \n    Ok(())\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::fs;\n    \n    #[test]\n    fn test_user_creation() {\n        let user = User::new(\"John\".to_string(), \"john@example.com\".to_string()).unwrap();\n        assert_eq!(user.name, \"John\");\n        assert_eq!(user.email, \"john@example.com\");\n    }\n    \n    #[test]\n    fn test_invalid_email() {\n        let result = User::new(\"John\".to_string(), \"invalid\".to_string());\n        assert!(result.is_err());\n    }\n    \n    #[test]\n    fn test_csv_parsing() {\n        let user = User::from_csv_line(\"John,john@example.com\").unwrap();\n        assert_eq!(user.name, \"John\");\n        assert_eq!(user.email, \"john@example.com\");\n    }\n    \n    #[test]\n    fn test_manager_operations() {\n        let mut manager = UserManager::new(\":memory:\"); // Use fake path for testing\n        \n        assert_eq!(manager.user_count(), 0);\n        \n        manager.add_user(\"John\", \"john@example.com\").unwrap();\n        assert_eq!(manager.user_count(), 1);\n        \n        let user = manager.get_user(\"John\").unwrap();\n        assert_eq!(user.email, \"john@example.com\");\n        \n        let removed = manager.remove_user(\"John\").unwrap();\n        assert_eq!(removed.name, \"John\");\n        assert_eq!(manager.user_count(), 0);\n    }\n}\n```\n\n## Key Improvements Made\n\n1. **Proper Error Handling**: Uses `Result<T, E>` instead of `unwrap()`\n2. **Input Validation**: Validates email format and handles malformed data\n3. **Better Performance**: Uses `BufReader` and references instead of cloning\n4. **Atomic File Writes**: Prevents data corruption during saves\n5. **Comprehensive API**: More methods for common operations\n6. **Documentation**: Proper doc comments\n7. **Testing**: Unit tests for reliability\n8. **Type Safety**: Strong typing with proper error types\n\n## Additional Improvements You Could Make\n\n1. **Add serde support for JSON/TOML formats**\n2. **Use async I/O for better performance**\n3. **Add indexing for faster lookups**\n4. **Implement more sophisticated validation**\n5. **Add logging instead of println!/eprintln!**\n\nThis refactored version is much more robust and follows Rust best practices!",
    "tags": [
      "code-review",
      "error-handling",
      "refactoring",
      "best-practices",
      "file-io",
      "validation",
      "testing",
      "api-design"
    ],
    "instruction": "I found some Rust code online that I want to use, but it looks really messy and I'm not sure if it's good quality. Can you help me review this code and suggest improvements?\n\n```rust\nuse std::collections::HashMap;\nuse std::fs::File;\nuse std::io::Read;\n\nstruct UserManager {\n    users: HashMap<String, String>,\n    file_path: String,\n}\n\nimpl UserManager {\n    fn new(path: String) -> UserManager {\n        UserManager {\n            users: HashMap::new(),\n            file_path: path,\n        }\n    }\n    \n    fn load_users(&mut self) {\n        let mut file = File::open(&self.file_path).unwrap();\n        let mut contents = String::new();\n        file.read_to_string(&mut contents).unwrap();\n        \n        for line in contents.lines() {\n            let parts: Vec<&str> = line.split(',').collect();\n            self.users.insert(parts[0].to_string(), parts[1].to_string());\n        }\n    }\n    \n    fn add_user(&mut self, name: String, email: String) {\n        self.users.insert(name, email);\n    }\n    \n    fn get_user(&self, name: String) -> String {\n        self.users.get(&name).unwrap().clone()\n    }\n    \n    fn save_users(&self) {\n        use std::io::Write;\n        let mut file = File::create(&self.file_path).unwrap();\n        for (name, email) in &self.users {\n            writeln!(file, \"{},{}\", name, email).unwrap();\n        }\n    }\n}\n\nfn main() {\n    let mut manager = UserManager::new(\"users.txt\".to_string());\n    manager.load_users();\n    manager.add_user(\"John\".to_string(), \"john@example.com\".to_string());\n    println!(\"John's email: {}\", manager.get_user(\"John\".to_string()));\n    manager.save_users();\n}\n```"
  },
  {
    "output": "Great question! You've encountered several common runtime panic scenarios in Rust. Let me walk through each issue and show you how to identify and fix them systematically.\n\n## Issue 1: Index Out of Bounds\n\nIn your `process_data` function:\n\n```rust\n// PROBLEM: This will panic on the last iteration\nfor i in 0..numbers.len() {\n    let current = numbers[i];     // OK\n    let next = numbers[i + 1];    // PANIC! When i = len-1, i+1 = len (out of bounds)\n    // ...\n}\n```\n\n**Why it happens:**\n- When `numbers.len() = 5`, `i` goes from 0 to 4\n- On the last iteration (`i = 4`), you try to access `numbers[5]` which doesn't exist\n\n**Debugging technique:**\n```rust\n// Add debug prints to see what's happening\nfor i in 0..numbers.len() {\n    println!(\"i = {}, len = {}, accessing index {}\", i, numbers.len(), i + 1);\n    let current = numbers[i];\n    let next = numbers[i + 1];  // This will show you exactly where it fails\n    // ...\n}\n```\n\n## Issue 2: Integer Overflow (Debug Mode)\n\nThe \"attempt to subtract with overflow\" happens here:\n\n```rust\nlet diff = current - next;  // If next > current and you're using unsigned types\n```\n\n**In debug mode**, Rust panics on integer overflow. **In release mode**, it wraps around silently.\n\n## Issue 3: Division by Zero\n\nIn `calculate_average`:\n\n```rust\nsum / data.len() as u32  // PANIC if data.len() == 0\n```\n\n## Issue 4: Empty Collection Access\n\nIn `find_min_index` with an empty vector:\n\n```rust\nfor i in 1..arr.len() {  // If arr.len() == 0, this range is 1..0 (empty)\n    // Never executes\n}\nmin_idx  // Returns 0, but arr[0] doesn't exist!\n```\n\n## Fixed Version with Proper Error Handling\n\n```rust\nuse std::error::Error;\nuse std::fmt;\n\n// Define custom error types for better error handling\n#[derive(Debug)]\nenum ProcessingError {\n    EmptyInput,\n    InsufficientData,\n    Overflow,\n}\n\nimpl fmt::Display for ProcessingError {\n    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {\n        match self {\n            ProcessingError::EmptyInput => write!(f, \"Input data is empty\"),\n            ProcessingError::InsufficientData => write!(f, \"Not enough data to process\"),\n            ProcessingError::Overflow => write!(f, \"Arithmetic overflow occurred\"),\n        }\n    }\n}\n\nimpl Error for ProcessingError {}\n\ntype Result<T> = std::result::Result<T, ProcessingError>;\n\n// Fixed version of process_data\nfn process_data(numbers: Vec<i32>) -> Result<Vec<i32>> {\n    if numbers.is_empty() {\n        return Err(ProcessingError::EmptyInput);\n    }\n    \n    if numbers.len() < 2 {\n        return Err(ProcessingError::InsufficientData);\n    }\n    \n    let mut result = Vec::new();\n    \n    // Process pairs: stop before the last element\n    for i in 0..(numbers.len() - 1) {  // Fixed: subtract 1 from length\n        let current = numbers[i];\n        let next = numbers[i + 1];\n        \n        // Handle potential overflow safely\n        let diff = match current.checked_sub(next) {\n            Some(d) => d,\n            None => return Err(ProcessingError::Overflow),\n        };\n        \n        result.push(diff.abs());\n    }\n    \n    Ok(result)\n}\n\n// Alternative: using iterators (more idiomatic)\nfn process_data_iterative(numbers: Vec<i32>) -> Result<Vec<i32>> {\n    if numbers.len() < 2 {\n        return Err(ProcessingError::InsufficientData);\n    }\n    \n    let result: Result<Vec<i32>> = numbers\n        .windows(2)  // Creates overlapping pairs: [a,b], [b,c], [c,d], ...\n        .map(|pair| {\n            let current = pair[0];\n            let next = pair[1];\n            \n            current.checked_sub(next)\n                .map(|diff| diff.abs())\n                .ok_or(ProcessingError::Overflow)\n        })\n        .collect();\n    \n    result\n}\n\n// Fixed calculate_average with proper error handling\nfn calculate_average(data: &[u32]) -> Result<u32> {\n    if data.is_empty() {\n        return Err(ProcessingError::EmptyInput);\n    }\n    \n    let sum: u64 = data.iter().map(|&x| x as u64).sum();  // Use u64 to prevent overflow\n    Ok((sum / data.len() as u64) as u32)\n}\n\n// Alternative: return Option for simpler error handling\nfn calculate_average_option(data: &[u32]) -> Option<u32> {\n    if data.is_empty() {\n        return None;\n    }\n    \n    let sum: u64 = data.iter().map(|&x| x as u64).sum();\n    Some((sum / data.len() as u64) as u32)\n}\n\n// Fixed find_min_index\nfn find_min_index(arr: &[i32]) -> Option<usize> {\n    if arr.is_empty() {\n        return None;\n    }\n    \n    let mut min_idx = 0;\n    for i in 1..arr.len() {\n        if arr[i] < arr[min_idx] {\n            min_idx = i;\n        }\n    }\n    Some(min_idx)\n}\n\n// Alternative: using iterator methods\nfn find_min_index_iterative(arr: &[i32]) -> Option<usize> {\n    arr.iter()\n        .enumerate()\n        .min_by_key(|(_, &value)| value)\n        .map(|(index, _)| index)\n}\n\n// Defensive programming: add bounds checking helpers\nfn safe_index<T>(slice: &[T], index: usize) -> Option<&T> {\n    slice.get(index)\n}\n\nfn safe_subtract(a: i32, b: i32) -> Option<i32> {\n    a.checked_sub(b)\n}\n\n// Example of adding runtime checks and logging\nfn process_data_with_logging(numbers: Vec<i32>) -> Result<Vec<i32>> {\n    println!(\"Processing {} numbers\", numbers.len());\n    \n    if numbers.is_empty() {\n        println!(\"Error: Empty input\");\n        return Err(ProcessingError::EmptyInput);\n    }\n    \n    if numbers.len() < 2 {\n        println!(\"Error: Need at least 2 numbers, got {}\", numbers.len());\n        return Err(ProcessingError::InsufficientData);\n    }\n    \n    let mut result = Vec::with_capacity(numbers.len() - 1);\n    \n    for i in 0..(numbers.len() - 1) {\n        let current = numbers[i];\n        let next = numbers[i + 1];\n        \n        println!(\"Step {}: {} - {} = ?\", i, current, next);\n        \n        match current.checked_sub(next) {\n            Some(diff) => {\n                let abs_diff = diff.abs();\n                println!(\"  Result: {}\", abs_diff);\n                result.push(abs_diff);\n            }\n            None => {\n                println!(\"  Error: Overflow in subtraction\");\n                return Err(ProcessingError::Overflow);\n            }\n        }\n    }\n    \n    Ok(result)\n}\n\nfn main() {\n    // Test with various inputs to find edge cases\n    \n    println!(\"=== Test 1: Normal case ===\");\n    let data = vec![10, 5, 8, 3, 12];\n    match process_data(data) {\n        Ok(result) => println!(\"Differences: {:?}\", result),\n        Err(e) => println!(\"Error: {}\", e),\n    }\n    \n    println!(\"\\n=== Test 2: Empty vector ===\");\n    let empty_data: Vec<i32> = vec![];\n    match process_data(empty_data) {\n        Ok(result) => println!(\"Differences: {:?}\", result),\n        Err(e) => println!(\"Error: {}\", e),\n    }\n    \n    println!(\"\\n=== Test 3: Single element ===\");\n    let single_data = vec![42];\n    match process_data(single_data) {\n        Ok(result) => println!(\"Differences: {:?}\", result),\n        Err(e) => println!(\"Error: {}\", e),\n    }\n    \n    println!(\"\\n=== Test 4: Average calculation ===\");\n    let averages = vec![100, 200, 300];\n    match calculate_average(&averages) {\n        Ok(avg) => println!(\"Average: {}\", avg),\n        Err(e) => println!(\"Error: {}\", e),\n    }\n    \n    let empty_averages: Vec<u32> = vec![];\n    match calculate_average(&empty_averages) {\n        Ok(avg) => println!(\"Average: {}\", avg),\n        Err(e) => println!(\"Error: {}\", e),\n    }\n    \n    println!(\"\\n=== Test 5: Finding minimum ===\");\n    let numbers = vec![5, 2, 8, 1, 9];\n    match find_min_index(&numbers) {\n        Some(idx) => println!(\"Min index: {} (value: {})\", idx, numbers[idx]),\n        None => println!(\"No minimum found (empty array)\"),\n    }\n    \n    let empty_numbers: Vec<i32> = vec![];\n    match find_min_index(&empty_numbers) {\n        Some(idx) => println!(\"Min index: {}\", idx),\n        None => println!(\"No minimum found (empty array)\"),\n    }\n    \n    println!(\"\\n=== Test 6: With logging ===\");\n    let test_data = vec![1, 5, 3];\n    match process_data_with_logging(test_data) {\n        Ok(result) => println!(\"Final result: {:?}\", result),\n        Err(e) => println!(\"Failed: {}\", e),\n    }\n}\n\n// Additional debugging utilities\n#[cfg(debug_assertions)]\nmacro_rules! debug_bounds_check {\n    ($slice:expr, $index:expr) => {\n        if $index >= $slice.len() {\n            panic!(\n                \"Index {} is out of bounds for slice of length {} at {}:{}\",\n                $index,\n                $slice.len(),\n                file!(),\n                line!()\n            );\n        }\n    };\n}\n\n#[cfg(not(debug_assertions))]\nmacro_rules! debug_bounds_check {\n    ($slice:expr, $index:expr) => {};\n}\n\n// Example usage of the debugging macro\nfn safe_access_with_debug(arr: &[i32], index: usize) -> Option<i32> {\n    debug_bounds_check!(arr, index);\n    arr.get(index).copied()\n}\n```\n\n## Key Debugging Strategies\n\n1. **Add bounds checking**: Always verify array/slice access\n2. **Handle edge cases**: Empty collections, single elements, etc.\n3. **Use `checked_*` methods**: `checked_sub`, `checked_add`, etc.\n4. **Return `Result` or `Option`**: Don't panic, handle errors gracefully\n5. **Add logging/prints**: See exactly where failures occur\n6. **Test edge cases**: Empty inputs, single elements, extreme values\n7. **Use iterator methods**: Often safer than manual indexing\n\n## Common Runtime Error Patterns to Watch For\n\n- **Off-by-one errors**: `array[i + 1]` in loops\n- **Empty collection access**: Always check `is_empty()` first\n- **Integer overflow**: Use checked arithmetic in debug builds\n- **Division by zero**: Check denominators\n- **Unwrap on None/Err**: Use pattern matching instead\n\nThe key is to think defensively and handle all possible failure cases explicitly rather than assuming inputs will always be valid!",
    "tags": [
      "debugging",
      "runtime-errors",
      "panics",
      "bounds-checking",
      "error-handling",
      "overflow",
      "edge-cases",
      "defensive-programming"
    ],
    "instruction": "Help! My Rust program compiles fine but crashes at runtime with a panic. I'm getting \"index out of bounds\" errors and \"attempt to subtract with overflow\" errors. I can't figure out what's wrong. Here's the problematic code:\n\n```rust\nfn process_data(numbers: Vec<i32>) -> Vec<i32> {\n    let mut result = Vec::new();\n    \n    for i in 0..numbers.len() {\n        let current = numbers[i];\n        let next = numbers[i + 1];\n        let diff = current - next;\n        result.push(diff.abs());\n    }\n    \n    result\n}\n\nfn calculate_average(data: &[u32]) -> u32 {\n    let sum: u32 = data.iter().sum();\n    sum / data.len() as u32\n}\n\nfn find_min_index(arr: &[i32]) -> usize {\n    let mut min_idx = 0;\n    for i in 1..arr.len() {\n        if arr[i] < arr[min_idx] {\n            min_idx = i;\n        }\n    }\n    min_idx\n}\n\nfn main() {\n    let data = vec![10, 5, 8, 3, 12];\n    let result = process_data(data);\n    println!(\"Differences: {:?}\", result);\n    \n    let averages = vec![100, 200, 300];\n    println!(\"Average: {}\", calculate_average(&averages));\n    \n    let empty_vec: Vec<i32> = vec![];\n    println!(\"Min index: {}\", find_min_index(&empty_vec));\n}\n```\n\nIt sometimes works but sometimes crashes. What's going wrong?"
  },
  {
    "output": "Absolutely! Dependency management in Rust can be confusing coming from npm or pip. Let me walk you through everything you need to know about Cargo and crate management.\n\n## Understanding Cargo.toml vs Other Package Managers\n\n**Python (pip)**: Dependencies in `requirements.txt` or `pyproject.toml`\n**JavaScript (npm)**: Dependencies in `package.json`\n**Rust (cargo)**: Dependencies in `Cargo.toml`\n\nThe key difference: Rust is much stricter about versioning and compatibility.\n\n## Basic Cargo.toml Structure\n\n```toml\n# Cargo.toml\n[package]\nname = \"my-project\"           # Your project name\nversion = \"0.1.0\"            # Your project version (semantic versioning)\nedition = \"2021\"             # Rust edition (like language version)\nauthors = [\"Your Name <email@example.com>\"]\nlicense = \"MIT\"              # Optional: license\ndescription = \"A short description\"  # Optional: for publishing\nrepository = \"https://github.com/user/repo\"  # Optional\n\n# Regular dependencies (like npm dependencies)\n[dependencies]\nserde = \"1.0\"                # Latest 1.x version\ntokio = { version = \"1.0\", features = [\"full\"] }\nclap = { version = \"4.0\", features = [\"derive\"] }\n\n# Development dependencies (like npm devDependencies)\n[dev-dependencies]\ntokio-test = \"0.4\"\n\n# Build dependencies (used during compilation)\n[build-dependencies]\ncc = \"1.0\"\n\n# Target-specific dependencies\n[target.'cfg(windows)'.dependencies]\nwinapi = \"0.3\"\n\n[target.'cfg(unix)'.dependencies]\nlibc = \"0.2\"\n```\n\n## Adding Dependencies: Multiple Ways\n\n### Method 1: `cargo add` (Recommended for newer Cargo versions)\n\n```bash\n# Add latest compatible version\ncargo add serde\n\n# Add with specific features\ncargo add tokio --features full\n\n# Add development dependency\ncargo add --dev serde_test\n\n# Add with version constraint\ncargo add serde --version \"1.0.150\"\n\n# Add from git repository\ncargo add my-crate --git https://github.com/user/my-crate\n\n# Add local dependency\ncargo add my-local-crate --path ../my-local-crate\n```\n\n### Method 2: Manual Cargo.toml editing\n\n```toml\n[dependencies]\n# Exact version\nserde = \"=1.0.150\"\n\n# Compatible version (most common)\nserde = \"1.0\"        # Means >=1.0.0, <2.0.0\nserde = \"1.0.150\"    # Means >=1.0.150, <1.1.0\nserde = \"^1.0.150\"   # Same as above (explicit)\n\n# Tilde requirements (patch-level changes)\nserde = \"~1.0.150\"   # Means >=1.0.150, <1.1.0\n\n# Wildcard\nserde = \"1.*\"        # Means >=1.0.0, <2.0.0\n\n# Range\nserde = \">=1.0, <2.0\"\n\n# With features\nserde = { version = \"1.0\", features = [\"derive\", \"rc\"] }\n\n# Optional dependency (can be enabled with features)\nserde = { version = \"1.0\", optional = true }\n\n# Git dependency\nmy-crate = { git = \"https://github.com/user/my-crate\" }\nmy-crate = { git = \"https://github.com/user/my-crate\", branch = \"main\" }\nmy-crate = { git = \"https://github.com/user/my-crate\", tag = \"v1.0.0\" }\nmy-crate = { git = \"https://github.com/user/my-crate\", rev = \"abc123\" }\n\n# Local path dependency\nmy-local = { path = \"../my-local-crate\" }\n```\n\n## Understanding Version Requirements (SemVer)\n\nRust uses semantic versioning (MAJOR.MINOR.PATCH):\n\n```toml\n# Version requirement examples\n\"1.0\"      # >=1.0.0, <2.0.0 (allows minor updates)\n\"1.0.0\"    # >=1.0.0, <1.1.0 (allows patch updates only)\n\"=1.0.0\"   # Exactly 1.0.0 (no updates)\n\"^1.0.0\"   # >=1.0.0, <2.0.0 (default behavior)\n\"~1.0.0\"   # >=1.0.0, <1.1.0 (patch updates only)\n\"1.0.*\"    # >=1.0.0, <1.1.0 (patch updates only)\n\n# Multiple constraints\n\">=1.2, <1.5\"  # Between 1.2 and 1.5\n```\n\n## Working with Features\n\nMany crates have optional features to reduce compile time and binary size:\n\n```toml\n[dependencies]\n# Common crates with features\nserde = { version = \"1.0\", features = [\"derive\"] }\ntokio = { version = \"1.0\", features = [\"macros\", \"rt-multi-thread\", \"net\"] }\nclap = { version = \"4.0\", features = [\"derive\", \"env\"] }\nreqwest = { version = \"0.11\", features = [\"json\", \"rustls-tls\"] }\nsqlx = { version = \"0.7\", features = [\"runtime-tokio-rustls\", \"postgres\"] }\n\n# You can also disable default features\nserde = { version = \"1.0\", default-features = false, features = [\"derive\"] }\n```\n\n## Dealing with Version Conflicts\n\n### Problem: Conflicting Versions\n\n```bash\n# This error means two crates need different versions of the same dependency\nerror: failed to select a version for `serde`.\n    required by package `my-crate v0.1.0`\n    versions that meet the requirements `^1.0.100` are: 1.0.200\n    \n    the package `other-crate` depends on `serde`, with features: `derive` but `serde` does not have these features.\n```\n\n### Solutions:\n\n1. **Check compatibility:**\n```bash\n# See what's actually being used\ncargo tree\n\n# See duplicated dependencies\ncargo tree --duplicates\n\n# Check specific dependency\ncargo tree --package serde\n```\n\n2. **Update dependencies:**\n```bash\n# Update all dependencies within semver constraints\ncargo update\n\n# Update specific dependency\ncargo update serde\n\n# Update to latest (ignoring Cargo.lock)\nrm Cargo.lock && cargo build\n```\n\n3. **Use compatible versions:**\n```toml\n[dependencies]\n# If one crate needs serde 1.0.150+ and another needs 1.0.100+\n# Specify a version that satisfies both\nserde = \"1.0.150\"\n```\n\n## Common Dependency Patterns\n\n### Web Development Stack\n```toml\n[dependencies]\n# Web framework\naxum = \"0.7\"\n# or actix-web = \"4.0\"\n# or warp = \"0.3\"\n\n# Async runtime\ntokio = { version = \"1.0\", features = [\"full\"] }\n\n# Serialization\nserde = { version = \"1.0\", features = [\"derive\"] }\nserde_json = \"1.0\"\n\n# Database\nsqlx = { version = \"0.7\", features = [\"postgres\", \"runtime-tokio-rustls\"] }\n# or diesel = { version = \"2.0\", features = [\"postgres\"] }\n\n# HTTP client\nreqwest = { version = \"0.11\", features = [\"json\"] }\n\n# Error handling\nanyhow = \"1.0\"\nthiserror = \"1.0\"\n\n# Logging\ntracing = \"0.1\"\ntracing-subscriber = \"0.3\"\n\n# Configuration\nconfig = \"0.14\"\ndotenvy = \"0.15\"  # .env file support\n\n# UUID generation\nuuid = { version = \"1.0\", features = [\"v4\", \"serde\"] }\n```\n\n### CLI Application Stack\n```toml\n[dependencies]\n# Command line parsing\nclap = { version = \"4.0\", features = [\"derive\"] }\n\n# Error handling\nanyhow = \"1.0\"\n\n# File I/O and paths\ndirs = \"5.0\"  # User directories\nwalkdir = \"2.0\"  # Directory traversal\n\n# Serialization\nserde = { version = \"1.0\", features = [\"derive\"] }\ntoml = \"0.8\"  # TOML parsing\n\n# Terminal UI (optional)\ncrossterm = \"0.27\"  # Cross-platform terminal manipulation\nratatui = \"0.24\"    # Terminal UI framework\n\n# Progress bars\nindicatif = \"0.17\"\n\n# Colored output\ncolored = \"2.0\"\n```\n\n## Troubleshooting Common Issues\n\n### Issue 1: \"cargo add\" not found\n\n```bash\n# Update Cargo (cargo add was added in 1.62)\nrustup update\n\n# Or manually edit Cargo.toml and run:\ncargo build\n```\n\n### Issue 2: Features not found\n\n```bash\n# Check what features are available\ncargo add --dry-run some-crate\n\n# Or check on crates.io\n# Visit: https://crates.io/crates/CRATE_NAME\n```\n\n### Issue 3: Build failures after adding dependencies\n\n```bash\n# Clean build cache\ncargo clean\n\n# Check for incompatible features\ncargo check --verbose\n\n# Update Rust itself\nrustup update\n```\n\n### Issue 4: Slow compilation\n\n```toml\n# Use fewer features\nserde = { version = \"1.0\", default-features = false, features = [\"derive\"] }\n\n# Use faster linker (add to ~/.cargo/config.toml)\n[target.x86_64-unknown-linux-gnu]\nlinker = \"clang\"\nrustflags = [\"-C\", \"link-arg=-fuse-ld=lld\"]\n```\n\n## Useful Cargo Commands\n\n```bash\n# Dependency management\ncargo add CRATE              # Add dependency\ncargo remove CRATE           # Remove dependency\ncargo update                 # Update dependencies\ncargo tree                   # Show dependency tree\ncargo tree --duplicates      # Show duplicate dependencies\n\n# Build and check\ncargo check                  # Fast syntax check\ncargo build                  # Build project\ncargo build --release        # Optimized build\ncargo run                    # Build and run\n\n# Information\ncargo search QUERY           # Search crates.io\ncargo info CRATE             # Show crate information (if you have cargo-info)\n\n# Maintenance\ncargo clean                  # Clean build artifacts\ncargo outdated               # Show outdated dependencies (requires cargo-outdated)\ncargo audit                  # Security audit (requires cargo-audit)\n```\n\n## Best Practices\n\n1. **Pin versions in applications, use ranges in libraries**\n2. **Use `Cargo.lock` in applications** (commit it to git)\n3. **Don't commit `Cargo.lock` for libraries**\n4. **Regularly update dependencies**: `cargo update`\n5. **Use minimal features**: Only enable what you need\n6. **Check security**: `cargo install cargo-audit && cargo audit`\n7. **Check for outdated deps**: `cargo install cargo-outdated && cargo outdated`\n\nThis should give you a solid foundation for managing dependencies in Rust!",
    "tags": [
      "dependencies",
      "cargo",
      "package-management",
      "versioning",
      "features",
      "troubleshooting",
      "best-practices",
      "workflow"
    ],
    "instruction": "I'm new to Rust and coming from Python/JavaScript. I keep running into weird dependency issues when trying to add crates to my project. Sometimes `cargo add` doesn't work, sometimes versions conflict, and I don't understand the Cargo.toml file. Can you walk me through dependency management step by step?"
  },
  {
    "output": "Excellent question! Deploying Rust applications properly requires understanding compilation targets, optimization settings, and deployment strategies. Let me walk you through the complete process.\n\n## Production Builds: Optimization and Configuration\n\n### Basic Production Build\n\n```bash\n# Basic release build (optimized)\ncargo build --release\n\n# The binary will be in target/release/your-app-name\n./target/release/your-app-name\n```\n\n### Advanced Build Configuration\n\nCreate a `.cargo/config.toml` file for build optimizations:\n\n```toml\n# .cargo/config.toml\n[target.x86_64-unknown-linux-gnu]\n# Use faster linker\nlinker = \"clang\"\nrustflags = [\"-C\", \"link-arg=-fuse-ld=lld\"]\n\n[build]\n# Number of parallel jobs (adjust for your machine)\njobs = 4\n\n# Target for this project\ntarget = \"x86_64-unknown-linux-gnu\"\n```\n\nOptimize your `Cargo.toml` for production:\n\n```toml\n# Cargo.toml\n[package]\nname = \"my-app\"\nversion = \"0.1.0\"\nedition = \"2021\"\n\n# Production optimizations\n[profile.release]\nopt-level = 3           # Maximum optimization\nlto = true              # Link Time Optimization\ncodegen-units = 1       # Better optimization (slower compile)\npanic = \"abort\"         # Smaller binary size\nstrip = true            # Remove debug symbols\n\n# Custom profile for even smaller binaries\n[profile.release-small]\ninherits = \"release\"\nopt-level = \"z\"         # Optimize for size\nlto = true\ncodegen-units = 1\npanic = \"abort\"\nstrip = true\noverflow-checks = false\n\n# Dependencies optimization\n[profile.release.package.\"*\"]\nopt-level = 3\n\n[dependencies]\n# Production dependencies\nserde = { version = \"1.0\", features = [\"derive\"], default-features = false }\ntokio = { version = \"1.0\", features = [\"rt-multi-thread\", \"net\"], default-features = false }\n```\n\n### Build with Custom Profile\n\n```bash\n# Use the custom small profile\ncargo build --profile release-small\n\n# Check binary size\nls -lh target/release-small/my-app\n```\n\n## Cross-Compilation for Different Targets\n\n### Setting Up Cross-Compilation\n\n```bash\n# Install target toolchains\nrustup target add x86_64-unknown-linux-gnu     # Linux x64\nrustup target add x86_64-unknown-linux-musl    # Linux x64 (static)\nrustup target add x86_64-pc-windows-gnu        # Windows x64\nrustup target add x86_64-apple-darwin          # macOS x64\nrustup target add aarch64-unknown-linux-gnu    # Linux ARM64\nrustup target add aarch64-apple-darwin         # macOS ARM64 (M1/M2)\n\n# List available targets\nrustup target list\n\n# List installed targets\nrustup target list --installed\n```\n\n### Cross-Compilation Commands\n\n```bash\n# Compile for different targets\ncargo build --release --target x86_64-unknown-linux-gnu\ncargo build --release --target x86_64-unknown-linux-musl  # Static binary\ncargo build --release --target x86_64-pc-windows-gnu\ncargo build --release --target aarch64-unknown-linux-gnu\n\n# Binaries will be in target/TARGET/release/\nls target/x86_64-unknown-linux-musl/release/\n```\n\n### Installing Cross-Compilation Tools\n\nFor complex cross-compilation, use the `cross` tool:\n\n```bash\n# Install cross (uses Docker for cross-compilation)\ncargo install cross\n\n# Use cross instead of cargo for cross-compilation\ncross build --release --target x86_64-unknown-linux-musl\ncross build --release --target aarch64-unknown-linux-gnu\ncross build --release --target x86_64-pc-windows-gnu\n```\n\n## Docker Deployment Strategies\n\n### Strategy 1: Multi-Stage Build (Recommended)\n\n```dockerfile\n# Dockerfile - Multi-stage build for smallest image\n# Build stage\nFROM rust:1.75-alpine AS builder\n\n# Install build dependencies\nRUN apk add --no-cache musl-dev\n\n# Create app directory\nWORKDIR /app\n\n# Copy manifests\nCOPY Cargo.toml Cargo.lock ./\n\n# Cache dependencies - create dummy main.rs\nRUN mkdir src && echo \"fn main() {}\" > src/main.rs\nRUN cargo build --release --target x86_64-unknown-linux-musl\nRUN rm src/main.rs\n\n# Copy source code\nCOPY src ./src\n\n# Build application\nRUN touch src/main.rs  # Trigger rebuild\nRUN cargo build --release --target x86_64-unknown-linux-musl\n\n# Runtime stage\nFROM alpine:latest AS runtime\n\n# Install runtime dependencies (if any)\nRUN apk add --no-cache ca-certificates\n\n# Create non-root user\nRUN addgroup -g 1000 appgroup && \\\n    adduser -D -s /bin/sh -u 1000 -G appgroup appuser\n\n# Copy binary from builder stage\nCOPY --from=builder /app/target/x86_64-unknown-linux-musl/release/my-app /usr/local/bin/my-app\n\n# Set permissions\nRUN chown appuser:appgroup /usr/local/bin/my-app\nRUN chmod +x /usr/local/bin/my-app\n\n# Switch to non-root user\nUSER appuser\n\n# Expose port (if it's a web app)\nEXPOSE 8080\n\n# Run the application\nCMD [\"my-app\"]\n```\n\n### Strategy 2: Distroless Image (Even Smaller)\n\n```dockerfile\n# Dockerfile with distroless\nFROM rust:1.75-alpine AS builder\n\nWORKDIR /app\nCOPY Cargo.toml Cargo.lock ./\n\n# Create dummy main and build dependencies\nRUN mkdir src && echo \"fn main() {}\" > src/main.rs\nRUN cargo build --release --target x86_64-unknown-linux-musl\nRRM rm src/main.rs\n\n# Build real application\nCOPY src ./src\nRUN touch src/main.rs\nRUN cargo build --release --target x86_64-unknown-linux-musl\n\n# Use distroless image (no shell, minimal attack surface)\nFROM gcr.io/distroless/static:nonroot\n\n# Copy binary\nCOPY --from=builder /app/target/x86_64-unknown-linux-musl/release/my-app /my-app\n\n# Expose port\nEXPOSE 8080\n\n# Run as non-root\nUSER nonroot:nonroot\n\nENTRYPOINT [\"/my-app\"]\n```\n\n### Strategy 3: Scratch Image (Smallest Possible)\n\n```dockerfile\n# Dockerfile with scratch (only for static binaries)\nFROM rust:1.75-alpine AS builder\n\nWORKDIR /app\nCOPY . .\n\n# Build static binary\nRUN cargo build --release --target x86_64-unknown-linux-musl\n\n# Use scratch (empty image)\nFROM scratch\n\n# Copy static binary\nCOPY --from=builder /app/target/x86_64-unknown-linux-musl/release/my-app /my-app\n\n# Copy CA certificates if needed for HTTPS\nCOPY --from=builder /etc/ssl/certs/ca-certificates.crt /etc/ssl/certs/\n\nEXPOSE 8080\nENTRYPOINT [\"/my-app\"]\n```\n\n## Build and Deploy Scripts\n\n### Build Script for Multiple Targets\n\n```bash\n#!/bin/bash\n# build.sh - Build for multiple targets\n\nset -e\n\nAPP_NAME=\"my-app\"\nVERSION=\"$(cargo metadata --no-deps --format-version 1 | jq -r '.packages[0].version')\"\n\necho \"Building $APP_NAME v$VERSION for multiple targets...\"\n\n# Clean previous builds\ncargo clean\n\n# Build for different targets\nTARGETS=(\n    \"x86_64-unknown-linux-gnu\"\n    \"x86_64-unknown-linux-musl\"\n    \"x86_64-pc-windows-gnu\"\n    \"aarch64-unknown-linux-gnu\"\n    \"x86_64-apple-darwin\"\n    \"aarch64-apple-darwin\"\n)\n\nmkdir -p dist\n\nfor target in \"${TARGETS[@]}\"; do\n    echo \"Building for $target...\"\n    \n    if command -v cross &> /dev/null; then\n        cross build --release --target \"$target\"\n    else\n        cargo build --release --target \"$target\"\n    fi\n    \n    # Copy binary to dist folder\n    if [[ \"$target\" == *\"windows\"* ]]; then\n        cp \"target/$target/release/$APP_NAME.exe\" \"dist/$APP_NAME-$VERSION-$target.exe\"\n    else\n        cp \"target/$target/release/$APP_NAME\" \"dist/$APP_NAME-$VERSION-$target\"\n    fi\n    \n    echo \"\u2713 Built $target\"\ndone\n\necho \"Build complete! Binaries in dist/\"\nls -lh dist/\n```\n\n### Docker Build and Push Script\n\n```bash\n#!/bin/bash\n# docker-deploy.sh\n\nset -e\n\nAPP_NAME=\"my-app\"\nREGISTRY=\"your-registry.com\"\nVERSION=\"$(cargo metadata --no-deps --format-version 1 | jq -r '.packages[0].version')\"\nGIT_HASH=\"$(git rev-parse --short HEAD)\"\n\necho \"Building Docker image for $APP_NAME v$VERSION ($GIT_HASH)\"\n\n# Build image\ndocker build -t \"$REGISTRY/$APP_NAME:$VERSION\" .\ndocker build -t \"$REGISTRY/$APP_NAME:latest\" .\ndocker build -t \"$REGISTRY/$APP_NAME:$GIT_HASH\" .\n\n# Show image size\necho \"Image size:\"\ndocker images | grep \"$REGISTRY/$APP_NAME\"\n\n# Test the image\necho \"Testing image...\"\ndocker run --rm \"$REGISTRY/$APP_NAME:$VERSION\" --version\n\n# Push to registry\necho \"Pushing to registry...\"\ndocker push \"$REGISTRY/$APP_NAME:$VERSION\"\ndocker push \"$REGISTRY/$APP_NAME:latest\"\ndocker push \"$REGISTRY/$APP_NAME:$GIT_HASH\"\n\necho \"Deploy complete!\"\n```\n\n## Environment-Specific Configuration\n\n### Configuration Management\n\n```rust\n// src/config.rs\nuse serde::Deserialize;\nuse std::env;\n\n#[derive(Debug, Deserialize, Clone)]\npub struct Config {\n    pub server_host: String,\n    pub server_port: u16,\n    pub database_url: String,\n    pub log_level: String,\n    pub environment: Environment,\n}\n\n#[derive(Debug, Deserialize, Clone, PartialEq)]\n#[serde(rename_all = \"lowercase\")]\npub enum Environment {\n    Development,\n    Staging,\n    Production,\n}\n\nimpl Config {\n    pub fn from_env() -> Result<Self, config::ConfigError> {\n        let env = env::var(\"ENVIRONMENT\").unwrap_or_else(|_| \"development\".to_string());\n        \n        let config = config::Config::builder()\n            // Default configuration\n            .set_default(\"server_host\", \"0.0.0.0\")?\n            .set_default(\"server_port\", 8080)?\n            .set_default(\"log_level\", \"info\")?\n            .set_default(\"environment\", &env)?\n            \n            // Environment-specific config files\n            .add_source(config::File::with_name(\"config/default\").required(false))\n            .add_source(config::File::with_name(&format!(\"config/{}\", env)).required(false))\n            \n            // Environment variables (override config files)\n            .add_source(config::Environment::with_prefix(\"APP\"))\n            \n            .build()?;\n        \n        config.try_deserialize()\n    }\n    \n    pub fn is_production(&self) -> bool {\n        self.environment == Environment::Production\n    }\n}\n```\n\n### Environment Files\n\n```yaml\n# config/default.yaml\nserver_host: \"127.0.0.1\"\nserver_port: 3000\nlog_level: \"debug\"\ndatabase_url: \"postgresql://localhost/myapp_dev\"\n```\n\n```yaml\n# config/production.yaml\nserver_host: \"0.0.0.0\"\nserver_port: 8080\nlog_level: \"warn\"\n# database_url will come from environment variable in production\n```\n\n## Deployment Checklist\n\n### Pre-Deployment\n\n```bash\n# 1. Run tests\ncargo test\n\n# 2. Check for security vulnerabilities\ncargo audit\n\n# 3. Check for outdated dependencies\ncargo outdated\n\n# 4. Lint code\ncargo clippy -- -D warnings\n\n# 5. Format code\ncargo fmt --check\n\n# 6. Build and test release binary\ncargo build --release\n./target/release/my-app --version\n\n# 7. Test Docker build\ndocker build -t my-app:test .\ndocker run --rm my-app:test --version\n```\n\n### CI/CD Integration (GitHub Actions)\n\n```yaml\n# .github/workflows/deploy.yml\nname: Deploy\n\non:\n  push:\n    tags: ['v*']\n\njobs:\n  build-and-deploy:\n    runs-on: ubuntu-latest\n    \n    steps:\n    - uses: actions/checkout@v4\n    \n    - name: Install Rust\n      uses: actions-rs/toolchain@v1\n      with:\n        toolchain: stable\n        override: true\n        components: rustfmt, clippy\n    \n    - name: Cache cargo\n      uses: actions/cache@v3\n      with:\n        path: ~/.cargo\n        key: ${{ runner.os }}-cargo-${{ hashFiles('**/Cargo.lock') }}\n    \n    - name: Run tests\n      run: cargo test\n    \n    - name: Lint\n      run: cargo clippy -- -D warnings\n    \n    - name: Security audit\n      run: |\n        cargo install cargo-audit\n        cargo audit\n    \n    - name: Build release\n      run: cargo build --release\n    \n    - name: Build and push Docker image\n      env:\n        REGISTRY: ghcr.io\n        IMAGE_NAME: ${{ github.repository }}\n      run: |\n        echo ${{ secrets.GITHUB_TOKEN }} | docker login $REGISTRY -u ${{ github.actor }} --password-stdin\n        docker build -t $REGISTRY/$IMAGE_NAME:${{ github.ref_name }} .\n        docker push $REGISTRY/$IMAGE_NAME:${{ github.ref_name }}\n```\n\nThis comprehensive approach will give you production-ready Rust deployments with proper optimization, cross-compilation support, and containerization!",
    "tags": [
      "deployment",
      "production-builds",
      "cross-compilation",
      "docker",
      "optimization",
      "ci-cd",
      "configuration",
      "build-scripts"
    ],
    "instruction": "I'm trying to deploy my Rust application but I'm running into issues with different compilation targets, optimizations, and packaging. How do I properly build and deploy Rust applications for production? What about cross-compilation and Docker?"
  },
  {
    "output": "Great question! Testing in Rust is indeed powerful and built into the language. Coming from Python, you'll find some similarities but also some unique Rust-specific patterns. Let me walk you through everything step by step.\n\n## Basic Unit Tests (Like Python's unittest)\n\n```rust\n// src/lib.rs or src/math.rs\npub fn add(a: i32, b: i32) -> i32 {\n    a + b\n}\n\npub fn divide(a: f64, b: f64) -> Result<f64, String> {\n    if b == 0.0 {\n        Err(\"Cannot divide by zero\".to_string())\n    } else {\n        Ok(a / b)\n    }\n}\n\n// Tests go in the same file with #[cfg(test)] module\n#[cfg(test)]\nmod tests {\n    use super::*;  // Import functions from parent module\n    \n    #[test]\n    fn test_add() {\n        assert_eq!(add(2, 3), 5);\n        assert_eq!(add(-1, 1), 0);\n        assert_eq!(add(0, 0), 0);\n    }\n    \n    #[test]\n    fn test_divide_success() {\n        let result = divide(10.0, 2.0).unwrap();\n        assert_eq!(result, 5.0);\n    }\n    \n    #[test]\n    fn test_divide_by_zero() {\n        let result = divide(10.0, 0.0);\n        assert!(result.is_err());\n        assert_eq!(result.unwrap_err(), \"Cannot divide by zero\");\n    }\n    \n    #[test]\n    #[should_panic]\n    fn test_panic_behavior() {\n        // Test that something should panic\n        panic!(\"This test expects a panic\");\n    }\n    \n    #[test]\n    #[should_panic(expected = \"specific message\")]\n    fn test_specific_panic() {\n        panic!(\"specific message here\");\n    }\n    \n    #[test]\n    #[ignore]  // Skip this test unless specifically requested\n    fn expensive_test() {\n        // This test takes a long time\n        assert_eq!(1, 1);\n    }\n}\n```\n\nRun tests with:\n```bash\n# Run all tests\ncargo test\n\n# Run specific test\ncargo test test_add\n\n# Run ignored tests too\ncargo test -- --ignored\n\n# Show println! output even for passing tests\ncargo test -- --nocapture\n```\n\n## Testing Structs and Methods\n\n```rust\n// src/user.rs\n#[derive(Debug, PartialEq)]\npub struct User {\n    pub name: String,\n    pub email: String,\n    pub age: u32,\n}\n\nimpl User {\n    pub fn new(name: String, email: String, age: u32) -> Result<Self, String> {\n        if name.is_empty() {\n            return Err(\"Name cannot be empty\".to_string());\n        }\n        \n        if !email.contains('@') {\n            return Err(\"Invalid email format\".to_string());\n        }\n        \n        if age > 150 {\n            return Err(\"Invalid age\".to_string());\n        }\n        \n        Ok(User { name, email, age })\n    }\n    \n    pub fn is_adult(&self) -> bool {\n        self.age >= 18\n    }\n    \n    pub fn update_email(&mut self, new_email: String) -> Result<(), String> {\n        if !new_email.contains('@') {\n            return Err(\"Invalid email format\".to_string());\n        }\n        self.email = new_email;\n        Ok(())\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    \n    #[test]\n    fn test_user_creation_valid() {\n        let user = User::new(\n            \"John Doe\".to_string(),\n            \"john@example.com\".to_string(),\n            25\n        ).unwrap();\n        \n        assert_eq!(user.name, \"John Doe\");\n        assert_eq!(user.email, \"john@example.com\");\n        assert_eq!(user.age, 25);\n    }\n    \n    #[test]\n    fn test_user_creation_invalid_email() {\n        let result = User::new(\n            \"John Doe\".to_string(),\n            \"invalid-email\".to_string(),\n            25\n        );\n        \n        assert!(result.is_err());\n        assert_eq!(result.unwrap_err(), \"Invalid email format\");\n    }\n    \n    #[test]\n    fn test_user_creation_empty_name() {\n        let result = User::new(\n            \"\".to_string(),\n            \"john@example.com\".to_string(),\n            25\n        );\n        \n        assert!(result.is_err());\n        assert_eq!(result.unwrap_err(), \"Name cannot be empty\");\n    }\n    \n    #[test]\n    fn test_is_adult() {\n        let adult = User::new(\"John\".to_string(), \"john@example.com\".to_string(), 25).unwrap();\n        let minor = User::new(\"Jane\".to_string(), \"jane@example.com\".to_string(), 16).unwrap();\n        \n        assert!(adult.is_adult());\n        assert!(!minor.is_adult());\n    }\n    \n    #[test]\n    fn test_update_email() {\n        let mut user = User::new(\"John\".to_string(), \"john@example.com\".to_string(), 25).unwrap();\n        \n        // Valid email update\n        let result = user.update_email(\"newemail@example.com\".to_string());\n        assert!(result.is_ok());\n        assert_eq!(user.email, \"newemail@example.com\");\n        \n        // Invalid email update\n        let result = user.update_email(\"invalid\".to_string());\n        assert!(result.is_err());\n        // Email should remain unchanged\n        assert_eq!(user.email, \"newemail@example.com\");\n    }\n    \n    // Test helper function\n    fn create_test_user() -> User {\n        User::new(\"Test User\".to_string(), \"test@example.com\".to_string(), 30).unwrap()\n    }\n    \n    #[test]\n    fn test_with_helper() {\n        let user = create_test_user();\n        assert_eq!(user.name, \"Test User\");\n    }\n}\n```\n\n## Testing Async Code\n\n```rust\n// Add to Cargo.toml:\n// [dev-dependencies]\n// tokio-test = \"0.4\"\n\nuse std::time::Duration;\nuse tokio::time::sleep;\n\npub async fn fetch_data(delay_ms: u64) -> Result<String, String> {\n    sleep(Duration::from_millis(delay_ms)).await;\n    \n    if delay_ms > 1000 {\n        Err(\"Timeout\".to_string())\n    } else {\n        Ok(\"Data fetched successfully\".to_string())\n    }\n}\n\npub async fn process_multiple_requests(delays: Vec<u64>) -> Vec<Result<String, String>> {\n    let mut results = Vec::new();\n    \n    for delay in delays {\n        results.push(fetch_data(delay).await);\n    }\n    \n    results\n}\n\n#[cfg(test)]\nmod async_tests {\n    use super::*;\n    use tokio_test;\n    \n    #[tokio::test]  // Use tokio::test instead of test for async functions\n    async fn test_fetch_data_success() {\n        let result = fetch_data(100).await;\n        assert!(result.is_ok());\n        assert_eq!(result.unwrap(), \"Data fetched successfully\");\n    }\n    \n    #[tokio::test]\n    async fn test_fetch_data_timeout() {\n        let result = fetch_data(2000).await;\n        assert!(result.is_err());\n        assert_eq!(result.unwrap_err(), \"Timeout\");\n    }\n    \n    #[tokio::test]\n    async fn test_multiple_requests() {\n        let delays = vec![100, 200, 1500];  // Last one should timeout\n        let results = process_multiple_requests(delays).await;\n        \n        assert_eq!(results.len(), 3);\n        assert!(results[0].is_ok());\n        assert!(results[1].is_ok());\n        assert!(results[2].is_err());\n    }\n    \n    #[tokio::test]\n    #[should_panic]\n    async fn test_async_panic() {\n        panic!(\"Async panic test\");\n    }\n}\n```\n\n## Integration Tests (Like Python's integration tests)\n\nCreate `tests/integration_test.rs` (separate from `src/`):\n\n```rust\n// tests/integration_test.rs\n// This tests your crate as an external user would\nuse my_crate::User;  // Replace my_crate with your actual crate name\n\n#[test]\nfn test_user_integration() {\n    let user = User::new(\n        \"Integration Test\".to_string(),\n        \"integration@example.com\".to_string(),\n        25\n    ).unwrap();\n    \n    assert!(user.is_adult());\n}\n\n#[test]\nfn test_full_user_workflow() {\n    // Test a complete workflow\n    let mut user = User::new(\n        \"Workflow Test\".to_string(),\n        \"workflow@example.com\".to_string(),\n        20\n    ).unwrap();\n    \n    assert!(user.is_adult());\n    \n    user.update_email(\"newemail@example.com\".to_string()).unwrap();\n    assert_eq!(user.email, \"newemail@example.com\");\n}\n```\n\n## Advanced Testing Patterns\n\n### Property-Based Testing (Like Python's Hypothesis)\n\n```toml\n# Add to Cargo.toml [dev-dependencies]\nproptest = \"1.0\"\n```\n\n```rust\nuse proptest::prelude::*;\n\n// Property-based test: any valid user should be creatable\nproptest! {\n    #[test]\n    fn test_user_creation_property(\n        name in \"[a-zA-Z ]{1,50}\",  // Non-empty string\n        email in \"[a-zA-Z0-9]+@[a-zA-Z0-9]+\\\\.[a-zA-Z]{2,}\",  // Valid email pattern\n        age in 1u32..150u32  // Valid age range\n    ) {\n        let user = User::new(name.clone(), email.clone(), age);\n        prop_assert!(user.is_ok());\n        \n        let user = user.unwrap();\n        prop_assert_eq!(user.name, name);\n        prop_assert_eq!(user.email, email);\n        prop_assert_eq!(user.age, age);\n    }\n}\n\n// Property: addition should be commutative\nproptest! {\n    #[test]\n    fn test_addition_commutative(a in -1000i32..1000i32, b in -1000i32..1000i32) {\n        prop_assert_eq!(add(a, b), add(b, a));\n    }\n}\n```\n\n### Mocking and Test Doubles\n\n```toml\n# Add to Cargo.toml [dev-dependencies]\nmockall = \"0.11\"\n```\n\n```rust\nuse mockall::predicate::*;\nuse mockall::mock;\n\n// Define a trait for what we want to mock\ntrait DataStore {\n    fn get_user(&self, id: u32) -> Result<User, String>;\n    fn save_user(&mut self, user: &User) -> Result<(), String>;\n}\n\n// Generate mock implementation\nmock! {\n    DataStore {}\n    \n    impl DataStore for DataStore {\n        fn get_user(&self, id: u32) -> Result<User, String>;\n        fn save_user(&mut self, user: &User) -> Result<(), String>;\n    }\n}\n\nstruct UserService<T: DataStore> {\n    store: T,\n}\n\nimpl<T: DataStore> UserService<T> {\n    fn new(store: T) -> Self {\n        Self { store }\n    }\n    \n    fn get_adult_user(&self, id: u32) -> Result<User, String> {\n        let user = self.store.get_user(id)?;\n        if user.is_adult() {\n            Ok(user)\n        } else {\n            Err(\"User is not an adult\".to_string())\n        }\n    }\n}\n\n#[cfg(test)]\nmod mock_tests {\n    use super::*;\n    \n    #[test]\n    fn test_get_adult_user_success() {\n        let mut mock_store = MockDataStore::new();\n        \n        // Set up mock expectations\n        mock_store\n            .expect_get_user()\n            .with(eq(1))\n            .times(1)\n            .returning(|_| {\n                Ok(User::new(\n                    \"Adult User\".to_string(),\n                    \"adult@example.com\".to_string(),\n                    25\n                ).unwrap())\n            });\n        \n        let service = UserService::new(mock_store);\n        let result = service.get_adult_user(1);\n        \n        assert!(result.is_ok());\n        assert_eq!(result.unwrap().age, 25);\n    }\n    \n    #[test]\n    fn test_get_adult_user_minor() {\n        let mut mock_store = MockDataStore::new();\n        \n        mock_store\n            .expect_get_user()\n            .with(eq(2))\n            .returning(|_| {\n                Ok(User::new(\n                    \"Minor User\".to_string(),\n                    \"minor@example.com\".to_string(),\n                    16\n                ).unwrap())\n            });\n        \n        let service = UserService::new(mock_store);\n        let result = service.get_adult_user(2);\n        \n        assert!(result.is_err());\n        assert_eq!(result.unwrap_err(), \"User is not an adult\");\n    }\n}\n```\n\n## Test Organization and Best Practices\n\n### Custom Test Assertions\n\n```rust\n// Custom assertion macros\nmacro_rules! assert_user_valid {\n    ($user:expr) => {\n        assert!(!$user.name.is_empty(), \"User name should not be empty\");\n        assert!($user.email.contains('@'), \"User email should contain @\");\n        assert!($user.age <= 150, \"User age should be reasonable\");\n    };\n}\n\n#[test]\nfn test_with_custom_assertion() {\n    let user = User::new(\"Test\".to_string(), \"test@example.com\".to_string(), 30).unwrap();\n    assert_user_valid!(user);\n}\n```\n\n### Test Configuration and Setup\n\n```rust\nstruct TestContext {\n    users: Vec<User>,\n    temp_dir: std::path::PathBuf,\n}\n\nimpl TestContext {\n    fn new() -> Self {\n        let temp_dir = std::env::temp_dir().join(format!(\"test_{}\", uuid::Uuid::new_v4()));\n        std::fs::create_dir_all(&temp_dir).unwrap();\n        \n        let users = vec![\n            User::new(\"Alice\".to_string(), \"alice@example.com\".to_string(), 25).unwrap(),\n            User::new(\"Bob\".to_string(), \"bob@example.com\".to_string(), 30).unwrap(),\n        ];\n        \n        Self { users, temp_dir }\n    }\n}\n\nimpl Drop for TestContext {\n    fn drop(&mut self) {\n        // Cleanup\n        let _ = std::fs::remove_dir_all(&self.temp_dir);\n    }\n}\n\n#[test]\nfn test_with_context() {\n    let ctx = TestContext::new();\n    assert_eq!(ctx.users.len(), 2);\n    assert!(ctx.temp_dir.exists());\n    // TestContext automatically cleans up when test ends\n}\n```\n\n## Running Tests Effectively\n\n```bash\n# Different ways to run tests\ncargo test                          # All tests\ncargo test user                     # Tests with \"user\" in name\ncargo test -- --test-threads=1      # Run tests sequentially\ncargo test -- --nocapture           # Show println! output\ncargo test --release                # Test optimized build\ncargo test --lib                    # Only unit tests\ncargo test --bins                   # Only binary tests\ncargo test --tests                  # Only integration tests\ncargo test --doc                    # Only doc tests\n\n# Useful flags\ncargo test -- --ignored             # Run ignored tests\ncargo test -- --show-output         # Show output from passing tests\ncargo test -- --quiet               # Minimal output\n```\n\nKey differences from Python testing:\n- Tests are built into the language/cargo\n- No separate test discovery - use `#[test]` attribute\n- Strong type system catches many errors at compile time\n- Excellent built-in assertion macros\n- Great integration with Rust's ownership system\n\nThis should give you a solid foundation for testing in Rust!",
    "tags": [
      "testing",
      "unit-tests",
      "integration-tests",
      "async-testing",
      "mocking",
      "property-testing",
      "test-organization",
      "best-practices"
    ],
    "instruction": "I'm new to Rust and coming from Python. Everyone says Rust is great for testing, but I'm overwhelmed by all the different testing approaches. Can you walk me through how to write good tests in Rust?"
  },
  {
    "output": "Great question! This is exactly what every developer wonders when first hearing about Rust. Let me explain what makes Rust special and why it's worth learning, especially coming from Python/JavaScript.\n\n## The Problem Rust Solves\n\nIn Python/JavaScript, you don't think about memory management - the garbage collector handles it. But this comes with costs:\n\n**Python/JavaScript approach:**\n```python\n# Python - you don't worry about memory\ndef process_data():\n    data = [1, 2, 3, 4, 5]  # Allocated automatically\n    result = [x * 2 for x in data]  # More allocation\n    return result  # Garbage collector cleans up eventually\n```\n\n**Problems with this approach:**\n- Unpredictable performance (garbage collection pauses)\n- Higher memory usage\n- Can't control when cleanup happens\n- Runtime errors possible (null pointer exceptions)\n\n**C/C++ approach:**\n```c\n// C - you manage memory manually\nint* process_data() {\n    int* data = malloc(5 * sizeof(int));  // Manual allocation\n    // ... do work ...\n    return data;  // Caller must remember to free()!\n}\n// Easy to forget free() -> memory leak\n// Easy to use after free() -> crash\n// Easy to free twice -> crash\n```\n\n**Rust's approach:**\n```rust\n// Rust - compiler enforces memory safety at compile time\nfn process_data() -> Vec<i32> {\n    let data = vec![1, 2, 3, 4, 5];  // Allocated on heap\n    let result: Vec<i32> = data.iter().map(|x| x * 2).collect();\n    result  // Memory automatically freed when data goes out of scope\n}  // No garbage collector needed, no manual free() needed\n```\n\n## What Makes Rust Special: Zero-Cost Memory Safety\n\n### Ownership: Who's Responsible for Cleanup?\n\n```rust\n// Think of ownership like owning a physical object\nfn main() {\n    let data = vec![1, 2, 3];  // I own this vector\n    \n    process_data(data);  // I give ownership to the function\n    \n    // println!(\"{:?}\", data);  // ERROR! I no longer own it\n}\n\nfn process_data(data: Vec<i32>) {  // Function now owns the data\n    println!(\"{:?}\", data);\n}  // Data is automatically freed here when owner goes away\n```\n\nCompare to Python:\n```python\ndef main():\n    data = [1, 2, 3]  # Reference to list\n    process_data(data)  # Pass reference\n    print(data)  # Still works - both variables point to same list\n\ndef process_data(data):\n    print(data)\n    # Garbage collector will clean up eventually\n```\n\n### Borrowing: Temporary Access Without Taking Ownership\n\n```rust\nfn main() {\n    let data = vec![1, 2, 3];\n    \n    // Borrow the data (like lending your book to a friend)\n    let length = get_length(&data);  // &data means \"borrow, don't take\"\n    \n    println!(\"Length: {}\", length);\n    println!(\"Original data: {:?}\", data);  // I still own it!\n}\n\nfn get_length(data: &Vec<i32>) -> usize {  // I'm borrowing, not owning\n    data.len()  // I can read it but not take it\n}  // Borrow ends here, ownership returns to main\n```\n\n### Mutable Borrowing: Controlled Mutation\n\n```rust\nfn main() {\n    let mut data = vec![1, 2, 3];\n    \n    // Borrow mutably (like letting friend edit your document)\n    double_values(&mut data);  // &mut means \"borrow with edit rights\"\n    \n    println!(\"Modified: {:?}\", data);  // [2, 4, 6]\n}\n\nfn double_values(data: &mut Vec<i32>) {\n    for value in data.iter_mut() {\n        *value *= 2;\n    }\n}\n```\n\n## Why This Matters: Real-World Benefits\n\n### 1. Performance Without Garbage Collection\n\n```rust\n// Rust: Predictable performance\nuse std::time::Instant;\n\nfn main() {\n    let start = Instant::now();\n    \n    for _ in 0..1_000_000 {\n        let data = vec![1, 2, 3, 4, 5];  // Allocated\n        process_data(data);  // Freed immediately when function ends\n    }\n    \n    println!(\"Time: {:?}\", start.elapsed());  // Consistent timing\n}\n```\n\nIn Python/JavaScript, this would have unpredictable pauses for garbage collection.\n\n### 2. Thread Safety Built-In\n\n```rust\nuse std::thread;\nuse std::sync::Arc;\n\nfn main() {\n    let data = Arc::new(vec![1, 2, 3, 4, 5]);  // Thread-safe reference counting\n    let mut handles = vec![];\n    \n    for i in 0..3 {\n        let data_clone = Arc::clone(&data);  // Clone the reference, not data\n        let handle = thread::spawn(move || {\n            println!(\"Thread {}: {:?}\", i, data_clone);\n        });\n        handles.push(handle);\n    }\n    \n    for handle in handles {\n        handle.join().unwrap();\n    }\n}\n```\n\nThe compiler guarantees no data races! In Python, you'd need locks and careful programming.\n\n### 3. Catch Bugs at Compile Time\n\n```rust\n// This won't compile - Rust catches the bug!\nfn buggy_code() {\n    let data = vec![1, 2, 3];\n    let first = &data[0];  // Borrow first element\n    \n    data.push(4);  // ERROR! Can't modify while borrowed\n    \n    println!(\"First: {}\", first);  // This could be dangerous in other languages\n}\n```\n\nRust compiler says: \"Error: cannot borrow `data` as mutable because it is also borrowed as immutable\"\n\nIn Python/JavaScript, this might work sometimes and crash other times.\n\n## Learning Path: What You Need to Know\n\n### Start Here: Basic Ownership\n\n```rust\n// 1. Every value has exactly one owner\nlet s1 = String::from(\"hello\");\nlet s2 = s1;  // s1 is no longer valid (moved to s2)\n// println!(\"{}\", s1);  // ERROR!\n\n// 2. When owner goes out of scope, value is dropped\n{\n    let s = String::from(\"hello\");  // s is valid from here\n}  // s goes out of scope and is dropped here\n\n// 3. Functions can take ownership\nfn takes_ownership(s: String) {  // s comes into scope\n    println!(\"{}\", s);\n}  // s goes out of scope and is dropped\n\n// 4. Or borrow references\nfn borrows_value(s: &String) {  // s is a reference\n    println!(\"{}\", s);\n}  // s goes out of scope, but doesn't drop the value (doesn't own it)\n```\n\n### Simple Rules to Remember\n\n1. **One owner at a time**: Only one variable can own data\n2. **Borrowing is temporary**: References (`&`) let you use data without owning it\n3. **Mutable XOR immutable**: Either many immutable references OR one mutable reference\n4. **Compiler is your friend**: It catches memory bugs before they happen\n\n## Why Learn Rust? The Practical Benefits\n\n### Coming from Python:\n- **Speed**: 10-100x faster execution\n- **Deployment**: Single binary, no runtime dependencies\n- **Memory usage**: Much lower memory footprint\n- **Reliability**: Catch bugs at compile time instead of production\n\n### Coming from JavaScript:\n- **Type safety**: No more `undefined is not a function`\n- **Performance**: No event loop blocking\n- **Concurrency**: True parallelism without callback hell\n- **Predictability**: No garbage collection pauses\n\n### Use Cases Where Rust Shines:\n- **Web backends**: Fast, safe APIs (like Express but faster and safer)\n- **CLI tools**: Fast startup, single binary distribution\n- **Systems programming**: Operating systems, embedded systems\n- **WebAssembly**: High-performance web applications\n- **Blockchain/crypto**: Security and performance critical\n- **Game engines**: Real-time performance requirements\n\n## Your First Rust Program\n\n```rust\n// main.rs - A simple web server\nuse std::io::prelude::*;\nuse std::net::{TcpListener, TcpStream};\n\nfn main() {\n    let listener = TcpListener::bind(\"127.0.0.1:7878\").unwrap();\n    println!(\"Server running on http://127.0.0.1:7878\");\n    \n    for stream in listener.incoming() {\n        let stream = stream.unwrap();\n        handle_connection(stream);\n    }\n}\n\nfn handle_connection(mut stream: TcpStream) {\n    let mut buffer = [0; 1024];\n    stream.read(&mut buffer).unwrap();\n    \n    let response = \"HTTP/1.1 200 OK\\r\\n\\r\\nHello from Rust!\";\n    stream.write(response.as_bytes()).unwrap();\n    stream.flush().unwrap();\n}\n```\n\nThis creates a working web server in ~20 lines with:\n- Memory safety (no buffer overflows)\n- Thread safety (can easily add threading)\n- Performance (minimal overhead)\n- Reliability (compiler-checked error handling)\n\n## The Bottom Line\n\nRust gives you:\n- **Python's ease of use** (high-level abstractions)\n- **C's performance** (zero-cost abstractions)\n- **Better safety than both** (compile-time guarantees)\n\nThe ownership system seems complex at first, but it's just a way to make memory management explicit and safe. Once you understand it, you'll wonder how you ever lived without it!\n\nStart with small projects, read the compiler errors (they're very helpful!), and don't worry about fighting the borrow checker at first - it's teaching you to write better code.",
    "tags": [
      "beginner",
      "introduction",
      "ownership",
      "memory-management",
      "python-comparison",
      "javascript-comparison",
      "why-rust",
      "getting-started"
    ],
    "instruction": "I'm completely new to Rust and coming from Python/JavaScript. I keep hearing about ownership and borrowing but I don't understand what the big deal is. Can you explain what makes Rust different and why I should learn it?"
  },
  {
    "output": "Excellent question! Smart pointers are one of the more confusing aspects of Rust initially, but they're incredibly powerful once you understand when and why to use each one. Let me break them down with practical examples.\n\n## Understanding the Problem Smart Pointers Solve\n\nFirst, let's understand why we need smart pointers. Rust's basic ownership rules are:\n1. Each value has exactly one owner\n2. When the owner goes out of scope, the value is dropped\n\nBut sometimes we need to break these rules safely:\n\n```rust\n// This doesn't work with basic ownership:\nstruct Node {\n    value: i32,\n    children: Vec<Node>,  // This works fine\n    parent: ???,          // How do we reference the parent?\n}\n\n// Or this scenario:\nlet data = expensive_computation();\nlet worker1 = start_worker(data);  // data moved here\nlet worker2 = start_worker(data);  // ERROR: data already moved!\n```\n\nSmart pointers solve these problems by providing different ownership models.\n\n## Box<T>: Heap Allocation\n\n`Box<T>` is the simplest smart pointer - it just puts data on the heap instead of the stack.\n\n### When to use Box<T>:\n- Large data that would overflow the stack\n- Recursive data structures\n- Trait objects when you need owned values\n\n```rust\n// Example 1: Large data\nstruct LargeStruct {\n    data: [u8; 1_000_000],  // 1MB - too big for stack\n}\n\nfn main() {\n    // This might overflow the stack:\n    // let large = LargeStruct { data: [0; 1_000_000] };\n    \n    // This puts it on the heap:\n    let large = Box::new(LargeStruct { data: [0; 1_000_000] });\n    println!(\"Large struct created on heap\");\n}  // Box automatically frees the heap memory here\n\n// Example 2: Recursive data structures\n#[derive(Debug)]\nenum List {\n    Cons(i32, Box<List>),  // Box breaks the infinite size problem\n    Nil,\n}\n\nimpl List {\n    fn new() -> List {\n        List::Nil\n    }\n    \n    fn prepend(self, elem: i32) -> List {\n        List::Cons(elem, Box::new(self))\n    }\n    \n    fn len(&self) -> usize {\n        match self {\n            List::Cons(_, tail) => 1 + tail.len(),\n            List::Nil => 0,\n        }\n    }\n}\n\nfn main() {\n    let list = List::new()\n        .prepend(1)\n        .prepend(2)\n        .prepend(3);\n    \n    println!(\"List: {:?}\", list);\n    println!(\"Length: {}\", list.len());\n}\n\n// Example 3: Trait objects\ntrait Animal {\n    fn make_sound(&self);\n}\n\nstruct Dog;\nstruct Cat;\n\nimpl Animal for Dog {\n    fn make_sound(&self) {\n        println!(\"Woof!\");\n    }\n}\n\nimpl Animal for Cat {\n    fn make_sound(&self) {\n        println!(\"Meow!\");\n    }\n}\n\nfn main() {\n    // Vector of different animals (trait objects)\n    let animals: Vec<Box<dyn Animal>> = vec![\n        Box::new(Dog),\n        Box::new(Cat),\n        Box::new(Dog),\n    ];\n    \n    for animal in &animals {\n        animal.make_sound();\n    }\n}\n```\n\n## Rc<T>: Reference Counting for Single-Threaded Shared Ownership\n\n`Rc<T>` (Reference Counted) allows multiple owners of the same data in single-threaded contexts.\n\n### When to use Rc<T>:\n- Multiple parts of your program need to own the same data\n- Single-threaded applications only\n- Graph-like data structures\n\n```rust\nuse std::rc::Rc;\n\n// Example 1: Shared data\n#[derive(Debug)]\nstruct SharedData {\n    value: i32,\n    name: String,\n}\n\nfn main() {\n    // Create shared data\n    let data = Rc::new(SharedData {\n        value: 42,\n        name: \"Shared\".to_string(),\n    });\n    \n    // Clone the Rc (cheap - just increments reference count)\n    let data1 = Rc::clone(&data);\n    let data2 = Rc::clone(&data);\n    let data3 = Rc::clone(&data);\n    \n    println!(\"Reference count: {}\", Rc::strong_count(&data));  // 4\n    \n    println!(\"Data1: {:?}\", data1);\n    println!(\"Data2: {:?}\", data2);\n    println!(\"Data3: {:?}\", data3);\n    \n    // When all Rc's are dropped, data is freed\n    drop(data1);\n    println!(\"Reference count after drop: {}\", Rc::strong_count(&data));  // 3\n}\n\n// Example 2: Tree with parent references\n#[derive(Debug)]\nstruct TreeNode {\n    value: i32,\n    children: Vec<Rc<TreeNode>>,\n    // Note: we can't have parent: Rc<TreeNode> here because it would create cycles\n}\n\nimpl TreeNode {\n    fn new(value: i32) -> Rc<Self> {\n        Rc::new(TreeNode {\n            value,\n            children: Vec::new(),\n        })\n    }\n    \n    fn add_child(self: &Rc<Self>, child: Rc<TreeNode>) {\n        // This is a problem - we can't mutate through Rc!\n        // self.children.push(child);  // ERROR!\n    }\n}\n\n// We need interior mutability for this - see RefCell below\n```\n\n## Arc<T>: Atomic Reference Counting for Multi-Threaded Shared Ownership\n\n`Arc<T>` (Atomically Reference Counted) is like `Rc<T>` but thread-safe.\n\n### When to use Arc<T>:\n- Multiple threads need to own the same data\n- Thread-safe shared state\n- Concurrent programming\n\n```rust\nuse std::sync::Arc;\nuse std::thread;\nuse std::time::Duration;\n\n// Example 1: Sharing data across threads\n#[derive(Debug)]\nstruct Config {\n    database_url: String,\n    api_key: String,\n    timeout: Duration,\n}\n\nfn main() {\n    let config = Arc::new(Config {\n        database_url: \"postgres://localhost/mydb\".to_string(),\n        api_key: \"secret123\".to_string(),\n        timeout: Duration::from_secs(30),\n    });\n    \n    let mut handles = vec![];\n    \n    // Spawn multiple threads that share the config\n    for i in 0..3 {\n        let config_clone = Arc::clone(&config);\n        let handle = thread::spawn(move || {\n            println!(\"Thread {}: Using database {}\", i, config_clone.database_url);\n            println!(\"Thread {}: API key length: {}\", i, config_clone.api_key.len());\n            thread::sleep(Duration::from_millis(100));\n        });\n        handles.push(handle);\n    }\n    \n    // Wait for all threads to complete\n    for handle in handles {\n        handle.join().unwrap();\n    }\n    \n    println!(\"Reference count: {}\", Arc::strong_count(&config));\n}\n\n// Example 2: Shared cache across workers\nuse std::collections::HashMap;\nuse std::sync::Mutex;  // We'll need this for mutation\n\ntype Cache = Arc<Mutex<HashMap<String, String>>>;\n\nfn worker(id: usize, cache: Cache) {\n    thread::sleep(Duration::from_millis(id as u64 * 100));\n    \n    // Access the cache (need to lock for mutation)\n    {\n        let mut cache_guard = cache.lock().unwrap();\n        cache_guard.insert(format!(\"key_{}\", id), format!(\"value_{}\", id));\n        println!(\"Worker {} inserted data\", id);\n    }\n    \n    // Read from cache\n    {\n        let cache_guard = cache.lock().unwrap();\n        println!(\"Worker {} sees cache: {:?}\", id, *cache_guard);\n    }\n}\n\nfn main() {\n    let cache: Cache = Arc::new(Mutex::new(HashMap::new()));\n    let mut handles = vec![];\n    \n    for i in 0..3 {\n        let cache_clone = Arc::clone(&cache);\n        let handle = thread::spawn(move || worker(i, cache_clone));\n        handles.push(handle);\n    }\n    \n    for handle in handles {\n        handle.join().unwrap();\n    }\n}\n```\n\n## RefCell<T>: Interior Mutability\n\n`RefCell<T>` provides \"interior mutability\" - the ability to mutate data even when you have only immutable references.\n\n### When to use RefCell<T>:\n- You need to mutate data through shared references\n- Single-threaded contexts only\n- Often combined with Rc<T>\n\n```rust\nuse std::cell::RefCell;\nuse std::rc::Rc;\n\n// Example 1: Basic interior mutability\nfn main() {\n    let data = RefCell::new(vec![1, 2, 3]);\n    \n    // Even though data is not mut, we can modify its contents\n    data.borrow_mut().push(4);\n    data.borrow_mut().push(5);\n    \n    println!(\"Data: {:?}\", data.borrow());  // [1, 2, 3, 4, 5]\n}\n\n// Example 2: Tree with mutable structure using Rc<RefCell<T>>\n#[derive(Debug)]\nstruct TreeNode {\n    value: i32,\n    children: RefCell<Vec<Rc<RefCell<TreeNode>>>>,\n}\n\nimpl TreeNode {\n    fn new(value: i32) -> Rc<RefCell<Self>> {\n        Rc::new(RefCell::new(TreeNode {\n            value,\n            children: RefCell::new(Vec::new()),\n        }))\n    }\n    \n    fn add_child(self: &Rc<RefCell<Self>>, child: Rc<RefCell<TreeNode>>) {\n        self.borrow_mut().children.borrow_mut().push(child);\n    }\n    \n    fn print_tree(node: &Rc<RefCell<TreeNode>>, depth: usize) {\n        let indent = \"  \".repeat(depth);\n        println!(\"{}Node: {}\", indent, node.borrow().value);\n        \n        for child in node.borrow().children.borrow().iter() {\n            Self::print_tree(child, depth + 1);\n        }\n    }\n}\n\nfn main() {\n    let root = TreeNode::new(1);\n    let child1 = TreeNode::new(2);\n    let child2 = TreeNode::new(3);\n    let grandchild = TreeNode::new(4);\n    \n    root.add_child(child1.clone());\n    root.add_child(child2.clone());\n    child1.add_child(grandchild);\n    \n    TreeNode::print_tree(&root, 0);\n}\n\n// Example 3: Runtime borrow checking\nfn main() {\n    let data = RefCell::new(vec![1, 2, 3]);\n    \n    // Multiple immutable borrows are OK\n    let borrow1 = data.borrow();\n    let borrow2 = data.borrow();\n    println!(\"Borrow1: {:?}\", *borrow1);\n    println!(\"Borrow2: {:?}\", *borrow2);\n    drop(borrow1);\n    drop(borrow2);\n    \n    // Mutable borrow (exclusive)\n    let mut borrow3 = data.borrow_mut();\n    borrow3.push(4);\n    drop(borrow3);\n    \n    // This would panic at runtime:\n    // let borrow4 = data.borrow();\n    // let mut borrow5 = data.borrow_mut();  // PANIC!\n}\n```\n\n## Common Combinations and Patterns\n\n### Rc<RefCell<T>>: Shared Mutable Data (Single-Threaded)\n\n```rust\nuse std::cell::RefCell;\nuse std::rc::Rc;\n\ntype SharedList = Rc<RefCell<Vec<i32>>>;\n\nfn add_to_list(list: &SharedList, value: i32) {\n    list.borrow_mut().push(value);\n}\n\nfn print_list(list: &SharedList, name: &str) {\n    println!(\"{}: {:?}\", name, list.borrow());\n}\n\nfn main() {\n    let list1: SharedList = Rc::new(RefCell::new(vec![1, 2, 3]));\n    let list2 = Rc::clone(&list1);\n    let list3 = Rc::clone(&list1);\n    \n    add_to_list(&list1, 4);\n    add_to_list(&list2, 5);\n    add_to_list(&list3, 6);\n    \n    print_list(&list1, \"List1\");\n    print_list(&list2, \"List2\");\n    print_list(&list3, \"List3\");\n    // All print the same: [1, 2, 3, 4, 5, 6]\n}\n```\n\n### Arc<Mutex<T>>: Shared Mutable Data (Multi-Threaded)\n\n```rust\nuse std::sync::{Arc, Mutex};\nuse std::thread;\n\ntype SharedCounter = Arc<Mutex<i32>>;\n\nfn increment_counter(counter: &SharedCounter, times: i32) {\n    for _ in 0..times {\n        let mut count = counter.lock().unwrap();\n        *count += 1;\n    }\n}\n\nfn main() {\n    let counter: SharedCounter = Arc::new(Mutex::new(0));\n    let mut handles = vec![];\n    \n    for i in 0..3 {\n        let counter_clone = Arc::clone(&counter);\n        let handle = thread::spawn(move || {\n            increment_counter(&counter_clone, 10);\n            println!(\"Thread {} finished\", i);\n        });\n        handles.push(handle);\n    }\n    \n    for handle in handles {\n        handle.join().unwrap();\n    }\n    \n    println!(\"Final count: {}\", *counter.lock().unwrap());\n}\n```\n\n## Decision Tree: Which Smart Pointer to Use?\n\n```rust\n// Use this decision tree:\n\n// Do you need heap allocation?\n// \u2514\u2500 Yes: Box<T>\n//    \u2514\u2500 Do you need multiple owners?\n//        \u2514\u2500 No: Box<T>\n//        \u2514\u2500 Yes: Are you using threads?\n//            \u2514\u2500 No: Rc<T>\n//            \u2514\u2500 Yes: Arc<T>\n//                \u2514\u2500 Do you need mutation?\n//                    \u2514\u2500 No: Arc<T>\n//                    \u2514\u2500 Yes: Arc<Mutex<T>> or Arc<RwLock<T>>\n\n// Do you need interior mutability (single-threaded)?\n// \u2514\u2500 Yes: RefCell<T> (often combined with Rc<RefCell<T>>)\n\n// Do you need to break reference cycles?\n// \u2514\u2500 Yes: Use Weak<T> with Rc<T> or Arc<T>\n```\n\n## Quick Reference\n\n| Smart Pointer | Use Case | Thread Safe | Mutable |\n|---------------|----------|-------------|----------|\n| `Box<T>` | Heap allocation, single owner | N/A | Yes (if mut) |\n| `Rc<T>` | Multiple owners, single thread | No | No |\n| `Arc<T>` | Multiple owners, multi-threaded | Yes | No |\n| `RefCell<T>` | Interior mutability, runtime checks | No | Yes |\n| `Mutex<T>` | Thread-safe mutation | Yes | Yes |\n| `RwLock<T>` | Multiple readers OR one writer | Yes | Yes |\n\n## Common Patterns Summary\n\n- **`Box<T>`**: Owned heap data\n- **`Rc<T>`**: Shared immutable data (single-threaded)\n- **`Arc<T>`**: Shared immutable data (multi-threaded)\n- **`Rc<RefCell<T>>`**: Shared mutable data (single-threaded)\n- **`Arc<Mutex<T>>`**: Shared mutable data (multi-threaded)\n- **`Arc<RwLock<T>>`**: Shared data with frequent reads, occasional writes\n\nStart with the simplest option that works, and only add complexity when you need it!",
    "tags": [
      "smart-pointers",
      "box",
      "rc",
      "arc",
      "refcell",
      "memory-management",
      "ownership",
      "interior-mutability",
      "thread-safety"
    ],
    "instruction": "I'm starting to understand ownership, but I keep running into issues with smart pointers. I see Box, Rc, Arc, RefCell everywhere and I don't know when to use which one. Can you explain the different smart pointer types and when I need them?"
  },
  {
    "output": "Perfect question! The borrow checker errors are the most confusing part of learning Rust, but once you understand the rules, they'll start making sense. Let me break down exactly what's happening and why.\n\n## The Core Borrow Checker Rules\n\nThe borrow checker enforces these rules at compile time:\n\n1. **At any given time, you can have EITHER:**\n   - One mutable reference (`&mut T`)\n   - OR any number of immutable references (`&T`)\n   - BUT NOT BOTH at the same time\n\n2. **References must always be valid** (no dangling pointers)\n\n3. **Values can only be moved once** (unless they implement `Copy`)\n\nLet's see why these rules exist and how they prevent bugs.\n\n## Error 1: \"Cannot borrow as mutable\"\n\n### The Problem:\n```rust\nfn main() {\n    let mut data = vec![1, 2, 3, 4, 5];\n    \n    let first = &data[0];        // Immutable borrow starts here\n    println!(\"First: {}\", first);\n    \n    data.push(6);               // ERROR: cannot borrow `data` as mutable\n    \n    println!(\"First: {}\", first); // Immutable borrow used here\n}\n```\n\n### Why This Fails:\nIn other languages, this could cause a crash! Here's what could happen:\n\n```rust\n// Imagine if Rust allowed this (it doesn't!):\nlet mut data = vec![1, 2, 3];     // Capacity: 3, stored at memory address 0x1000\nlet first = &data[0];             // first points to 0x1000 (where data[0] lives)\n\n// When we push to a full vector, it might reallocate:\ndata.push(4);                     // Vector outgrows capacity!\n                                  // Rust allocates new memory at 0x2000\n                                  // Copies [1,2,3] to new location\n                                  // Frees old memory at 0x1000\n                                  // Updates data to point to 0x2000\n\n// Now first still points to 0x1000 (freed memory!) - DANGLING POINTER!\nprintln!(\"First: {}\", first);     // Could crash or print garbage\n```\n\n### The Fix - End the Borrow Early:\n```rust\nfn main() {\n    let mut data = vec![1, 2, 3, 4, 5];\n    \n    {\n        let first = &data[0];        // Immutable borrow starts\n        println!(\"First: {}\", first);\n    }                               // Immutable borrow ends here\n    \n    data.push(6);                   // Now we can mutate\n    println!(\"Data: {:?}\", data);\n}\n```\n\n### Or Clone the Data:\n```rust\nfn main() {\n    let mut data = vec![1, 2, 3, 4, 5];\n    \n    let first_value = data[0];      // Copy the value (i32 implements Copy)\n    // or\n    let first_clone = data[0].clone(); // Explicitly clone\n    \n    data.push(6);                   // No borrow, so this works\n    \n    println!(\"First: {}\", first_value);\n}\n```\n\n## Error 2: \"Use of moved value\"\n\n### The Problem:\n```rust\nfn main() {\n    let data = vec![1, 2, 3];\n    \n    let worker1 = process_data(data);  // data moved into function\n    let worker2 = process_data(data);  // ERROR: use of moved value: `data`\n}\n\nfn process_data(data: Vec<i32>) -> String {\n    format!(\"Processed {} items\", data.len())\n}\n```\n\n### Why This Fails:\nRust prevents \"double free\" errors. If both `worker1` and `worker2` owned the same vector, when they both go out of scope, Rust would try to free the same memory twice - crash!\n\n### Fix 1 - Borrow Instead of Move:\n```rust\nfn main() {\n    let data = vec![1, 2, 3];\n    \n    let worker1 = process_data(&data);  // Borrow, don't move\n    let worker2 = process_data(&data);  // Can borrow multiple times\n    \n    println!(\"Still can use data: {:?}\", data);\n}\n\nfn process_data(data: &Vec<i32>) -> String {  // Take a reference\n    format!(\"Processed {} items\", data.len())\n}\n```\n\n### Fix 2 - Clone the Data:\n```rust\nfn main() {\n    let data = vec![1, 2, 3];\n    \n    let worker1 = process_data(data.clone());  // Clone for first worker\n    let worker2 = process_data(data);          // Move original to second\n}\n\nfn process_data(data: Vec<i32>) -> String {\n    format!(\"Processed {} items\", data.len())\n}\n```\n\n### Fix 3 - Use Reference Counting:\n```rust\nuse std::rc::Rc;\n\nfn main() {\n    let data = Rc::new(vec![1, 2, 3]);\n    \n    let worker1 = process_data(Rc::clone(&data));  // Increment ref count\n    let worker2 = process_data(Rc::clone(&data));  // Increment ref count\n    \n    println!(\"Original data still accessible: {:?}\", data);\n}\n\nfn process_data(data: Rc<Vec<i32>>) -> String {\n    format!(\"Processed {} items\", data.len())\n}\n```\n\n## Complex Example: Understanding Multiple Borrows\n\n```rust\n// This fails:\nfn problematic_code() {\n    let mut users = vec![\n        \"Alice\".to_string(),\n        \"Bob\".to_string(),\n        \"Charlie\".to_string()\n    ];\n    \n    let first_user = &users[0];       // Immutable borrow\n    \n    users.push(\"David\".to_string());  // ERROR: Can't mutate while borrowed\n    \n    println!(\"First user: {}\", first_user);\n}\n\n// This works:\nfn working_code() {\n    let mut users = vec![\n        \"Alice\".to_string(),\n        \"Bob\".to_string(),\n        \"Charlie\".to_string()\n    ];\n    \n    // Option 1: Clone the string\n    let first_user = users[0].clone();\n    users.push(\"David\".to_string());\n    println!(\"First user: {}\", first_user);\n    \n    // Option 2: Use index instead of reference\n    let first_index = 0;\n    users.push(\"Eve\".to_string());\n    println!(\"First user: {}\", users[first_index]);\n    \n    // Option 3: Separate the operations\n    println!(\"First user: {}\", users[0]);\n    users.push(\"Frank\".to_string());\n}\n```\n\n## Common Patterns and Solutions\n\n### Pattern 1: Iterator Invalidation\n```rust\n// This fails:\nfn remove_empty_strings_bad(strings: &mut Vec<String>) {\n    for (i, s) in strings.iter().enumerate() {  // Immutable borrow\n        if s.is_empty() {\n            strings.remove(i);  // ERROR: Can't mutate while iterating\n        }\n    }\n}\n\n// This works:\nfn remove_empty_strings_good(strings: &mut Vec<String>) {\n    // Collect indices to remove (avoid borrowing strings)\n    let mut to_remove = Vec::new();\n    for (i, s) in strings.iter().enumerate() {\n        if s.is_empty() {\n            to_remove.push(i);\n        }\n    }\n    \n    // Remove in reverse order to maintain correct indices\n    for &i in to_remove.iter().rev() {\n        strings.remove(i);\n    }\n}\n\n// Even better - use retain:\nfn remove_empty_strings_best(strings: &mut Vec<String>) {\n    strings.retain(|s| !s.is_empty());\n}\n```\n\n### Pattern 2: Updating Values While Iterating\n```rust\n// This fails:\nfn double_values_bad(numbers: &mut Vec<i32>) {\n    for num in numbers.iter() {  // Immutable borrow\n        *num *= 2;  // ERROR: Can't mutate through immutable reference\n    }\n}\n\n// This works:\nfn double_values_good(numbers: &mut Vec<i32>) {\n    for num in numbers.iter_mut() {  // Mutable borrow\n        *num *= 2;  // OK: mutable reference allows mutation\n    }\n}\n\n// Or use functional style:\nfn double_values_functional(numbers: Vec<i32>) -> Vec<i32> {\n    numbers.into_iter().map(|x| x * 2).collect()\n}\n```\n\n### Pattern 3: Nested Borrowing\n```rust\nuse std::collections::HashMap;\n\n// This fails:\nfn update_nested_bad(map: &mut HashMap<String, Vec<i32>>) {\n    let values = map.get_mut(\"key1\").unwrap();  // Mutable borrow of map\n    \n    if values.is_empty() {\n        map.insert(\"key2\".to_string(), vec![1, 2, 3]);  // ERROR: map already borrowed\n    }\n}\n\n// This works:\nfn update_nested_good(map: &mut HashMap<String, Vec<i32>>) {\n    let is_empty = map.get(\"key1\")  // Immutable borrow\n        .map(|v| v.is_empty())\n        .unwrap_or(true);\n    // Borrow ends here\n    \n    if is_empty {\n        map.insert(\"key2\".to_string(), vec![1, 2, 3]);  // Now we can mutate\n    }\n}\n\n// Or use entry API:\nfn update_nested_best(map: &mut HashMap<String, Vec<i32>>) {\n    use std::collections::hash_map::Entry;\n    \n    match map.entry(\"key1\".to_string()) {\n        Entry::Occupied(entry) => {\n            if entry.get().is_empty() {\n                map.insert(\"key2\".to_string(), vec![1, 2, 3]);\n            }\n        }\n        Entry::Vacant(_) => {\n            map.insert(\"key2\".to_string(), vec![1, 2, 3]);\n        }\n    }\n}\n```\n\n## Debugging Borrow Checker Errors\n\n### Step 1: Read the Error Carefully\n```rust\nfn main() {\n    let mut data = vec![1, 2, 3];\n    let reference = &data[0];\n    data.push(4);\n    println!(\"{}\", reference);\n}\n```\n\nError message:\n```\nerror[E0502]: cannot borrow `data` as mutable because it is also borrowed as immutable\n --> src/main.rs:4:5\n  |\n3 |     let reference = &data[0];\n  |                      ---- immutable borrow occurs here\n4 |     data.push(4);\n  |     ^^^^^^^^^^^^ mutable borrow occurs here\n5 |     println!(\"{}\", reference);\n  |                    --------- immutable borrow later used here\n```\n\n### Step 2: Identify the Conflicting Borrows\n- **Immutable borrow**: Line 3 (`&data[0]`)\n- **Mutable borrow**: Line 4 (`data.push(4)`)\n- **Conflict**: Both borrows are active at line 5\n\n### Step 3: Choose a Solution Strategy\n1. **End the immutable borrow early** (add scopes)\n2. **Clone the data** instead of borrowing\n3. **Restructure the code** to avoid the conflict\n4. **Use different data structures** (e.g., `Rc<RefCell<T>>`)\n\n## Mental Model: Think Like the Borrow Checker\n\nThe borrow checker asks these questions:\n\n1. **\"Is this reference still being used later?\"**\n   - If yes, the borrow stays active\n   - If no, the borrow ends\n\n2. **\"Are there any other active borrows?\"**\n   - Immutable + Immutable = OK\n   - Mutable + Anything = NOT OK\n\n3. **\"Could this operation invalidate existing references?\"**\n   - Vector reallocation, moving values, etc.\n   - If yes, prevent it while references exist\n\n## Quick Reference: Common Solutions\n\n| Error | Quick Fix |\n|-------|----------|\n| \"cannot borrow as mutable\" | End immutable borrows early with `{}` scopes |\n| \"use of moved value\" | Use `&` to borrow instead of move, or `.clone()` |\n| \"cannot move out of borrowed content\" | Clone the data or restructure ownership |\n| \"borrow might not live long enough\" | Add lifetime parameters or restructure |\n\nRemember: The borrow checker is trying to prevent real bugs that would crash your program in other languages. Once you get used to it, you'll appreciate the safety it provides!",
    "tags": [
      "borrow-checker",
      "common-errors",
      "ownership-debugging",
      "mutable-borrowing",
      "moved-values",
      "compiler-errors",
      "memory-safety",
      "troubleshooting"
    ],
    "instruction": "I understand the basics now, but I keep seeing confusing error messages like 'cannot borrow as mutable' and 'use of moved value'. Why can't I just change things like I do in other languages? What exactly are these borrow checker rules?"
  },
  {
    "output": "Great question! Closures in Rust are similar to JavaScript in concept but have some important differences due to Rust's ownership system. Let me walk you through everything step by step.\n\n## Basic Closure Syntax\n\n```rust\n// JavaScript closure:\n// const add = (x, y) => x + y;\n// const greet = name => `Hello, ${name}!`;\n\n// Rust equivalents:\nfn main() {\n    let add = |x, y| x + y;                    // Parameters in |pipes|\n    let greet = |name| format!(\"Hello, {}!\", name);\n    \n    println!(\"5 + 3 = {}\", add(5, 3));\n    println!(\"{}\", greet(\"Alice\"));\n    \n    // Closures can also have explicit types\n    let multiply: fn(i32, i32) -> i32 = |x, y| x * y;\n    let divide = |x: f64, y: f64| -> f64 { x / y };\n    \n    println!(\"4 * 6 = {}\", multiply(4, 6));\n    println!(\"10.0 / 3.0 = {}\", divide(10.0, 3.0));\n}\n```\n\n## Capturing Variables from Environment\n\nThis is where Rust differs from JavaScript due to ownership:\n\n```rust\nfn main() {\n    let name = String::from(\"World\");\n    let age = 25;\n    \n    // Different ways closures can capture variables:\n    \n    // 1. Immutable borrow (most common)\n    let greet = || {\n        println!(\"Hello, {}! You are {} years old.\", name, age);\n    };\n    \n    greet();\n    println!(\"Name is still usable: {}\", name);  // name wasn't moved\n    \n    // 2. Mutable borrow\n    let mut counter = 0;\n    let mut increment = || {\n        counter += 1;\n        println!(\"Counter: {}\", counter);\n    };\n    \n    increment();  // Counter: 1\n    increment();  // Counter: 2\n    // println!(\"{}\", counter);  // ERROR: counter is mutably borrowed by closure\n    \n    drop(increment);  // End the mutable borrow\n    println!(\"Final counter: {}\", counter);  // Now we can use counter\n    \n    // 3. Taking ownership with 'move'\n    let message = String::from(\"Secret message\");\n    let capture_message = move || {\n        println!(\"Captured: {}\", message);  // message is moved into closure\n    };\n    \n    capture_message();\n    // println!(\"{}\", message);  // ERROR: message was moved\n}\n```\n\n## The Three Closure Traits: Fn, FnMut, FnOnce\n\nRust has three different closure traits that determine how the closure can be called:\n\n```rust\nuse std::thread;\n\nfn main() {\n    // FnOnce: Can be called once (consumes captured values)\n    let data = vec![1, 2, 3];\n    let consume_data = move || {\n        println!(\"Processing: {:?}\", data);\n        data  // Returns data, consuming it\n    };\n    \n    let result = consume_data();  // Can only call once\n    // consume_data();  // ERROR: closure has been moved\n    \n    // FnMut: Can be called multiple times and mutate captured values\n    let mut counter = 0;\n    let mut increment = || {\n        counter += 1;\n        counter\n    };\n    \n    println!(\"Count: {}\", increment());  // 1\n    println!(\"Count: {}\", increment());  // 2\n    \n    // Fn: Can be called multiple times without mutating\n    let multiplier = 3;\n    let multiply_by_three = |x| x * multiplier;\n    \n    println!(\"5 * 3 = {}\", multiply_by_three(5));\n    println!(\"7 * 3 = {}\", multiply_by_three(7));\n    println!(\"Multiplier is still: {}\", multiplier);\n}\n\n// Functions that take closures\nfn call_once<F>(f: F) -> i32 \nwhere \n    F: FnOnce() -> i32  // Can only be called once\n{\n    f()\n}\n\nfn call_multiple_times<F>(mut f: F) \nwhere \n    F: FnMut() -> i32  // Can be called multiple times\n{\n    for i in 1..=3 {\n        println!(\"Call {}: {}\", i, f());\n    }\n}\n\nfn call_readonly<F>(f: F) \nwhere \n    F: Fn(i32) -> i32  // Immutable, can be called many times\n{\n    for i in 1..=3 {\n        println!(\"f({}) = {}\", i, f(i));\n    }\n}\n\nfn example_usage() {\n    // FnOnce example\n    let data = vec![1, 2, 3];\n    let sum = call_once(move || data.iter().sum());\n    println!(\"Sum: {}\", sum);\n    \n    // FnMut example\n    let mut count = 0;\n    call_multiple_times(|| {\n        count += 1;\n        count\n    });\n    \n    // Fn example\n    call_readonly(|x| x * x);\n}\n```\n\n## Closures with Iterator Methods (Very Common Pattern)\n\n```rust\nfn main() {\n    let numbers = vec![1, 2, 3, 4, 5, 6, 7, 8, 9, 10];\n    \n    // map: Transform each element\n    let doubled: Vec<i32> = numbers\n        .iter()\n        .map(|x| x * 2)\n        .collect();\n    println!(\"Doubled: {:?}\", doubled);\n    \n    // filter: Keep elements that match condition\n    let evens: Vec<&i32> = numbers\n        .iter()\n        .filter(|&x| x % 2 == 0)\n        .collect();\n    println!(\"Evens: {:?}\", evens);\n    \n    // fold/reduce: Combine all elements\n    let sum = numbers\n        .iter()\n        .fold(0, |acc, &x| acc + x);\n    println!(\"Sum: {}\", sum);\n    \n    // Chaining operations\n    let result: Vec<i32> = numbers\n        .iter()\n        .filter(|&x| x % 2 == 0)    // Keep evens\n        .map(|x| x * x)             // Square them\n        .collect();\n    println!(\"Even squares: {:?}\", result);\n    \n    // for_each: Side effects (like forEach in JS)\n    numbers\n        .iter()\n        .filter(|&x| x > 5)\n        .for_each(|x| println!(\"Large number: {}\", x));\n}\n\n// Working with strings\nfn string_processing() {\n    let words = vec![\"hello\", \"world\", \"rust\", \"programming\"];\n    \n    // Find words longer than 4 characters\n    let long_words: Vec<&str> = words\n        .iter()\n        .filter(|word| word.len() > 4)\n        .copied()  // Convert from &&str to &str\n        .collect();\n    \n    println!(\"Long words: {:?}\", long_words);\n    \n    // Create a sentence\n    let sentence = words\n        .iter()\n        .map(|word| word.to_uppercase())\n        .collect::<Vec<String>>()\n        .join(\" \");\n    \n    println!(\"Sentence: {}\", sentence);\n}\n```\n\n## Advanced Closure Patterns\n\n### Returning Closures from Functions\n\n```rust\n// This doesn't work - closures have unknown size\n// fn make_adder(x: i32) -> impl Fn(i32) -> i32 {\n//     |y| x + y  // ERROR: can't capture x\n// }\n\n// This works - use move to capture by value\nfn make_adder(x: i32) -> impl Fn(i32) -> i32 {\n    move |y| x + y\n}\n\n// Returning boxed closures for more flexibility\nfn make_formatter(prefix: String) -> Box<dyn Fn(&str) -> String> {\n    Box::new(move |text| format!(\"{}: {}\", prefix, text))\n}\n\nfn main() {\n    let add_five = make_adder(5);\n    println!(\"10 + 5 = {}\", add_five(10));\n    \n    let error_formatter = make_formatter(\"ERROR\".to_string());\n    println!(\"{}\", error_formatter(\"Something went wrong\"));\n}\n```\n\n### Closures in Structs\n\n```rust\nstruct EventHandler<F> \nwhere \n    F: Fn(&str)\n{\n    name: String,\n    handler: F,\n}\n\nimpl<F> EventHandler<F> \nwhere \n    F: Fn(&str)\n{\n    fn new(name: String, handler: F) -> Self {\n        EventHandler { name, handler }\n    }\n    \n    fn handle_event(&self, event: &str) {\n        println!(\"Handler '{}' processing event:\", self.name);\n        (self.handler)(event);\n    }\n}\n\nfn main() {\n    let logger = EventHandler::new(\n        \"Logger\".to_string(),\n        |event| println!(\"LOG: {}\", event)\n    );\n    \n    let counter = {\n        let mut count = 0;\n        EventHandler::new(\n            \"Counter\".to_string(),\n            move |_event| {\n                count += 1;\n                println!(\"Event count: {}\", count);\n            }\n        )\n    };\n    \n    logger.handle_event(\"User logged in\");\n    counter.handle_event(\"Page viewed\");\n    counter.handle_event(\"Button clicked\");\n}\n```\n\n### Async Closures\n\n```rust\nuse std::future::Future;\nuse tokio::time::{sleep, Duration};\n\n// Async closure (experimental feature in stable Rust)\nasync fn process_with_async_closure() {\n    let numbers = vec![1, 2, 3, 4, 5];\n    \n    // Note: async closures are not yet stable in Rust\n    // This is how you might work with async operations in closures:\n    \n    let futures: Vec<_> = numbers\n        .into_iter()\n        .map(|n| async move {\n            sleep(Duration::from_millis(100)).await;\n            n * 2\n        })\n        .collect();\n    \n    let results = futures::future::join_all(futures).await;\n    println!(\"Async results: {:?}\", results);\n}\n\n// Helper function that takes async closure-like behavior\nasync fn map_async<T, U, F, Fut>(items: Vec<T>, f: F) -> Vec<U>\nwhere\n    F: Fn(T) -> Fut,\n    Fut: Future<Output = U>,\n{\n    let futures: Vec<_> = items.into_iter().map(f).collect();\n    futures::future::join_all(futures).await\n}\n\n#[tokio::main]\nasync fn main() {\n    let numbers = vec![1, 2, 3, 4];\n    \n    let results = map_async(numbers, |n| async move {\n        sleep(Duration::from_millis(n as u64 * 100)).await;\n        n * n\n    }).await;\n    \n    println!(\"Squared with delay: {:?}\", results);\n}\n```\n\n## Real-World Examples\n\n### Configuration and Builder Patterns\n\n```rust\nstruct ApiClient {\n    base_url: String,\n    timeout: std::time::Duration,\n    headers: std::collections::HashMap<String, String>,\n}\n\nimpl ApiClient {\n    fn new() -> Self {\n        Self {\n            base_url: \"https://api.example.com\".to_string(),\n            timeout: std::time::Duration::from_secs(30),\n            headers: std::collections::HashMap::new(),\n        }\n    }\n    \n    // Method that takes a closure to configure the client\n    fn configure<F>(mut self, config: F) -> Self \n    where \n        F: FnOnce(&mut Self)\n    {\n        config(&mut self);\n        self\n    }\n}\n\nfn main() {\n    let client = ApiClient::new()\n        .configure(|client| {\n            client.timeout = std::time::Duration::from_secs(60);\n            client.headers.insert(\"Authorization\".to_string(), \"Bearer token123\".to_string());\n        });\n    \n    println!(\"Client configured with timeout: {:?}\", client.timeout);\n}\n```\n\n### Event Processing Pipeline\n\n```rust\nstruct Pipeline<T> {\n    data: Vec<T>,\n}\n\nimpl<T> Pipeline<T> {\n    fn new(data: Vec<T>) -> Self {\n        Pipeline { data }\n    }\n    \n    fn filter<F>(self, predicate: F) -> Self \n    where \n        F: Fn(&T) -> bool\n    {\n        let filtered_data = self.data.into_iter().filter(predicate).collect();\n        Pipeline { data: filtered_data }\n    }\n    \n    fn map<U, F>(self, transform: F) -> Pipeline<U> \n    where \n        F: Fn(T) -> U\n    {\n        let transformed_data = self.data.into_iter().map(transform).collect();\n        Pipeline { data: transformed_data }\n    }\n    \n    fn for_each<F>(self, action: F) \n    where \n        F: Fn(&T)\n    {\n        for item in &self.data {\n            action(item);\n        }\n    }\n    \n    fn collect(self) -> Vec<T> {\n        self.data\n    }\n}\n\nfn main() {\n    let numbers = vec![1, 2, 3, 4, 5, 6, 7, 8, 9, 10];\n    \n    Pipeline::new(numbers)\n        .filter(|&x| x % 2 == 0)           // Keep evens\n        .map(|x| x * x)                    // Square them\n        .filter(|&x| x > 10)               // Keep large squares\n        .for_each(|&x| println!(\"Result: {}\", x));\n}\n```\n\n## Common Gotchas and Solutions\n\n### Gotcha 1: Borrowing vs Moving\n\n```rust\nfn main() {\n    let data = vec![1, 2, 3];\n    \n    // This borrows data\n    let closure1 = || {\n        println!(\"Data length: {}\", data.len());\n    };\n    \n    // This tries to move data - ERROR!\n    // let closure2 = || {\n    //     data  // This would move data out of the environment\n    // };\n    \n    // Solution: use move if you need to transfer ownership\n    let data2 = vec![4, 5, 6];\n    let closure2 = move || {\n        println!(\"Data2: {:?}\", data2);  // data2 is moved into closure\n        data2\n    };\n    \n    closure1();  // Can still use closure1\n    let result = closure2();  // closure2 consumes data2\n    println!(\"Result: {:?}\", result);\n}\n```\n\n### Gotcha 2: Mutable Borrowing Rules\n\n```rust\nfn main() {\n    let mut counter = 0;\n    \n    // This creates a mutable borrow\n    let mut increment = || {\n        counter += 1;\n    };\n    \n    increment();\n    // println!(\"{}\", counter);  // ERROR: counter is still mutably borrowed\n    increment();\n    \n    // Solution: end the borrow explicitly\n    drop(increment);\n    println!(\"Counter: {}\", counter);  // Now we can access counter\n}\n```\n\n## Key Differences from JavaScript\n\n| JavaScript | Rust |\n|------------|------|\n| `const f = (x) => x + 1` | `let f = \\|x\\| x + 1` |\n| Always captures by reference | Can capture by reference, mutable reference, or value |\n| No compile-time checks | Strict borrowing rules enforced |\n| Dynamic typing | Static typing with inference |\n| Garbage collected | Manual memory management |\n\n## Tips for Success\n\n1. **Start simple**: Use closures with iterators (`map`, `filter`, `fold`)\n2. **Understand capture modes**: When to use `move` vs regular capture\n3. **Learn the traits**: `Fn`, `FnMut`, `FnOnce` determine how closures can be used\n4. **Practice with real examples**: Event handlers, configuration, data processing\n5. **Read compiler errors**: They're usually very helpful for closure issues\n\nClosures in Rust are incredibly powerful once you understand the ownership implications. They enable elegant functional programming while maintaining Rust's safety guarantees!",
    "tags": [
      "closures",
      "functional-programming",
      "iterators",
      "capture-modes",
      "fn-traits",
      "move-semantics",
      "javascript-comparison",
      "advanced-patterns"
    ],
    "instruction": "I'm getting comfortable with Rust basics, but I'm struggling with closures and functional programming patterns. Coming from JavaScript, I thought I understood closures, but Rust's closure syntax and ownership rules are confusing me. Can you explain how closures work in Rust?"
  },
  {
    "output": "Excellent question! Rust has a fantastic ecosystem for web development. Let me walk you through HTTP clients, servers, JSON handling, and async patterns with practical examples.\n\n## Making HTTP Requests with reqwest\n\n### Basic HTTP Client\n\n```rust\n// Cargo.toml dependencies:\n// [dependencies]\n// reqwest = { version = \"0.11\", features = [\"json\"] }\n// tokio = { version = \"1.0\", features = [\"full\"] }\n// serde = { version = \"1.0\", features = [\"derive\"] }\n// serde_json = \"1.0\"\n\nuse reqwest;\nuse serde::{Deserialize, Serialize};\nuse std::collections::HashMap;\n\n#[derive(Debug, Serialize, Deserialize)]\nstruct User {\n    id: u32,\n    name: String,\n    email: String,\n}\n\n#[derive(Debug, Serialize, Deserialize)]\nstruct Post {\n    #[serde(rename = \"userId\")]\n    user_id: u32,\n    id: u32,\n    title: String,\n    body: String,\n}\n\n#[tokio::main]\nasync fn main() -> Result<(), Box<dyn std::error::Error>> {\n    // Create HTTP client\n    let client = reqwest::Client::new();\n    \n    // GET request\n    let response = client\n        .get(\"https://jsonplaceholder.typicode.com/users/1\")\n        .send()\n        .await?;\n    \n    println!(\"Status: {}\", response.status());\n    \n    // Parse JSON response\n    let user: User = response.json().await?;\n    println!(\"User: {:?}\", user);\n    \n    // GET with query parameters\n    let mut params = HashMap::new();\n    params.insert(\"userId\", \"1\");\n    \n    let posts: Vec<Post> = client\n        .get(\"https://jsonplaceholder.typicode.com/posts\")\n        .query(&params)\n        .send()\n        .await?\n        .json()\n        .await?;\n    \n    println!(\"User's posts: {}\", posts.len());\n    \n    // POST request with JSON body\n    let new_post = Post {\n        user_id: 1,\n        id: 0,  // Will be set by server\n        title: \"My New Post\".to_string(),\n        body: \"This is the content of my post.\".to_string(),\n    };\n    \n    let created_post: Post = client\n        .post(\"https://jsonplaceholder.typicode.com/posts\")\n        .json(&new_post)\n        .send()\n        .await?\n        .json()\n        .await?;\n    \n    println!(\"Created post: {:?}\", created_post);\n    \n    Ok(())\n}\n```\n\n### Advanced HTTP Client with Error Handling\n\n```rust\nuse reqwest::{Client, Response};\nuse serde_json::Value;\nuse std::time::Duration;\nuse thiserror::Error;\n\n#[derive(Error, Debug)]\npub enum ApiError {\n    #[error(\"HTTP request failed: {0}\")]\n    Request(#[from] reqwest::Error),\n    \n    #[error(\"JSON parsing failed: {0}\")]\n    Json(#[from] serde_json::Error),\n    \n    #[error(\"API returned error: {status} - {message}\")]\n    Api { status: u16, message: String },\n    \n    #[error(\"Timeout occurred\")]\n    Timeout,\n}\n\npub struct ApiClient {\n    client: Client,\n    base_url: String,\n    api_key: Option<String>,\n}\n\nimpl ApiClient {\n    pub fn new(base_url: String) -> Self {\n        let client = Client::builder()\n            .timeout(Duration::from_secs(30))\n            .user_agent(\"MyApp/1.0\")\n            .build()\n            .expect(\"Failed to create HTTP client\");\n        \n        Self {\n            client,\n            base_url,\n            api_key: None,\n        }\n    }\n    \n    pub fn with_api_key(mut self, api_key: String) -> Self {\n        self.api_key = Some(api_key);\n        self\n    }\n    \n    async fn handle_response(response: Response) -> Result<Value, ApiError> {\n        let status = response.status();\n        \n        if status.is_success() {\n            let json: Value = response.json().await?;\n            Ok(json)\n        } else {\n            let error_text = response.text().await.unwrap_or_else(|_| \"Unknown error\".to_string());\n            Err(ApiError::Api {\n                status: status.as_u16(),\n                message: error_text,\n            })\n        }\n    }\n    \n    pub async fn get(&self, endpoint: &str) -> Result<Value, ApiError> {\n        let url = format!(\"{}/{}\", self.base_url, endpoint.trim_start_matches('/'));\n        \n        let mut request = self.client.get(&url);\n        \n        if let Some(ref api_key) = self.api_key {\n            request = request.header(\"Authorization\", format!(\"Bearer {}\", api_key));\n        }\n        \n        let response = request.send().await?;\n        Self::handle_response(response).await\n    }\n    \n    pub async fn post<T: Serialize>(&self, endpoint: &str, data: &T) -> Result<Value, ApiError> {\n        let url = format!(\"{}/{}\", self.base_url, endpoint.trim_start_matches('/'));\n        \n        let mut request = self.client\n            .post(&url)\n            .json(data);\n        \n        if let Some(ref api_key) = self.api_key {\n            request = request.header(\"Authorization\", format!(\"Bearer {}\", api_key));\n        }\n        \n        let response = request.send().await?;\n        Self::handle_response(response).await\n    }\n}\n\n// Usage example\n#[tokio::main]\nasync fn main() -> Result<(), ApiError> {\n    let client = ApiClient::new(\"https://api.example.com\".to_string())\n        .with_api_key(\"your-api-key\".to_string());\n    \n    match client.get(\"/users/123\").await {\n        Ok(user_data) => println!(\"User: {}\", user_data),\n        Err(ApiError::Api { status, message }) => {\n            println!(\"API error {}: {}\", status, message);\n        }\n        Err(e) => println!(\"Other error: {}\", e),\n    }\n    \n    Ok(())\n}\n```\n\n## Building Web Servers with Axum\n\n### Basic Web Server\n\n```rust\n// Cargo.toml dependencies:\n// [dependencies]\n// axum = \"0.7\"\n// tokio = { version = \"1.0\", features = [\"full\"] }\n// tower = \"0.4\"\n// tower-http = { version = \"0.5\", features = [\"trace\", \"cors\"] }\n// serde = { version = \"1.0\", features = [\"derive\"] }\n// serde_json = \"1.0\"\n// tracing = \"0.1\"\n// tracing-subscriber = \"0.3\"\n\nuse axum::{\n    extract::{Path, Query, State},\n    http::StatusCode,\n    response::Json,\n    routing::{get, post},\n    Router,\n};\nuse serde::{Deserialize, Serialize};\nuse std::collections::HashMap;\nuse std::sync::{Arc, Mutex};\nuse tower_http::trace::TraceLayer;\nuse tracing_subscriber;\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\nstruct User {\n    id: u32,\n    name: String,\n    email: String,\n}\n\n#[derive(Debug, Deserialize)]\nstruct CreateUserRequest {\n    name: String,\n    email: String,\n}\n\n#[derive(Debug, Deserialize)]\nstruct UserQuery {\n    limit: Option<u32>,\n    offset: Option<u32>,\n}\n\n// Shared application state\ntype AppState = Arc<Mutex<HashMap<u32, User>>>;\n\n// Route handlers\nasync fn get_users(\n    Query(params): Query<UserQuery>,\n    State(state): State<AppState>,\n) -> Json<Vec<User>> {\n    let users = state.lock().unwrap();\n    let mut all_users: Vec<User> = users.values().cloned().collect();\n    \n    // Apply pagination\n    let offset = params.offset.unwrap_or(0) as usize;\n    let limit = params.limit.unwrap_or(10) as usize;\n    \n    if offset < all_users.len() {\n        all_users = all_users.into_iter().skip(offset).take(limit).collect();\n    } else {\n        all_users = vec![];\n    }\n    \n    Json(all_users)\n}\n\nasync fn get_user(\n    Path(user_id): Path<u32>,\n    State(state): State<AppState>,\n) -> Result<Json<User>, StatusCode> {\n    let users = state.lock().unwrap();\n    \n    match users.get(&user_id) {\n        Some(user) => Ok(Json(user.clone())),\n        None => Err(StatusCode::NOT_FOUND),\n    }\n}\n\nasync fn create_user(\n    State(state): State<AppState>,\n    Json(request): Json<CreateUserRequest>,\n) -> Result<Json<User>, StatusCode> {\n    let mut users = state.lock().unwrap();\n    \n    // Generate new ID\n    let new_id = users.keys().max().unwrap_or(&0) + 1;\n    \n    let new_user = User {\n        id: new_id,\n        name: request.name,\n        email: request.email,\n    };\n    \n    users.insert(new_id, new_user.clone());\n    \n    Ok(Json(new_user))\n}\n\nasync fn health_check() -> &'static str {\n    \"OK\"\n}\n\n#[tokio::main]\nasync fn main() {\n    // Initialize tracing\n    tracing_subscriber::fmt::init();\n    \n    // Initialize application state\n    let state: AppState = Arc::new(Mutex::new(HashMap::new()));\n    \n    // Add some sample data\n    {\n        let mut users = state.lock().unwrap();\n        users.insert(1, User {\n            id: 1,\n            name: \"Alice\".to_string(),\n            email: \"alice@example.com\".to_string(),\n        });\n        users.insert(2, User {\n            id: 2,\n            name: \"Bob\".to_string(),\n            email: \"bob@example.com\".to_string(),\n        });\n    }\n    \n    // Build the application router\n    let app = Router::new()\n        .route(\"/health\", get(health_check))\n        .route(\"/users\", get(get_users).post(create_user))\n        .route(\"/users/:id\", get(get_user))\n        .layer(TraceLayer::new_for_http())\n        .with_state(state);\n    \n    // Start the server\n    let listener = tokio::net::TcpListener::bind(\"0.0.0.0:3000\")\n        .await\n        .unwrap();\n    \n    println!(\"Server running on http://0.0.0.0:3000\");\n    \n    axum::serve(listener, app).await.unwrap();\n}\n```\n\n### Advanced Web Server with Database and Middleware\n\n```rust\nuse axum::{\n    extract::{Request, State},\n    http::{HeaderMap, StatusCode},\n    middleware::{self, Next},\n    response::{IntoResponse, Response},\n    routing::{get, post},\n    Json, Router,\n};\nuse serde::{Deserialize, Serialize};\nuse sqlx::{PgPool, Pool, Postgres};\nuse std::time::Instant;\nuse tower_http::cors::CorsLayer;\nuse uuid::Uuid;\n\n#[derive(Debug, Serialize, Deserialize, sqlx::FromRow)]\nstruct User {\n    id: Uuid,\n    name: String,\n    email: String,\n    created_at: chrono::DateTime<chrono::Utc>,\n}\n\n#[derive(Debug, Deserialize)]\nstruct CreateUserRequest {\n    name: String,\n    email: String,\n}\n\n// Application state with database pool\n#[derive(Clone)]\nstruct AppState {\n    db: PgPool,\n}\n\n// Custom error type\n#[derive(Debug)]\nstruct AppError(anyhow::Error);\n\nimpl IntoResponse for AppError {\n    fn into_response(self) -> Response {\n        (\n            StatusCode::INTERNAL_SERVER_ERROR,\n            format!(\"Something went wrong: {}\", self.0),\n        )\n            .into_response()\n    }\n}\n\nimpl<E> From<E> for AppError\nwhere\n    E: Into<anyhow::Error>,\n{\n    fn from(err: E) -> Self {\n        Self(err.into())\n    }\n}\n\ntype Result<T> = std::result::Result<T, AppError>;\n\n// Middleware for logging requests\nasync fn logging_middleware(request: Request, next: Next) -> Response {\n    let start = Instant::now();\n    let method = request.method().clone();\n    let uri = request.uri().clone();\n    \n    let response = next.run(request).await;\n    \n    let duration = start.elapsed();\n    let status = response.status();\n    \n    println!(\n        \"{} {} {} - {:?}\",\n        method, uri, status, duration\n    );\n    \n    response\n}\n\n// Middleware for API key authentication\nasync fn auth_middleware(headers: HeaderMap, request: Request, next: Next) -> Result<Response> {\n    if let Some(auth_header) = headers.get(\"authorization\") {\n        if let Ok(auth_str) = auth_header.to_str() {\n            if auth_str.starts_with(\"Bearer \") {\n                let token = &auth_str[7..];\n                if token == \"valid-api-key\" {\n                    return Ok(next.run(request).await);\n                }\n            }\n        }\n    }\n    \n    Ok((StatusCode::UNAUTHORIZED, \"Invalid API key\").into_response())\n}\n\n// Database operations\nasync fn get_users_from_db(State(state): State<AppState>) -> Result<Json<Vec<User>>> {\n    let users = sqlx::query_as::<_, User>(\"SELECT * FROM users ORDER BY created_at DESC\")\n        .fetch_all(&state.db)\n        .await?;\n    \n    Ok(Json(users))\n}\n\nasync fn create_user_in_db(\n    State(state): State<AppState>,\n    Json(request): Json<CreateUserRequest>,\n) -> Result<Json<User>> {\n    let user = sqlx::query_as::<_, User>(\n        r#\"\n        INSERT INTO users (id, name, email, created_at)\n        VALUES ($1, $2, $3, $4)\n        RETURNING *\n        \"#,\n    )\n    .bind(Uuid::new_v4())\n    .bind(&request.name)\n    .bind(&request.email)\n    .bind(chrono::Utc::now())\n    .fetch_one(&state.db)\n    .await?;\n    \n    Ok(Json(user))\n}\n\n#[tokio::main]\nasync fn main() -> anyhow::Result<()> {\n    tracing_subscriber::fmt::init();\n    \n    // Connect to database\n    let database_url = std::env::var(\"DATABASE_URL\")\n        .unwrap_or_else(|_| \"postgresql://localhost/myapp\".to_string());\n    \n    let db = sqlx::postgres::PgPoolOptions::new()\n        .max_connections(20)\n        .connect(&database_url)\n        .await?;\n    \n    // Run migrations\n    sqlx::migrate!(\"./migrations\").run(&db).await?;\n    \n    let state = AppState { db };\n    \n    // Public routes\n    let public_routes = Router::new()\n        .route(\"/health\", get(|| async { \"OK\" }));\n    \n    // Protected routes (require API key)\n    let protected_routes = Router::new()\n        .route(\"/users\", get(get_users_from_db).post(create_user_in_db))\n        .route_layer(middleware::from_fn(auth_middleware));\n    \n    // Combine all routes\n    let app = Router::new()\n        .merge(public_routes)\n        .merge(protected_routes)\n        .layer(middleware::from_fn(logging_middleware))\n        .layer(CorsLayer::permissive())\n        .with_state(state);\n    \n    let listener = tokio::net::TcpListener::bind(\"0.0.0.0:3000\").await?;\n    \n    println!(\"Server running on http://0.0.0.0:3000\");\n    axum::serve(listener, app).await?;\n    \n    Ok(())\n}\n```\n\n## JSON Handling with Serde\n\n### Advanced JSON Processing\n\n```rust\nuse serde::{Deserialize, Serialize, Deserializer};\nuse serde_json::{json, Value};\nuse std::collections::HashMap;\n\n#[derive(Debug, Serialize, Deserialize)]\nstruct ApiResponse<T> {\n    success: bool,\n    data: Option<T>,\n    error: Option<String>,\n    metadata: HashMap<String, Value>,\n}\n\n#[derive(Debug, Serialize, Deserialize)]\nstruct User {\n    id: u32,\n    #[serde(rename = \"firstName\")]\n    first_name: String,\n    #[serde(rename = \"lastName\")]\n    last_name: String,\n    email: String,\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    phone: Option<String>,\n    #[serde(with = \"date_format\")]\n    created_at: chrono::DateTime<chrono::Utc>,\n    #[serde(default)]\n    is_active: bool,\n}\n\n// Custom date format\nmod date_format {\n    use chrono::{DateTime, Utc};\n    use serde::{self, Deserialize, Deserializer, Serializer};\n    \n    const FORMAT: &str = \"%Y-%m-%d %H:%M:%S\";\n    \n    pub fn serialize<S>(\n        date: &DateTime<Utc>,\n        serializer: S,\n    ) -> Result<S::Ok, S::Error>\n    where\n        S: Serializer,\n    {\n        let s = format!(\"{}\", date.format(FORMAT));\n        serializer.serialize_str(&s)\n    }\n    \n    pub fn deserialize<'de, D>(\n        deserializer: D,\n    ) -> Result<DateTime<Utc>, D::Error>\n    where\n        D: Deserializer<'de>,\n    {\n        let s = String::deserialize(deserializer)?;\n        DateTime::parse_from_str(&s, FORMAT)\n            .map(|dt| dt.with_timezone(&Utc))\n            .map_err(serde::de::Error::custom)\n    }\n}\n\n// Working with dynamic JSON\nfn process_dynamic_json() -> Result<(), serde_json::Error> {\n    let json_string = r#\"{\n        \"users\": [\n            {\n                \"id\": 1,\n                \"firstName\": \"John\",\n                \"lastName\": \"Doe\",\n                \"email\": \"john@example.com\",\n                \"created_at\": \"2024-01-15 10:30:00\",\n                \"is_active\": true\n            },\n            {\n                \"id\": 2,\n                \"firstName\": \"Jane\",\n                \"lastName\": \"Smith\",\n                \"email\": \"jane@example.com\",\n                \"phone\": \"+1234567890\",\n                \"created_at\": \"2024-01-16 14:20:00\"\n            }\n        ],\n        \"total\": 2,\n        \"page\": 1\n    }\"#;\n    \n    // Parse to dynamic Value first\n    let value: Value = serde_json::from_str(json_string)?;\n    \n    // Extract specific fields\n    if let Some(total) = value[\"total\"].as_u64() {\n        println!(\"Total users: {}\", total);\n    }\n    \n    // Parse users array\n    if let Some(users_array) = value[\"users\"].as_array() {\n        for user_value in users_array {\n            let user: User = serde_json::from_value(user_value.clone())?;\n            println!(\"User: {} {} ({})\", user.first_name, user.last_name, user.email);\n        }\n    }\n    \n    Ok(())\n}\n\n// Building JSON responses\nfn build_api_responses() {\n    // Success response\n    let user = User {\n        id: 1,\n        first_name: \"John\".to_string(),\n        last_name: \"Doe\".to_string(),\n        email: \"john@example.com\".to_string(),\n        phone: Some(\"+1234567890\".to_string()),\n        created_at: chrono::Utc::now(),\n        is_active: true,\n    };\n    \n    let success_response = ApiResponse {\n        success: true,\n        data: Some(user),\n        error: None,\n        metadata: {\n            let mut map = HashMap::new();\n            map.insert(\"version\".to_string(), json!(\"1.0\"));\n            map.insert(\"timestamp\".to_string(), json!(chrono::Utc::now()));\n            map\n        },\n    };\n    \n    println!(\"Success: {}\", serde_json::to_string_pretty(&success_response).unwrap());\n    \n    // Error response\n    let error_response: ApiResponse<()> = ApiResponse {\n        success: false,\n        data: None,\n        error: Some(\"User not found\".to_string()),\n        metadata: HashMap::new(),\n    };\n    \n    println!(\"Error: {}\", serde_json::to_string_pretty(&error_response).unwrap());\n}\n\nfn main() {\n    process_dynamic_json().unwrap();\n    build_api_responses();\n}\n```\n\n## Best Practices for Async Web Development\n\n1. **Use connection pools** for databases\n2. **Implement proper error handling** with custom error types\n3. **Add middleware** for logging, authentication, CORS\n4. **Structure your code** with modules and proper separation of concerns\n5. **Use environment variables** for configuration\n6. **Implement health checks** for monitoring\n7. **Add request/response validation**\n8. **Use structured logging** with tracing\n\n## Quick Start Commands\n\n```bash\n# Create new web project\ncargo new my-web-app\ncd my-web-app\n\n# Add common web dependencies\ncargo add axum tokio serde serde_json\ncargo add --features full tokio\ncargo add --features derive serde\ncargo add --features json reqwest\n\n# For database integration\ncargo add sqlx --features runtime-tokio-rustls,postgres\n\n# For development\ncargo add --dev tokio-test\n\n# Run with auto-reload (install cargo-watch first)\ncargo install cargo-watch\ncargo watch -x run\n```\n\nThis gives you a solid foundation for building web applications in Rust with proper async patterns, error handling, and JSON processing!",
    "tags": [
      "web-development",
      "http-requests",
      "reqwest",
      "axum",
      "json",
      "serde",
      "async-programming",
      "web-servers",
      "networking"
    ],
    "instruction": "I'm building web applications and need to understand networking in Rust. How do I make HTTP requests, build web servers, and handle JSON? What are the best practices for async web development?"
  },
  {
    "output": "Excellent question! Rust has a rich ecosystem for file I/O and data serialization. Let me walk you through everything from basic file operations to working with different data formats.\n\n## Basic File I/O Operations\n\n### Reading and Writing Files\n\n```rust\nuse std::fs;\nuse std::io::{self, Read, Write, BufRead, BufReader, BufWriter};\nuse std::path::Path;\n\nfn basic_file_operations() -> io::Result<()> {\n    // Simple file reading (entire file at once)\n    let content = fs::read_to_string(\"config.txt\")?;\n    println!(\"File content: {}\", content);\n    \n    // Simple file writing (overwrites existing file)\n    fs::write(\"output.txt\", \"Hello, Rust!\")?;\n    \n    // Reading binary files\n    let binary_data = fs::read(\"image.png\")?;\n    println!(\"File size: {} bytes\", binary_data.len());\n    \n    // Writing binary data\n    let data = vec![0u8, 1, 2, 3, 4, 5];\n    fs::write(\"binary_output.bin\", &data)?;\n    \n    Ok(())\n}\n\n// More control with File handles\nuse std::fs::File;\n\nfn advanced_file_operations() -> io::Result<()> {\n    // Reading with buffering (memory efficient for large files)\n    let file = File::open(\"large_file.txt\")?;\n    let reader = BufReader::new(file);\n    \n    for (line_num, line) in reader.lines().enumerate() {\n        let line = line?;\n        println!(\"Line {}: {}\", line_num + 1, line);\n        \n        if line_num >= 10 {\n            break; // Only read first 10 lines\n        }\n    }\n    \n    // Writing with buffering\n    let file = File::create(\"buffered_output.txt\")?;\n    let mut writer = BufWriter::new(file);\n    \n    for i in 0..1000 {\n        writeln!(writer, \"Line number: {}\", i)?;\n    }\n    \n    writer.flush()?; // Ensure all data is written\n    \n    Ok(())\n}\n\n// Safe file operations with error handling\nfn safe_file_operations() {\n    match read_file_safely(\"config.json\") {\n        Ok(content) => println!(\"File content: {}\", content),\n        Err(e) => eprintln!(\"Failed to read file: {}\", e),\n    }\n    \n    if let Err(e) = write_file_safely(\"log.txt\", \"Application started\") {\n        eprintln!(\"Failed to write to log: {}\", e);\n    }\n}\n\nfn read_file_safely<P: AsRef<Path>>(path: P) -> io::Result<String> {\n    let path = path.as_ref();\n    \n    if !path.exists() {\n        return Err(io::Error::new(\n            io::ErrorKind::NotFound,\n            format!(\"File not found: {}\", path.display()),\n        ));\n    }\n    \n    fs::read_to_string(path)\n}\n\nfn write_file_safely<P: AsRef<Path>>(path: P, content: &str) -> io::Result<()> {\n    let path = path.as_ref();\n    \n    // Create parent directories if they don't exist\n    if let Some(parent) = path.parent() {\n        fs::create_dir_all(parent)?;\n    }\n    \n    fs::write(path, content)\n}\n\nfn main() {\n    if let Err(e) = basic_file_operations() {\n        eprintln!(\"Basic file operations failed: {}\", e);\n    }\n    \n    if let Err(e) = advanced_file_operations() {\n        eprintln!(\"Advanced file operations failed: {}\", e);\n    }\n    \n    safe_file_operations();\n}\n```\n\n## Working with JSON\n\n```rust\n// Cargo.toml:\n// [dependencies]\n// serde = { version = \"1.0\", features = [\"derive\"] }\n// serde_json = \"1.0\"\n\nuse serde::{Deserialize, Serialize};\nuse std::fs;\nuse std::collections::HashMap;\n\n#[derive(Debug, Serialize, Deserialize, Clone)]\nstruct Config {\n    app_name: String,\n    version: String,\n    debug: bool,\n    database: DatabaseConfig,\n    features: Vec<String>,\n    #[serde(default)]\n    optional_setting: Option<String>,\n}\n\n#[derive(Debug, Serialize, Deserialize, Clone)]\nstruct DatabaseConfig {\n    host: String,\n    port: u16,\n    database: String,\n    #[serde(skip_serializing_if = \"Option::is_none\")]\n    password: Option<String>,\n}\n\nimpl Default for Config {\n    fn default() -> Self {\n        Config {\n            app_name: \"MyApp\".to_string(),\n            version: \"1.0.0\".to_string(),\n            debug: false,\n            database: DatabaseConfig {\n                host: \"localhost\".to_string(),\n                port: 5432,\n                database: \"myapp\".to_string(),\n                password: None,\n            },\n            features: vec![\"auth\".to_string(), \"logging\".to_string()],\n            optional_setting: None,\n        }\n    }\n}\n\nfn json_operations() -> Result<(), Box<dyn std::error::Error>> {\n    // Create default config\n    let config = Config::default();\n    \n    // Serialize to JSON string\n    let json_string = serde_json::to_string_pretty(&config)?;\n    println!(\"Config as JSON:\\n{}\", json_string);\n    \n    // Write to file\n    fs::write(\"config.json\", &json_string)?;\n    \n    // Read from file\n    let file_content = fs::read_to_string(\"config.json\")?;\n    let loaded_config: Config = serde_json::from_str(&file_content)?;\n    \n    println!(\"Loaded config: {:?}\", loaded_config);\n    \n    // Working with dynamic JSON (when structure is unknown)\n    let dynamic_json = r#\"{\n        \"users\": [\n            {\"name\": \"Alice\", \"age\": 30},\n            {\"name\": \"Bob\", \"age\": 25}\n        ],\n        \"total\": 2\n    }\"#;\n    \n    let value: serde_json::Value = serde_json::from_str(dynamic_json)?;\n    \n    if let Some(users) = value[\"users\"].as_array() {\n        for user in users {\n            if let (Some(name), Some(age)) = (user[\"name\"].as_str(), user[\"age\"].as_u64()) {\n                println!(\"User: {} is {} years old\", name, age);\n            }\n        }\n    }\n    \n    // Merge JSON objects\n    let mut base_config: serde_json::Value = serde_json::to_value(&config)?;\n    let override_config: serde_json::Value = serde_json::from_str(r#\"{\n        \"debug\": true,\n        \"database\": {\n            \"host\": \"production.db.com\"\n        }\n    }\"#)?;\n    \n    merge_json(&mut base_config, override_config);\n    let merged_config: Config = serde_json::from_value(base_config)?;\n    \n    println!(\"Merged config: {:?}\", merged_config);\n    \n    Ok(())\n}\n\n// Helper function to merge JSON objects\nfn merge_json(base: &mut serde_json::Value, overlay: serde_json::Value) {\n    match (base, overlay) {\n        (serde_json::Value::Object(base_map), serde_json::Value::Object(overlay_map)) => {\n            for (key, value) in overlay_map {\n                if base_map.contains_key(&key) && base_map[&key].is_object() && value.is_object() {\n                    merge_json(&mut base_map[&key], value);\n                } else {\n                    base_map.insert(key, value);\n                }\n            }\n        }\n        _ => *base = overlay,\n    }\n}\n```\n\n## Working with YAML\n\n```rust\n// Cargo.toml:\n// [dependencies]\n// serde_yaml = \"0.9\"\n\nuse serde_yaml;\n\nfn yaml_operations() -> Result<(), Box<dyn std::error::Error>> {\n    let config = Config::default();\n    \n    // Serialize to YAML\n    let yaml_string = serde_yaml::to_string(&config)?;\n    println!(\"Config as YAML:\\n{}\", yaml_string);\n    \n    // Write to file\n    fs::write(\"config.yaml\", &yaml_string)?;\n    \n    // Read from file\n    let file_content = fs::read_to_string(\"config.yaml\")?;\n    let loaded_config: Config = serde_yaml::from_str(&file_content)?;\n    \n    println!(\"Loaded from YAML: {:?}\", loaded_config);\n    \n    // Working with multiple YAML documents in one file\n    let multi_doc_yaml = r#\"---\nname: Document 1\nvalue: 100\n---\nname: Document 2\nvalue: 200\n---\nname: Document 3\nvalue: 300\"#;\n    \n    #[derive(Debug, Deserialize)]\n    struct Document {\n        name: String,\n        value: u32,\n    }\n    \n    let documents: Vec<Document> = serde_yaml::Deserializer::from_str(multi_doc_yaml)\n        .map(|doc| Document::deserialize(doc))\n        .collect::<Result<Vec<_>, _>>()?;\n    \n    for doc in documents {\n        println!(\"Document: {} = {}\", doc.name, doc.value);\n    }\n    \n    Ok(())\n}\n```\n\n## Working with CSV\n\n```rust\n// Cargo.toml:\n// [dependencies]\n// csv = \"1.3\"\n\nuse csv::{Reader, Writer};\nuse std::error::Error;\nuse std::ffi::OsString;\n\n#[derive(Debug, Serialize, Deserialize)]\nstruct Employee {\n    id: u32,\n    name: String,\n    department: String,\n    salary: f64,\n    #[serde(with = \"date_format\")]\n    hire_date: chrono::NaiveDate,\n}\n\nmod date_format {\n    use chrono::NaiveDate;\n    use serde::{self, Deserialize, Deserializer, Serializer};\n    \n    const FORMAT: &str = \"%Y-%m-%d\";\n    \n    pub fn serialize<S>(date: &NaiveDate, serializer: S) -> Result<S::Ok, S::Error>\n    where\n        S: Serializer,\n    {\n        let s = format!(\"{}\", date.format(FORMAT));\n        serializer.serialize_str(&s)\n    }\n    \n    pub fn deserialize<'de, D>(deserializer: D) -> Result<NaiveDate, D::Error>\n    where\n        D: Deserializer<'de>,\n    {\n        let s = String::deserialize(deserializer)?;\n        NaiveDate::parse_from_str(&s, FORMAT).map_err(serde::de::Error::custom)\n    }\n}\n\nfn csv_operations() -> Result<(), Box<dyn Error>> {\n    // Create sample data\n    let employees = vec![\n        Employee {\n            id: 1,\n            name: \"Alice Johnson\".to_string(),\n            department: \"Engineering\".to_string(),\n            salary: 85000.0,\n            hire_date: chrono::NaiveDate::from_ymd_opt(2020, 1, 15).unwrap(),\n        },\n        Employee {\n            id: 2,\n            name: \"Bob Smith\".to_string(),\n            department: \"Marketing\".to_string(),\n            salary: 65000.0,\n            hire_date: chrono::NaiveDate::from_ymd_opt(2021, 3, 10).unwrap(),\n        },\n        Employee {\n            id: 3,\n            name: \"Carol Davis\".to_string(),\n            department: \"Engineering\".to_string(),\n            salary: 92000.0,\n            hire_date: chrono::NaiveDate::from_ymd_opt(2019, 11, 5).unwrap(),\n        },\n    ];\n    \n    // Write CSV file\n    let mut wtr = Writer::from_path(\"employees.csv\")?;\n    \n    for employee in &employees {\n        wtr.serialize(employee)?;\n    }\n    wtr.flush()?;\n    \n    println!(\"CSV file written successfully\");\n    \n    // Read CSV file\n    let mut rdr = Reader::from_path(\"employees.csv\")?;\n    \n    println!(\"Reading employees from CSV:\");\n    for result in rdr.deserialize() {\n        let employee: Employee = result?;\n        println!(\n            \"ID: {}, Name: {}, Dept: {}, Salary: ${:.2}, Hired: {}\",\n            employee.id,\n            employee.name,\n            employee.department,\n            employee.salary,\n            employee.hire_date\n        );\n    }\n    \n    // Filter and process CSV data\n    let mut rdr = Reader::from_path(\"employees.csv\")?;\n    let engineering_employees: Vec<Employee> = rdr\n        .deserialize()\n        .filter_map(|result| result.ok())\n        .filter(|emp: &Employee| emp.department == \"Engineering\")\n        .collect();\n    \n    println!(\"\\nEngineering employees:\");\n    for emp in engineering_employees {\n        println!(\"  {} - ${:.2}\", emp.name, emp.salary);\n    }\n    \n    // Calculate statistics\n    let mut rdr = Reader::from_path(\"employees.csv\")?;\n    let salaries: Vec<f64> = rdr\n        .deserialize()\n        .filter_map(|result: Result<Employee, _>| result.ok())\n        .map(|emp| emp.salary)\n        .collect();\n    \n    if !salaries.is_empty() {\n        let avg_salary = salaries.iter().sum::<f64>() / salaries.len() as f64;\n        let max_salary = salaries.iter().fold(0.0, |acc, &x| acc.max(x));\n        let min_salary = salaries.iter().fold(f64::INFINITY, |acc, &x| acc.min(x));\n        \n        println!(\"\\nSalary statistics:\");\n        println!(\"  Average: ${:.2}\", avg_salary);\n        println!(\"  Maximum: ${:.2}\", max_salary);\n        println!(\"  Minimum: ${:.2}\", min_salary);\n    }\n    \n    Ok(())\n}\n```\n\n## Working with TOML\n\n```rust\n// Cargo.toml:\n// [dependencies]\n// toml = \"0.8\"\n\nuse toml;\n\nfn toml_operations() -> Result<(), Box<dyn Error>> {\n    let config = Config::default();\n    \n    // Serialize to TOML\n    let toml_string = toml::to_string_pretty(&config)?;\n    println!(\"Config as TOML:\\n{}\", toml_string);\n    \n    // Write to file\n    fs::write(\"config.toml\", &toml_string)?;\n    \n    // Read from file\n    let file_content = fs::read_to_string(\"config.toml\")?;\n    let loaded_config: Config = toml::from_str(&file_content)?;\n    \n    println!(\"Loaded from TOML: {:?}\", loaded_config);\n    \n    Ok(())\n}\n```\n\n## Configuration Management System\n\n```rust\nuse std::path::PathBuf;\nuse thiserror::Error;\n\n#[derive(Error, Debug)]\npub enum ConfigError {\n    #[error(\"File not found: {0}\")]\n    FileNotFound(PathBuf),\n    \n    #[error(\"Parse error: {0}\")]\n    ParseError(String),\n    \n    #[error(\"IO error: {0}\")]\n    IoError(#[from] std::io::Error),\n    \n    #[error(\"JSON error: {0}\")]\n    JsonError(#[from] serde_json::Error),\n    \n    #[error(\"YAML error: {0}\")]\n    YamlError(#[from] serde_yaml::Error),\n    \n    #[error(\"TOML error: {0}\")]\n    TomlError(#[from] toml::de::Error),\n}\n\npub struct ConfigManager;\n\nimpl ConfigManager {\n    pub fn load_config<T>(path: &str) -> Result<T, ConfigError>\n    where\n        T: for<'de> Deserialize<'de>,\n    {\n        let path_buf = PathBuf::from(path);\n        \n        if !path_buf.exists() {\n            return Err(ConfigError::FileNotFound(path_buf));\n        }\n        \n        let content = fs::read_to_string(&path_buf)?;\n        \n        match path_buf.extension().and_then(|s| s.to_str()) {\n            Some(\"json\") => {\n                let config = serde_json::from_str(&content)?;\n                Ok(config)\n            }\n            Some(\"yaml\") | Some(\"yml\") => {\n                let config = serde_yaml::from_str(&content)?;\n                Ok(config)\n            }\n            Some(\"toml\") => {\n                let config = toml::from_str(&content)\n                    .map_err(|e| ConfigError::TomlError(e))?;\n                Ok(config)\n            }\n            _ => Err(ConfigError::ParseError(\"Unsupported file format\".to_string())),\n        }\n    }\n    \n    pub fn save_config<T>(config: &T, path: &str) -> Result<(), ConfigError>\n    where\n        T: Serialize,\n    {\n        let path_buf = PathBuf::from(path);\n        \n        // Create directory if it doesn't exist\n        if let Some(parent) = path_buf.parent() {\n            fs::create_dir_all(parent)?;\n        }\n        \n        let content = match path_buf.extension().and_then(|s| s.to_str()) {\n            Some(\"json\") => serde_json::to_string_pretty(config)?,\n            Some(\"yaml\") | Some(\"yml\") => serde_yaml::to_string(config)?,\n            Some(\"toml\") => toml::to_string_pretty(config)\n                .map_err(|e| ConfigError::ParseError(e.to_string()))?,\n            _ => return Err(ConfigError::ParseError(\"Unsupported file format\".to_string())),\n        };\n        \n        fs::write(path_buf, content)?;\n        Ok(())\n    }\n    \n    pub fn load_with_fallbacks<T>(paths: &[&str]) -> Result<T, ConfigError>\n    where\n        T: for<'de> Deserialize<'de> + Default,\n    {\n        for path in paths {\n            match Self::load_config(path) {\n                Ok(config) => return Ok(config),\n                Err(ConfigError::FileNotFound(_)) => continue,\n                Err(e) => return Err(e),\n            }\n        }\n        \n        // If no config files found, return default\n        Ok(T::default())\n    }\n}\n\n// Usage example\nfn config_management_example() {\n    let config = Config::default();\n    \n    // Save in different formats\n    if let Err(e) = ConfigManager::save_config(&config, \"config/app.json\") {\n        eprintln!(\"Failed to save JSON config: {}\", e);\n    }\n    \n    if let Err(e) = ConfigManager::save_config(&config, \"config/app.yaml\") {\n        eprintln!(\"Failed to save YAML config: {}\", e);\n    }\n    \n    if let Err(e) = ConfigManager::save_config(&config, \"config/app.toml\") {\n        eprintln!(\"Failed to save TOML config: {}\", e);\n    }\n    \n    // Load with fallbacks\n    let loaded_config: Config = ConfigManager::load_with_fallbacks(&[\n        \"config/local.json\",\n        \"config/app.json\",\n        \"config/default.yaml\",\n    ])\n    .unwrap_or_default();\n    \n    println!(\"Loaded config: {:?}\", loaded_config);\n}\n\nfn main() {\n    println!(\"=== JSON Operations ===\");\n    if let Err(e) = json_operations() {\n        eprintln!(\"JSON operations failed: {}\", e);\n    }\n    \n    println!(\"\\n=== YAML Operations ===\");\n    if let Err(e) = yaml_operations() {\n        eprintln!(\"YAML operations failed: {}\", e);\n    }\n    \n    println!(\"\\n=== CSV Operations ===\");\n    if let Err(e) = csv_operations() {\n        eprintln!(\"CSV operations failed: {}\", e);\n    }\n    \n    println!(\"\\n=== TOML Operations ===\");\n    if let Err(e) = toml_operations() {\n        eprintln!(\"TOML operations failed: {}\", e);\n    }\n    \n    println!(\"\\n=== Configuration Management ===\");\n    config_management_example();\n}\n```\n\n## Best Practices\n\n1. **Use `BufReader` and `BufWriter`** for large files\n2. **Handle errors properly** - don't unwrap file operations\n3. **Create parent directories** before writing files\n4. **Use appropriate data formats** - JSON for APIs, YAML for configs, CSV for data\n5. **Implement configuration layering** - defaults \u2192 environment \u2192 local overrides\n6. **Use streaming for large datasets** instead of loading everything into memory\n7. **Add validation** to your configuration structs\n8. **Use `#[serde(default)]`** for optional configuration fields\n\nThis gives you a complete toolkit for handling files and data serialization in Rust!",
    "tags": [
      "file-io",
      "serialization",
      "json",
      "yaml",
      "csv",
      "toml",
      "configuration",
      "data-formats",
      "serde",
      "file-handling"
    ],
    "instruction": "I need to work with files, read configurations, and handle different data formats like JSON, YAML, and CSV in my Rust application. What's the best way to handle file I/O and serialization?"
  },
  {
    "output": "Excellent question! Performance optimization in Rust requires understanding both the language's zero-cost abstractions and practical profiling techniques. Let me walk you through comprehensive performance optimization strategies.\n\n## Setting Up Benchmarking with Criterion\n\n### Basic Benchmarking Setup\n\n```rust\n// Cargo.toml\n// [dev-dependencies]\n// criterion = { version = \"0.5\", features = [\"html_reports\"] }\n\n// [[bench]]\n// name = \"my_benchmarks\"\n// harness = false\n\nuse criterion::{black_box, criterion_group, criterion_main, Criterion, BenchmarkId};\nuse std::collections::HashMap;\n\nfn fibonacci_recursive(n: u64) -> u64 {\n    match n {\n        0 | 1 => n,\n        _ => fibonacci_recursive(n - 1) + fibonacci_recursive(n - 2),\n    }\n}\n\nfn fibonacci_iterative(n: u64) -> u64 {\n    if n <= 1 {\n        return n;\n    }\n    \n    let mut a = 0;\n    let mut b = 1;\n    \n    for _ in 2..=n {\n        let temp = a + b;\n        a = b;\n        b = temp;\n    }\n    \n    b\n}\n\nfn fibonacci_memoized(n: u64, memo: &mut HashMap<u64, u64>) -> u64 {\n    if let Some(&result) = memo.get(&n) {\n        return result;\n    }\n    \n    let result = match n {\n        0 | 1 => n,\n        _ => fibonacci_memoized(n - 1, memo) + fibonacci_memoized(n - 2, memo),\n    };\n    \n    memo.insert(n, result);\n    result\n}\n\nfn bench_fibonacci(c: &mut Criterion) {\n    let mut group = c.benchmark_group(\"fibonacci\");\n    \n    for i in [10u64, 20, 30].iter() {\n        group.bench_with_input(BenchmarkId::new(\"recursive\", i), i, |b, i| {\n            b.iter(|| fibonacci_recursive(black_box(*i)))\n        });\n        \n        group.bench_with_input(BenchmarkId::new(\"iterative\", i), i, |b, i| {\n            b.iter(|| fibonacci_iterative(black_box(*i)))\n        });\n        \n        group.bench_with_input(BenchmarkId::new(\"memoized\", i), i, |b, i| {\n            b.iter(|| {\n                let mut memo = HashMap::new();\n                fibonacci_memoized(black_box(*i), &mut memo)\n            })\n        });\n    }\n    \n    group.finish();\n}\n\n// Benchmarking data structures\nfn bench_data_structures(c: &mut Criterion) {\n    let mut group = c.benchmark_group(\"data_structures\");\n    \n    let data: Vec<i32> = (0..1000).collect();\n    \n    // Vector operations\n    group.bench_function(\"vec_push\", |b| {\n        b.iter(|| {\n            let mut vec = Vec::new();\n            for i in 0..1000 {\n                vec.push(black_box(i));\n            }\n            vec\n        })\n    });\n    \n    group.bench_function(\"vec_with_capacity\", |b| {\n        b.iter(|| {\n            let mut vec = Vec::with_capacity(1000);\n            for i in 0..1000 {\n                vec.push(black_box(i));\n            }\n            vec\n        })\n    });\n    \n    // HashMap operations\n    group.bench_function(\"hashmap_insert\", |b| {\n        b.iter(|| {\n            let mut map = HashMap::new();\n            for &item in &data {\n                map.insert(black_box(item), black_box(item * 2));\n            }\n            map\n        })\n    });\n    \n    group.bench_function(\"hashmap_with_capacity\", |b| {\n        b.iter(|| {\n            let mut map = HashMap::with_capacity(1000);\n            for &item in &data {\n                map.insert(black_box(item), black_box(item * 2));\n            }\n            map\n        })\n    });\n    \n    group.finish();\n}\n\ncriterion_group!(benches, bench_fibonacci, bench_data_structures);\ncriterion_main!(benches);\n```\n\n## Memory Allocation Optimization\n\n### Avoiding Unnecessary Allocations\n\n```rust\nuse std::collections::HashMap;\nuse criterion::{black_box, Criterion};\n\n// BAD: Multiple allocations\nfn process_strings_bad(strings: &[&str]) -> Vec<String> {\n    let mut result = Vec::new();\n    \n    for s in strings {\n        let upper = s.to_uppercase();        // Allocation 1\n        let trimmed = upper.trim().to_string(); // Allocation 2\n        let prefixed = format!(\"PREFIX_{}\", trimmed); // Allocation 3\n        result.push(prefixed);               // Allocation 4\n    }\n    \n    result\n}\n\n// GOOD: Minimize allocations\nfn process_strings_good(strings: &[&str]) -> Vec<String> {\n    let mut result = Vec::with_capacity(strings.len()); // Pre-allocate\n    \n    for s in strings {\n        let mut processed = String::with_capacity(s.len() + 7); // \"PREFIX_\" = 7 chars\n        processed.push_str(\"PREFIX_\");\n        \n        for c in s.chars() {\n            processed.extend(c.to_uppercase()); // In-place transformation\n        }\n        \n        result.push(processed);\n    }\n    \n    result\n}\n\n// BETTER: Use iterators and avoid intermediate collections\nfn process_strings_best(strings: &[&str]) -> Vec<String> {\n    strings\n        .iter()\n        .map(|s| {\n            let mut result = String::with_capacity(s.len() + 7);\n            result.push_str(\"PREFIX_\");\n            result.extend(s.chars().flat_map(|c| c.to_uppercase()));\n            result\n        })\n        .collect()\n}\n\n// Memory pool pattern for repeated allocations\nstruct StringPool {\n    pool: Vec<String>,\n}\n\nimpl StringPool {\n    fn new() -> Self {\n        Self { pool: Vec::new() }\n    }\n    \n    fn get(&mut self) -> String {\n        self.pool.pop().unwrap_or_else(String::new)\n    }\n    \n    fn return_string(&mut self, mut s: String) {\n        s.clear(); // Clear content but keep capacity\n        if self.pool.len() < 100 { // Limit pool size\n            self.pool.push(s);\n        }\n    }\n}\n\nfn process_with_pool(strings: &[&str], pool: &mut StringPool) -> Vec<String> {\n    let mut results = Vec::with_capacity(strings.len());\n    \n    for s in strings {\n        let mut temp = pool.get();\n        temp.push_str(\"PREFIX_\");\n        temp.push_str(s);\n        \n        results.push(temp.clone());\n        pool.return_string(temp);\n    }\n    \n    results\n}\n```\n\n## CPU-Intensive Optimizations\n\n### SIMD and Vectorization\n\n```rust\n// Enable target features for SIMD\n#[cfg(target_arch = \"x86_64\")]\nuse std::arch::x86_64::*;\n\n// Scalar version\nfn sum_slice_scalar(data: &[f32]) -> f32 {\n    data.iter().sum()\n}\n\n// SIMD version (x86_64 only)\n#[cfg(target_arch = \"x86_64\")]\n#[target_feature(enable = \"avx2\")]\nunsafe fn sum_slice_simd(data: &[f32]) -> f32 {\n    let mut sum = _mm256_setzero_ps();\n    let chunks = data.chunks_exact(8);\n    let remainder = chunks.remainder();\n    \n    for chunk in chunks {\n        let values = _mm256_loadu_ps(chunk.as_ptr());\n        sum = _mm256_add_ps(sum, values);\n    }\n    \n    // Extract sum from SIMD register\n    let mut result = [0.0f32; 8];\n    _mm256_storeu_ps(result.as_mut_ptr(), sum);\n    let simd_sum: f32 = result.iter().sum();\n    \n    // Add remainder\n    simd_sum + remainder.iter().sum::<f32>()\n}\n\n// Cross-platform SIMD with std::simd (nightly)\n// #![feature(portable_simd)]\n// use std::simd::*;\n// \n// fn sum_slice_portable_simd(data: &[f32]) -> f32 {\n//     let (chunks, remainder) = data.as_chunks::<8>();\n//     let simd_sum: f32x8 = chunks\n//         .iter()\n//         .fold(f32x8::splat(0.0), |acc, chunk| acc + f32x8::from_array(*chunk));\n//     \n//     simd_sum.reduce_sum() + remainder.iter().sum::<f32>()\n// }\n\n// Benchmark SIMD vs scalar\nfn bench_simd_vs_scalar(c: &mut Criterion) {\n    let data: Vec<f32> = (0..10000).map(|i| i as f32).collect();\n    \n    let mut group = c.benchmark_group(\"simd_comparison\");\n    \n    group.bench_function(\"scalar\", |b| {\n        b.iter(|| sum_slice_scalar(black_box(&data)))\n    });\n    \n    #[cfg(target_arch = \"x86_64\")]\n    group.bench_function(\"simd\", |b| {\n        b.iter(|| unsafe { sum_slice_simd(black_box(&data)) })\n    });\n    \n    group.finish();\n}\n```\n\n### Efficient Data Structures and Algorithms\n\n```rust\nuse std::collections::{BTreeMap, HashMap};\nuse std::hash::{BuildHasher, Hasher};\nuse ahash::AHasher;\n\n// Custom hash function for better performance\n#[derive(Default)]\nstruct FastHasher;\n\nimpl BuildHasher for FastHasher {\n    type Hasher = AHasher;\n    \n    fn build_hasher(&self) -> Self::Hasher {\n        AHasher::default()\n    }\n}\n\n// Optimized data structure choices\nfn compare_data_structures(c: &mut Criterion) {\n    let data: Vec<(i32, i32)> = (0..1000).map(|i| (i, i * 2)).collect();\n    \n    let mut group = c.benchmark_group(\"data_structure_comparison\");\n    \n    // HashMap with default hasher\n    group.bench_function(\"hashmap_default\", |b| {\n        b.iter(|| {\n            let mut map = HashMap::new();\n            for &(k, v) in &data {\n                map.insert(black_box(k), black_box(v));\n            }\n            map\n        })\n    });\n    \n    // HashMap with fast hasher\n    group.bench_function(\"hashmap_fast\", |b| {\n        b.iter(|| {\n            let mut map = HashMap::with_hasher(FastHasher);\n            for &(k, v) in &data {\n                map.insert(black_box(k), black_box(v));\n            }\n            map\n        })\n    });\n    \n    // BTreeMap for comparison\n    group.bench_function(\"btreemap\", |b| {\n        b.iter(|| {\n            let mut map = BTreeMap::new();\n            for &(k, v) in &data {\n                map.insert(black_box(k), black_box(v));\n            }\n            map\n        })\n    });\n    \n    group.finish();\n}\n\n// Cache-friendly data layouts\n#[derive(Clone)]\nstruct Point3D {\n    x: f32,\n    y: f32,\n    z: f32,\n}\n\n// Array of Structures (AoS) - cache unfriendly for operations on single components\ntype PointsAoS = Vec<Point3D>;\n\n// Structure of Arrays (SoA) - cache friendly for component-wise operations\n#[derive(Clone)]\nstruct PointsSoA {\n    x: Vec<f32>,\n    y: Vec<f32>,\n    z: Vec<f32>,\n}\n\nimpl PointsSoA {\n    fn new(capacity: usize) -> Self {\n        Self {\n            x: Vec::with_capacity(capacity),\n            y: Vec::with_capacity(capacity),\n            z: Vec::with_capacity(capacity),\n        }\n    }\n    \n    fn push(&mut self, point: Point3D) {\n        self.x.push(point.x);\n        self.y.push(point.y);\n        self.z.push(point.z);\n    }\n    \n    fn len(&self) -> usize {\n        self.x.len()\n    }\n}\n\n// Benchmark cache performance\nfn bench_cache_performance(c: &mut Criterion) {\n    let points_aos: PointsAoS = (0..10000)\n        .map(|i| Point3D {\n            x: i as f32,\n            y: (i * 2) as f32,\n            z: (i * 3) as f32,\n        })\n        .collect();\n    \n    let mut points_soa = PointsSoA::new(10000);\n    for point in &points_aos {\n        points_soa.push(point.clone());\n    }\n    \n    let mut group = c.benchmark_group(\"cache_performance\");\n    \n    // Sum only X coordinates - AoS version\n    group.bench_function(\"sum_x_aos\", |b| {\n        b.iter(|| {\n            black_box(&points_aos)\n                .iter()\n                .map(|p| p.x)\n                .sum::<f32>()\n        })\n    });\n    \n    // Sum only X coordinates - SoA version (more cache friendly)\n    group.bench_function(\"sum_x_soa\", |b| {\n        b.iter(|| {\n            black_box(&points_soa.x)\n                .iter()\n                .sum::<f32>()\n        })\n    });\n    \n    group.finish();\n}\n```\n\n## Profiling and Analysis Tools\n\n### Using perf and flamegraph\n\n```bash\n# Install perf (Linux) and flamegraph\ncargo install flamegraph\n\n# Profile your application\ncargo flamegraph --bin my_app\n\n# Or for benchmarks\ncargo flamegraph --bench my_benchmarks\n\n# On macOS, use dtrace instead\ncargo flamegraph --dev --bin my_app\n```\n\n### Built-in Profiling Code\n\n```rust\nuse std::time::{Duration, Instant};\nuse std::collections::HashMap;\n\nstruct Profiler {\n    timings: HashMap<String, Vec<Duration>>,\n}\n\nimpl Profiler {\n    fn new() -> Self {\n        Self {\n            timings: HashMap::new(),\n        }\n    }\n    \n    fn time<F, R>(&mut self, name: &str, f: F) -> R\n    where\n        F: FnOnce() -> R,\n    {\n        let start = Instant::now();\n        let result = f();\n        let duration = start.elapsed();\n        \n        self.timings\n            .entry(name.to_string())\n            .or_insert_with(Vec::new)\n            .push(duration);\n        \n        result\n    }\n    \n    fn report(&self) {\n        println!(\"\\n=== Performance Report ===\");\n        for (name, times) in &self.timings {\n            let total: Duration = times.iter().sum();\n            let avg = total / times.len() as u32;\n            let min = times.iter().min().unwrap();\n            let max = times.iter().max().unwrap();\n            \n            println!(\n                \"{}: {} calls, avg: {:?}, min: {:?}, max: {:?}, total: {:?}\",\n                name, times.len(), avg, min, max, total\n            );\n        }\n    }\n}\n\n// Usage example\nfn profile_example() {\n    let mut profiler = Profiler::new();\n    \n    for i in 0..100 {\n        profiler.time(\"fibonacci_recursive\", || {\n            fibonacci_recursive(20)\n        });\n        \n        profiler.time(\"fibonacci_iterative\", || {\n            fibonacci_iterative(20)\n        });\n    }\n    \n    profiler.report();\n}\n```\n\n## Compile-Time Optimizations\n\n### Profile-Guided Optimization (PGO)\n\n```toml\n# Cargo.toml optimizations\n[profile.release]\nopt-level = 3                # Maximum optimization\nlto = \"fat\"                  # Link-time optimization\ncodegen-units = 1           # Single codegen unit for better optimization\npanic = \"abort\"             # Smaller binary, faster startup\nstrip = true                # Remove debug symbols\n\n# Profile-guided optimization\n[profile.release-pgo]\ninherits = \"release\"\nopt-level = 3\nlto = \"fat\"\ncodegen-units = 1\n\n# For PGO, you need to:\n# 1. Build with PGO instrumentation:\n# RUSTFLAGS=\"-Cprofile-generate=/tmp/pgo-data\" cargo build --release\n# 2. Run your application with representative workload\n# 3. Build with PGO optimization:\n# RUSTFLAGS=\"-Cprofile-use=/tmp/pgo-data\" cargo build --release\n```\n\n### Inline and Compiler Hints\n\n```rust\n// Force inlining for hot functions\n#[inline(always)]\nfn fast_math_operation(x: f64, y: f64) -> f64 {\n    x * y + x.sqrt()\n}\n\n// Prevent inlining for cold functions\n#[inline(never)]\nfn cold_error_handler(error: &str) {\n    eprintln!(\"Error: {}\", error);\n    // Heavy error handling logic\n}\n\n// Likely/unlikely branch hints\nfn process_with_hints(data: &[i32]) -> i32 {\n    let mut sum = 0;\n    \n    for &value in data {\n        if likely(value > 0) {  // Custom likely macro\n            sum += value;\n        } else if unlikely(value < -1000) {  // Custom unlikely macro\n            // Handle edge case\n            sum += value * 2;\n        }\n    }\n    \n    sum\n}\n\n// Custom likely/unlikely macros\nmacro_rules! likely {\n    ($expr:expr) => {\n        #[allow(unused_unsafe)]\n        unsafe {\n            std::intrinsics::likely($expr)\n        }\n    };\n}\n\nmacro_rules! unlikely {\n    ($expr:expr) => {\n        #[allow(unused_unsafe)]\n        unsafe {\n            std::intrinsics::unlikely($expr)\n        }\n    };\n}\n\n// Note: These intrinsics require nightly Rust\n// For stable Rust, use std::hint::black_box to prevent over-optimization\nuse std::hint::black_box;\n\nfn benchmark_safe(data: &[i32]) -> i32 {\n    let result = data.iter().sum();\n    black_box(result) // Prevent compiler from optimizing away the computation\n}\n```\n\n## Common Performance Pitfalls\n\n```rust\n// PITFALL 1: Unnecessary cloning\n// BAD\nfn process_strings_bad(strings: Vec<String>) -> Vec<String> {\n    strings.iter().map(|s| s.clone().to_uppercase()).collect()\n}\n\n// GOOD\nfn process_strings_good(strings: &[String]) -> Vec<String> {\n    strings.iter().map(|s| s.to_uppercase()).collect()\n}\n\n// PITFALL 2: Repeated allocations in loops\n// BAD\nfn concatenate_bad(strings: &[&str]) -> String {\n    let mut result = String::new();\n    for s in strings {\n        result = result + s; // Creates new String each time!\n    }\n    result\n}\n\n// GOOD\nfn concatenate_good(strings: &[&str]) -> String {\n    let total_len = strings.iter().map(|s| s.len()).sum();\n    let mut result = String::with_capacity(total_len);\n    for s in strings {\n        result.push_str(s);\n    }\n    result\n}\n\n// PITFALL 3: Using the wrong data structure\n// For frequent random access: Vec\n// For frequent insertion/removal at ends: VecDeque\n// For frequent insertion/removal in middle: LinkedList (rarely optimal)\n// For sorted data with range queries: BTreeMap\n// For fast lookup: HashMap\n\n// PITFALL 4: Not using iterators effectively\n// BAD\nfn filter_and_map_bad(data: &[i32]) -> Vec<i32> {\n    let mut filtered = Vec::new();\n    for &x in data {\n        if x > 0 {\n            filtered.push(x);\n        }\n    }\n    \n    let mut mapped = Vec::new();\n    for x in filtered {\n        mapped.push(x * 2);\n    }\n    \n    mapped\n}\n\n// GOOD\nfn filter_and_map_good(data: &[i32]) -> Vec<i32> {\n    data.iter()\n        .filter(|&&x| x > 0)\n        .map(|&x| x * 2)\n        .collect()\n}\n```\n\n## Performance Testing Setup\n\n```bash\n# Run benchmarks\ncargo bench\n\n# Generate detailed reports\ncargo bench -- --output-format html\n\n# Profile specific benchmark\ncargo bench fibonacci\n\n# Compare against baseline\ncargo bench -- --save-baseline main\n# ... make changes ...\ncargo bench -- --baseline main\n```\n\nThese techniques will help you build highly optimized Rust applications. Start with profiling to identify bottlenecks, then apply the appropriate optimization strategies!",
    "tags": [
      "performance",
      "optimization",
      "benchmarking",
      "criterion",
      "profiling",
      "simd",
      "memory-optimization",
      "cpu-optimization",
      "compile-optimizations"
    ],
    "instruction": "I'm working on performance-critical applications and need to optimize my Rust code. How do I profile, benchmark, and optimize for maximum performance? What are the common performance pitfalls to avoid?"
  },
  {
    "output": "Excellent question! Rust has unique design patterns that leverage its ownership system and type safety. Let me walk you through the most important patterns that every Rust developer should master.\n\n## 1. RAII Pattern (Resource Acquisition Is Initialization)\n\nRAII is fundamental to Rust - resources are tied to object lifetimes and automatically cleaned up.\n\n### Basic RAII Examples\n\n```rust\nuse std::fs::File;\nuse std::io::{self, Write};\nuse std::sync::{Mutex, MutexGuard};\n\n// File handles automatically close when dropped\nfn file_raii_example() -> io::Result<()> {\n    let mut file = File::create(\"output.txt\")?;\n    file.write_all(b\"Hello, RAII!\")?;\n    // File automatically closed when `file` goes out of scope\n    Ok(())\n}\n\n// Custom RAII guard\nstruct DatabaseConnection {\n    id: u32,\n}\n\nimpl DatabaseConnection {\n    fn new(id: u32) -> Self {\n        println!(\"Opening database connection {}\", id);\n        Self { id }\n    }\n    \n    fn execute_query(&self, query: &str) {\n        println!(\"Connection {}: Executing {}\", self.id, query);\n    }\n}\n\nimpl Drop for DatabaseConnection {\n    fn drop(&mut self) {\n        println!(\"Closing database connection {}\", self.id);\n    }\n}\n\n// Lock guards demonstrate RAII\nfn mutex_raii_example() {\n    let data = Mutex::new(vec![1, 2, 3]);\n    \n    {\n        let mut guard: MutexGuard<Vec<i32>> = data.lock().unwrap();\n        guard.push(4);\n        // Lock automatically released when guard goes out of scope\n    }\n    \n    println!(\"Data: {:?}\", data.lock().unwrap());\n}\n\n// Custom RAII for complex resource management\nstruct ResourceManager {\n    resources: Vec<String>,\n}\n\nimpl ResourceManager {\n    fn new() -> Self {\n        println!(\"Acquiring system resources\");\n        Self {\n            resources: vec![\"GPU\".to_string(), \"Network\".to_string()],\n        }\n    }\n    \n    fn use_resource(&self, name: &str) {\n        if self.resources.contains(&name.to_string()) {\n            println!(\"Using resource: {}\", name);\n        }\n    }\n}\n\nimpl Drop for ResourceManager {\n    fn drop(&mut self) {\n        println!(\"Releasing resources: {:?}\", self.resources);\n    }\n}\n\nfn raii_example() {\n    let _db = DatabaseConnection::new(1);\n    let _manager = ResourceManager::new();\n    \n    // Both resources automatically cleaned up at end of scope\n    println!(\"Function ending - resources will be cleaned up\");\n}\n```\n\n## 2. Builder Pattern\n\nThe Builder pattern is excellent for constructing complex objects with many optional parameters.\n\n### Basic Builder Implementation\n\n```rust\n#[derive(Debug, Clone)]\nstruct HttpRequest {\n    method: String,\n    url: String,\n    headers: Vec<(String, String)>,\n    body: Option<String>,\n    timeout: std::time::Duration,\n    retry_count: u32,\n}\n\nstruct HttpRequestBuilder {\n    method: Option<String>,\n    url: Option<String>,\n    headers: Vec<(String, String)>,\n    body: Option<String>,\n    timeout: std::time::Duration,\n    retry_count: u32,\n}\n\nimpl HttpRequestBuilder {\n    fn new() -> Self {\n        Self {\n            method: None,\n            url: None,\n            headers: Vec::new(),\n            body: None,\n            timeout: std::time::Duration::from_secs(30),\n            retry_count: 3,\n        }\n    }\n    \n    fn method(mut self, method: impl Into<String>) -> Self {\n        self.method = Some(method.into());\n        self\n    }\n    \n    fn url(mut self, url: impl Into<String>) -> Self {\n        self.url = Some(url.into());\n        self\n    }\n    \n    fn header(mut self, key: impl Into<String>, value: impl Into<String>) -> Self {\n        self.headers.push((key.into(), value.into()));\n        self\n    }\n    \n    fn body(mut self, body: impl Into<String>) -> Self {\n        self.body = Some(body.into());\n        self\n    }\n    \n    fn timeout(mut self, timeout: std::time::Duration) -> Self {\n        self.timeout = timeout;\n        self\n    }\n    \n    fn retry_count(mut self, count: u32) -> Self {\n        self.retry_count = count;\n        self\n    }\n    \n    fn build(self) -> Result<HttpRequest, String> {\n        let method = self.method.ok_or(\"Method is required\")?;\n        let url = self.url.ok_or(\"URL is required\")?;\n        \n        Ok(HttpRequest {\n            method,\n            url,\n            headers: self.headers,\n            body: self.body,\n            timeout: self.timeout,\n            retry_count: self.retry_count,\n        })\n    }\n}\n\nimpl HttpRequest {\n    fn builder() -> HttpRequestBuilder {\n        HttpRequestBuilder::new()\n    }\n}\n\nfn builder_example() {\n    let request = HttpRequest::builder()\n        .method(\"POST\")\n        .url(\"https://api.example.com/users\")\n        .header(\"Content-Type\", \"application/json\")\n        .header(\"Authorization\", \"Bearer token123\")\n        .body(r#\"{\"name\": \"Alice\", \"email\": \"alice@example.com\"}\"#)\n        .timeout(std::time::Duration::from_secs(60))\n        .retry_count(5)\n        .build()\n        .expect(\"Failed to build request\");\n    \n    println!(\"Built request: {:?}\", request);\n}\n```\n\n### Advanced Builder with Type State Pattern\n\n```rust\n// Type-state builder ensures required fields at compile time\nstruct DatabaseConfigBuilder<State> {\n    host: Option<String>,\n    port: Option<u16>,\n    database: Option<String>,\n    _state: std::marker::PhantomData<State>,\n}\n\n// States\nstruct NoHost;\nstruct HasHost;\nstruct HasPort;\nstruct Complete;\n\nimpl DatabaseConfigBuilder<NoHost> {\n    fn new() -> Self {\n        Self {\n            host: None,\n            port: None,\n            database: None,\n            _state: std::marker::PhantomData,\n        }\n    }\n    \n    fn host(self, host: impl Into<String>) -> DatabaseConfigBuilder<HasHost> {\n        DatabaseConfigBuilder {\n            host: Some(host.into()),\n            port: self.port,\n            database: self.database,\n            _state: std::marker::PhantomData,\n        }\n    }\n}\n\nimpl DatabaseConfigBuilder<HasHost> {\n    fn port(self, port: u16) -> DatabaseConfigBuilder<HasPort> {\n        DatabaseConfigBuilder {\n            host: self.host,\n            port: Some(port),\n            database: self.database,\n            _state: std::marker::PhantomData,\n        }\n    }\n}\n\nimpl DatabaseConfigBuilder<HasPort> {\n    fn database(self, db: impl Into<String>) -> DatabaseConfigBuilder<Complete> {\n        DatabaseConfigBuilder {\n            host: self.host,\n            port: self.port,\n            database: Some(db.into()),\n            _state: std::marker::PhantomData,\n        }\n    }\n}\n\n#[derive(Debug)]\nstruct DatabaseConfig {\n    host: String,\n    port: u16,\n    database: String,\n}\n\nimpl DatabaseConfigBuilder<Complete> {\n    fn build(self) -> DatabaseConfig {\n        DatabaseConfig {\n            host: self.host.unwrap(),\n            port: self.port.unwrap(),\n            database: self.database.unwrap(),\n        }\n    }\n}\n\nfn type_state_builder_example() {\n    // This enforces the correct order at compile time\n    let config = DatabaseConfigBuilder::new()\n        .host(\"localhost\")\n        .port(5432)\n        .database(\"myapp\")\n        .build();\n    \n    println!(\"Database config: {:?}\", config);\n    \n    // This won't compile - missing required steps:\n    // let invalid = DatabaseConfigBuilder::new().build(); // ERROR!\n}\n```\n\n## 3. State Machine Pattern\n\nState machines are powerful for modeling complex workflows and ensuring valid state transitions.\n\n### Type-Safe State Machine\n\n```rust\n// States as types\nstruct Disconnected;\nstruct Connecting;\nstruct Connected;\nstruct Error;\n\n// Connection with state\nstruct Connection<State> {\n    address: String,\n    _state: std::marker::PhantomData<State>,\n}\n\n// State-specific implementations\nimpl Connection<Disconnected> {\n    fn new(address: String) -> Self {\n        Self {\n            address,\n            _state: std::marker::PhantomData,\n        }\n    }\n    \n    fn connect(self) -> Result<Connection<Connected>, Connection<Error>> {\n        println!(\"Connecting to {}...\", self.address);\n        \n        // Simulate connection logic\n        if self.address.contains(\"localhost\") {\n            Ok(Connection {\n                address: self.address,\n                _state: std::marker::PhantomData,\n            })\n        } else {\n            Err(Connection {\n                address: self.address,\n                _state: std::marker::PhantomData,\n            })\n        }\n    }\n}\n\nimpl Connection<Connected> {\n    fn send_data(&self, data: &str) {\n        println!(\"Sending to {}: {}\", self.address, data);\n    }\n    \n    fn disconnect(self) -> Connection<Disconnected> {\n        println!(\"Disconnecting from {}\", self.address);\n        Connection {\n            address: self.address,\n            _state: std::marker::PhantomData,\n        }\n    }\n}\n\nimpl Connection<Error> {\n    fn retry(self) -> Connection<Disconnected> {\n        println!(\"Retrying connection to {}\", self.address);\n        Connection {\n            address: self.address,\n            _state: std::marker::PhantomData,\n        }\n    }\n    \n    fn get_error(&self) -> String {\n        format!(\"Failed to connect to {}\", self.address)\n    }\n}\n\nfn state_machine_example() {\n    let conn = Connection::new(\"localhost:8080\".to_string());\n    \n    match conn.connect() {\n        Ok(connected) => {\n            connected.send_data(\"Hello, server!\");\n            let disconnected = connected.disconnect();\n            println!(\"Connection cycle complete\");\n        }\n        Err(error) => {\n            println!(\"Connection failed: {}\", error.get_error());\n            let retry_conn = error.retry();\n        }\n    }\n}\n```\n\n### Runtime State Machine with Enums\n\n```rust\n#[derive(Debug, Clone)]\nenum OrderState {\n    Pending { items: Vec<String> },\n    Processing { order_id: u32, items: Vec<String> },\n    Shipped { order_id: u32, tracking_number: String },\n    Delivered { order_id: u32, delivery_date: String },\n    Cancelled { reason: String },\n}\n\n#[derive(Debug)]\nstruct Order {\n    state: OrderState,\n}\n\nimpl Order {\n    fn new(items: Vec<String>) -> Self {\n        Self {\n            state: OrderState::Pending { items },\n        }\n    }\n    \n    fn process(self, order_id: u32) -> Result<Self, String> {\n        match self.state {\n            OrderState::Pending { items } => Ok(Self {\n                state: OrderState::Processing { order_id, items },\n            }),\n            _ => Err(\"Can only process pending orders\".to_string()),\n        }\n    }\n    \n    fn ship(self, tracking_number: String) -> Result<Self, String> {\n        match self.state {\n            OrderState::Processing { order_id, .. } => Ok(Self {\n                state: OrderState::Shipped { order_id, tracking_number },\n            }),\n            _ => Err(\"Can only ship processing orders\".to_string()),\n        }\n    }\n    \n    fn deliver(self, delivery_date: String) -> Result<Self, String> {\n        match self.state {\n            OrderState::Shipped { order_id, .. } => Ok(Self {\n                state: OrderState::Delivered { order_id, delivery_date },\n            }),\n            _ => Err(\"Can only deliver shipped orders\".to_string()),\n        }\n    }\n    \n    fn cancel(self, reason: String) -> Self {\n        Self {\n            state: OrderState::Cancelled { reason },\n        }\n    }\n    \n    fn get_status(&self) -> String {\n        match &self.state {\n            OrderState::Pending { items } => format!(\"Pending: {} items\", items.len()),\n            OrderState::Processing { order_id, .. } => format!(\"Processing order {}\", order_id),\n            OrderState::Shipped { tracking_number, .. } => format!(\"Shipped: {}\", tracking_number),\n            OrderState::Delivered { delivery_date, .. } => format!(\"Delivered on {}\", delivery_date),\n            OrderState::Cancelled { reason } => format!(\"Cancelled: {}\", reason),\n        }\n    }\n}\n\nfn order_state_machine_example() {\n    let items = vec![\"Laptop\".to_string(), \"Mouse\".to_string()];\n    let order = Order::new(items);\n    \n    println!(\"Initial: {}\", order.get_status());\n    \n    let order = order.process(12345).expect(\"Failed to process\");\n    println!(\"After processing: {}\", order.get_status());\n    \n    let order = order.ship(\"TRACK123\".to_string()).expect(\"Failed to ship\");\n    println!(\"After shipping: {}\", order.get_status());\n    \n    let order = order.deliver(\"2024-01-15\".to_string()).expect(\"Failed to deliver\");\n    println!(\"Final: {}\", order.get_status());\n}\n```\n\n## 4. Newtype Pattern\n\nNewtype provides type safety and prevents mixing up similar types.\n\n```rust\n// Basic newtype\n#[derive(Debug, Clone, Copy, PartialEq, Eq, PartialOrd, Ord)]\nstruct UserId(u64);\n\n#[derive(Debug, Clone, Copy, PartialEq, Eq, PartialOrd, Ord)]\nstruct ProductId(u64);\n\n#[derive(Debug, Clone, Copy, PartialEq, Eq)]\nstruct Price(u32); // Price in cents\n\nimpl Price {\n    fn new(dollars: u32, cents: u32) -> Self {\n        Self(dollars * 100 + cents)\n    }\n    \n    fn to_dollars(&self) -> f64 {\n        self.0 as f64 / 100.0\n    }\n    \n    fn add(&self, other: Price) -> Price {\n        Price(self.0 + other.0)\n    }\n}\n\n// Newtype with validation\n#[derive(Debug, Clone, PartialEq, Eq)]\nstruct Email(String);\n\nimpl Email {\n    fn new(email: String) -> Result<Self, String> {\n        if email.contains('@') && email.contains('.') {\n            Ok(Self(email))\n        } else {\n            Err(\"Invalid email format\".to_string())\n        }\n    }\n    \n    fn as_str(&self) -> &str {\n        &self.0\n    }\n}\n\n// Newtype for units\n#[derive(Debug, Clone, Copy, PartialEq, PartialOrd)]\nstruct Meters(f64);\n\n#[derive(Debug, Clone, Copy, PartialEq, PartialOrd)]\nstruct Feet(f64);\n\nimpl Meters {\n    fn to_feet(&self) -> Feet {\n        Feet(self.0 * 3.28084)\n    }\n}\n\nimpl Feet {\n    fn to_meters(&self) -> Meters {\n        Meters(self.0 / 3.28084)\n    }\n}\n\nfn newtype_example() {\n    let user_id = UserId(123);\n    let product_id = ProductId(456);\n    \n    // This prevents accidentally mixing up IDs:\n    // let result = user_id == product_id; // Compile error!\n    \n    let price1 = Price::new(10, 50); // $10.50\n    let price2 = Price::new(5, 25);  // $5.25\n    let total = price1.add(price2);\n    \n    println!(\"Total price: ${:.2}\", total.to_dollars());\n    \n    let email = Email::new(\"user@example.com\".to_string()).unwrap();\n    println!(\"Email: {}\", email.as_str());\n    \n    let distance_m = Meters(100.0);\n    let distance_ft = distance_m.to_feet();\n    println!(\"{}m = {}ft\", distance_m.0, distance_ft.0);\n}\n```\n\n## 5. Strategy Pattern with Traits\n\n```rust\n// Strategy trait\ntrait PaymentProcessor {\n    fn process_payment(&self, amount: f64, currency: &str) -> Result<String, String>;\n    fn get_fee(&self, amount: f64) -> f64;\n}\n\n// Concrete strategies\nstruct CreditCardProcessor {\n    fee_rate: f64,\n}\n\nstruct PayPalProcessor {\n    fee_rate: f64,\n}\n\nstruct BankTransferProcessor;\n\nimpl PaymentProcessor for CreditCardProcessor {\n    fn process_payment(&self, amount: f64, currency: &str) -> Result<String, String> {\n        if amount <= 0.0 {\n            return Err(\"Invalid amount\".to_string());\n        }\n        Ok(format!(\"Credit card payment of {:.2} {} processed\", amount, currency))\n    }\n    \n    fn get_fee(&self, amount: f64) -> f64 {\n        amount * self.fee_rate\n    }\n}\n\nimpl PaymentProcessor for PayPalProcessor {\n    fn process_payment(&self, amount: f64, currency: &str) -> Result<String, String> {\n        if amount <= 0.0 {\n            return Err(\"Invalid amount\".to_string());\n        }\n        Ok(format!(\"PayPal payment of {:.2} {} processed\", amount, currency))\n    }\n    \n    fn get_fee(&self, amount: f64) -> f64 {\n        amount * self.fee_rate + 0.30 // Fixed fee + percentage\n    }\n}\n\nimpl PaymentProcessor for BankTransferProcessor {\n    fn process_payment(&self, amount: f64, currency: &str) -> Result<String, String> {\n        if amount < 10.0 {\n            return Err(\"Minimum amount for bank transfer is 10.00\".to_string());\n        }\n        Ok(format!(\"Bank transfer of {:.2} {} processed\", amount, currency))\n    }\n    \n    fn get_fee(&self, amount: f64) -> f64 {\n        if amount > 1000.0 { 0.0 } else { 5.0 } // Free for large amounts\n    }\n}\n\n// Context that uses strategy\nstruct PaymentService {\n    processor: Box<dyn PaymentProcessor>,\n}\n\nimpl PaymentService {\n    fn new(processor: Box<dyn PaymentProcessor>) -> Self {\n        Self { processor }\n    }\n    \n    fn change_processor(&mut self, processor: Box<dyn PaymentProcessor>) {\n        self.processor = processor;\n    }\n    \n    fn process_payment(&self, amount: f64, currency: &str) -> Result<String, String> {\n        let fee = self.processor.get_fee(amount);\n        let total = amount + fee;\n        \n        match self.processor.process_payment(amount, currency) {\n            Ok(result) => Ok(format!(\"{} (Fee: {:.2}, Total: {:.2})\", result, fee, total)),\n            Err(e) => Err(e),\n        }\n    }\n}\n\nfn strategy_example() {\n    let credit_card = CreditCardProcessor { fee_rate: 0.03 };\n    let paypal = PayPalProcessor { fee_rate: 0.025 };\n    let bank_transfer = BankTransferProcessor;\n    \n    let mut payment_service = PaymentService::new(Box::new(credit_card));\n    \n    println!(\"{}\", payment_service.process_payment(100.0, \"USD\").unwrap());\n    \n    payment_service.change_processor(Box::new(paypal));\n    println!(\"{}\", payment_service.process_payment(100.0, \"USD\").unwrap());\n    \n    payment_service.change_processor(Box::new(bank_transfer));\n    println!(\"{}\", payment_service.process_payment(1500.0, \"USD\").unwrap());\n}\n```\n\n## 6. Command Pattern\n\n```rust\n// Command trait\ntrait Command {\n    fn execute(&self);\n    fn undo(&self);\n    fn description(&self) -> String;\n}\n\n// Receiver\nstruct Document {\n    content: String,\n    history: Vec<String>,\n}\n\nimpl Document {\n    fn new() -> Self {\n        Self {\n            content: String::new(),\n            history: Vec::new(),\n        }\n    }\n    \n    fn insert_text(&mut self, text: &str, position: usize) {\n        self.history.push(self.content.clone());\n        self.content.insert_str(position, text);\n    }\n    \n    fn delete_text(&mut self, start: usize, end: usize) {\n        self.history.push(self.content.clone());\n        self.content.drain(start..end);\n    }\n    \n    fn restore(&mut self, content: String) {\n        self.content = content;\n    }\n    \n    fn get_content(&self) -> &str {\n        &self.content\n    }\n}\n\n// Concrete commands\nstruct InsertCommand {\n    document: std::rc::Rc<std::cell::RefCell<Document>>,\n    text: String,\n    position: usize,\n    previous_content: std::cell::RefCell<Option<String>>,\n}\n\nimpl InsertCommand {\n    fn new(document: std::rc::Rc<std::cell::RefCell<Document>>, text: String, position: usize) -> Self {\n        Self {\n            document,\n            text,\n            position,\n            previous_content: std::cell::RefCell::new(None),\n        }\n    }\n}\n\nimpl Command for InsertCommand {\n    fn execute(&self) {\n        let mut doc = self.document.borrow_mut();\n        *self.previous_content.borrow_mut() = Some(doc.get_content().to_string());\n        doc.insert_text(&self.text, self.position);\n    }\n    \n    fn undo(&self) {\n        if let Some(ref content) = *self.previous_content.borrow() {\n            self.document.borrow_mut().restore(content.clone());\n        }\n    }\n    \n    fn description(&self) -> String {\n        format!(\"Insert '{}' at position {}\", self.text, self.position)\n    }\n}\n\n// Command invoker (like a text editor)\nstruct Editor {\n    document: std::rc::Rc<std::cell::RefCell<Document>>,\n    command_history: Vec<Box<dyn Command>>,\n    current_position: usize,\n}\n\nimpl Editor {\n    fn new() -> Self {\n        Self {\n            document: std::rc::Rc::new(std::cell::RefCell::new(Document::new())),\n            command_history: Vec::new(),\n            current_position: 0,\n        }\n    }\n    \n    fn execute_command(&mut self, command: Box<dyn Command>) {\n        println!(\"Executing: {}\", command.description());\n        command.execute();\n        \n        // Remove any commands after current position (for redo functionality)\n        self.command_history.truncate(self.current_position);\n        self.command_history.push(command);\n        self.current_position += 1;\n    }\n    \n    fn undo(&mut self) {\n        if self.current_position > 0 {\n            self.current_position -= 1;\n            let command = &self.command_history[self.current_position];\n            println!(\"Undoing: {}\", command.description());\n            command.undo();\n        }\n    }\n    \n    fn redo(&mut self) {\n        if self.current_position < self.command_history.len() {\n            let command = &self.command_history[self.current_position];\n            println!(\"Redoing: {}\", command.description());\n            command.execute();\n            self.current_position += 1;\n        }\n    }\n    \n    fn get_content(&self) -> String {\n        self.document.borrow().get_content().to_string()\n    }\n}\n\nfn command_example() {\n    let mut editor = Editor::new();\n    \n    let insert1 = InsertCommand::new(\n        editor.document.clone(),\n        \"Hello, \".to_string(),\n        0,\n    );\n    \n    let insert2 = InsertCommand::new(\n        editor.document.clone(),\n        \"World!\".to_string(),\n        7,\n    );\n    \n    editor.execute_command(Box::new(insert1));\n    println!(\"Content: '{}'\", editor.get_content());\n    \n    editor.execute_command(Box::new(insert2));\n    println!(\"Content: '{}'\", editor.get_content());\n    \n    editor.undo();\n    println!(\"After undo: '{}'\", editor.get_content());\n    \n    editor.redo();\n    println!(\"After redo: '{}'\", editor.get_content());\n}\n\nfn main() {\n    println!(\"=== RAII Pattern ===\");\n    raii_example();\n    \n    println!(\"\\n=== Builder Pattern ===\");\n    builder_example();\n    \n    println!(\"\\n=== Type State Builder ===\");\n    type_state_builder_example();\n    \n    println!(\"\\n=== State Machine ===\");\n    state_machine_example();\n    \n    println!(\"\\n=== Order State Machine ===\");\n    order_state_machine_example();\n    \n    println!(\"\\n=== Newtype Pattern ===\");\n    newtype_example();\n    \n    println!(\"\\n=== Strategy Pattern ===\");\n    strategy_example();\n    \n    println!(\"\\n=== Command Pattern ===\");\n    command_example();\n}\n```\n\nThese patterns form the foundation of idiomatic Rust code. Each pattern leverages Rust's type system to provide safety, performance, and expressiveness. The key is choosing the right pattern for your specific use case and understanding how Rust's ownership system enhances traditional design patterns.",
    "tags": [
      "design-patterns",
      "raii",
      "builder-pattern",
      "state-machine",
      "newtype",
      "strategy-pattern",
      "command-pattern",
      "type-safety",
      "rust-idioms"
    ],
    "instruction": "I want to understand Rust's design patterns and common idioms. What are the most important patterns every Rust developer should know? How do I implement patterns like Builder, State Machine, and RAII effectively?"
  },
  {
    "output": "Excellent question! Unsafe Rust and FFI are powerful tools for systems programming and interoperating with existing C code. Let me show you when to use unsafe, how to do it safely, and comprehensive FFI patterns.\n\n## Understanding When to Use Unsafe\n\n### The Five Unsafe Superpowers\n\nUnsafe Rust gives you five additional capabilities:\n\n```rust\n// 1. Dereference raw pointers\n// 2. Call unsafe functions\n// 3. Implement unsafe traits\n// 4. Access/modify mutable static variables\n// 5. Access fields of unions\n\nfn unsafe_demonstrations() {\n    // 1. Raw pointer dereferencing\n    let x = 42;\n    let raw_ptr = &x as *const i32;\n    let value = unsafe { *raw_ptr }; // Dereference raw pointer\n    println!(\"Value from raw pointer: {}\", value);\n    \n    // 2. Calling unsafe functions\n    let slice = &[1, 2, 3, 4, 5];\n    let element = unsafe { slice.get_unchecked(2) }; // Skip bounds checking\n    println!(\"Element: {}\", element);\n    \n    // 3. Mutable static (shared global state)\n    static mut COUNTER: i32 = 0;\n    unsafe {\n        COUNTER += 1;\n        println!(\"Counter: {}\", COUNTER);\n    }\n}\n```\n\n### Safe Abstractions Over Unsafe Code\n\nThe key principle: wrap unsafe code in safe APIs that maintain Rust's guarantees.\n\n```rust\nuse std::ptr;\nuse std::alloc::{alloc, dealloc, Layout};\n\n// GOOD: Safe wrapper around unsafe operations\nstruct SafeBuffer {\n    ptr: *mut u8,\n    len: usize,\n    capacity: usize,\n}\n\nimpl SafeBuffer {\n    fn new(capacity: usize) -> Self {\n        let layout = Layout::array::<u8>(capacity).expect(\"Invalid layout\");\n        let ptr = unsafe { alloc(layout) };\n        \n        if ptr.is_null() {\n            panic!(\"Allocation failed\");\n        }\n        \n        Self {\n            ptr,\n            len: 0,\n            capacity,\n        }\n    }\n    \n    fn push(&mut self, value: u8) -> Result<(), &'static str> {\n        if self.len >= self.capacity {\n            return Err(\"Buffer full\");\n        }\n        \n        unsafe {\n            // SAFETY: We've checked bounds above, and ptr is valid\n            ptr::write(self.ptr.add(self.len), value);\n        }\n        self.len += 1;\n        Ok(())\n    }\n    \n    fn get(&self, index: usize) -> Option<u8> {\n        if index < self.len {\n            unsafe {\n                // SAFETY: index is within bounds\n                Some(ptr::read(self.ptr.add(index)))\n            }\n        } else {\n            None\n        }\n    }\n    \n    fn as_slice(&self) -> &[u8] {\n        unsafe {\n            // SAFETY: ptr is valid, len is correct\n            std::slice::from_raw_parts(self.ptr, self.len)\n        }\n    }\n}\n\nimpl Drop for SafeBuffer {\n    fn drop(&mut self) {\n        unsafe {\n            let layout = Layout::array::<u8>(self.capacity).expect(\"Invalid layout\");\n            dealloc(self.ptr, layout);\n        }\n    }\n}\n\n// The public API is completely safe\nfn safe_buffer_example() {\n    let mut buffer = SafeBuffer::new(10);\n    \n    for i in 0..5 {\n        buffer.push(i).unwrap();\n    }\n    \n    println!(\"Buffer contents: {:?}\", buffer.as_slice());\n    \n    if let Some(value) = buffer.get(2) {\n        println!(\"Element at index 2: {}\", value);\n    }\n}\n```\n\n## C Interop and FFI Basics\n\n### Calling C Functions from Rust\n\n```rust\n// External C function declarations\nextern \"C\" {\n    // Standard C library functions\n    fn strlen(s: *const std::os::raw::c_char) -> std::os::raw::c_ulong;\n    fn strcpy(dest: *mut std::os::raw::c_char, src: *const std::os::raw::c_char) -> *mut std::os::raw::c_char;\n    fn malloc(size: std::os::raw::c_ulong) -> *mut std::os::raw::c_void;\n    fn free(ptr: *mut std::os::raw::c_void);\n    \n    // Math functions\n    fn pow(base: f64, exponent: f64) -> f64;\n    fn sin(x: f64) -> f64;\n    fn cos(x: f64) -> f64;\n}\n\n// Safe wrapper for C string operations\nuse std::ffi::{CString, CStr};\nuse std::os::raw::{c_char, c_void, c_ulong};\n\nfn c_string_operations() {\n    // Convert Rust string to C string\n    let rust_string = \"Hello, C world!\";\n    let c_string = CString::new(rust_string).expect(\"CString creation failed\");\n    \n    // Call C strlen function\n    let length = unsafe {\n        strlen(c_string.as_ptr())\n    };\n    \n    println!(\"C strlen result: {}\", length);\n    \n    // Allocate C memory and copy string\n    let dest_ptr = unsafe {\n        malloc(length + 1) as *mut c_char\n    };\n    \n    if !dest_ptr.is_null() {\n        unsafe {\n            strcpy(dest_ptr, c_string.as_ptr());\n            \n            // Convert back to Rust string\n            let copied_cstr = CStr::from_ptr(dest_ptr);\n            if let Ok(copied_str) = copied_cstr.to_str() {\n                println!(\"Copied string: {}\", copied_str);\n            }\n            \n            // Don't forget to free!\n            free(dest_ptr as *mut c_void);\n        }\n    }\n}\n\n// Using C math functions\nfn c_math_functions() {\n    let base = 2.0;\n    let exponent = 8.0;\n    \n    let result = unsafe { pow(base, exponent) };\n    println!(\"{} ^ {} = {}\", base, exponent, result);\n    \n    let angle = std::f64::consts::PI / 4.0; // 45 degrees\n    let sin_result = unsafe { sin(angle) };\n    let cos_result = unsafe { cos(angle) };\n    \n    println!(\"sin(\u03c0/4) = {}\", sin_result);\n    println!(\"cos(\u03c0/4) = {}\", cos_result);\n}\n```\n\n### Creating C-Compatible Functions in Rust\n\n```rust\n// Functions that can be called from C\n#[no_mangle]\npub extern \"C\" fn add_numbers(a: i32, b: i32) -> i32 {\n    a + b\n}\n\n#[no_mangle]\npub extern \"C\" fn process_array(arr: *const i32, len: usize) -> i32 {\n    if arr.is_null() {\n        return -1; // Error code\n    }\n    \n    let slice = unsafe {\n        // SAFETY: Caller guarantees arr is valid for len elements\n        std::slice::from_raw_parts(arr, len)\n    };\n    \n    slice.iter().sum()\n}\n\n#[no_mangle]\npub extern \"C\" fn create_string_buffer(size: usize) -> *mut c_char {\n    let layout = Layout::array::<u8>(size).expect(\"Invalid layout\");\n    unsafe {\n        let ptr = alloc(layout) as *mut c_char;\n        if !ptr.is_null() {\n            // Initialize to null bytes\n            ptr::write_bytes(ptr, 0, size);\n        }\n        ptr\n    }\n}\n\n#[no_mangle]\npub extern \"C\" fn free_string_buffer(ptr: *mut c_char, size: usize) {\n    if !ptr.is_null() {\n        unsafe {\n            let layout = Layout::array::<u8>(size).expect(\"Invalid layout\");\n            dealloc(ptr as *mut u8, layout);\n        }\n    }\n}\n\n// C-compatible struct\n#[repr(C)]\npub struct Point {\n    x: f64,\n    y: f64,\n}\n\n#[no_mangle]\npub extern \"C\" fn distance(p1: *const Point, p2: *const Point) -> f64 {\n    if p1.is_null() || p2.is_null() {\n        return -1.0; // Error\n    }\n    \n    unsafe {\n        let p1 = &*p1;\n        let p2 = &*p2;\n        \n        let dx = p1.x - p2.x;\n        let dy = p1.y - p2.y;\n        \n        (dx * dx + dy * dy).sqrt()\n    }\n}\n\n// For building a C library:\n// Create a header file (example.h):\n/*\n#include <stdint.h>\n#include <stddef.h>\n\ntypedef struct {\n    double x;\n    double y;\n} Point;\n\nint32_t add_numbers(int32_t a, int32_t b);\nint32_t process_array(const int32_t* arr, size_t len);\nchar* create_string_buffer(size_t size);\nvoid free_string_buffer(char* ptr, size_t size);\ndouble distance(const Point* p1, const Point* p2);\n*/\n```\n\n## Advanced FFI Patterns\n\n### Working with Complex C Libraries\n\n```rust\n// Example: Binding to a hypothetical C graphics library\n\n// C types\ntype GraphicsHandle = *mut std::os::raw::c_void;\n\n#[repr(C)]\npub struct Color {\n    r: u8,\n    g: u8,\n    b: u8,\n    a: u8,\n}\n\n#[repr(C)]\npub struct Rect {\n    x: i32,\n    y: i32,\n    width: u32,\n    height: u32,\n}\n\n// External C functions\nextern \"C\" {\n    fn graphics_init() -> GraphicsHandle;\n    fn graphics_cleanup(handle: GraphicsHandle);\n    fn graphics_draw_rect(handle: GraphicsHandle, rect: *const Rect, color: *const Color) -> i32;\n    fn graphics_present(handle: GraphicsHandle);\n}\n\n// Safe Rust wrapper\npub struct Graphics {\n    handle: GraphicsHandle,\n}\n\nimpl Graphics {\n    pub fn new() -> Result<Self, &'static str> {\n        let handle = unsafe { graphics_init() };\n        \n        if handle.is_null() {\n            Err(\"Failed to initialize graphics\")\n        } else {\n            Ok(Self { handle })\n        }\n    }\n    \n    pub fn draw_rect(&self, rect: Rect, color: Color) -> Result<(), &'static str> {\n        let result = unsafe {\n            graphics_draw_rect(self.handle, &rect, &color)\n        };\n        \n        if result == 0 {\n            Ok(())\n        } else {\n            Err(\"Failed to draw rectangle\")\n        }\n    }\n    \n    pub fn present(&self) {\n        unsafe {\n            graphics_present(self.handle);\n        }\n    }\n}\n\nimpl Drop for Graphics {\n    fn drop(&mut self) {\n        unsafe {\n            graphics_cleanup(self.handle);\n        }\n    }\n}\n\n// Safe usage\nfn graphics_example() {\n    if let Ok(graphics) = Graphics::new() {\n        let rect = Rect {\n            x: 10,\n            y: 20,\n            width: 100,\n            height: 50,\n        };\n        \n        let color = Color {\n            r: 255,\n            g: 0,\n            b: 0,\n            a: 255,\n        };\n        \n        if graphics.draw_rect(rect, color).is_ok() {\n            graphics.present();\n        }\n    }\n}\n```\n\n### Callback Functions and Function Pointers\n\n```rust\n// C callback type\ntype ProgressCallback = extern \"C\" fn(progress: f32, user_data: *mut c_void);\n\nextern \"C\" {\n    fn long_running_operation(\n        callback: ProgressCallback,\n        user_data: *mut c_void,\n    ) -> i32;\n}\n\n// Rust callback implementation\nextern \"C\" fn progress_callback(progress: f32, user_data: *mut c_void) {\n    if !user_data.is_null() {\n        unsafe {\n            let counter = &mut *(user_data as *mut i32);\n            *counter += 1;\n            println!(\"Progress: {:.1}% (callback #{} )\", progress * 100.0, counter);\n        }\n    }\n}\n\n// Safe wrapper for callback operations\nstruct OperationManager;\n\nimpl OperationManager {\n    pub fn run_with_progress<F>(&self, mut progress_fn: F) -> Result<(), &'static str>\n    where\n        F: FnMut(f32),\n    {\n        // Create a boxed closure that we can pass to C\n        let closure: Box<Box<dyn FnMut(f32)>> = Box::new(Box::new(progress_fn));\n        let user_data = Box::into_raw(closure) as *mut c_void;\n        \n        extern \"C\" fn rust_callback_wrapper(progress: f32, user_data: *mut c_void) {\n            unsafe {\n                let closure = &mut *(user_data as *mut Box<dyn FnMut(f32)>);\n                closure(progress);\n            }\n        }\n        \n        let result = unsafe {\n            long_running_operation(rust_callback_wrapper, user_data)\n        };\n        \n        // Clean up\n        unsafe {\n            let _ = Box::from_raw(user_data as *mut Box<dyn FnMut(f32)>);\n        }\n        \n        if result == 0 {\n            Ok(())\n        } else {\n            Err(\"Operation failed\")\n        }\n    }\n}\n\nfn callback_example() {\n    let manager = OperationManager;\n    \n    let mut call_count = 0;\n    \n    let result = manager.run_with_progress(|progress| {\n        call_count += 1;\n        println!(\"Rust closure: {:.1}% (call {})\", progress * 100.0, call_count);\n    });\n    \n    match result {\n        Ok(()) => println!(\"Operation completed successfully\"),\n        Err(e) => println!(\"Operation failed: {}\", e),\n    }\n}\n```\n\n## Memory Safety with Unsafe Code\n\n### Common Pitfalls and How to Avoid Them\n\n```rust\n// DANGER: Use after free\nfn dangerous_use_after_free() {\n    let mut vec = vec![1, 2, 3];\n    let ptr = vec.as_mut_ptr();\n    \n    drop(vec); // Free the memory\n    \n    // DON'T DO THIS:\n    // unsafe {\n    //     *ptr = 42; // Use after free!\n    // }\n}\n\n// SAFE: Proper lifetime management\nfn safe_pointer_usage() {\n    let mut vec = vec![1, 2, 3];\n    \n    // Keep vec alive while using pointer\n    {\n        let ptr = vec.as_mut_ptr();\n        unsafe {\n            *ptr = 42; // Safe: vec is still alive\n        }\n    }\n    \n    println!(\"Modified vec: {:?}\", vec);\n}\n\n// DANGER: Buffer overflow\nfn dangerous_buffer_access() {\n    let arr = [1, 2, 3];\n    let ptr = arr.as_ptr();\n    \n    // DON'T DO THIS:\n    // unsafe {\n    //     let value = *ptr.add(10); // Out of bounds!\n    // }\n}\n\n// SAFE: Bounds checking\nfn safe_buffer_access() {\n    let arr = [1, 2, 3];\n    let ptr = arr.as_ptr();\n    let len = arr.len();\n    \n    for i in 0..len {\n        unsafe {\n            let value = *ptr.add(i); // Safe: within bounds\n            println!(\"arr[{}] = {}\", i, value);\n        }\n    }\n}\n\n// SAFE: RAII for C resource management\nstruct CFileHandle {\n    file: *mut std::os::raw::c_void,\n}\n\nextern \"C\" {\n    fn fopen(filename: *const c_char, mode: *const c_char) -> *mut std::os::raw::c_void;\n    fn fclose(file: *mut std::os::raw::c_void) -> i32;\n    fn fwrite(\n        data: *const std::os::raw::c_void,\n        size: usize,\n        count: usize,\n        file: *mut std::os::raw::c_void,\n    ) -> usize;\n}\n\nimpl CFileHandle {\n    fn create(filename: &str) -> Result<Self, &'static str> {\n        let filename_c = CString::new(filename).map_err(|_| \"Invalid filename\")?;\n        let mode_c = CString::new(\"w\").unwrap();\n        \n        let file = unsafe {\n            fopen(filename_c.as_ptr(), mode_c.as_ptr())\n        };\n        \n        if file.is_null() {\n            Err(\"Failed to open file\")\n        } else {\n            Ok(Self { file })\n        }\n    }\n    \n    fn write_data(&self, data: &[u8]) -> Result<usize, &'static str> {\n        let written = unsafe {\n            fwrite(\n                data.as_ptr() as *const std::os::raw::c_void,\n                1,\n                data.len(),\n                self.file,\n            )\n        };\n        \n        if written == data.len() {\n            Ok(written)\n        } else {\n            Err(\"Write failed\")\n        }\n    }\n}\n\nimpl Drop for CFileHandle {\n    fn drop(&mut self) {\n        unsafe {\n            fclose(self.file);\n        }\n    }\n}\n```\n\n## Building and Linking with C Libraries\n\n### Build Script (build.rs)\n\n```rust\n// build.rs\nfn main() {\n    // Link against system libraries\n    println!(\"cargo:rustc-link-lib=m\");  // Math library\n    println!(\"cargo:rustc-link-lib=pthread\");  // Pthreads\n    \n    // Link against custom library\n    println!(\"cargo:rustc-link-search=native=/usr/local/lib\");\n    println!(\"cargo:rustc-link-lib=mylib\");\n    \n    // Compile C code\n    cc::Build::new()\n        .file(\"src/helper.c\")\n        .include(\"src\")\n        .compile(\"helper\");\n    \n    // Tell Cargo to rerun build script if files change\n    println!(\"cargo:rerun-if-changed=src/helper.c\");\n    println!(\"cargo:rerun-if-changed=src/helper.h\");\n}\n```\n\n### Cargo.toml for FFI Projects\n\n```toml\n[package]\nname = \"ffi-example\"\nversion = \"0.1.0\"\nedition = \"2021\"\nbuild = \"build.rs\"\n\n[dependencies]\n# For C string handling\nlibc = \"0.2\"\n\n[build-dependencies]\n# For compiling C code\ncc = \"1.0\"\n# For generating bindings\nbindgen = \"0.69\"\n```\n\n## Best Practices Summary\n\n1. **Minimize unsafe code** - Use safe abstractions\n2. **Document safety invariants** - Use `// SAFETY:` comments\n3. **Test thoroughly** - Unsafe code needs extra testing\n4. **Use tools** - Miri, AddressSanitizer, Valgrind\n5. **Wrap in safe APIs** - Don't expose raw pointers\n6. **Handle errors properly** - Check for null pointers, validate bounds\n7. **Use RAII** - Automatic resource cleanup\n8. **Be explicit about lifetimes** - Document when pointers are valid\n\nUnsafe Rust is a powerful tool, but use it sparingly and always wrap it in safe abstractions. The goal is to provide memory safety guarantees to your users while getting the performance and interoperability you need.",
    "tags": [
      "unsafe-rust",
      "ffi",
      "c-interop",
      "memory-safety",
      "raw-pointers",
      "c-libraries",
      "bindgen",
      "system-programming",
      "performance"
    ],
    "instruction": "I need to interface with existing C libraries and write performance-critical code. When should I use unsafe Rust and how do I do it safely? Can you show me how to work with FFI and C interop?"
  },
  {
    "output": "Excellent question! Rust macros are indeed one of the most powerful features of the language. They allow you to write code that writes code, enabling incredible expressiveness and eliminating boilerplate. Let me walk you through everything from basic to advanced macro programming.\n\n## Types of Macros in Rust\n\nRust has two main types of macros:\n1. **Declarative macros** (`macro_rules!`) - Pattern matching on code\n2. **Procedural macros** - Functions that manipulate token streams\n\n## Declarative Macros (macro_rules!)\n\nThese are the most common and accessible type of macros.\n\n### Basic Declarative Macros\n\n```rust\n// Simple function-like macro\nmacro_rules! say_hello {\n    () => {\n        println!(\"Hello, world!\");\n    };\n}\n\n// Macro with parameters\nmacro_rules! greet {\n    ($name:expr) => {\n        println!(\"Hello, {}!\", $name);\n    };\n}\n\n// Multiple patterns\nmacro_rules! calculate {\n    // Addition\n    ($a:expr + $b:expr) => {\n        $a + $b\n    };\n    // Multiplication\n    ($a:expr * $b:expr) => {\n        $a * $b\n    };\n    // Power (using repetition)\n    ($base:expr ^ $exp:expr) => {\n        ($base as f64).powf($exp as f64)\n    };\n}\n\nfn basic_macro_examples() {\n    say_hello!();  // Hello, world!\n    \n    greet!(\"Alice\");  // Hello, Alice!\n    greet!(\"Bob\");    // Hello, Bob!\n    \n    let sum = calculate!(5 + 3);      // 8\n    let product = calculate!(4 * 7);  // 28\n    let power = calculate!(2 ^ 8);    // 256.0\n    \n    println!(\"Sum: {}, Product: {}, Power: {}\", sum, product, power);\n}\n```\n\n### Macro Fragment Specifiers\n\n```rust\n// Different fragment types\nmacro_rules! demonstrate_fragments {\n    // Expression\n    (expr: $e:expr) => {\n        println!(\"Expression: {}\", $e);\n    };\n    // Identifier\n    (ident: $i:ident) => {\n        let $i = 42;\n        println!(\"{} = {}\", stringify!($i), $i);\n    };\n    // Type\n    (type: $t:ty) => {\n        let _: $t = Default::default();\n        println!(\"Type: {}\", stringify!($t));\n    };\n    // Pattern\n    (pat: $p:pat) => {\n        match 42 {\n            $p => println!(\"Pattern matched!\"),\n            _ => println!(\"Pattern didn't match\"),\n        }\n    };\n    // Statement\n    (stmt: $s:stmt) => {\n        $s\n        println!(\"Statement executed\");\n    };\n    // Block\n    (block: $b:block) => {\n        let result = $b;\n        println!(\"Block result: {:?}\", result);\n    };\n}\n\nfn fragment_examples() {\n    demonstrate_fragments!(expr: 2 + 3 * 4);\n    demonstrate_fragments!(ident: my_variable);\n    demonstrate_fragments!(type: Vec<i32>);\n    demonstrate_fragments!(pat: 42);\n    demonstrate_fragments!(stmt: let x = 10);\n    demonstrate_fragments!(block: { 1 + 2 + 3 });\n}\n```\n\n### Advanced Declarative Macros with Repetition\n\n```rust\n// Macro for creating hash maps\nmacro_rules! hashmap {\n    // Empty map\n    () => {\n        std::collections::HashMap::new()\n    };\n    // Map with key-value pairs\n    ($($key:expr => $value:expr),* $(,)?) => {{\n        let mut map = std::collections::HashMap::new();\n        $(\n            map.insert($key, $value);\n        )*\n        map\n    }};\n}\n\n// Macro for creating vectors with different syntax\nmacro_rules! avec {\n    // Empty vector\n    () => {\n        Vec::new()\n    };\n    // Vector with elements\n    ($($element:expr),* $(,)?) => {\n        vec![$($element),*]\n    };\n    // Vector with repeated element\n    ($element:expr; $count:expr) => {\n        vec![$element; $count]\n    };\n}\n\n// Macro for function generation\nmacro_rules! generate_getters_setters {\n    ($struct_name:ident { $($field:ident: $field_type:ty),* $(,)? }) => {\n        impl $struct_name {\n            $(\n                // Getter\n                paste::paste! {\n                    pub fn [<get_ $field>](&self) -> &$field_type {\n                        &self.$field\n                    }\n                    \n                    // Setter\n                    pub fn [<set_ $field>](&mut self, value: $field_type) {\n                        self.$field = value;\n                    }\n                }\n            )*\n        }\n    };\n}\n\n// Usage examples\nuse std::collections::HashMap;\n\nfn advanced_macro_examples() {\n    // HashMap creation\n    let map1: HashMap<&str, i32> = hashmap!();\n    let map2 = hashmap!{\n        \"apple\" => 5,\n        \"banana\" => 3,\n        \"orange\" => 8,\n    };\n    \n    println!(\"Empty map: {:?}\", map1);\n    println!(\"Fruit map: {:?}\", map2);\n    \n    // Vector creation\n    let vec1: Vec<i32> = avec!();\n    let vec2 = avec![1, 2, 3, 4, 5];\n    let vec3 = avec![0; 10];\n    \n    println!(\"Empty vec: {:?}\", vec1);\n    println!(\"Number vec: {:?}\", vec2);\n    println!(\"Repeated vec: {:?}\", vec3);\n}\n\n// Struct for getter/setter generation\n#[derive(Debug)]\nstruct Person {\n    name: String,\n    age: u32,\n    email: String,\n}\n\n// This would generate getters and setters\n// generate_getters_setters!(Person {\n//     name: String,\n//     age: u32,\n//     email: String,\n// });\n```\n\n### Recursive and Complex Macros\n\n```rust\n// Recursive macro for calculating factorial at compile time\nmacro_rules! factorial {\n    (0) => { 1 };\n    (1) => { 1 };\n    ($n:expr) => {\n        $n * factorial!($n - 1)\n    };\n}\n\n// Macro for creating enums with automatic implementations\nmacro_rules! create_enum {\n    (\n        $(#[$attr:meta])*\n        $vis:vis enum $name:ident {\n            $($variant:ident $(= $value:expr)?),* $(,)?\n        }\n    ) => {\n        $(#[$attr])*\n        #[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]\n        $vis enum $name {\n            $($variant $(= $value)?),*\n        }\n        \n        impl $name {\n            pub fn variants() -> &'static [Self] {\n                &[$(Self::$variant),*]\n            }\n            \n            pub fn name(&self) -> &'static str {\n                match self {\n                    $(Self::$variant => stringify!($variant)),*\n                }\n            }\n            \n            pub fn from_name(name: &str) -> Option<Self> {\n                match name {\n                    $(stringify!($variant) => Some(Self::$variant)),*,\n                    _ => None,\n                }\n            }\n        }\n        \n        impl std::fmt::Display for $name {\n            fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n                write!(f, \"{}\", self.name())\n            }\n        }\n    };\n}\n\n// DSL (Domain Specific Language) macro\nmacro_rules! html {\n    // Self-closing tags\n    (<$tag:ident />) => {\n        format!(\"<{} />\", stringify!($tag))\n    };\n    // Tags with content\n    (<$tag:ident> $($content:tt)* </$close_tag:ident>) => {{\n        assert_eq!(stringify!($tag), stringify!($close_tag), \"Mismatched tags\");\n        format!(\"<{}>{}</{}>\", stringify!($tag), html!($($content)*), stringify!($tag))\n    }};\n    // Tags with attributes\n    (<$tag:ident $($attr:ident = $value:expr),*> $($content:tt)* </$close_tag:ident>) => {{\n        assert_eq!(stringify!($tag), stringify!($close_tag), \"Mismatched tags\");\n        let attrs = vec![$( format!(\"{}=\\\"{}\\\"\", stringify!($attr), $value) ),*].join(\" \");\n        let attr_str = if attrs.is_empty() { String::new() } else { format!(\" {}\", attrs) };\n        format!(\"<{}{}>{}</{}>\", stringify!($tag), attr_str, html!($($content)*), stringify!($tag))\n    }};\n    // Text content\n    ($text:expr) => {\n        $text.to_string()\n    };\n    // Multiple elements\n    ($($element:tt)*) => {\n        vec![$(html!($element)),*].join(\"\")\n    };\n}\n\n// Usage examples\nfn complex_macro_examples() {\n    // Compile-time factorial\n    const FACT_5: u64 = factorial!(5);\n    println!(\"5! = {}\", FACT_5);\n    \n    // Custom enum creation\n    create_enum! {\n        #[doc = \"HTTP status codes\"]\n        pub enum HttpStatus {\n            Ok = 200,\n            NotFound = 404,\n            InternalServerError = 500,\n        }\n    }\n    \n    for status in HttpStatus::variants() {\n        println!(\"Status: {} ({})\", status, *status as u16);\n    }\n    \n    if let Some(status) = HttpStatus::from_name(\"Ok\") {\n        println!(\"Found status: {}\", status);\n    }\n    \n    // HTML DSL\n    let html_content = html! {\n        <html>\n            <head>\n                <title>\"My Page\"</title>\n            </head>\n            <body>\n                <h1 class=\"header\">\"Welcome!\"</h1>\n                <p>\"This is generated by a macro.\"</p>\n                <br />\n            </body>\n        </html>\n    };\n    \n    println!(\"Generated HTML:\\n{}\", html_content);\n}\n```\n\n## Procedural Macros\n\nProcedural macros are more powerful but require a separate crate.\n\n### Function-like Procedural Macros\n\n```rust\n// In a separate proc-macro crate (Cargo.toml: proc-macro = true)\nuse proc_macro::TokenStream;\nuse quote::quote;\nuse syn::{parse_macro_input, Expr, LitStr};\n\n#[proc_macro]\npub fn sql(input: TokenStream) -> TokenStream {\n    let sql_query = parse_macro_input!(input as LitStr);\n    let query_str = sql_query.value();\n    \n    // In a real implementation, you'd validate SQL syntax here\n    if !query_str.to_uppercase().starts_with(\"SELECT\") {\n        return syn::Error::new_spanned(sql_query, \"Only SELECT queries are supported\")\n            .to_compile_error()\n            .into();\n    }\n    \n    let output = quote! {\n        {\n            let query = #query_str;\n            println!(\"Executing SQL: {}\", query);\n            // Return mock result\n            vec![\"Mock\", \"Data\"]\n        }\n    };\n    \n    output.into()\n}\n\n// Usage: sql!(\"SELECT * FROM users WHERE age > 18\")\n```\n\n### Derive Macros\n\n```rust\n// Custom derive macro for automatic builder pattern\nuse proc_macro::TokenStream;\nuse quote::quote;\nuse syn::{parse_macro_input, Data, DeriveInput, Fields};\n\n#[proc_macro_derive(Builder)]\npub fn derive_builder(input: TokenStream) -> TokenStream {\n    let input = parse_macro_input!(input as DeriveInput);\n    let name = &input.ident;\n    let builder_name = format_ident!(\"{}Builder\", name);\n    \n    let fields = match &input.data {\n        Data::Struct(data) => match &data.fields {\n            Fields::Named(fields) => &fields.named,\n            _ => panic!(\"Builder only supports named fields\"),\n        },\n        _ => panic!(\"Builder only supports structs\"),\n    };\n    \n    // Generate builder struct fields\n    let builder_fields = fields.iter().map(|field| {\n        let name = &field.ident;\n        let ty = &field.ty;\n        quote! {\n            #name: Option<#ty>\n        }\n    });\n    \n    // Generate builder methods\n    let builder_methods = fields.iter().map(|field| {\n        let name = &field.ident;\n        let ty = &field.ty;\n        quote! {\n            pub fn #name(mut self, #name: #ty) -> Self {\n                self.#name = Some(#name);\n                self\n            }\n        }\n    });\n    \n    // Generate build method\n    let build_fields = fields.iter().map(|field| {\n        let name = &field.ident;\n        quote! {\n            #name: self.#name.ok_or(concat!(\"Missing field: \", stringify!(#name)))?\n        }\n    });\n    \n    let expanded = quote! {\n        pub struct #builder_name {\n            #(#builder_fields,)*\n        }\n        \n        impl #builder_name {\n            pub fn new() -> Self {\n                Self {\n                    #(#(field.ident): None,)*\n                }\n            }\n            \n            #(#builder_methods)*\n            \n            pub fn build(self) -> Result<#name, &'static str> {\n                Ok(#name {\n                    #(#build_fields,)*\n                })\n            }\n        }\n        \n        impl #name {\n            pub fn builder() -> #builder_name {\n                #builder_name::new()\n            }\n        }\n    };\n    \n    TokenStream::from(expanded)\n}\n\n// Usage:\n// #[derive(Builder)]\n// struct User {\n//     name: String,\n//     age: u32,\n//     email: String,\n// }\n```\n\n### Attribute Macros\n\n```rust\n// Timing attribute macro\n#[proc_macro_attribute]\npub fn time_it(_args: TokenStream, input: TokenStream) -> TokenStream {\n    let input_fn = parse_macro_input!(input as syn::ItemFn);\n    let fn_name = &input_fn.sig.ident;\n    let fn_vis = &input_fn.vis;\n    let fn_sig = &input_fn.sig;\n    let fn_block = &input_fn.block;\n    \n    let output = quote! {\n        #fn_vis #fn_sig {\n            let start = std::time::Instant::now();\n            let result = (|| #fn_block)();\n            let duration = start.elapsed();\n            println!(\"Function {} took: {:?}\", stringify!(#fn_name), duration);\n            result\n        }\n    };\n    \n    output.into()\n}\n\n// Usage:\n// #[time_it]\n// fn expensive_operation() {\n//     std::thread::sleep(std::time::Duration::from_millis(100));\n// }\n```\n\n## Real-World Macro Examples\n\n### Testing Framework Macro\n\n```rust\n// Macro for creating test suites\nmacro_rules! test_suite {\n    (\n        $suite_name:ident {\n            $(\n                $test_name:ident: $test_body:block\n            ),* $(,)?\n        }\n    ) => {\n        mod $suite_name {\n            use super::*;\n            \n            $(\n                #[test]\n                fn $test_name() {\n                    println!(\"Running test: {}\", stringify!($test_name));\n                    $test_body\n                }\n            )*\n            \n            pub fn run_all_tests() {\n                println!(\"Running test suite: {}\", stringify!($suite_name));\n                $(\n                    print!(\"  {}: \", stringify!($test_name));\n                    std::panic::catch_unwind(|| $test_name())\n                        .map(|_| println!(\"PASS\"))\n                        .unwrap_or_else(|_| println!(\"FAIL\"));\n                )*\n            }\n        }\n    };\n}\n\n// Configuration macro\nmacro_rules! config {\n    (\n        $(\n            $key:ident: $type:ty = $default:expr\n        ),* $(,)?\n    ) => {\n        #[derive(Debug, Clone)]\n        pub struct Config {\n            $(pub $key: $type,)*\n        }\n        \n        impl Default for Config {\n            fn default() -> Self {\n                Self {\n                    $($key: $default,)*\n                }\n            }\n        }\n        \n        impl Config {\n            pub fn from_env() -> Self {\n                let mut config = Self::default();\n                \n                $(\n                    if let Ok(val) = std::env::var(stringify!($key).to_uppercase()) {\n                        if let Ok(parsed) = val.parse::<$type>() {\n                            config.$key = parsed;\n                        }\n                    }\n                )*\n                \n                config\n            }\n            \n            pub fn set_from_args(&mut self, args: &[String]) {\n                for arg in args {\n                    $(\n                        if arg.starts_with(&format!(\"--{}=\", stringify!($key))) {\n                            if let Some(value) = arg.split('=').nth(1) {\n                                if let Ok(parsed) = value.parse::<$type>() {\n                                    self.$key = parsed;\n                                }\n                            }\n                        }\n                    )*\n                }\n            }\n        }\n    };\n}\n\n// Logging macro with different levels\nmacro_rules! log {\n    (ERROR, $($arg:tt)*) => {\n        eprintln!(\"[ERROR] {}: {}\", chrono::Utc::now().format(\"%Y-%m-%d %H:%M:%S\"), format!($($arg)*))\n    };\n    (WARN, $($arg:tt)*) => {\n        eprintln!(\"[WARN]  {}: {}\", chrono::Utc::now().format(\"%Y-%m-%d %H:%M:%S\"), format!($($arg)*))\n    };\n    (INFO, $($arg:tt)*) => {\n        println!(\"[INFO]  {}: {}\", chrono::Utc::now().format(\"%Y-%m-%d %H:%M:%S\"), format!($($arg)*))\n    };\n    (DEBUG, $($arg:tt)*) => {\n        if cfg!(debug_assertions) {\n            println!(\"[DEBUG] {}: {}\", chrono::Utc::now().format(\"%Y-%m-%d %H:%M:%S\"), format!($($arg)*))\n        }\n    };\n}\n\n// Usage examples\nfn real_world_macro_examples() {\n    // Test suite\n    test_suite! {\n        math_tests {\n            test_addition: {\n                assert_eq!(2 + 2, 4);\n            },\n            test_multiplication: {\n                assert_eq!(3 * 4, 12);\n            },\n            test_division: {\n                assert_eq!(10 / 2, 5);\n            },\n        }\n    }\n    \n    // Configuration\n    config! {\n        port: u16 = 8080,\n        host: String = \"localhost\".to_string(),\n        debug: bool = false,\n        max_connections: usize = 100,\n    }\n    \n    let mut config = Config::from_env();\n    let args = vec![\"--port=3000\".to_string(), \"--debug=true\".to_string()];\n    config.set_from_args(&args);\n    \n    println!(\"Configuration: {:?}\", config);\n    \n    // Logging\n    log!(INFO, \"Application starting on {}:{}\", config.host, config.port);\n    log!(DEBUG, \"Debug mode: {}\", config.debug);\n    log!(WARN, \"This is a warning message\");\n    log!(ERROR, \"This is an error: {}\", \"something went wrong\");\n}\n\nfn main() {\n    println!(\"=== Basic Macros ===\");\n    basic_macro_examples();\n    \n    println!(\"\\n=== Fragment Examples ===\");\n    fragment_examples();\n    \n    println!(\"\\n=== Advanced Macros ===\");\n    advanced_macro_examples();\n    \n    println!(\"\\n=== Complex Macros ===\");\n    complex_macro_examples();\n    \n    println!(\"\\n=== Real-World Examples ===\");\n    real_world_macro_examples();\n}\n```\n\n## Best Practices and Tips\n\n1. **Start simple** - Begin with basic `macro_rules!` before moving to proc macros\n2. **Use `stringify!`** - Convert identifiers to strings\n3. **Use `concat!`** - Concatenate string literals at compile time\n4. **Debug with `cargo expand`** - See the generated code\n5. **Test thoroughly** - Macros can hide bugs\n6. **Document well** - Macros can be hard to understand\n7. **Consider alternatives** - Sometimes functions or generics are better\n8. **Use proc macros for complex logic** - When pattern matching isn't enough\n\n## When to Use Macros\n\n\u2705 **Good use cases:**\n- Eliminating boilerplate code\n- Creating DSLs (Domain Specific Languages)\n- Compile-time code generation\n- Conditional compilation\n- Generating repetitive implementations\n\n\u274c **Avoid macros for:**\n- Simple functions (use regular functions)\n- Type checking (use the type system)\n- Runtime behavior (use traits/functions)\n- When debugging is important (macros complicate debugging)\n\nMacros are incredibly powerful but should be used judiciously. They're best for eliminating repetitive code and creating expressive APIs that wouldn't be possible with regular Rust syntax.",
    "tags": [
      "macros",
      "macro-rules",
      "procedural-macros",
      "code-generation",
      "dsl",
      "metaprogramming",
      "derive-macros",
      "attribute-macros",
      "declarative-macros"
    ],
    "instruction": "I've been hearing about Rust macros being really powerful but also complex. Can you explain the different types of macros, when to use them, and show me how to build both simple and advanced macros?"
  },
  {
    "output": "```rust\n// This example compares BTreeMap and HashMap, showing their different characteristics\n// and when to use each data structure\n\nuse std::collections::{HashMap, BTreeMap};\nuse std::time::Instant;\n\n#[derive(Debug)]\nstruct TimingResult {\n    insert_time: u128,\n    lookup_time: u128,\n}\n\nfn main() {\n    println!(\"=== BTreeMap vs HashMap Comparison ===\");\n    \n    // Basic differences demonstration\n    println!(\"\\n=== Basic Usage ===\");\n    \n    // HashMap - uses hashing for O(1) average operations\n    let mut hash_map: HashMap<i32, String> = HashMap::new();\n    hash_map.insert(3, \"three\".to_string());\n    hash_map.insert(1, \"one\".to_string());\n    hash_map.insert(4, \"four\".to_string());\n    hash_map.insert(2, \"two\".to_string());\n    \n    // BTreeMap - uses balanced tree for O(log n) operations, keeps keys sorted\n    let mut btree_map: BTreeMap<i32, String> = BTreeMap::new();\n    btree_map.insert(3, \"three\".to_string());\n    btree_map.insert(1, \"one\".to_string());\n    btree_map.insert(4, \"four\".to_string());\n    btree_map.insert(2, \"two\".to_string());\n    \n    println!(\"HashMap iteration (random order): \");\n    for (k, v) in &hash_map {\n        print!(\"{}:{} \", k, v);\n    }\n    println!();\n    \n    println!(\"BTreeMap iteration (sorted order): \");\n    for (k, v) in &btree_map {\n        print!(\"{}:{} \", k, v);\n    }\n    println!();\n    \n    // Range queries - BTreeMap advantage\n    println!(\"\\n=== Range Queries (BTreeMap advantage) ===\");\n    let data: BTreeMap<i32, &str> = (1..=10)\n        .map(|i| (i, match i % 3 {\n            0 => \"fizz\",\n            1 => \"buzz\", \n            _ => \"normal\"\n        }))\n        .collect();\n    \n    // Get all values between 3 and 7 (inclusive)\n    let range_values: Vec<(&i32, &&str)> = data.range(3..=7).collect();\n    println!(\"Values from 3 to 7: {:?}\", range_values);\n    \n    // Split operations\n    let mut split_map = data.clone();\n    let upper_half = split_map.split_off(&6);\n    println!(\"Lower half (1-5): {:?}\", split_map);\n    println!(\"Upper half (6-10): {:?}\", upper_half);\n    \n    // Performance comparison\n    println!(\"\\n=== Performance Comparison ===\");\n    \n    fn benchmark_inserts<Map>(mut map: Map, size: usize) -> u128 \n    where \n        Map: std::iter::Extend<(i32, String)>,\n    {\n        let start = Instant::now();\n        map.extend((0..size).map(|i| (i as i32, format!(\"value_{}\", i))));\n        start.elapsed().as_nanos()\n    }\n    \n    let hash_time = benchmark_inserts(HashMap::new(), 10000);\n    let btree_time = benchmark_inserts(BTreeMap::new(), 10000);\n    \n    println!(\"HashMap insert time: {} ns\", hash_time);\n    println!(\"BTreeMap insert time: {} ns\", btree_time);\n    println!(\"HashMap is ~{:.1}x faster for inserts\", btree_time as f64 / hash_time as f64);\n    \n    // Memory layout and cache performance\n    println!(\"\\n=== When to use each ===\");\n    println!(\"Use HashMap when:\");\n    println!(\"- You need O(1) average lookup/insert/delete\");\n    println!(\"- You don't need sorted iteration\");\n    println!(\"- Memory usage is not a primary concern\");\n    println!(\"- You have a good hash function\");\n    \n    println!(\"\\nUse BTreeMap when:\");\n    println!(\"- You need sorted iteration\");\n    println!(\"- You need range queries\");\n    println!(\"- You need split/merge operations\");\n    println!(\"- You want predictable O(log n) performance\");\n    println!(\"- Memory locality is important\");\n    \n    // Specific use cases\n    println!(\"\\n=== Specific Use Cases ===\");\n    \n    // Frequency counter with HashMap\n    let text = \"the quick brown fox jumps over the lazy dog\";\n    let mut word_freq: HashMap<&str, usize> = HashMap::new();\n    for word in text.split_whitespace() {\n        *word_freq.entry(word).or_insert(0) += 1;\n    }\n    println!(\"Word frequencies (HashMap): {:?}\", word_freq);\n    \n    // Ordered statistics with BTreeMap\n    let mut scores: BTreeMap<i32, String> = BTreeMap::new();\n    scores.insert(95, \"Alice\".to_string());\n    scores.insert(87, \"Bob\".to_string());\n    scores.insert(92, \"Charlie\".to_string());\n    scores.insert(88, \"David\".to_string());\n    \n    println!(\"\\nTop 3 scores (BTreeMap - naturally sorted):\");\n    for (score, name) in scores.iter().rev().take(3) {\n        println!(\"  {}: {}\", name, score);\n    }\n    \n    // Range-based operations\n    let passing_scores: Vec<_> = scores.range(90..).collect();\n    println!(\"Passing scores (>=90): {:?}\", passing_scores);\n}\n\n// Key concepts:\n// - HashMap: O(1) average operations, unordered, uses hashing\n// - BTreeMap: O(log n) operations, ordered, uses balanced tree\n// - BTreeMap provides range queries and split operations\n// - HashMap is faster for simple key-value operations\n// - BTreeMap is better for ordered data and range queries\n// - Choose based on your specific use case requirements\n```",
    "tags": [
      "btreemap",
      "hashmap",
      "collections",
      "performance",
      "comparison"
    ],
    "instruction": "Compare BTreeMap vs HashMap and show when to use each"
  },
  {
    "output": "```rust\n// This example demonstrates advanced Result<T, E> patterns and comprehensive error handling\n// Result is Rust's primary error handling mechanism, providing explicit error management\n\nuse std::fs::File;\nuse std::io::{self, Read, Write};\nuse std::num::ParseIntError;\nuse std::fmt;\n\n// Custom error types for different error scenarios\n#[derive(Debug, Clone)]\nenum DatabaseError {\n    ConnectionFailed(String),\n    QueryFailed(String),\n    RecordNotFound(u32),\n    ValidationError(String),\n}\n\nimpl fmt::Display for DatabaseError {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        match self {\n            DatabaseError::ConnectionFailed(msg) => write!(f, \"Database connection failed: {}\", msg),\n            DatabaseError::QueryFailed(msg) => write!(f, \"Query execution failed: {}\", msg),\n            DatabaseError::RecordNotFound(id) => write!(f, \"Record with ID {} not found\", id),\n            DatabaseError::ValidationError(msg) => write!(f, \"Validation error: {}\", msg),\n        }\n    }\n}\n\nimpl std::error::Error for DatabaseError {}\n\n// Comprehensive error type that can represent multiple error sources\n#[derive(Debug)]\nenum AppError {\n    Database(DatabaseError),\n    Io(io::Error),\n    Parse(ParseIntError),\n    Custom(String),\n}\n\nimpl fmt::Display for AppError {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        match self {\n            AppError::Database(err) => write!(f, \"Database error: {}\", err),\n            AppError::Io(err) => write!(f, \"IO error: {}\", err),\n            AppError::Parse(err) => write!(f, \"Parse error: {}\", err),\n            AppError::Custom(msg) => write!(f, \"Application error: {}\", msg),\n        }\n    }\n}\n\nimpl std::error::Error for AppError {}\n\n// Implementing From trait for automatic error conversion\nimpl From<DatabaseError> for AppError {\n    fn from(err: DatabaseError) -> Self {\n        AppError::Database(err)\n    }\n}\n\nimpl From<io::Error> for AppError {\n    fn from(err: io::Error) -> Self {\n        AppError::Io(err)\n    }\n}\n\nimpl From<ParseIntError> for AppError {\n    fn from(err: ParseIntError) -> Self {\n        AppError::Parse(err)\n    }\n}\n\n// Result type alias for convenience\ntype AppResult<T> = Result<T, AppError>;\n\n// Database operations that can fail\nfn connect_to_database(connection_string: &str) -> Result<String, DatabaseError> {\n    if connection_string.is_empty() {\n        Err(DatabaseError::ConnectionFailed(\"Empty connection string\".to_string()))\n    } else if connection_string == \"invalid\" {\n        Err(DatabaseError::ConnectionFailed(\"Invalid credentials\".to_string()))\n    } else {\n        Ok(format!(\"Connected to: {}\", connection_string))\n    }\n}\n\nfn fetch_user(id: u32) -> Result<String, DatabaseError> {\n    match id {\n        0 => Err(DatabaseError::ValidationError(\"User ID cannot be zero\".to_string())),\n        999 => Err(DatabaseError::RecordNotFound(id)),\n        _ => Ok(format!(\"User {} data\", id)),\n    }\n}\n\nfn execute_query(query: &str) -> Result<Vec<String>, DatabaseError> {\n    if query.is_empty() {\n        Err(DatabaseError::QueryFailed(\"Empty query\".to_string()))\n    } else if query.contains(\"DROP\") {\n        Err(DatabaseError::QueryFailed(\"Dangerous query detected\".to_string()))\n    } else {\n        Ok(vec![\n            format!(\"Result 1 for: {}\", query),\n            format!(\"Result 2 for: {}\", query),\n        ])\n    }\n}\n\n// Advanced error handling patterns\nfn complex_operation(user_id: &str, query: &str) -> AppResult<Vec<String>> {\n    // Parse user ID - automatic conversion from ParseIntError to AppError\n    let id: u32 = user_id.parse()?;\n    \n    // Connect to database - manual conversion using ?\n    let _connection = connect_to_database(\"valid_connection\")?;\n    \n    // Fetch user data - chaining operations\n    let _user_data = fetch_user(id)?;\n    \n    // Execute query and return results\n    let results = execute_query(query)?;\n    \n    Ok(results)\n}\n\n// Error recovery patterns\nfn operation_with_fallback(user_id: u32) -> AppResult<String> {\n    // Try primary operation, fall back on error\n    match fetch_user(user_id) {\n        Ok(data) => Ok(data),\n        Err(DatabaseError::RecordNotFound(_)) => {\n            // Fallback: create default user\n            println!(\"User not found, creating default\");\n            Ok(\"Default user data\".to_string())\n        }\n        Err(other) => Err(AppError::Database(other)),\n    }\n}\n\n// Error mapping and transformation\nfn transform_errors(input: &str) -> AppResult<i32> {\n    input\n        .parse::<i32>()\n        .map_err(|_| AppError::Custom(format!(\"Failed to parse '{}' as integer\", input)))\n        .and_then(|num| {\n            if num < 0 {\n                Err(AppError::Custom(\"Number must be positive\".to_string()))\n            } else {\n                Ok(num * 2)\n            }\n        })\n}\n\n// Collecting results - stop on first error vs. collect all errors\nfn batch_operations(inputs: &[&str]) -> (Vec<i32>, Vec<String>) {\n    let mut successes = Vec::new();\n    let mut errors = Vec::new();\n    \n    for input in inputs {\n        match transform_errors(input) {\n            Ok(value) => successes.push(value),\n            Err(e) => errors.push(e.to_string()),\n        }\n    }\n    \n    (successes, errors)\n}\n\n// Early return with multiple error types\nfn read_and_parse_file(filename: &str) -> AppResult<Vec<i32>> {\n    let mut file = File::open(filename)?; // io::Error -> AppError\n    let mut contents = String::new();\n    file.read_to_string(&mut contents)?; // io::Error -> AppError\n    \n    let numbers: Result<Vec<i32>, ParseIntError> = contents\n        .lines()\n        .map(|line| line.trim().parse::<i32>())\n        .collect();\n    \n    Ok(numbers?) // ParseIntError -> AppError\n}\n\n// Custom result combinators\ntrait ResultExt<T, E> {\n    fn log_error(self) -> Result<T, E>;\n    fn with_context(self, context: &str) -> Result<T, AppError> \n    where \n        E: std::error::Error + 'static;\n}\n\nimpl<T, E> ResultExt<T, E> for Result<T, E> \nwhere \n    E: fmt::Display,\n{\n    fn log_error(self) -> Result<T, E> {\n        match &self {\n            Err(e) => println!(\"Error occurred: {}\", e),\n            Ok(_) => {}\n        }\n        self\n    }\n    \n    fn with_context(self, context: &str) -> Result<T, AppError> \n    where \n        E: std::error::Error + 'static,\n    {\n        self.map_err(|e| AppError::Custom(format!(\"{}: {}\", context, e)))\n    }\n}\n\nfn main() -> AppResult<()> {\n    println!(\"=== Advanced Result Patterns ===\");\n    \n    // Basic error handling with ?\n    println!(\"\\n=== Basic Operations ===\");\n    match complex_operation(\"123\", \"SELECT * FROM users\") {\n        Ok(results) => println!(\"Success: {:?}\", results),\n        Err(e) => println!(\"Error: {}\", e),\n    }\n    \n    // Error with invalid input\n    match complex_operation(\"abc\", \"SELECT * FROM users\") {\n        Ok(results) => println!(\"Success: {:?}\", results),\n        Err(e) => println!(\"Parse error: {}\", e),\n    }\n    \n    // Error recovery patterns\n    println!(\"\\n=== Error Recovery ===\");\n    match operation_with_fallback(999) {\n        Ok(data) => println!(\"Recovered: {}\", data),\n        Err(e) => println!(\"Recovery failed: {}\", e),\n    }\n    \n    // Error transformation\n    println!(\"\\n=== Error Transformation ===\");\n    let test_inputs = [\"42\", \"abc\", \"-5\", \"100\"];\n    for input in &test_inputs {\n        match transform_errors(input) {\n            Ok(result) => println!(\"'{}' -> {}\", input, result),\n            Err(e) => println!(\"'{}' -> Error: {}\", input, e),\n        }\n    }\n    \n    // Batch operations - collect all results\n    println!(\"\\n=== Batch Operations ===\");\n    let (successes, errors) = batch_operations(&test_inputs);\n    println!(\"Successes: {:?}\", successes);\n    println!(\"Errors: {:?}\", errors);\n    \n    // Custom result combinators\n    println!(\"\\n=== Custom Combinators ===\");\n    let result = \"invalid\"\n        .parse::<i32>()\n        .log_error()\n        .with_context(\"Parsing user input\");\n    \n    match result {\n        Ok(num) => println!(\"Parsed: {}\", num),\n        Err(e) => println!(\"Context error: {}\", e),\n    }\n    \n    // Nested Results - working with Option<Result<T, E>>\n    println!(\"\\n=== Nested Results ===\");\n    let data = Some(\"42\");\n    let result: Option<Result<i32, ParseIntError>> = data.map(|s| s.parse());\n    \n    match result.transpose() {\n        Ok(Some(num)) => println!(\"Parsed number: {}\", num),\n        Ok(None) => println!(\"No data provided\"),\n        Err(e) => println!(\"Parse error: {}\", e),\n    }\n    \n    // Error propagation chain\n    println!(\"\\n=== Error Propagation ===\");\n    fn chain_operations() -> AppResult<String> {\n        let conn = connect_to_database(\"valid\")?;\n        let user = fetch_user(42)?;\n        let results = execute_query(\"SELECT name FROM users\")?;\n        Ok(format!(\"Chain complete: {} -> {} -> {:?}\", conn, user, results))\n    }\n    \n    match chain_operations() {\n        Ok(result) => println!(\"Chain result: {}\", result),\n        Err(e) => println!(\"Chain failed: {}\", e),\n    }\n    \n    Ok(())\n}\n\n// Key concepts:\n// - Custom error types with Display and Error traits\n// - From trait for automatic error conversion\n// - Result<T, E> chaining with ? operator\n// - Error recovery with fallback strategies\n// - Error transformation and mapping\n// - Batch error handling - collect vs. early return\n// - Custom result combinators for enhanced functionality\n// - Type aliases for complex Result types\n// - Nested Result/Option handling with transpose()\n```",
    "tags": [
      "result",
      "error-handling",
      "custom-errors",
      "advanced",
      "patterns"
    ],
    "instruction": "Demonstrate advanced Result patterns and comprehensive error handling strategies"
  },
  {
    "output": "```rust\n// This example demonstrates nested pattern matching with complex data structures\n// Pattern matching can destructure multiple levels of enums, structs, and tuples\n\n#[derive(Debug, Clone, PartialEq)]\nenum Status {\n    Active,\n    Inactive,\n    Suspended { reason: String, until: Option<u64> },\n}\n\n#[derive(Debug, Clone)]\nenum UserRole {\n    Guest,\n    Member { since: u64 },\n    Moderator { permissions: Vec<String> },\n    Admin { level: AdminLevel },\n}\n\n#[derive(Debug, Clone)]\nenum AdminLevel {\n    Junior,\n    Senior,\n    Super { access_code: String },\n}\n\n#[derive(Debug, Clone)]\nstruct User {\n    id: u32,\n    name: String,\n    email: String,\n    role: UserRole,\n    status: Status,\n    metadata: Option<UserMetadata>,\n}\n\n#[derive(Debug, Clone)]\nstruct UserMetadata {\n    last_login: Option<u64>,\n    login_count: u32,\n    preferences: Vec<(String, String)>,\n}\n\n// Network message types for complex matching\n#[derive(Debug)]\nenum NetworkMessage {\n    Request { \n        id: u32, \n        method: HttpMethod, \n        path: String,\n        headers: Vec<(String, String)>,\n    },\n    Response { \n        id: u32, \n        status: u16, \n        body: ResponseBody,\n    },\n    Error { \n        id: u32, \n        code: ErrorCode,\n        message: String,\n    },\n}\n\n#[derive(Debug)]\nenum HttpMethod {\n    Get,\n    Post { content_type: String },\n    Put { content_type: String },\n    Delete,\n}\n\n#[derive(Debug)]\nenum ResponseBody {\n    Json(String),\n    Html(String),\n    Binary(Vec<u8>),\n    Empty,\n}\n\n#[derive(Debug)]\nenum ErrorCode {\n    BadRequest,\n    Unauthorized,\n    NotFound,\n    InternalError { details: String },\n}\n\nfn main() {\n    println!(\"=== Nested Pattern Matching Examples ===\");\n    \n    // Complex user data for testing\n    let users = vec![\n        User {\n            id: 1,\n            name: \"Alice\".to_string(),\n            email: \"alice@example.com\".to_string(),\n            role: UserRole::Admin { level: AdminLevel::Super { access_code: \"SECRET\".to_string() } },\n            status: Status::Active,\n            metadata: Some(UserMetadata {\n                last_login: Some(1634567890),\n                login_count: 150,\n                preferences: vec![(\"theme\".to_string(), \"dark\".to_string())],\n            }),\n        },\n        User {\n            id: 2,\n            name: \"Bob\".to_string(),\n            email: \"bob@example.com\".to_string(),\n            role: UserRole::Moderator { permissions: vec![\"read\".to_string(), \"write\".to_string()] },\n            status: Status::Suspended { reason: \"Policy violation\".to_string(), until: Some(1634654290) },\n            metadata: None,\n        },\n        User {\n            id: 3,\n            name: \"Charlie\".to_string(),\n            email: \"charlie@example.com\".to_string(),\n            role: UserRole::Member { since: 1634567890 },\n            status: Status::Active,\n            metadata: Some(UserMetadata {\n                last_login: None,\n                login_count: 5,\n                preferences: vec![],\n            }),\n        },\n    ];\n    \n    // Nested pattern matching with users\n    println!(\"\\n=== User Analysis ===\");\n    for user in &users {\n        analyze_user(user);\n    }\n    \n    // Network message processing\n    println!(\"\\n=== Network Message Processing ===\");\n    let messages = vec![\n        NetworkMessage::Request {\n            id: 1,\n            method: HttpMethod::Post { content_type: \"application/json\".to_string() },\n            path: \"/api/users\".to_string(),\n            headers: vec![(\"Authorization\".to_string(), \"Bearer token123\".to_string())],\n        },\n        NetworkMessage::Response {\n            id: 1,\n            status: 201,\n            body: ResponseBody::Json(r#\"{\"id\": 123, \"name\": \"New User\"}\"#.to_string()),\n        },\n        NetworkMessage::Error {\n            id: 2,\n            code: ErrorCode::InternalError { details: \"Database connection failed\".to_string() },\n            message: \"Internal server error\".to_string(),\n        },\n    ];\n    \n    for message in &messages {\n        process_network_message(message);\n    }\n    \n    // Advanced pattern matching scenarios\n    println!(\"\\n=== Advanced Patterns ===\");\n    advanced_pattern_examples();\n}\n\nfn analyze_user(user: &User) {\n    // Complex nested pattern matching\n    match user {\n        // Super admin with metadata and recent login\n        User {\n            role: UserRole::Admin { level: AdminLevel::Super { access_code } },\n            status: Status::Active,\n            metadata: Some(UserMetadata { last_login: Some(timestamp), login_count, .. }),\n            ..\n        } if *login_count > 100 => {\n            println!(\"Super admin {} (code: {}) - Very active with {} logins, last seen at {}\", \n                     user.name, access_code, login_count, timestamp);\n        }\n        \n        // Regular admin\n        User {\n            role: UserRole::Admin { level: AdminLevel::Junior | AdminLevel::Senior },\n            status: Status::Active,\n            ..\n        } => {\n            println!(\"Admin {} - Standard privileges\", user.name);\n        }\n        \n        // Suspended moderator with specific reason\n        User {\n            role: UserRole::Moderator { permissions },\n            status: Status::Suspended { reason, until: Some(end_time) },\n            ..\n        } => {\n            println!(\"Moderator {} suspended until {} for: {} (had {} permissions)\", \n                     user.name, end_time, reason, permissions.len());\n        }\n        \n        // Active member with preferences\n        User {\n            role: UserRole::Member { since },\n            status: Status::Active,\n            metadata: Some(UserMetadata { preferences, .. }),\n            ..\n        } if !preferences.is_empty() => {\n            println!(\"Member {} (since {}) with {} preferences\", \n                     user.name, since, preferences.len());\n        }\n        \n        // New member without metadata\n        User {\n            role: UserRole::Member { .. },\n            metadata: None,\n            ..\n        } => {\n            println!(\"New member {} - no metadata yet\", user.name);\n        }\n        \n        // Catch-all for other cases\n        User { name, status, .. } => {\n            println!(\"User {} with status: {:?}\", name, status);\n        }\n    }\n}\n\nfn process_network_message(message: &NetworkMessage) {\n    match message {\n        // POST request with JSON content type and auth header\n        NetworkMessage::Request {\n            id,\n            method: HttpMethod::Post { content_type },\n            path,\n            headers,\n        } if content_type == \"application/json\" => {\n            // Further nested matching on headers\n            let has_auth = headers.iter().any(|(key, _)| key == \"Authorization\");\n            println!(\"Authenticated JSON POST {} to {}: auth={}\", id, path, has_auth);\n        }\n        \n        // GET requests\n        NetworkMessage::Request {\n            id,\n            method: HttpMethod::Get,\n            path,\n            ..\n        } => {\n            println!(\"GET request {} to {}\", id, path);\n        }\n        \n        // Successful response with JSON body\n        NetworkMessage::Response {\n            id,\n            status: 200..=299,\n            body: ResponseBody::Json(data),\n        } => {\n            println!(\"Success response {}: {} bytes of JSON\", id, data.len());\n        }\n        \n        // Error response\n        NetworkMessage::Response {\n            id,\n            status: 400..=599,\n            body,\n        } => {\n            let body_type = match body {\n                ResponseBody::Json(_) => \"JSON\",\n                ResponseBody::Html(_) => \"HTML\",\n                ResponseBody::Binary(_) => \"Binary\",\n                ResponseBody::Empty => \"Empty\",\n            };\n            println!(\"Error response {}: {} body\", id, body_type);\n        }\n        \n        // Internal error with details\n        NetworkMessage::Error {\n            id,\n            code: ErrorCode::InternalError { details },\n            message,\n        } => {\n            println!(\"Internal error {}: {} ({})\", id, message, details);\n        }\n        \n        // Other errors\n        NetworkMessage::Error { id, code, message } => {\n            println!(\"Error {}: {} - {:?}\", id, message, code);\n        }\n        \n        // Catch-all\n        _ => {\n            println!(\"Other message: {:?}\", message);\n        }\n    }\n}\n\nfn advanced_pattern_examples() {\n    // Tuple destructuring with nested patterns\n    let data = (\n        (\"Alice\", 25),\n        Some(vec![1, 2, 3]),\n        Status::Suspended { reason: \"Test\".to_string(), until: None },\n    );\n    \n    match data {\n        ((name, age), Some(numbers), Status::Suspended { reason, until: None })\n            if age > 18 && numbers.len() > 2 => {\n            println!(\"Adult {} with {} items, suspended for: {}\", name, numbers.len(), reason);\n        }\n        _ => println!(\"Other data pattern\"),\n    }\n    \n    // Nested Option and Result patterns\n    let nested_result: Result<Option<Vec<i32>>, String> = Ok(Some(vec![1, 2, 3]));\n    \n    match nested_result {\n        Ok(Some(ref numbers)) if numbers.len() > 2 => {\n            println!(\"Success with {} numbers: {:?}\", numbers.len(), numbers);\n        }\n        Ok(Some(numbers)) => {\n            println!(\"Success with few numbers: {:?}\", numbers);\n        }\n        Ok(None) => {\n            println!(\"Success but no data\");\n        }\n        Err(e) => {\n            println!(\"Error: {}\", e);\n        }\n    }\n    \n    // Reference patterns and borrowing in matches\n    let user_refs = vec![\n        &UserRole::Admin { level: AdminLevel::Super { access_code: \"ABC\".to_string() } },\n        &UserRole::Member { since: 123456 },\n    ];\n    \n    for role_ref in user_refs {\n        match role_ref {\n            UserRole::Admin { level: AdminLevel::Super { access_code } } => {\n                println!(\"Super admin with code: {}\", access_code);\n            }\n            UserRole::Member { since } => {\n                println!(\"Member since: {}\", since);\n            }\n            _ => println!(\"Other role\"),\n        }\n    }\n    \n    // Array and slice patterns\n    let numbers = [1, 2, 3, 4, 5];\n    match numbers {\n        [first, .., last] => {\n            println!(\"Array: first={}, last={}\", first, last);\n        }\n    }\n    \n    let slice = &numbers[1..4];\n    match slice {\n        [a, b, c] => {\n            println!(\"Slice of 3: [{}, {}, {}]\", a, b, c);\n        }\n        _ => println!(\"Different slice length\"),\n    }\n}\n\n// Key concepts:\n// - Nested destructuring of complex enum variants\n// - Pattern guards with if conditions\n// - Wildcard patterns (..) for ignoring parts\n// - Reference patterns in match arms\n// - Range patterns (200..=299)\n// - Multiple pattern alternatives (A | B)\n// - Binding subpatterns with @\n// - Array and slice pattern matching\n// - Combining multiple pattern types in single match\n```",
    "tags": [
      "pattern-matching",
      "nested",
      "enums",
      "structs",
      "complex"
    ],
    "instruction": "Show nested pattern matching with complex data structures"
  },
  {
    "output": "```rust\n// This example demonstrates if let and while let for concise pattern matching\n// These constructs provide syntactic sugar for matching specific patterns\n\n#[derive(Debug)]\nenum Message {\n    Text(String),\n    Number(i32),\n    Quit,\n    ChangeColor(i32, i32, i32),\n}\n\n#[derive(Debug)]\nenum ConnectionState {\n    Disconnected,\n    Connecting,\n    Connected { session_id: String },\n    Error { code: u32, message: String },\n}\n\nfn main() {\n    println!(\"=== if let Pattern Matching ===\");\n    \n    // Basic if let usage\n    let message = Message::Text(\"Hello, World!\".to_string());\n    \n    // Instead of match with single arm\n    if let Message::Text(content) = message {\n        println!(\"Received text message: {}\", content);\n    }\n    \n    // This is equivalent to:\n    // match message {\n    //     Message::Text(content) => println!(\"Received text message: {}\", content),\n    //     _ => {}\n    // }\n    \n    // if let with else\n    let number_msg = Message::Number(42);\n    if let Message::Number(n) = number_msg {\n        println!(\"Got number: {}\", n);\n    } else {\n        println!(\"Not a number message\");\n    }\n    \n    // Nested if let patterns\n    let connection = ConnectionState::Connected { \n        session_id: \"session_123\".to_string() \n    };\n    \n    if let ConnectionState::Connected { session_id } = connection {\n        if session_id.starts_with(\"session_\") {\n            println!(\"Valid session: {}\", session_id);\n        }\n    }\n    \n    // if let with Option\n    let maybe_value: Option<i32> = Some(5);\n    if let Some(value) = maybe_value {\n        println!(\"Option contains: {}\", value);\n    }\n    \n    // if let with Result\n    let result: Result<i32, &str> = Ok(10);\n    if let Ok(success_value) = result {\n        println!(\"Operation succeeded with: {}\", success_value);\n    }\n    \n    // Multiple if let conditions\n    let data = Some(vec![1, 2, 3, 4, 5]);\n    if let Some(ref numbers) = data {\n        if let Some(&first) = numbers.first() {\n            println!(\"First number: {}\", first);\n        }\n    }\n    \n    println!(\"\\n=== while let Pattern Matching ===\");\n    \n    // while let with iterator\n    let mut values = vec![1, 2, 3, 4, 5].into_iter();\n    \n    while let Some(value) = values.next() {\n        println!(\"Processing: {}\", value);\n        if value == 3 {\n            break;\n        }\n    }\n    \n    // while let with Option chain\n    let mut maybe_number = Some(10);\n    while let Some(number) = maybe_number {\n        println!(\"Current number: {}\", number);\n        if number > 0 {\n            maybe_number = Some(number - 3);\n        } else {\n            maybe_number = None;\n        }\n    }\n    \n    // while let with Result and error handling\n    let mut operations = vec![\n        Ok(\"Success 1\"),\n        Ok(\"Success 2\"), \n        Err(\"Error occurred\"),\n        Ok(\"Success 3\"),\n    ].into_iter();\n    \n    while let Some(operation) = operations.next() {\n        match operation {\n            Ok(msg) => println!(\"Operation success: {}\", msg),\n            Err(err) => {\n                println!(\"Operation failed: {}\", err);\n                break; // Stop on first error\n            }\n        }\n    }\n    \n    // while let with destructuring\n    let mut pairs = vec![(1, \"one\"), (2, \"two\"), (3, \"three\")].into_iter();\n    while let Some((number, word)) = pairs.next() {\n        println!(\"{}: {}\", number, word);\n    }\n    \n    println!(\"\\n=== Practical Examples ===\");\n    \n    // Processing a queue-like structure\n    let mut message_queue = vec![\n        Message::Text(\"Hello\".to_string()),\n        Message::Number(42),\n        Message::ChangeColor(255, 0, 0),\n        Message::Quit,\n        Message::Text(\"After quit\".to_string()),\n    ];\n    \n    while let Some(msg) = message_queue.pop() {\n        if let Message::Quit = msg {\n            println!(\"Received quit message, stopping\");\n            break;\n        }\n        \n        match msg {\n            Message::Text(content) => println!(\"Text: {}\", content),\n            Message::Number(n) => println!(\"Number: {}\", n),\n            Message::ChangeColor(r, g, b) => println!(\"Color: RGB({}, {}, {})\", r, g, b),\n            Message::Quit => unreachable!(),\n        }\n    }\n    \n    // Parsing with if let chains\n    fn parse_config(input: &str) -> Option<(String, i32)> {\n        let parts: Vec<&str> = input.split('=').collect();\n        if let [key, value] = parts.as_slice() {\n            if let Ok(parsed_value) = value.parse::<i32>() {\n                return Some((key.to_string(), parsed_value));\n            }\n        }\n        None\n    }\n    \n    let configs = vec![\"timeout=30\", \"retries=5\", \"invalid\", \"port=8080\"];\n    for config in configs {\n        if let Some((key, value)) = parse_config(config) {\n            println!(\"Config: {} = {}\", key, value);\n        } else {\n            println!(\"Invalid config: {}\", config);\n        }\n    }\n    \n    // State machine with while let\n    #[derive(Debug)]\n    enum State {\n        Start,\n        Processing(i32),\n        Done(String),\n        Error(String),\n    }\n    \n    let mut current_state = State::Start;\n    let mut step = 0;\n    \n    while let State::Start | State::Processing(_) = current_state {\n        match current_state {\n            State::Start => {\n                println!(\"Starting process...\");\n                current_state = State::Processing(0);\n            }\n            State::Processing(count) => {\n                println!(\"Processing step: {}\", count);\n                step += 1;\n                if step < 3 {\n                    current_state = State::Processing(count + 1);\n                } else if step == 3 {\n                    current_state = State::Done(\"Completed successfully\".to_string());\n                } else {\n                    current_state = State::Error(\"Too many steps\".to_string());\n                }\n            }\n            _ => unreachable!(),\n        }\n    }\n    \n    println!(\"Final state: {:?}\", current_state);\n    \n    println!(\"\\n=== Comparison: match vs if let vs while let ===\");\n    \n    // When to use each:\n    println!(\"Use match when:\");\n    println!(\"- Handling multiple patterns\");\n    println!(\"- Need exhaustive matching\");\n    println!(\"- Complex pattern matching logic\");\n    \n    println!(\"\\nUse if let when:\");\n    println!(\"- Only care about one specific pattern\");\n    println!(\"- Want to ignore other cases\");\n    println!(\"- Need optional else clause\");\n    \n    println!(\"\\nUse while let when:\");\n    println!(\"- Iterating while pattern matches\");\n    println!(\"- Processing until specific condition\");\n    println!(\"- State machine implementations\");\n}\n\n// Key concepts:\n// - if let provides concise single-pattern matching\n// - while let enables iteration based on pattern matching\n// - More readable than match when only one pattern matters\n// - Can be combined with else clauses\n// - Useful for Option and Result unwrapping\n// - Great for iterator processing and state machines\n// - Reduces boilerplate compared to full match expressions\n```",
    "tags": [
      "if-let",
      "while-let",
      "pattern-matching",
      "control-flow"
    ],
    "instruction": "Demonstrate if let and while let patterns for concise pattern matching"
  },
  {
    "output": "```rust\n// This example demonstrates destructuring patterns for structs, tuples, and complex data\n// Destructuring allows extracting values from data structures in pattern matching\n\n#[derive(Debug, Clone)]\nstruct Point {\n    x: f64,\n    y: f64,\n}\n\n#[derive(Debug, Clone)]\nstruct Rectangle {\n    top_left: Point,\n    bottom_right: Point,\n    color: Color,\n}\n\n#[derive(Debug, Clone)]\nstruct Color {\n    r: u8,\n    g: u8,\n    b: u8,\n    alpha: Option<u8>,\n}\n\n#[derive(Debug)]\nstruct Person {\n    name: String,\n    age: u32,\n    address: Address,\n    contacts: Vec<Contact>,\n}\n\n#[derive(Debug)]\nstruct Address {\n    street: String,\n    city: String,\n    zip: String,\n}\n\n#[derive(Debug)]\nenum Contact {\n    Email(String),\n    Phone { country_code: String, number: String },\n    Social { platform: String, handle: String },\n}\n\nfn main() {\n    println!(\"=== Basic Struct Destructuring ===\");\n    \n    let point = Point { x: 3.0, y: 4.0 };\n    \n    // Basic destructuring\n    let Point { x, y } = point;\n    println!(\"Point coordinates: x={}, y={}\", x, y);\n    \n    // Destructuring with renaming\n    let Point { x: pos_x, y: pos_y } = point;\n    println!(\"Renamed: pos_x={}, pos_y={}\", pos_x, pos_y);\n    \n    // Partial destructuring with ..\n    let Point { x, .. } = point;\n    println!(\"Only x coordinate: {}\", x);\n    \n    println!(\"\\n=== Tuple Destructuring ===\");\n    \n    // Simple tuple destructuring\n    let tuple = (1, \"hello\", 3.14, true);\n    let (num, text, pi, flag) = tuple;\n    println!(\"Tuple values: {}, {}, {}, {}\", num, text, pi, flag);\n    \n    // Nested tuple destructuring\n    let nested = ((1, 2), (3, 4), (5, 6));\n    let ((a, b), (c, d), (e, f)) = nested;\n    println!(\"Nested tuples: a={}, b={}, c={}, d={}, e={}, f={}\", a, b, c, d, e, f);\n    \n    // Ignoring values with _\n    let (first, _, third, _) = tuple;\n    println!(\"First and third: {}, {}\", first, third);\n    \n    // Using .. to ignore multiple values\n    let (first_val, .., last_val) = (1, 2, 3, 4, 5);\n    println!(\"First: {}, Last: {}\", first_val, last_val);\n    \n    println!(\"\\n=== Complex Nested Destructuring ===\");\n    \n    let rect = Rectangle {\n        top_left: Point { x: 0.0, y: 10.0 },\n        bottom_right: Point { x: 10.0, y: 0.0 },\n        color: Color { r: 255, g: 0, b: 0, alpha: Some(128) },\n    };\n    \n    // Deep destructuring\n    let Rectangle {\n        top_left: Point { x: x1, y: y1 },\n        bottom_right: Point { x: x2, y: y2 },\n        color: Color { r, g, b, alpha },\n    } = rect;\n    \n    println!(\"Rectangle: ({}, {}) to ({}, {})\", x1, y1, x2, y2);\n    println!(\"Color: RGB({}, {}, {}) with alpha: {:?}\", r, g, b, alpha);\n    \n    // Partial nested destructuring\n    let Rectangle {\n        top_left: Point { x: top_x, .. },\n        color: Color { r: red, .. },\n        ..\n    } = Rectangle {\n        top_left: Point { x: 5.0, y: 5.0 },\n        bottom_right: Point { x: 15.0, y: 0.0 },\n        color: Color { r: 100, g: 150, b: 200, alpha: None },\n    };\n    \n    println!(\"Partial destructuring: top_x={}, red={}\", top_x, red);\n    \n    println!(\"\\n=== Function Parameter Destructuring ===\");\n    \n    // Function that takes destructured parameters\n    fn calculate_distance(Point { x: x1, y: y1 }: Point, Point { x: x2, y: y2 }: Point) -> f64 {\n        ((x2 - x1).powi(2) + (y2 - y1).powi(2)).sqrt()\n    }\n    \n    let p1 = Point { x: 0.0, y: 0.0 };\n    let p2 = Point { x: 3.0, y: 4.0 };\n    println!(\"Distance: {}\", calculate_distance(p1, p2));\n    \n    // Closure with destructuring\n    let points = vec![\n        Point { x: 1.0, y: 2.0 },\n        Point { x: 3.0, y: 4.0 },\n        Point { x: 5.0, y: 6.0 },\n    ];\n    \n    let x_coordinates: Vec<f64> = points\n        .iter()\n        .map(|Point { x, .. }| *x)\n        .collect();\n    println!(\"X coordinates: {:?}\", x_coordinates);\n    \n    println!(\"\\n=== Array and Slice Destructuring ===\");\n    \n    // Fixed-size array destructuring\n    let array = [1, 2, 3, 4, 5];\n    let [first, second, ..] = array;\n    println!(\"First two elements: {}, {}\", first, second);\n    \n    let [.., second_last, last] = array;\n    println!(\"Last two elements: {}, {}\", second_last, last);\n    \n    // Slice pattern matching\n    fn process_slice(slice: &[i32]) {\n        match slice {\n            [] => println!(\"Empty slice\"),\n            [x] => println!(\"Single element: {}\", x),\n            [x, y] => println!(\"Two elements: {}, {}\", x, y),\n            [first, .., last] => println!(\"Multiple elements: first={}, last={}\", first, last),\n        }\n    }\n    \n    process_slice(&[]);\n    process_slice(&[42]);\n    process_slice(&[1, 2]);\n    process_slice(&[1, 2, 3, 4, 5]);\n    \n    println!(\"\\n=== Reference Destructuring ===\");\n    \n    let point_ref = &Point { x: 7.0, y: 8.0 };\n    \n    // Destructuring references\n    let &Point { x: ref_x, y: ref_y } = point_ref;\n    println!(\"Reference destructuring: x={}, y={}\", ref_x, ref_y);\n    \n    // Using ref to create references during destructuring\n    let Point { x: ref x_ref, y: ref y_ref } = Point { x: 9.0, y: 10.0 };\n    println!(\"Created references: x_ref={}, y_ref={}\", x_ref, y_ref);\n    \n    println!(\"\\n=== Complex Real-World Example ===\");\n    \n    let person = Person {\n        name: \"Alice Johnson\".to_string(),\n        age: 30,\n        address: Address {\n            street: \"123 Main St\".to_string(),\n            city: \"Springfield\".to_string(),\n            zip: \"12345\".to_string(),\n        },\n        contacts: vec![\n            Contact::Email(\"alice@example.com\".to_string()),\n            Contact::Phone {\n                country_code: \"+1\".to_string(),\n                number: \"555-0123\".to_string(),\n            },\n            Contact::Social {\n                platform: \"Twitter\".to_string(),\n                handle: \"@alice_codes\".to_string(),\n            },\n        ],\n    };\n    \n    // Complex destructuring with pattern matching\n    analyze_person(&person);\n    \n    // Destructuring in loops\n    let contacts_info = vec![\n        (\"email\", \"primary\", \"alice@work.com\"),\n        (\"phone\", \"mobile\", \"+1-555-0123\"),\n        (\"social\", \"twitter\", \"@alice\"),\n    ];\n    \n    for (contact_type, category, value) in contacts_info {\n        println!(\"{} ({}): {}\", contact_type, category, value);\n    }\n    \n    // Destructuring with if let\n    if let Person {\n        name,\n        age,\n        address: Address { city, .. },\n        ..\n    } = person {\n        println!(\"Person {} ({}) lives in {}\", name, age, city);\n    }\n}\n\nfn analyze_person(person: &Person) {\n    // Destructuring in function body\n    let Person {\n        name,\n        age,\n        address: Address { city, zip, .. },\n        contacts,\n    } = person;\n    \n    println!(\"Analyzing person: {} (age {})\", name, age);\n    println!(\"Location: {} {}\", city, zip);\n    \n    // Destructuring in match with enum\n    for contact in contacts {\n        match contact {\n            Contact::Email(email) => {\n                println!(\"Email contact: {}\", email);\n            }\n            Contact::Phone { country_code, number } => {\n                println!(\"Phone contact: {} {}\", country_code, number);\n            }\n            Contact::Social { platform, handle } => {\n                println!(\"Social contact: {} on {}\", handle, platform);\n            }\n        }\n    }\n}\n\n// Key concepts:\n// - Struct destructuring extracts fields by name\n// - Tuple destructuring extracts by position\n// - Use .. to ignore remaining fields/elements\n// - Destructuring works in let, match, function parameters\n// - Can rename fields during destructuring\n// - Reference destructuring with & and ref patterns\n// - Array/slice destructuring with fixed patterns\n// - Nested destructuring for complex data structures\n// - Partial destructuring ignores unneeded parts\n```",
    "tags": [
      "destructuring",
      "pattern-matching",
      "structs",
      "tuples"
    ],
    "instruction": "Show destructuring of structs, tuples, and complex patterns"
  },
  {
    "output": "```rust\n// This example demonstrates implementing state machines using enums and pattern matching\n// State machines provide a clean way to model complex stateful behavior\n\nuse std::collections::HashMap;\n\n// Traffic light state machine\n#[derive(Debug, Clone, PartialEq)]\nenum TrafficLight {\n    Red { timer: u32 },\n    Yellow { timer: u32 },\n    Green { timer: u32 },\n}\n\nimpl TrafficLight {\n    fn new() -> Self {\n        TrafficLight::Red { timer: 30 }\n    }\n    \n    fn tick(&mut self) -> Option<TrafficEvent> {\n        match self {\n            TrafficLight::Red { timer } => {\n                if *timer > 0 {\n                    *timer -= 1;\n                    None\n                } else {\n                    *self = TrafficLight::Green { timer: 45 };\n                    Some(TrafficEvent::Changed(\"Red to Green\".to_string()))\n                }\n            }\n            TrafficLight::Green { timer } => {\n                if *timer > 0 {\n                    *timer -= 1;\n                    None\n                } else {\n                    *self = TrafficLight::Yellow { timer: 5 };\n                    Some(TrafficEvent::Changed(\"Green to Yellow\".to_string()))\n                }\n            }\n            TrafficLight::Yellow { timer } => {\n                if *timer > 0 {\n                    *timer -= 1;\n                    None\n                } else {\n                    *self = TrafficLight::Red { timer: 30 };\n                    Some(TrafficEvent::Changed(\"Yellow to Red\".to_string()))\n                }\n            }\n        }\n    }\n    \n    fn get_state(&self) -> &str {\n        match self {\n            TrafficLight::Red { .. } => \"RED\",\n            TrafficLight::Yellow { .. } => \"YELLOW\", \n            TrafficLight::Green { .. } => \"GREEN\",\n        }\n    }\n    \n    fn remaining_time(&self) -> u32 {\n        match self {\n            TrafficLight::Red { timer } | \n            TrafficLight::Yellow { timer } | \n            TrafficLight::Green { timer } => *timer,\n        }\n    }\n}\n\n#[derive(Debug)]\nenum TrafficEvent {\n    Changed(String),\n}\n\n// Connection state machine with error handling\n#[derive(Debug, Clone)]\nenum ConnectionState {\n    Disconnected,\n    Connecting { attempts: u32 },\n    Connected { session_id: String },\n    Reconnecting { attempts: u32, last_session: String },\n    Failed { error: String },\n}\n\n#[derive(Debug)]\nenum ConnectionEvent {\n    Connect,\n    ConnectionSuccess(String),\n    ConnectionFailed(String),\n    Disconnect,\n    NetworkError(String),\n    Retry,\n}\n\nimpl ConnectionState {\n    fn new() -> Self {\n        ConnectionState::Disconnected\n    }\n    \n    fn handle_event(&mut self, event: ConnectionEvent) -> Vec<String> {\n        let mut messages = Vec::new();\n        \n        match (self.clone(), event) {\n            // From Disconnected\n            (ConnectionState::Disconnected, ConnectionEvent::Connect) => {\n                *self = ConnectionState::Connecting { attempts: 1 };\n                messages.push(\"Starting connection attempt 1\".to_string());\n            }\n            \n            // From Connecting\n            (ConnectionState::Connecting { attempts }, ConnectionEvent::ConnectionSuccess(session_id)) => {\n                *self = ConnectionState::Connected { session_id: session_id.clone() };\n                messages.push(format!(\"Connected successfully with session {}\", session_id));\n            }\n            \n            (ConnectionState::Connecting { attempts }, ConnectionEvent::ConnectionFailed(error)) => {\n                if attempts < 3 {\n                    *self = ConnectionState::Connecting { attempts: attempts + 1 };\n                    messages.push(format!(\"Connection failed ({}), retrying... (attempt {})\", error, attempts + 1));\n                } else {\n                    *self = ConnectionState::Failed { error: error.clone() };\n                    messages.push(format!(\"Connection failed after {} attempts: {}\", attempts, error));\n                }\n            }\n            \n            // From Connected\n            (ConnectionState::Connected { session_id }, ConnectionEvent::Disconnect) => {\n                *self = ConnectionState::Disconnected;\n                messages.push(format!(\"Disconnected from session {}\", session_id));\n            }\n            \n            (ConnectionState::Connected { session_id }, ConnectionEvent::NetworkError(error)) => {\n                *self = ConnectionState::Reconnecting { attempts: 1, last_session: session_id };\n                messages.push(format!(\"Network error ({}), attempting to reconnect...\", error));\n            }\n            \n            // From Reconnecting\n            (ConnectionState::Reconnecting { attempts, last_session }, ConnectionEvent::ConnectionSuccess(session_id)) => {\n                *self = ConnectionState::Connected { session_id: session_id.clone() };\n                messages.push(format!(\"Reconnected with new session {}\", session_id));\n            }\n            \n            (ConnectionState::Reconnecting { attempts, last_session }, ConnectionEvent::ConnectionFailed(error)) => {\n                if attempts < 5 {\n                    *self = ConnectionState::Reconnecting { attempts: attempts + 1, last_session };\n                    messages.push(format!(\"Reconnection failed ({}), retrying... (attempt {})\", error, attempts + 1));\n                } else {\n                    *self = ConnectionState::Failed { error: format!(\"Reconnection failed after {} attempts\", attempts) };\n                    messages.push(\"Reconnection attempts exhausted, giving up\".to_string());\n                }\n            }\n            \n            // From Failed\n            (ConnectionState::Failed { .. }, ConnectionEvent::Retry) => {\n                *self = ConnectionState::Disconnected;\n                messages.push(\"Reset to disconnected state, ready to retry\".to_string());\n            }\n            \n            // Invalid transitions\n            (current_state, invalid_event) => {\n                messages.push(format!(\"Invalid event {:?} for state {:?}\", invalid_event, current_state));\n            }\n        }\n        \n        messages\n    }\n    \n    fn can_connect(&self) -> bool {\n        matches!(self, ConnectionState::Disconnected)\n    }\n    \n    fn is_connected(&self) -> bool {\n        matches!(self, ConnectionState::Connected { .. })\n    }\n}\n\n// Order processing state machine\n#[derive(Debug, Clone)]\nenum OrderState {\n    Created { items: Vec<String>, total: f64 },\n    PaymentPending { items: Vec<String>, total: f64, payment_id: String },\n    Paid { items: Vec<String>, total: f64, payment_id: String },\n    Shipped { items: Vec<String>, total: f64, tracking_number: String },\n    Delivered { items: Vec<String>, total: f64, delivery_date: String },\n    Cancelled { reason: String },\n    Refunded { amount: f64, reason: String },\n}\n\n#[derive(Debug)]\nenum OrderEvent {\n    InitiatePayment(String),\n    PaymentCompleted,\n    PaymentFailed(String),\n    Ship(String),\n    MarkDelivered(String),\n    Cancel(String),\n    Refund(String),\n}\n\nimpl OrderState {\n    fn new(items: Vec<String>, total: f64) -> Self {\n        OrderState::Created { items, total }\n    }\n    \n    fn process_event(&mut self, event: OrderEvent) -> Result<String, String> {\n        match (self.clone(), event) {\n            (OrderState::Created { items, total }, OrderEvent::InitiatePayment(payment_id)) => {\n                *self = OrderState::PaymentPending { items, total, payment_id: payment_id.clone() };\n                Ok(format!(\"Payment initiated with ID: {}\", payment_id))\n            }\n            \n            (OrderState::Created { .. }, OrderEvent::Cancel(reason)) => {\n                *self = OrderState::Cancelled { reason: reason.clone() };\n                Ok(format!(\"Order cancelled: {}\", reason))\n            }\n            \n            (OrderState::PaymentPending { items, total, payment_id }, OrderEvent::PaymentCompleted) => {\n                *self = OrderState::Paid { items, total, payment_id };\n                Ok(\"Payment completed successfully\".to_string())\n            }\n            \n            (OrderState::PaymentPending { items, total, .. }, OrderEvent::PaymentFailed(reason)) => {\n                *self = OrderState::Created { items, total };\n                Err(format!(\"Payment failed: {}\", reason))\n            }\n            \n            (OrderState::Paid { items, total, .. }, OrderEvent::Ship(tracking_number)) => {\n                *self = OrderState::Shipped { items, total, tracking_number: tracking_number.clone() };\n                Ok(format!(\"Order shipped with tracking number: {}\", tracking_number))\n            }\n            \n            (OrderState::Shipped { items, total, .. }, OrderEvent::MarkDelivered(delivery_date)) => {\n                *self = OrderState::Delivered { items, total, delivery_date: delivery_date.clone() };\n                Ok(format!(\"Order delivered on: {}\", delivery_date))\n            }\n            \n            (OrderState::Paid { .. } | OrderState::Shipped { .. }, OrderEvent::Cancel(reason)) => {\n                *self = OrderState::Cancelled { reason: reason.clone() };\n                Ok(format!(\"Order cancelled: {}\", reason))\n            }\n            \n            (OrderState::Paid { total, .. } | \n             OrderState::Shipped { total, .. } | \n             OrderState::Delivered { total, .. }, OrderEvent::Refund(reason)) => {\n                *self = OrderState::Refunded { amount: total, reason: reason.clone() };\n                Ok(format!(\"Refund processed: ${:.2} - {}\", total, reason))\n            }\n            \n            (current_state, invalid_event) => {\n                Err(format!(\"Cannot process {:?} in state {:?}\", invalid_event, current_state))\n            }\n        }\n    }\n    \n    fn get_status(&self) -> String {\n        match self {\n            OrderState::Created { .. } => \"Created\".to_string(),\n            OrderState::PaymentPending { .. } => \"Payment Pending\".to_string(),\n            OrderState::Paid { .. } => \"Paid\".to_string(),\n            OrderState::Shipped { tracking_number, .. } => format!(\"Shipped ({})\", tracking_number),\n            OrderState::Delivered { delivery_date, .. } => format!(\"Delivered ({})\", delivery_date),\n            OrderState::Cancelled { reason } => format!(\"Cancelled ({})\", reason),\n            OrderState::Refunded { amount, .. } => format!(\"Refunded (${:.2})\", amount),\n        }\n    }\n}\n\nfn main() {\n    println!(\"=== Traffic Light State Machine ===\");\n    \n    let mut traffic_light = TrafficLight::new();\n    println!(\"Initial state: {} ({}s remaining)\", traffic_light.get_state(), traffic_light.remaining_time());\n    \n    // Simulate traffic light for a few cycles\n    for second in 1..=100 {\n        if let Some(event) = traffic_light.tick() {\n            println!(\"Second {}: {:?}\", second, event);\n        }\n        \n        if second % 10 == 0 {\n            println!(\"Second {}: {} ({}s remaining)\", \n                     second, traffic_light.get_state(), traffic_light.remaining_time());\n        }\n    }\n    \n    println!(\"\\n=== Connection State Machine ===\");\n    \n    let mut connection = ConnectionState::new();\n    let events = vec![\n        ConnectionEvent::Connect,\n        ConnectionEvent::ConnectionFailed(\"Network timeout\".to_string()),\n        ConnectionEvent::ConnectionFailed(\"DNS error\".to_string()),\n        ConnectionEvent::ConnectionSuccess(\"session_123\".to_string()),\n        ConnectionEvent::NetworkError(\"Connection lost\".to_string()),\n        ConnectionEvent::ConnectionSuccess(\"session_456\".to_string()),\n        ConnectionEvent::Disconnect,\n    ];\n    \n    for event in events {\n        let messages = connection.handle_event(event);\n        for message in messages {\n            println!(\"Connection: {}\", message);\n        }\n        println!(\"Current state: {:?}\\n\", connection);\n    }\n    \n    println!(\"=== Order Processing State Machine ===\");\n    \n    let mut order = OrderState::new(\n        vec![\"Laptop\".to_string(), \"Mouse\".to_string()],\n        1299.99\n    );\n    \n    let order_events = vec![\n        OrderEvent::InitiatePayment(\"pay_123\".to_string()),\n        OrderEvent::PaymentCompleted,\n        OrderEvent::Ship(\"TRACK123\".to_string()),\n        OrderEvent::MarkDelivered(\"2023-10-15\".to_string()),\n    ];\n    \n    println!(\"Order status: {}\", order.get_status());\n    \n    for event in order_events {\n        match order.process_event(event) {\n            Ok(message) => println!(\"Order: {}\", message),\n            Err(error) => println!(\"Order error: {}\", error),\n        }\n        println!(\"Order status: {}\\n\", order.get_status());\n    }\n    \n    // Demonstrate invalid transition\n    let mut cancelled_order = OrderState::new(vec![\"Item\".to_string()], 50.0);\n    cancelled_order.process_event(OrderEvent::Cancel(\"Customer request\".to_string())).unwrap();\n    \n    match cancelled_order.process_event(OrderEvent::Ship(\"INVALID\".to_string())) {\n        Ok(_) => println!(\"Unexpected success\"),\n        Err(error) => println!(\"Expected error: {}\", error),\n    }\n    \n    println!(\"\\n=== State Machine Benefits ===\");\n    println!(\"- Clear state representation with enums\");\n    println!(\"- Explicit state transitions\");\n    println!(\"- Compile-time validation of state logic\");\n    println!(\"- Pattern matching for event handling\");\n    println!(\"- Impossible states are unrepresentable\");\n    println!(\"- Easy to test and reason about\");\n}\n\n// Key concepts:\n// - Enums model discrete states with associated data\n// - Pattern matching handles state transitions\n// - Invalid transitions can be caught at compile time\n// - State machines make complex behavior predictable\n// - Associated data allows states to carry context\n// - Event-driven design with clear inputs/outputs\n// - Exhaustive matching ensures all cases are handled\n```",
    "tags": [
      "state-machine",
      "enums",
      "pattern-matching",
      "design-patterns"
    ],
    "instruction": "Implement a state machine using enums and pattern matching"
  },
  {
    "output": "```rust\n// This example demonstrates setting up a Cargo workspace with multiple crates\n// and advanced dependency management strategies\n\n// Cargo.toml (workspace root)\n/*\n[workspace]\nmembers = [\n    \"core\",\n    \"cli\",\n    \"web-api\",\n    \"shared\"\n]\nresolver = \"2\"\n\n[workspace.dependencies]\n# Shared dependencies across workspace\ntokio = { version = \"1.0\", features = [\"full\"] }\nserde = { version = \"1.0\", features = [\"derive\"] }\nanyhow = \"1.0\"\ntracing = \"0.1\"\n\n[workspace.metadata.release]\n# Release configuration for workspace\nshared-version = true\ntag-name = \"v{{version}}\"\n*/\n\n// core/Cargo.toml\n/*\n[package]\nname = \"myproject-core\"\nversion = \"0.1.0\"\nedition = \"2021\"\ndescription = \"Core business logic for MyProject\"\nlicense = \"MIT OR Apache-2.0\"\nrepository = \"https://github.com/user/myproject\"\n\n[dependencies]\n# Use workspace dependencies\ntokio = { workspace = true }\nserde = { workspace = true, features = [\"json\"] }\nanyhow = { workspace = true }\ntracing = { workspace = true }\n# Crate-specific dependencies\nuuid = { version = \"1.0\", features = [\"v4\", \"serde\"] }\nchrono = { version = \"0.4\", features = [\"serde\"] }\n\n[dev-dependencies]\ntokio-test = \"0.4\"\n*/\n\n// core/src/lib.rs\nuse serde::{Deserialize, Serialize};\nuse std::collections::HashMap;\nuse uuid::Uuid;\nuse chrono::{DateTime, Utc};\n\n#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]\npub struct User {\n    pub id: Uuid,\n    pub username: String,\n    pub email: String,\n    pub created_at: DateTime<Utc>,\n    pub metadata: HashMap<String, String>,\n}\n\n#[derive(Debug, thiserror::Error)]\npub enum CoreError {\n    #[error(\"User not found: {id}\")]\n    UserNotFound { id: Uuid },\n    #[error(\"Invalid email format: {email}\")]\n    InvalidEmail { email: String },\n    #[error(\"Database error: {0}\")]\n    Database(#[from] anyhow::Error),\n}\n\npub type Result<T> = std::result::Result<T, CoreError>;\n\n#[derive(Debug, Clone)]\npub struct UserService {\n    users: HashMap<Uuid, User>,\n}\n\nimpl UserService {\n    pub fn new() -> Self {\n        Self {\n            users: HashMap::new(),\n        }\n    }\n    \n    pub fn create_user(&mut self, username: String, email: String) -> Result<User> {\n        if !email.contains('@') {\n            return Err(CoreError::InvalidEmail { email });\n        }\n        \n        let user = User {\n            id: Uuid::new_v4(),\n            username,\n            email,\n            created_at: Utc::now(),\n            metadata: HashMap::new(),\n        };\n        \n        self.users.insert(user.id, user.clone());\n        Ok(user)\n    }\n    \n    pub fn get_user(&self, id: Uuid) -> Result<&User> {\n        self.users.get(&id).ok_or(CoreError::UserNotFound { id })\n    }\n    \n    pub fn list_users(&self) -> Vec<&User> {\n        self.users.values().collect()\n    }\n}\n\n// Feature flags example\n#[cfg(feature = \"advanced-metrics\")]\npub mod metrics {\n    use std::sync::atomic::{AtomicU64, Ordering};\n    \n    #[derive(Debug, Default)]\n    pub struct Metrics {\n        requests: AtomicU64,\n        errors: AtomicU64,\n    }\n    \n    impl Metrics {\n        pub fn increment_requests(&self) {\n            self.requests.fetch_add(1, Ordering::Relaxed);\n        }\n        \n        pub fn increment_errors(&self) {\n            self.errors.fetch_add(1, Ordering::Relaxed);\n        }\n        \n        pub fn get_stats(&self) -> (u64, u64) {\n            (\n                self.requests.load(Ordering::Relaxed),\n                self.errors.load(Ordering::Relaxed),\n            )\n        }\n    }\n}\n\n// shared/Cargo.toml\n/*\n[package]\nname = \"myproject-shared\"\nversion = \"0.1.0\"\nedition = \"2021\"\n\n[dependencies]\nserde = { workspace = true }\nanyhow = { workspace = true }\n*/\n\n// shared/src/lib.rs\nuse serde::{Deserialize, Serialize};\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct Config {\n    pub database_url: String,\n    pub api_port: u16,\n    pub log_level: String,\n    pub feature_flags: FeatureFlags,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct FeatureFlags {\n    pub advanced_metrics: bool,\n    pub rate_limiting: bool,\n    pub caching: bool,\n}\n\nimpl Default for Config {\n    fn default() -> Self {\n        Self {\n            database_url: \"sqlite::memory:\".to_string(),\n            api_port: 8080,\n            log_level: \"info\".to_string(),\n            feature_flags: FeatureFlags {\n                advanced_metrics: false,\n                rate_limiting: true,\n                caching: false,\n            },\n        }\n    }\n}\n\n// cli/Cargo.toml\n/*\n[package]\nname = \"myproject-cli\"\nversion = \"0.1.0\"\nedition = \"2021\"\n\n[[bin]]\nname = \"myproject\"\npath = \"src/main.rs\"\n\n[dependencies]\nmyproject-core = { path = \"../core\" }\nmyproject-shared = { path = \"../shared\" }\ntokio = { workspace = true }\nanyhow = { workspace = true }\nclap = { version = \"4.0\", features = [\"derive\"] }\ntracing = { workspace = true }\ntracing-subscriber = \"0.3\"\n*/\n\n// Build script example: cli/build.rs\n/*\nuse std::env;\nuse std::fs;\nuse std::path::Path;\n\nfn main() {\n    // Generate build info\n    let out_dir = env::var_os(\"OUT_DIR\").unwrap();\n    let dest_path = Path::new(&out_dir).join(\"build_info.rs\");\n    \n    let git_hash = std::process::Command::new(\"git\")\n        .args([\"rev-parse\", \"--short\", \"HEAD\"])\n        .output()\n        .ok()\n        .and_then(|output| String::from_utf8(output.stdout).ok())\n        .map(|s| s.trim().to_string())\n        .unwrap_or_else(|| \"unknown\".to_string());\n    \n    let build_time = chrono::Utc::now().to_rfc3339();\n    \n    fs::write(\n        dest_path,\n        format!(\n            r#\"\n            pub const GIT_HASH: &str = \"{}\";\n            pub const BUILD_TIME: &str = \"{}\";\n            \"#,\n            git_hash, build_time\n        ),\n    ).unwrap();\n    \n    println!(\"cargo:rerun-if-changed=.git/HEAD\");\n}\n*/\n\n// Cargo configuration examples\n// .cargo/config.toml\n/*\n[build]\ntarget-dir = \"target\"\n\n[target.x86_64-unknown-linux-gnu]\nlinker = \"clang\"\nrustflags = [\"-C\", \"link-arg=-fuse-ld=lld\"]\n\n[env]\nRUST_LOG = { value = \"debug\", relative = true }\n\n[alias]\nxt = \"nextest run\"\nfmt-check = \"fmt -- --check\"\nlint = \"clippy -- -D warnings\"\n*/\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    \n    #[test]\n    fn test_user_service() {\n        let mut service = UserService::new();\n        let user = service.create_user(\n            \"testuser\".to_string(),\n            \"test@example.com\".to_string(),\n        ).unwrap();\n        \n        assert_eq!(user.username, \"testuser\");\n        assert_eq!(user.email, \"test@example.com\");\n        \n        let retrieved = service.get_user(user.id).unwrap();\n        assert_eq!(retrieved, &user);\n    }\n    \n    #[test]\n    fn test_invalid_email() {\n        let mut service = UserService::new();\n        let result = service.create_user(\n            \"testuser\".to_string(),\n            \"invalid-email\".to_string(),\n        );\n        \n        assert!(matches!(result, Err(CoreError::InvalidEmail { .. })));\n    }\n}\n\n// Key concepts:\n// - Workspace organization with shared dependencies\n// - Cross-crate dependency management\n// - Feature flags for conditional compilation\n// - Build scripts for code generation\n// - Cargo configuration and aliases\n// - Proper crate structure and metadata\n// - Version management across workspace\n// - Development vs production configurations\n```",
    "tags": [
      "cargo",
      "workspace",
      "dependency-management",
      "project-structure",
      "build-scripts",
      "feature-flags",
      "crate-organization"
    ],
    "instruction": "Set up a Cargo workspace with multiple crates and dependency management"
  },
  {
    "output": "```rust\n// This example demonstrates production-ready configuration management\n// combining environment variables, config files, and validation\n\nuse serde::{Deserialize, Serialize};\nuse std::env;\nuse std::fs;\nuse std::path::{Path, PathBuf};\nuse std::time::Duration;\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct AppConfig {\n    pub server: ServerConfig,\n    pub database: DatabaseConfig,\n    pub logging: LoggingConfig,\n    pub security: SecurityConfig,\n    pub features: FeatureFlags,\n    pub external_services: ExternalServicesConfig,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ServerConfig {\n    pub host: String,\n    pub port: u16,\n    pub workers: usize,\n    pub max_connections: usize,\n    pub timeout_seconds: u64,\n    pub tls: Option<TlsConfig>,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct TlsConfig {\n    pub cert_path: PathBuf,\n    pub key_path: PathBuf,\n    pub ca_path: Option<PathBuf>,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct DatabaseConfig {\n    pub url: String,\n    pub pool_size: u32,\n    pub max_lifetime_seconds: u64,\n    pub timeout_seconds: u64,\n    pub migration_path: Option<PathBuf>,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct LoggingConfig {\n    pub level: String,\n    pub format: LogFormat,\n    pub file: Option<LogFileConfig>,\n    pub console: bool,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub enum LogFormat {\n    Json,\n    Pretty,\n    Compact,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct LogFileConfig {\n    pub path: PathBuf,\n    pub max_size_mb: u64,\n    pub max_files: u32,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct SecurityConfig {\n    pub jwt_secret: String,\n    pub jwt_expiry_hours: u64,\n    pub rate_limit: RateLimitConfig,\n    pub cors: CorsConfig,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct RateLimitConfig {\n    pub requests_per_minute: u32,\n    pub burst_size: u32,\n    pub enabled: bool,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct CorsConfig {\n    pub allowed_origins: Vec<String>,\n    pub allowed_methods: Vec<String>,\n    pub allowed_headers: Vec<String>,\n    pub max_age_seconds: u64,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct FeatureFlags {\n    pub metrics_enabled: bool,\n    pub tracing_enabled: bool,\n    pub cache_enabled: bool,\n    pub experimental_features: bool,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ExternalServicesConfig {\n    pub redis: Option<RedisConfig>,\n    pub email: Option<EmailConfig>,\n    pub storage: StorageConfig,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct RedisConfig {\n    pub url: String,\n    pub pool_size: u32,\n    pub timeout_seconds: u64,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct EmailConfig {\n    pub smtp_host: String,\n    pub smtp_port: u16,\n    pub username: String,\n    pub password: String,\n    pub from_address: String,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct StorageConfig {\n    pub backend: StorageBackend,\n    pub base_path: PathBuf,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub enum StorageBackend {\n    Local,\n    S3 { bucket: String, region: String },\n    Azure { container: String, account: String },\n}\n\n#[derive(Debug, thiserror::Error)]\npub enum ConfigError {\n    #[error(\"Configuration file not found: {path}\")]\n    FileNotFound { path: String },\n    #[error(\"Invalid configuration format: {0}\")]\n    InvalidFormat(#[from] toml::de::Error),\n    #[error(\"Environment variable error: {0}\")]\n    EnvVar(#[from] env::VarError),\n    #[error(\"Validation error: {message}\")]\n    Validation { message: String },\n    #[error(\"IO error: {0}\")]\n    Io(#[from] std::io::Error),\n}\n\npub type ConfigResult<T> = Result<T, ConfigError>;\n\nimpl Default for AppConfig {\n    fn default() -> Self {\n        Self {\n            server: ServerConfig {\n                host: \"127.0.0.1\".to_string(),\n                port: 8080,\n                workers: num_cpus::get(),\n                max_connections: 1000,\n                timeout_seconds: 30,\n                tls: None,\n            },\n            database: DatabaseConfig {\n                url: \"sqlite::memory:\".to_string(),\n                pool_size: 10,\n                max_lifetime_seconds: 3600,\n                timeout_seconds: 30,\n                migration_path: None,\n            },\n            logging: LoggingConfig {\n                level: \"info\".to_string(),\n                format: LogFormat::Pretty,\n                file: None,\n                console: true,\n            },\n            security: SecurityConfig {\n                jwt_secret: \"change-me-in-production\".to_string(),\n                jwt_expiry_hours: 24,\n                rate_limit: RateLimitConfig {\n                    requests_per_minute: 60,\n                    burst_size: 10,\n                    enabled: true,\n                },\n                cors: CorsConfig {\n                    allowed_origins: vec![\"*\".to_string()],\n                    allowed_methods: vec![\"GET\".to_string(), \"POST\".to_string()],\n                    allowed_headers: vec![\"Content-Type\".to_string()],\n                    max_age_seconds: 3600,\n                },\n            },\n            features: FeatureFlags {\n                metrics_enabled: false,\n                tracing_enabled: true,\n                cache_enabled: false,\n                experimental_features: false,\n            },\n            external_services: ExternalServicesConfig {\n                redis: None,\n                email: None,\n                storage: StorageConfig {\n                    backend: StorageBackend::Local,\n                    base_path: PathBuf::from(\"./storage\"),\n                },\n            },\n        }\n    }\n}\n\nimpl AppConfig {\n    /// Load configuration from multiple sources with precedence:\n    /// 1. Environment variables (highest priority)\n    /// 2. Configuration file\n    /// 3. Default values (lowest priority)\n    pub fn load() -> ConfigResult<Self> {\n        let mut config = Self::default();\n        \n        // Load from config file if it exists\n        if let Ok(config_path) = env::var(\"APP_CONFIG_PATH\") {\n            config = Self::load_from_file(&config_path)?;\n        } else {\n            // Try standard locations\n            for path in &[\"app.toml\", \"config/app.toml\", \"/etc/myapp/config.toml\"] {\n                if Path::new(path).exists() {\n                    config = Self::load_from_file(path)?;\n                    break;\n                }\n            }\n        }\n        \n        // Override with environment variables\n        config.apply_env_overrides()?;\n        \n        // Validate configuration\n        config.validate()?;\n        \n        Ok(config)\n    }\n    \n    pub fn load_from_file<P: AsRef<Path>>(path: P) -> ConfigResult<Self> {\n        let path = path.as_ref();\n        let contents = fs::read_to_string(path)\n            .map_err(|_| ConfigError::FileNotFound {\n                path: path.display().to_string(),\n            })?;\n        \n        let config: AppConfig = toml::from_str(&contents)?;\n        Ok(config)\n    }\n    \n    pub fn apply_env_overrides(&mut self) -> ConfigResult<()> {\n        // Server configuration\n        if let Ok(host) = env::var(\"APP_SERVER_HOST\") {\n            self.server.host = host;\n        }\n        if let Ok(port) = env::var(\"APP_SERVER_PORT\") {\n            self.server.port = port.parse().map_err(|_| ConfigError::Validation {\n                message: \"Invalid port number\".to_string(),\n            })?;\n        }\n        if let Ok(workers) = env::var(\"APP_SERVER_WORKERS\") {\n            self.server.workers = workers.parse().map_err(|_| ConfigError::Validation {\n                message: \"Invalid worker count\".to_string(),\n            })?;\n        }\n        \n        // Database configuration\n        if let Ok(db_url) = env::var(\"DATABASE_URL\") {\n            self.database.url = db_url;\n        }\n        if let Ok(pool_size) = env::var(\"APP_DB_POOL_SIZE\") {\n            self.database.pool_size = pool_size.parse().map_err(|_| ConfigError::Validation {\n                message: \"Invalid database pool size\".to_string(),\n            })?;\n        }\n        \n        // Logging configuration\n        if let Ok(log_level) = env::var(\"RUST_LOG\") {\n            self.logging.level = log_level;\n        }\n        \n        // Security configuration\n        if let Ok(jwt_secret) = env::var(\"APP_JWT_SECRET\") {\n            self.security.jwt_secret = jwt_secret;\n        }\n        \n        // Feature flags\n        if let Ok(metrics) = env::var(\"APP_METRICS_ENABLED\") {\n            self.features.metrics_enabled = metrics.parse().unwrap_or(false);\n        }\n        \n        // Redis configuration\n        if let Ok(redis_url) = env::var(\"REDIS_URL\") {\n            self.external_services.redis = Some(RedisConfig {\n                url: redis_url,\n                pool_size: env::var(\"APP_REDIS_POOL_SIZE\")\n                    .ok()\n                    .and_then(|s| s.parse().ok())\n                    .unwrap_or(10),\n                timeout_seconds: 5,\n            });\n        }\n        \n        Ok(())\n    }\n    \n    pub fn validate(&self) -> ConfigResult<()> {\n        // Validate server configuration\n        if self.server.port == 0 {\n            return Err(ConfigError::Validation {\n                message: \"Server port cannot be 0\".to_string(),\n            });\n        }\n        \n        if self.server.workers == 0 {\n            return Err(ConfigError::Validation {\n                message: \"Worker count must be greater than 0\".to_string(),\n            });\n        }\n        \n        // Validate database configuration\n        if self.database.url.is_empty() {\n            return Err(ConfigError::Validation {\n                message: \"Database URL cannot be empty\".to_string(),\n            });\n        }\n        \n        if self.database.pool_size == 0 {\n            return Err(ConfigError::Validation {\n                message: \"Database pool size must be greater than 0\".to_string(),\n            });\n        }\n        \n        // Validate security configuration\n        if self.security.jwt_secret == \"change-me-in-production\" {\n            eprintln!(\"WARNING: Using default JWT secret in production is unsafe!\");\n        }\n        \n        if self.security.jwt_secret.len() < 32 {\n            return Err(ConfigError::Validation {\n                message: \"JWT secret must be at least 32 characters\".to_string(),\n            });\n        }\n        \n        // Validate TLS configuration if enabled\n        if let Some(ref tls) = self.server.tls {\n            if !tls.cert_path.exists() {\n                return Err(ConfigError::Validation {\n                    message: format!(\"TLS certificate file not found: {:?}\", tls.cert_path),\n                });\n            }\n            \n            if !tls.key_path.exists() {\n                return Err(ConfigError::Validation {\n                    message: format!(\"TLS private key file not found: {:?}\", tls.key_path),\n                });\n            }\n        }\n        \n        Ok(())\n    }\n    \n    pub fn to_toml(&self) -> ConfigResult<String> {\n        toml::to_string_pretty(self)\n            .map_err(|e| ConfigError::Validation {\n                message: format!(\"Failed to serialize config: {}\", e),\n            })\n    }\n    \n    pub fn save_to_file<P: AsRef<Path>>(&self, path: P) -> ConfigResult<()> {\n        let contents = self.to_toml()?;\n        fs::write(path, contents)?;\n        Ok(())\n    }\n    \n    // Environment-specific configurations\n    pub fn for_development() -> Self {\n        let mut config = Self::default();\n        config.logging.level = \"debug\".to_string();\n        config.features.metrics_enabled = true;\n        config.features.tracing_enabled = true;\n        config.security.jwt_secret = \"dev-secret-key-not-for-production\".to_string();\n        config\n    }\n    \n    pub fn for_testing() -> Self {\n        let mut config = Self::default();\n        config.database.url = \"sqlite::memory:\".to_string();\n        config.logging.level = \"warn\".to_string();\n        config.logging.console = false;\n        config.server.port = 0; // Random port for tests\n        config.security.jwt_secret = \"test-secret-key-32-characters-long\".to_string();\n        config\n    }\n    \n    pub fn for_production() -> ConfigResult<Self> {\n        let mut config = Self::load()?;\n        \n        // Production-specific validations\n        if config.database.url.contains(\"sqlite::memory:\") {\n            return Err(ConfigError::Validation {\n                message: \"In-memory database not allowed in production\".to_string(),\n            });\n        }\n        \n        if config.security.jwt_secret.contains(\"dev\") || config.security.jwt_secret.contains(\"test\") {\n            return Err(ConfigError::Validation {\n                message: \"Development/test JWT secret detected in production\".to_string(),\n            });\n        }\n        \n        config.features.metrics_enabled = true;\n        config.logging.format = LogFormat::Json;\n        \n        Ok(config)\n    }\n}\n\n// Configuration builder for programmatic setup\npub struct ConfigBuilder {\n    config: AppConfig,\n}\n\nimpl ConfigBuilder {\n    pub fn new() -> Self {\n        Self {\n            config: AppConfig::default(),\n        }\n    }\n    \n    pub fn server_port(mut self, port: u16) -> Self {\n        self.config.server.port = port;\n        self\n    }\n    \n    pub fn database_url<S: Into<String>>(mut self, url: S) -> Self {\n        self.config.database.url = url.into();\n        self\n    }\n    \n    pub fn jwt_secret<S: Into<String>>(mut self, secret: S) -> Self {\n        self.config.security.jwt_secret = secret.into();\n        self\n    }\n    \n    pub fn enable_feature(mut self, feature: &str) -> Self {\n        match feature {\n            \"metrics\" => self.config.features.metrics_enabled = true,\n            \"tracing\" => self.config.features.tracing_enabled = true,\n            \"cache\" => self.config.features.cache_enabled = true,\n            \"experimental\" => self.config.features.experimental_features = true,\n            _ => {}\n        }\n        self\n    }\n    \n    pub fn build(self) -> ConfigResult<AppConfig> {\n        self.config.validate()?;\n        Ok(self.config)\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::env;\n    \n    #[test]\n    fn test_default_config() {\n        let config = AppConfig::default();\n        assert_eq!(config.server.port, 8080);\n        assert_eq!(config.database.url, \"sqlite::memory:\");\n    }\n    \n    #[test]\n    fn test_config_builder() {\n        let config = ConfigBuilder::new()\n            .server_port(3000)\n            .database_url(\"postgresql://localhost/test\")\n            .jwt_secret(\"test-secret-key-32-characters-long\")\n            .enable_feature(\"metrics\")\n            .build()\n            .unwrap();\n        \n        assert_eq!(config.server.port, 3000);\n        assert_eq!(config.database.url, \"postgresql://localhost/test\");\n        assert!(config.features.metrics_enabled);\n    }\n    \n    #[test]\n    fn test_env_override() {\n        env::set_var(\"APP_SERVER_PORT\", \"9000\");\n        env::set_var(\"DATABASE_URL\", \"postgresql://test\");\n        \n        let mut config = AppConfig::default();\n        config.apply_env_overrides().unwrap();\n        \n        assert_eq!(config.server.port, 9000);\n        assert_eq!(config.database.url, \"postgresql://test\");\n        \n        env::remove_var(\"APP_SERVER_PORT\");\n        env::remove_var(\"DATABASE_URL\");\n    }\n    \n    #[test]\n    fn test_validation() {\n        let mut config = AppConfig::default();\n        config.server.port = 0;\n        \n        assert!(config.validate().is_err());\n    }\n}\n\n// Key concepts:\n// - Layered configuration (defaults -> file -> env vars)\n// - Comprehensive validation with detailed error messages\n// - Environment-specific configurations\n// - Builder pattern for programmatic configuration\n// - TOML serialization for human-readable config files\n// - Security considerations for production deployments\n// - Feature flags for conditional functionality\n// - Structured configuration with nested types\n```",
    "tags": [
      "configuration",
      "environment-variables",
      "toml",
      "validation",
      "production",
      "security",
      "feature-flags",
      "builder-pattern"
    ],
    "instruction": "Implement comprehensive configuration management with environment variables and config files"
  },
  {
    "output": "```rust\n// This example demonstrates production-ready logging and observability\n// using the tracing ecosystem and custom metrics collection\n\nuse std::collections::HashMap;\nuse std::sync::atomic::{AtomicU64, Ordering};\nuse std::sync::Arc;\nuse std::time::{Duration, Instant};\nuse tokio::time::sleep;\nuse tracing::{\n    debug, error, info, instrument, span, warn, Instrument, Level, Span,\n};\nuse tracing_subscriber::{\n    filter::EnvFilter,\n    fmt::{self, format::FmtSpan},\n    layer::SubscriberExt,\n    util::SubscriberInitExt,\n    Layer,\n};\n\n// Custom metrics system\n#[derive(Debug, Clone)]\npub struct Metrics {\n    counters: Arc<parking_lot::RwLock<HashMap<String, AtomicU64>>>,\n    histograms: Arc<parking_lot::RwLock<HashMap<String, Vec<f64>>>>,\n    gauges: Arc<parking_lot::RwLock<HashMap<String, AtomicU64>>>,\n}\n\nimpl Default for Metrics {\n    fn default() -> Self {\n        Self {\n            counters: Arc::new(parking_lot::RwLock::new(HashMap::new())),\n            histograms: Arc::new(parking_lot::RwLock::new(HashMap::new())),\n            gauges: Arc::new(parking_lot::RwLock::new(HashMap::new())),\n        }\n    }\n}\n\nimpl Metrics {\n    pub fn increment_counter(&self, name: &str, value: u64) {\n        let counters = self.counters.read();\n        if let Some(counter) = counters.get(name) {\n            counter.fetch_add(value, Ordering::Relaxed);\n        } else {\n            drop(counters);\n            let mut counters = self.counters.write();\n            let counter = counters.entry(name.to_string())\n                .or_insert_with(|| AtomicU64::new(0));\n            counter.fetch_add(value, Ordering::Relaxed);\n        }\n    }\n    \n    pub fn set_gauge(&self, name: &str, value: u64) {\n        let gauges = self.gauges.read();\n        if let Some(gauge) = gauges.get(name) {\n            gauge.store(value, Ordering::Relaxed);\n        } else {\n            drop(gauges);\n            let mut gauges = self.gauges.write();\n            let gauge = gauges.entry(name.to_string())\n                .or_insert_with(|| AtomicU64::new(0));\n            gauge.store(value, Ordering::Relaxed);\n        }\n    }\n    \n    pub fn record_histogram(&self, name: &str, value: f64) {\n        let mut histograms = self.histograms.write();\n        let histogram = histograms.entry(name.to_string())\n            .or_insert_with(Vec::new);\n        histogram.push(value);\n        \n        // Keep only last 1000 values to prevent memory growth\n        if histogram.len() > 1000 {\n            histogram.drain(..histogram.len() - 1000);\n        }\n    }\n    \n    pub fn get_counter(&self, name: &str) -> u64 {\n        self.counters.read()\n            .get(name)\n            .map(|c| c.load(Ordering::Relaxed))\n            .unwrap_or(0)\n    }\n    \n    pub fn get_gauge(&self, name: &str) -> u64 {\n        self.gauges.read()\n            .get(name)\n            .map(|g| g.load(Ordering::Relaxed))\n            .unwrap_or(0)\n    }\n    \n    pub fn get_histogram_stats(&self, name: &str) -> Option<HistogramStats> {\n        let histograms = self.histograms.read();\n        histograms.get(name).map(|values| {\n            if values.is_empty() {\n                return HistogramStats::default();\n            }\n            \n            let mut sorted = values.clone();\n            sorted.sort_by(|a, b| a.partial_cmp(b).unwrap());\n            \n            let sum: f64 = sorted.iter().sum();\n            let count = sorted.len() as f64;\n            let mean = sum / count;\n            \n            let p50_idx = (count * 0.5) as usize;\n            let p95_idx = (count * 0.95) as usize;\n            let p99_idx = (count * 0.99) as usize;\n            \n            HistogramStats {\n                count: count as u64,\n                sum,\n                mean,\n                min: sorted[0],\n                max: sorted[sorted.len() - 1],\n                p50: sorted[p50_idx.min(sorted.len() - 1)],\n                p95: sorted[p95_idx.min(sorted.len() - 1)],\n                p99: sorted[p99_idx.min(sorted.len() - 1)],\n            }\n        })\n    }\n}\n\n#[derive(Debug, Clone, Default)]\npub struct HistogramStats {\n    pub count: u64,\n    pub sum: f64,\n    pub mean: f64,\n    pub min: f64,\n    pub max: f64,\n    pub p50: f64,\n    pub p95: f64,\n    pub p99: f64,\n}\n\n// Metrics middleware for tracking request metrics\npub struct MetricsMiddleware {\n    metrics: Metrics,\n}\n\nimpl MetricsMiddleware {\n    pub fn new(metrics: Metrics) -> Self {\n        Self { metrics }\n    }\n    \n    pub async fn track_request<F, Fut, T>(&self, operation: &str, future: F) -> T\n    where\n        F: FnOnce() -> Fut,\n        Fut: std::future::Future<Output = T>,\n    {\n        let start = Instant::now();\n        self.metrics.increment_counter(&format!(\"{}_requests_total\", operation), 1);\n        \n        let result = future().await;\n        \n        let duration = start.elapsed();\n        self.metrics.record_histogram(\n            &format!(\"{}_request_duration_seconds\", operation),\n            duration.as_secs_f64(),\n        );\n        \n        result\n    }\n}\n\n// Application context with metrics and tracing\n#[derive(Clone)]\npub struct AppContext {\n    pub metrics: Metrics,\n    pub config: AppConfig,\n}\n\n#[derive(Debug, Clone)]\npub struct AppConfig {\n    pub service_name: String,\n    pub version: String,\n    pub environment: String,\n}\n\n// Business logic with instrumentation\n#[derive(Debug)]\npub struct UserService {\n    context: AppContext,\n}\n\nimpl UserService {\n    pub fn new(context: AppContext) -> Self {\n        Self { context }\n    }\n    \n    #[instrument(\n        skip(self),\n        fields(\n            service.name = %self.context.config.service_name,\n            service.version = %self.context.config.version,\n            user.id = %user_id\n        )\n    )]\n    pub async fn get_user(&self, user_id: u64) -> Result<User, ServiceError> {\n        let _span = span!(Level::DEBUG, \"database_query\", table = \"users\").entered();\n        \n        info!(\"Fetching user from database\");\n        \n        // Simulate database operation with metrics tracking\n        let user = self.context.metrics.track_request(\"db_get_user\", || async {\n            // Simulate variable latency\n            let delay = match user_id % 4 {\n                0 => Duration::from_millis(10),\n                1 => Duration::from_millis(50),\n                2 => Duration::from_millis(100),\n                _ => Duration::from_millis(200),\n            };\n            \n            sleep(delay).await;\n            \n            if user_id == 0 {\n                return Err(ServiceError::NotFound {\n                    resource: \"user\".to_string(),\n                    id: user_id.to_string(),\n                });\n            }\n            \n            if user_id == 999 {\n                return Err(ServiceError::DatabaseError {\n                    message: \"Connection timeout\".to_string(),\n                });\n            }\n            \n            Ok(User {\n                id: user_id,\n                username: format!(\"user_{}\", user_id),\n                email: format!(\"user{}@example.com\", user_id),\n                created_at: chrono::Utc::now(),\n            })\n        }).await;\n        \n        match &user {\n            Ok(_) => {\n                debug!(\"User fetched successfully\");\n                self.context.metrics.increment_counter(\"user_fetch_success\", 1);\n            }\n            Err(e) => {\n                warn!(error = %e, \"Failed to fetch user\");\n                self.context.metrics.increment_counter(\"user_fetch_error\", 1);\n            }\n        }\n        \n        user\n    }\n    \n    #[instrument(skip(self), fields(batch_size = users.len()))]\n    pub async fn get_users_batch(&self, users: Vec<u64>) -> Vec<Result<User, ServiceError>> {\n        info!(\"Processing batch user request\");\n        \n        let mut results = Vec::new();\n        \n        for user_id in users {\n            let result = self.get_user(user_id)\n                .instrument(span!(Level::DEBUG, \"batch_item\", user.id = user_id))\n                .await;\n            results.push(result);\n        }\n        \n        let success_count = results.iter().filter(|r| r.is_ok()).count();\n        let error_count = results.len() - success_count;\n        \n        info!(\n            success_count,\n            error_count,\n            \"Batch processing completed\"\n        );\n        \n        self.context.metrics.increment_counter(\"batch_requests_total\", 1);\n        self.context.metrics.set_gauge(\"batch_success_rate\", \n            ((success_count as f64 / results.len() as f64) * 100.0) as u64);\n        \n        results\n    }\n}\n\n#[derive(Debug, Clone)]\npub struct User {\n    pub id: u64,\n    pub username: String,\n    pub email: String,\n    pub created_at: chrono::DateTime<chrono::Utc>,\n}\n\n#[derive(Debug, thiserror::Error)]\npub enum ServiceError {\n    #[error(\"Resource {resource} with id {id} not found\")]\n    NotFound { resource: String, id: String },\n    #[error(\"Database error: {message}\")]\n    DatabaseError { message: String },\n    #[error(\"Validation error: {message}\")]\n    ValidationError { message: String },\n}\n\n// Custom tracing layer for metrics integration\nstruct MetricsLayer {\n    metrics: Metrics,\n}\n\nimpl MetricsLayer {\n    fn new(metrics: Metrics) -> Self {\n        Self { metrics }\n    }\n}\n\nimpl<S> Layer<S> for MetricsLayer\nwhere\n    S: tracing::Subscriber,\n{\n    fn on_event(\n        &self,\n        event: &tracing::Event<'_>,\n        _ctx: tracing_subscriber::layer::Context<'_, S>,\n    ) {\n        let level = event.metadata().level();\n        \n        match *level {\n            Level::ERROR => self.metrics.increment_counter(\"log_errors_total\", 1),\n            Level::WARN => self.metrics.increment_counter(\"log_warnings_total\", 1),\n            Level::INFO => self.metrics.increment_counter(\"log_info_total\", 1),\n            Level::DEBUG => self.metrics.increment_counter(\"log_debug_total\", 1),\n            Level::TRACE => self.metrics.increment_counter(\"log_trace_total\", 1),\n        }\n    }\n}\n\n// Initialize observability stack\npub fn init_observability(config: &AppConfig, metrics: Metrics) -> Result<(), Box<dyn std::error::Error>> {\n    let env_filter = EnvFilter::try_from_default_env()\n        .unwrap_or_else(|_| EnvFilter::new(\"info\"));\n    \n    let formatting_layer = fmt::layer()\n        .with_target(false)\n        .with_thread_ids(true)\n        .with_thread_names(true)\n        .with_span_events(FmtSpan::CLOSE)\n        .pretty();\n    \n    let json_layer = fmt::layer()\n        .with_target(false)\n        .json()\n        .with_current_span(true)\n        .with_span_list(true);\n    \n    let metrics_layer = MetricsLayer::new(metrics.clone());\n    \n    match config.environment.as_str() {\n        \"production\" => {\n            tracing_subscriber::registry()\n                .with(env_filter)\n                .with(json_layer)\n                .with(metrics_layer)\n                .init();\n        }\n        _ => {\n            tracing_subscriber::registry()\n                .with(env_filter)\n                .with(formatting_layer)\n                .with(metrics_layer)\n                .init();\n        }\n    }\n    \n    info!(\n        service.name = config.service_name,\n        service.version = config.version,\n        environment = config.environment,\n        \"Observability initialized\"\n    );\n    \n    Ok(())\n}\n\n// Metrics reporting\npub async fn report_metrics(metrics: &Metrics) {\n    let span = span!(Level::INFO, \"metrics_report\").entered();\n    \n    info!(\"=== Metrics Report ===\");\n    \n    // Counter metrics\n    let counters = [\n        \"user_fetch_success\",\n        \"user_fetch_error\",\n        \"batch_requests_total\",\n        \"log_errors_total\",\n        \"log_warnings_total\",\n    ];\n    \n    for counter in &counters {\n        let value = metrics.get_counter(counter);\n        info!(metric.name = counter, metric.type = \"counter\", value, \"Counter metric\");\n    }\n    \n    // Gauge metrics\n    let gauges = [\"batch_success_rate\"];\n    for gauge in &gauges {\n        let value = metrics.get_gauge(gauge);\n        info!(metric.name = gauge, metric.type = \"gauge\", value, \"Gauge metric\");\n    }\n    \n    // Histogram metrics\n    let histograms = [\"db_get_user_request_duration_seconds\"];\n    for histogram in &histograms {\n        if let Some(stats) = metrics.get_histogram_stats(histogram) {\n            info!(\n                metric.name = histogram,\n                metric.type = \"histogram\",\n                count = stats.count,\n                mean = stats.mean,\n                p50 = stats.p50,\n                p95 = stats.p95,\n                p99 = stats.p99,\n                \"Histogram metric\"\n            );\n        }\n    }\n    \n    drop(span);\n}\n\n#[tokio::main]\nasync fn main() -> Result<(), Box<dyn std::error::Error>> {\n    let config = AppConfig {\n        service_name: \"user-service\".to_string(),\n        version: \"1.0.0\".to_string(),\n        environment: \"development\".to_string(),\n    };\n    \n    let metrics = Metrics::default();\n    \n    // Initialize observability\n    init_observability(&config, metrics.clone())?;\n    \n    let context = AppContext { metrics: metrics.clone(), config };\n    let user_service = UserService::new(context);\n    \n    // Simulate application workload\n    let root_span = span!(Level::INFO, \"application_run\").entered();\n    \n    info!(\"Starting application simulation\");\n    \n    // Single user requests\n    for user_id in [1, 2, 0, 999, 5] {\n        match user_service.get_user(user_id).await {\n            Ok(user) => info!(user.id = user.id, user.username = %user.username, \"User retrieved\"),\n            Err(e) => error!(error = %e, user.id = user_id, \"Failed to retrieve user\"),\n        }\n    }\n    \n    // Batch request\n    let batch_users = vec![10, 11, 12, 0, 13, 999, 14];\n    let batch_results = user_service.get_users_batch(batch_users).await;\n    \n    info!(\"Batch results: {} total\", batch_results.len());\n    \n    // Report metrics every few seconds in a real application\n    report_metrics(&metrics).await;\n    \n    // Simulate some additional load\n    for i in 0..10 {\n        let user_id = i + 20;\n        let _ = user_service.get_user(user_id)\n            .instrument(span!(Level::DEBUG, \"load_test\", iteration = i))\n            .await;\n    }\n    \n    // Final metrics report\n    report_metrics(&metrics).await;\n    \n    info!(\"Application simulation completed\");\n    drop(root_span);\n    \n    Ok(())\n}\n\n// Key concepts:\n// - Structured logging with tracing for observability\n// - Custom metrics collection (counters, gauges, histograms)\n// - Instrumentation of business logic with spans\n// - Metrics middleware for automatic request tracking\n// - Different logging formats for different environments\n// - Integration between tracing events and metrics\n// - Performance measurement with timing histograms\n// - Error rate tracking and success rate monitoring\n// - Contextual information in logs (user IDs, operations)\n```",
    "tags": [
      "tracing",
      "logging",
      "observability",
      "metrics",
      "instrumentation",
      "monitoring",
      "production",
      "structured-logging",
      "performance"
    ],
    "instruction": "Implement structured logging and observability with tracing and metrics"
  },
  {
    "output": "```rust\n// This example demonstrates graceful shutdown patterns for production Rust services\n// including signal handling, resource cleanup, and coordinated service termination\n\nuse std::sync::Arc;\nuse std::time::Duration;\nuse tokio::{\n    signal,\n    sync::{broadcast, mpsc, oneshot, RwLock, Semaphore},\n    task::JoinHandle,\n    time::{sleep, timeout},\n};\nuse tracing::{error, info, warn};\n\n#[derive(Debug, Clone)]\npub enum ShutdownSignal {\n    Terminate,\n    Interrupt,\n    Quit,\n    User(String),\n}\n\n// Shutdown coordinator manages the graceful shutdown process\n#[derive(Clone)]\npub struct ShutdownCoordinator {\n    // Broadcast channel for notifying all components\n    shutdown_tx: broadcast::Sender<ShutdownSignal>,\n    // Semaphore to track active operations\n    active_operations: Arc<Semaphore>,\n    // RwLock to coordinate shutdown phases\n    shutdown_state: Arc<RwLock<ShutdownState>>,\n}\n\n#[derive(Debug, Clone, PartialEq)]\nenum ShutdownState {\n    Running,\n    ShutdownInitiated,\n    StoppingServices,\n    WaitingForCompletion,\n    Completed,\n}\n\nimpl ShutdownCoordinator {\n    pub fn new() -> Self {\n        let (shutdown_tx, _) = broadcast::channel(16);\n        \n        Self {\n            shutdown_tx,\n            active_operations: Arc::new(Semaphore::new(1000)), // Max concurrent operations\n            shutdown_state: Arc::new(RwLock::new(ShutdownState::Running)),\n        }\n    }\n    \n    pub fn subscribe(&self) -> broadcast::Receiver<ShutdownSignal> {\n        self.shutdown_tx.subscribe()\n    }\n    \n    pub async fn initiate_shutdown(&self, signal: ShutdownSignal) {\n        let mut state = self.shutdown_state.write().await;\n        if *state == ShutdownState::Running {\n            *state = ShutdownState::ShutdownInitiated;\n            drop(state);\n            \n            info!(signal = ?signal, \"Initiating graceful shutdown\");\n            \n            if let Err(e) = self.shutdown_tx.send(signal) {\n                error!(error = %e, \"Failed to broadcast shutdown signal\");\n            }\n        }\n    }\n    \n    pub async fn track_operation<F, T>(&self, operation: F) -> Option<T>\n    where\n        F: std::future::Future<Output = T>,\n    {\n        // Check if shutdown has been initiated\n        {\n            let state = self.shutdown_state.read().await;\n            if *state != ShutdownState::Running {\n                return None;\n            }\n        }\n        \n        // Acquire permit for operation\n        let permit = self.active_operations.acquire().await.ok()?;\n        \n        let result = operation.await;\n        \n        drop(permit);\n        Some(result)\n    }\n    \n    pub async fn wait_for_completion(&self, timeout_duration: Duration) -> bool {\n        let mut state = self.shutdown_state.write().await;\n        *state = ShutdownState::WaitingForCompletion;\n        drop(state);\n        \n        info!(timeout_seconds = timeout_duration.as_secs(), \"Waiting for operations to complete\");\n        \n        // Wait for all operations to complete or timeout\n        let all_permits = Arc::clone(&self.active_operations);\n        let wait_result = timeout(timeout_duration, async {\n            // Acquire all permits, meaning no operations are running\n            let _permits = all_permits.acquire_many(1000).await;\n        }).await;\n        \n        let completed = wait_result.is_ok();\n        \n        let mut state = self.shutdown_state.write().await;\n        *state = ShutdownState::Completed;\n        \n        if completed {\n            info!(\"All operations completed gracefully\");\n        } else {\n            warn!(\"Shutdown timeout reached, forcing termination\");\n        }\n        \n        completed\n    }\n    \n    pub async fn is_shutting_down(&self) -> bool {\n        let state = self.shutdown_state.read().await;\n        *state != ShutdownState::Running\n    }\n}\n\n// HTTP server that supports graceful shutdown\npub struct HttpServer {\n    shutdown_coordinator: ShutdownCoordinator,\n    port: u16,\n}\n\nimpl HttpServer {\n    pub fn new(port: u16, shutdown_coordinator: ShutdownCoordinator) -> Self {\n        Self {\n            shutdown_coordinator,\n            port,\n        }\n    }\n    \n    pub async fn run(self) -> JoinHandle<()> {\n        let mut shutdown_rx = self.shutdown_coordinator.subscribe();\n        let coordinator = self.shutdown_coordinator.clone();\n        \n        tokio::spawn(async move {\n            info!(port = self.port, \"Starting HTTP server\");\n            \n            loop {\n                tokio::select! {\n                    // Simulate handling HTTP requests\n                    _ = self.handle_request() => {},\n                    \n                    // Listen for shutdown signal\n                    result = shutdown_rx.recv() => {\n                        match result {\n                            Ok(signal) => {\n                                info!(signal = ?signal, \"HTTP server received shutdown signal\");\n                                break;\n                            }\n                            Err(broadcast::error::RecvError::Closed) => {\n                                warn!(\"Shutdown channel closed unexpectedly\");\n                                break;\n                            }\n                            Err(broadcast::error::RecvError::Lagged(_)) => {\n                                warn!(\"Shutdown signal lagged, continuing\");\n                            }\n                        }\n                    }\n                }\n            }\n            \n            info!(\"HTTP server shutting down\");\n        })\n    }\n    \n    async fn handle_request(&self) {\n        if let Some(_) = self.shutdown_coordinator.track_operation(async {\n            // Simulate request processing\n            sleep(Duration::from_millis(100)).await;\n            \"Response\"\n        }).await {\n            // Request completed successfully\n        }\n    }\n}\n\n// Background worker that processes jobs\npub struct BackgroundWorker {\n    name: String,\n    shutdown_coordinator: ShutdownCoordinator,\n    job_rx: mpsc::Receiver<Job>,\n}\n\n#[derive(Debug, Clone)]\npub struct Job {\n    id: String,\n    data: String,\n}\n\nimpl BackgroundWorker {\n    pub fn new(\n        name: String,\n        shutdown_coordinator: ShutdownCoordinator,\n        job_rx: mpsc::Receiver<Job>,\n    ) -> Self {\n        Self {\n            name,\n            shutdown_coordinator,\n            job_rx,\n        }\n    }\n    \n    pub async fn run(mut self) -> JoinHandle<()> {\n        let mut shutdown_rx = self.shutdown_coordinator.subscribe();\n        \n        tokio::spawn(async move {\n            info!(worker = %self.name, \"Starting background worker\");\n            \n            loop {\n                tokio::select! {\n                    // Process jobs\n                    job = self.job_rx.recv() => {\n                        match job {\n                            Some(job) => {\n                                if let Some(_) = self.shutdown_coordinator.track_operation(\n                                    self.process_job(job)\n                                ).await {\n                                    // Job processed successfully\n                                }\n                            }\n                            None => {\n                                info!(worker = %self.name, \"Job channel closed\");\n                                break;\n                            }\n                        }\n                    }\n                    \n                    // Listen for shutdown\n                    result = shutdown_rx.recv() => {\n                        match result {\n                            Ok(signal) => {\n                                info!(\n                                    worker = %self.name,\n                                    signal = ?signal,\n                                    \"Worker received shutdown signal\"\n                                );\n                                break;\n                            }\n                            Err(_) => break,\n                        }\n                    }\n                }\n            }\n            \n            info!(worker = %self.name, \"Background worker shutting down\");\n        })\n    }\n    \n    async fn process_job(&self, job: Job) -> Result<(), String> {\n        info!(worker = %self.name, job.id = %job.id, \"Processing job\");\n        \n        // Simulate job processing time\n        sleep(Duration::from_millis(200)).await;\n        \n        // Simulate occasional failures\n        if job.id.ends_with(\"error\") {\n            return Err(\"Job processing failed\".to_string());\n        }\n        \n        info!(worker = %self.name, job.id = %job.id, \"Job completed\");\n        Ok(())\n    }\n}\n\n// Database connection pool with graceful shutdown\npub struct DatabasePool {\n    shutdown_coordinator: ShutdownCoordinator,\n    connections: Arc<RwLock<Vec<DatabaseConnection>>>,\n}\n\n#[derive(Debug, Clone)]\npub struct DatabaseConnection {\n    id: String,\n    active: bool,\n}\n\nimpl DatabasePool {\n    pub fn new(shutdown_coordinator: ShutdownCoordinator) -> Self {\n        let connections = (0..5)\n            .map(|i| DatabaseConnection {\n                id: format!(\"conn_{}\", i),\n                active: true,\n            })\n            .collect();\n        \n        Self {\n            shutdown_coordinator,\n            connections: Arc::new(RwLock::new(connections)),\n        }\n    }\n    \n    pub async fn execute_query(&self, query: &str) -> Option<String> {\n        self.shutdown_coordinator.track_operation(async {\n            // Simulate database query\n            sleep(Duration::from_millis(50)).await;\n            format!(\"Result for: {}\", query)\n        }).await\n    }\n    \n    pub async fn shutdown(&self) {\n        info!(\"Shutting down database pool\");\n        \n        let mut connections = self.connections.write().await;\n        for conn in connections.iter_mut() {\n            conn.active = false;\n            info!(connection.id = %conn.id, \"Closed database connection\");\n        }\n        \n        info!(\"Database pool shutdown complete\");\n    }\n}\n\n// Signal handler for Unix signals\npub async fn setup_signal_handlers(shutdown_coordinator: ShutdownCoordinator) -> JoinHandle<()> {\n    tokio::spawn(async move {\n        let mut sigterm = signal::unix::signal(signal::unix::SignalKind::terminate())\n            .expect(\"Failed to create SIGTERM handler\");\n        let mut sigint = signal::unix::signal(signal::unix::SignalKind::interrupt())\n            .expect(\"Failed to create SIGINT handler\");\n        let mut sigquit = signal::unix::signal(signal::unix::SignalKind::quit())\n            .expect(\"Failed to create SIGQUIT handler\");\n        \n        tokio::select! {\n            _ = sigterm.recv() => {\n                info!(\"Received SIGTERM\");\n                shutdown_coordinator.initiate_shutdown(ShutdownSignal::Terminate).await;\n            }\n            _ = sigint.recv() => {\n                info!(\"Received SIGINT (Ctrl+C)\");\n                shutdown_coordinator.initiate_shutdown(ShutdownSignal::Interrupt).await;\n            }\n            _ = sigquit.recv() => {\n                info!(\"Received SIGQUIT\");\n                shutdown_coordinator.initiate_shutdown(ShutdownSignal::Quit).await;\n            }\n        }\n    })\n}\n\n// Main application that coordinates all services\npub struct Application {\n    shutdown_coordinator: ShutdownCoordinator,\n    services: Vec<JoinHandle<()>>,\n    cleanup_tasks: Vec<Box<dyn Fn() -> std::pin::Pin<Box<dyn std::future::Future<Output = ()> + Send>> + Send>>,\n}\n\nimpl Application {\n    pub fn new() -> Self {\n        Self {\n            shutdown_coordinator: ShutdownCoordinator::new(),\n            services: Vec::new(),\n            cleanup_tasks: Vec::new(),\n        }\n    }\n    \n    pub fn add_service<F>(&mut self, service_factory: F)\n    where\n        F: FnOnce(ShutdownCoordinator) -> JoinHandle<()>,\n    {\n        let handle = service_factory(self.shutdown_coordinator.clone());\n        self.services.push(handle);\n    }\n    \n    pub fn add_cleanup_task<F, Fut>(&mut self, cleanup_fn: F)\n    where\n        F: Fn() -> Fut + Send + 'static,\n        Fut: std::future::Future<Output = ()> + Send + 'static,\n    {\n        self.cleanup_tasks.push(Box::new(move || Box::pin(cleanup_fn())));\n    }\n    \n    pub async fn run(mut self) {\n        info!(\"Starting application\");\n        \n        // Set up signal handlers\n        let _signal_handler = setup_signal_handlers(self.shutdown_coordinator.clone()).await;\n        \n        // Wait for shutdown signal or service failure\n        let mut shutdown_rx = self.shutdown_coordinator.subscribe();\n        \n        tokio::select! {\n            // Wait for any service to complete (which shouldn't happen in normal operation)\n            result = futures::future::select_all(&mut self.services) => {\n                warn!(\"Service exited unexpectedly: {:?}\", result.0);\n                self.shutdown_coordinator.initiate_shutdown(\n                    ShutdownSignal::User(\"Service failure\".to_string())\n                ).await;\n            }\n            \n            // Wait for shutdown signal\n            signal = shutdown_rx.recv() => {\n                match signal {\n                    Ok(signal) => {\n                        info!(signal = ?signal, \"Application received shutdown signal\");\n                    }\n                    Err(e) => {\n                        error!(error = %e, \"Error receiving shutdown signal\");\n                    }\n                }\n            }\n        }\n        \n        // Perform graceful shutdown\n        self.shutdown().await;\n    }\n    \n    async fn shutdown(self) {\n        info!(\"Beginning graceful shutdown sequence\");\n        \n        // Phase 1: Stop accepting new requests (services will handle this)\n        info!(\"Phase 1: Stopping services\");\n        \n        // Phase 2: Wait for active operations to complete\n        info!(\"Phase 2: Waiting for operations to complete\");\n        let completed = self.shutdown_coordinator.wait_for_completion(\n            Duration::from_secs(30)\n        ).await;\n        \n        if !completed {\n            warn!(\"Graceful shutdown timeout, proceeding with forced shutdown\");\n        }\n        \n        // Phase 3: Run cleanup tasks\n        info!(\"Phase 3: Running cleanup tasks\");\n        for cleanup_task in self.cleanup_tasks {\n            let cleanup_future = cleanup_task();\n            if let Err(_) = timeout(Duration::from_secs(5), cleanup_future).await {\n                warn!(\"Cleanup task timed out\");\n            }\n        }\n        \n        // Phase 4: Wait for services to finish\n        info!(\"Phase 4: Waiting for services to finish\");\n        for handle in self.services {\n            if let Err(e) = timeout(Duration::from_secs(5), handle).await {\n                warn!(error = %e, \"Service did not shut down within timeout\");\n            }\n        }\n        \n        info!(\"Graceful shutdown completed\");\n    }\n}\n\n#[tokio::main]\nasync fn main() -> Result<(), Box<dyn std::error::Error>> {\n    tracing_subscriber::fmt::init();\n    \n    let mut app = Application::new();\n    \n    // Add HTTP server\n    app.add_service(|coordinator| {\n        let server = HttpServer::new(8080, coordinator);\n        tokio::spawn(async move {\n            server.run().await.await.unwrap_or_default()\n        })\n    });\n    \n    // Add background workers\n    let (job_tx, job_rx) = mpsc::channel(100);\n    app.add_service(|coordinator| {\n        let worker = BackgroundWorker::new(\"worker-1\".to_string(), coordinator, job_rx);\n        tokio::spawn(async move {\n            worker.run().await.await.unwrap_or_default()\n        })\n    });\n    \n    // Add database pool cleanup\n    let db_pool = DatabasePool::new(app.shutdown_coordinator.clone());\n    let db_pool_clone = Arc::new(db_pool);\n    let cleanup_pool = Arc::clone(&db_pool_clone);\n    app.add_cleanup_task(move || {\n        let pool = Arc::clone(&cleanup_pool);\n        async move {\n            pool.shutdown().await;\n        }\n    });\n    \n    // Simulate some work\n    let job_producer = tokio::spawn(async move {\n        for i in 0..20 {\n            let job = Job {\n                id: format!(\"job_{}\", i),\n                data: format!(\"data_{}\", i),\n            };\n            \n            if job_tx.send(job).await.is_err() {\n                break;\n            }\n            \n            sleep(Duration::from_millis(500)).await;\n        }\n    });\n    \n    // Run the application\n    app.run().await;\n    \n    // Clean up the job producer\n    job_producer.abort();\n    \n    Ok(())\n}\n\n// Key concepts:\n// - Coordinated shutdown across multiple services\n// - Signal handling for Unix signals (SIGTERM, SIGINT, SIGQUIT)\n// - Graceful request completion with operation tracking\n// - Timeout-based forced shutdown as fallback\n// - Resource cleanup with custom cleanup tasks\n// - Broadcast channels for shutdown notification\n// - Semaphores for tracking active operations\n// - Multi-phase shutdown process\n// - Service health monitoring during shutdown\n```",
    "tags": [
      "graceful-shutdown",
      "signal-handling",
      "production",
      "coordination",
      "resource-cleanup",
      "tokio",
      "async",
      "service-management"
    ],
    "instruction": "Implement graceful shutdown and signal handling for production services"
  },
  {
    "output": "```rust\n// This example demonstrates production-ready error handling using anyhow and thiserror\n// for building robust applications with excellent error reporting\n\nuse anyhow::{anyhow, bail, Context, Result as AnyResult};\nuse std::fs;\nuse std::io;\nuse std::num::ParseIntError;\nuse thiserror::Error;\n\n// Domain-specific errors using thiserror for libraries\n#[derive(Error, Debug)]\npub enum UserServiceError {\n    #[error(\"User not found with ID: {id}\")]\n    NotFound { id: u64 },\n    \n    #[error(\"Invalid email format: {email}\")]\n    InvalidEmail { email: String },\n    \n    #[error(\"User already exists: {username}\")]\n    AlreadyExists { username: String },\n    \n    #[error(\"Database operation failed\")]\n    Database(#[from] DatabaseError),\n    \n    #[error(\"Validation failed: {message}\")]\n    Validation { message: String },\n    \n    #[error(\"Permission denied for user {user_id}: {action}\")]\n    PermissionDenied { user_id: u64, action: String },\n}\n\n#[derive(Error, Debug)]\npub enum DatabaseError {\n    #[error(\"Connection failed: {host}:{port}\")]\n    ConnectionFailed { host: String, port: u16 },\n    \n    #[error(\"Query execution failed: {query}\")]\n    QueryFailed { query: String },\n    \n    #[error(\"Transaction rolled back: {reason}\")]\n    TransactionFailed { reason: String },\n    \n    #[error(\"Connection pool exhausted\")]\n    PoolExhausted,\n    \n    #[error(\"Timeout after {seconds}s\")]\n    Timeout { seconds: u64 },\n    \n    #[error(\"IO error\")]\n    Io(#[from] io::Error),\n    \n    #[error(\"Parse error\")]\n    Parse(#[from] ParseIntError),\n}\n\n#[derive(Error, Debug)]\npub enum ConfigError {\n    #[error(\"Configuration file not found: {path}\")]\n    FileNotFound { path: String },\n    \n    #[error(\"Invalid configuration format\")]\n    InvalidFormat(#[from] toml::de::Error),\n    \n    #[error(\"Missing required field: {field}\")]\n    MissingField { field: String },\n    \n    #[error(\"Environment variable error: {var}\")]\n    EnvironmentVariable { var: String },\n    \n    #[error(\"Validation error: {message}\")]\n    Validation { message: String },\n}\n\n// Application-level errors for the main application\n#[derive(Error, Debug)]\npub enum AppError {\n    #[error(\"User service error\")]\n    UserService(#[from] UserServiceError),\n    \n    #[error(\"Configuration error\")]\n    Config(#[from] ConfigError),\n    \n    #[error(\"External API error: {service}\")]\n    ExternalApi { service: String, source: anyhow::Error },\n    \n    #[error(\"Rate limit exceeded: {limit} requests per {window}\")]\n    RateLimitExceeded { limit: u32, window: String },\n    \n    #[error(\"Service unavailable: {reason}\")]\n    ServiceUnavailable { reason: String },\n}\n\n// User domain model\n#[derive(Debug, Clone)]\npub struct User {\n    pub id: u64,\n    pub username: String,\n    pub email: String,\n    pub role: UserRole,\n}\n\n#[derive(Debug, Clone)]\npub enum UserRole {\n    Admin,\n    User,\n    Guest,\n}\n\n// Configuration with detailed error handling\n#[derive(Debug, serde::Deserialize)]\npub struct AppConfig {\n    pub database_url: String,\n    pub api_key: String,\n    pub max_connections: u32,\n    pub timeout_seconds: u64,\n}\n\nimpl AppConfig {\n    pub fn load_from_file(path: &str) -> Result<Self, ConfigError> {\n        let contents = fs::read_to_string(path)\n            .map_err(|_| ConfigError::FileNotFound {\n                path: path.to_string(),\n            })?;\n        \n        let config: AppConfig = toml::from_str(&contents)?;\n        config.validate()?;\n        Ok(config)\n    }\n    \n    pub fn load_from_env() -> Result<Self, ConfigError> {\n        let database_url = std::env::var(\"DATABASE_URL\")\n            .map_err(|_| ConfigError::EnvironmentVariable {\n                var: \"DATABASE_URL\".to_string(),\n            })?;\n        \n        let api_key = std::env::var(\"API_KEY\")\n            .map_err(|_| ConfigError::EnvironmentVariable {\n                var: \"API_KEY\".to_string(),\n            })?;\n        \n        let max_connections = std::env::var(\"MAX_CONNECTIONS\")\n            .unwrap_or_else(|_| \"10\".to_string())\n            .parse()\n            .map_err(|_| ConfigError::Validation {\n                message: \"MAX_CONNECTIONS must be a valid number\".to_string(),\n            })?;\n        \n        let timeout_seconds = std::env::var(\"TIMEOUT_SECONDS\")\n            .unwrap_or_else(|_| \"30\".to_string())\n            .parse()\n            .map_err(|_| ConfigError::Validation {\n                message: \"TIMEOUT_SECONDS must be a valid number\".to_string(),\n            })?;\n        \n        let config = AppConfig {\n            database_url,\n            api_key,\n            max_connections,\n            timeout_seconds,\n        };\n        \n        config.validate()?;\n        Ok(config)\n    }\n    \n    fn validate(&self) -> Result<(), ConfigError> {\n        if self.database_url.is_empty() {\n            return Err(ConfigError::MissingField {\n                field: \"database_url\".to_string(),\n            });\n        }\n        \n        if self.api_key.len() < 10 {\n            return Err(ConfigError::Validation {\n                message: \"API key must be at least 10 characters\".to_string(),\n            });\n        }\n        \n        if self.max_connections == 0 {\n            return Err(ConfigError::Validation {\n                message: \"max_connections must be greater than 0\".to_string(),\n            });\n        }\n        \n        Ok(())\n    }\n}\n\n// Database service with comprehensive error handling\npub struct DatabaseService {\n    config: AppConfig,\n}\n\nimpl DatabaseService {\n    pub fn new(config: AppConfig) -> Self {\n        Self { config }\n    }\n    \n    pub async fn get_user(&self, id: u64) -> Result<User, DatabaseError> {\n        // Simulate database connection\n        if id == 0 {\n            return Err(DatabaseError::QueryFailed {\n                query: format!(\"SELECT * FROM users WHERE id = {}\", id),\n            });\n        }\n        \n        if id == 999 {\n            return Err(DatabaseError::ConnectionFailed {\n                host: \"localhost\".to_string(),\n                port: 5432,\n            });\n        }\n        \n        if id == 888 {\n            return Err(DatabaseError::Timeout { seconds: 30 });\n        }\n        \n        Ok(User {\n            id,\n            username: format!(\"user_{}\", id),\n            email: format!(\"user{}@example.com\", id),\n            role: UserRole::User,\n        })\n    }\n    \n    pub async fn create_user(&self, username: &str, email: &str) -> Result<User, DatabaseError> {\n        // Simulate creation with potential conflicts\n        if username == \"admin\" {\n            return Err(DatabaseError::QueryFailed {\n                query: \"INSERT INTO users...\".to_string(),\n            });\n        }\n        \n        Ok(User {\n            id: 123,\n            username: username.to_string(),\n            email: email.to_string(),\n            role: UserRole::User,\n        })\n    }\n}\n\n// User service with business logic error handling\npub struct UserService {\n    db: DatabaseService,\n}\n\nimpl UserService {\n    pub fn new(db: DatabaseService) -> Self {\n        Self { db }\n    }\n    \n    pub async fn get_user(&self, id: u64) -> Result<User, UserServiceError> {\n        if id == 0 {\n            return Err(UserServiceError::NotFound { id });\n        }\n        \n        let user = self.db.get_user(id).await?;\n        Ok(user)\n    }\n    \n    pub async fn create_user(&self, username: &str, email: &str) -> Result<User, UserServiceError> {\n        // Validate email format\n        if !email.contains('@') {\n            return Err(UserServiceError::InvalidEmail {\n                email: email.to_string(),\n            });\n        }\n        \n        // Check for existing user (simulate)\n        if username == \"existing_user\" {\n            return Err(UserServiceError::AlreadyExists {\n                username: username.to_string(),\n            });\n        }\n        \n        // Validate username\n        if username.len() < 3 {\n            return Err(UserServiceError::Validation {\n                message: \"Username must be at least 3 characters\".to_string(),\n            });\n        }\n        \n        let user = self.db.create_user(username, email).await?;\n        Ok(user)\n    }\n    \n    pub async fn update_user_email(&self, user_id: u64, new_email: &str, requester_id: u64) -> Result<User, UserServiceError> {\n        // Check permissions\n        if user_id != requester_id {\n            let requester = self.get_user(requester_id).await?;\n            if !matches!(requester.role, UserRole::Admin) {\n                return Err(UserServiceError::PermissionDenied {\n                    user_id: requester_id,\n                    action: \"update_other_user_email\".to_string(),\n                });\n            }\n        }\n        \n        // Validate new email\n        if !new_email.contains('@') {\n            return Err(UserServiceError::InvalidEmail {\n                email: new_email.to_string(),\n            });\n        }\n        \n        let mut user = self.get_user(user_id).await?;\n        user.email = new_email.to_string();\n        Ok(user)\n    }\n}\n\n// External API client with anyhow for flexibility\npub struct ExternalApiClient {\n    api_key: String,\n}\n\nimpl ExternalApiClient {\n    pub fn new(api_key: String) -> Self {\n        Self { api_key }\n    }\n    \n    pub async fn fetch_user_profile(&self, user_id: u64) -> AnyResult<serde_json::Value> {\n        // Simulate API call with various error scenarios\n        if user_id == 404 {\n            bail!(\"User profile not found in external system\");\n        }\n        \n        if user_id == 500 {\n            return Err(anyhow!(\"External API server error\"))\n                .context(\"Failed to fetch user profile\")\n                .context(format!(\"User ID: {}\", user_id));\n        }\n        \n        if user_id == 429 {\n            bail!(\"Rate limit exceeded for API calls\");\n        }\n        \n        // Simulate successful response\n        Ok(serde_json::json!({\n            \"user_id\": user_id,\n            \"external_data\": \"some_data\",\n            \"status\": \"active\"\n        }))\n    }\n    \n    pub async fn send_notification(&self, user_id: u64, message: &str) -> AnyResult<()> {\n        if self.api_key.is_empty() {\n            bail!(\"API key not configured\");\n        }\n        \n        if message.is_empty() {\n            bail!(\"Notification message cannot be empty\");\n        }\n        \n        // Simulate API call\n        if user_id == 999 {\n            return Err(anyhow!(\"Network connection failed\"))\n                .context(\"Failed to send notification\")\n                .context(format!(\"User: {}, Message: {}\", user_id, message));\n        }\n        \n        Ok(())\n    }\n}\n\n// Application service that coordinates everything\npub struct ApplicationService {\n    user_service: UserService,\n    api_client: ExternalApiClient,\n}\n\nimpl ApplicationService {\n    pub fn new(user_service: UserService, api_client: ExternalApiClient) -> Self {\n        Self {\n            user_service,\n            api_client,\n        }\n    }\n    \n    // Complex operation with multiple error sources\n    pub async fn create_user_with_profile(&self, username: &str, email: &str) -> Result<User, AppError> {\n        // Create user in our system\n        let user = self.user_service.create_user(username, email).await?;\n        \n        // Fetch additional profile data from external API\n        match self.api_client.fetch_user_profile(user.id).await {\n            Ok(profile_data) => {\n                println!(\"External profile data: {}\", profile_data);\n            }\n            Err(e) => {\n                // Convert anyhow error to our app error\n                return Err(AppError::ExternalApi {\n                    service: \"profile_service\".to_string(),\n                    source: e,\n                });\n            }\n        }\n        \n        // Send welcome notification\n        if let Err(e) = self.api_client.send_notification(user.id, \"Welcome!\").await {\n            // Log error but don't fail the operation\n            eprintln!(\"Failed to send welcome notification: {:?}\", e);\n        }\n        \n        Ok(user)\n    }\n    \n    // Error handling with retry logic\n    pub async fn get_user_with_retry(&self, user_id: u64, max_retries: u32) -> AnyResult<User> {\n        let mut last_error = None;\n        \n        for attempt in 1..=max_retries {\n            match self.user_service.get_user(user_id).await {\n                Ok(user) => return Ok(user),\n                Err(UserServiceError::Database(DatabaseError::Timeout { .. })) => {\n                    last_error = Some(anyhow!(\"Database timeout on attempt {}\", attempt));\n                    if attempt < max_retries {\n                        tokio::time::sleep(std::time::Duration::from_millis(100 * attempt as u64)).await;\n                        continue;\n                    }\n                }\n                Err(UserServiceError::Database(DatabaseError::ConnectionFailed { .. })) => {\n                    last_error = Some(anyhow!(\"Database connection failed on attempt {}\", attempt));\n                    if attempt < max_retries {\n                        tokio::time::sleep(std::time::Duration::from_millis(200 * attempt as u64)).await;\n                        continue;\n                    }\n                }\n                Err(e) => {\n                    // Non-retryable error\n                    return Err(anyhow!(e)).context(\"Failed to get user\");\n                }\n            }\n        }\n        \n        Err(last_error.unwrap_or_else(|| anyhow!(\"All retry attempts failed\")))\n            .context(format!(\"Failed to get user {} after {} attempts\", user_id, max_retries))\n    }\n    \n    // Batch operation with partial failure handling\n    pub async fn process_user_batch(&self, user_ids: Vec<u64>) -> AnyResult<BatchResult> {\n        let mut successful = Vec::new();\n        let mut failed = Vec::new();\n        \n        for user_id in user_ids {\n            match self.user_service.get_user(user_id).await {\n                Ok(user) => {\n                    successful.push(user);\n                }\n                Err(e) => {\n                    failed.push(BatchError {\n                        user_id,\n                        error: format!(\"{}\", e),\n                    });\n                }\n            }\n        }\n        \n        if successful.is_empty() && !failed.is_empty() {\n            bail!(\"All users in batch failed to process\");\n        }\n        \n        Ok(BatchResult {\n            successful,\n            failed,\n        })\n    }\n}\n\n#[derive(Debug)]\npub struct BatchResult {\n    pub successful: Vec<User>,\n    pub failed: Vec<BatchError>,\n}\n\n#[derive(Debug)]\npub struct BatchError {\n    pub user_id: u64,\n    pub error: String,\n}\n\n// Error reporting utilities\npub fn report_error(error: &anyhow::Error) {\n    eprintln!(\"Error: {}\", error);\n    \n    let mut source = error.source();\n    while let Some(err) = source {\n        eprintln!(\"  Caused by: {}\", err);\n        source = err.source();\n    }\n    \n    // In production, you might send this to a logging service\n    if let Some(backtrace) = error.backtrace() {\n        eprintln!(\"Backtrace: {}\", backtrace);\n    }\n}\n\npub fn create_error_response(error: &AppError) -> serde_json::Value {\n    match error {\n        AppError::UserService(UserServiceError::NotFound { id }) => {\n            serde_json::json!({\n                \"error\": \"user_not_found\",\n                \"message\": format!(\"User with ID {} not found\", id),\n                \"code\": 404\n            })\n        }\n        AppError::UserService(UserServiceError::InvalidEmail { email }) => {\n            serde_json::json!({\n                \"error\": \"invalid_email\",\n                \"message\": format!(\"Invalid email format: {}\", email),\n                \"code\": 400\n            })\n        }\n        AppError::UserService(UserServiceError::PermissionDenied { user_id, action }) => {\n            serde_json::json!({\n                \"error\": \"permission_denied\",\n                \"message\": format!(\"User {} not allowed to perform: {}\", user_id, action),\n                \"code\": 403\n            })\n        }\n        AppError::RateLimitExceeded { limit, window } => {\n            serde_json::json!({\n                \"error\": \"rate_limit_exceeded\",\n                \"message\": format!\"Rate limit of {} requests per {} exceeded\", limit, window),\n                \"code\": 429\n            })\n        }\n        _ => {\n            serde_json::json!({\n                \"error\": \"internal_error\",\n                \"message\": \"An internal error occurred\",\n                \"code\": 500\n            })\n        }\n    }\n}\n\n#[tokio::main]\nasync fn main() -> AnyResult<()> {\n    // Load configuration with error handling\n    let config = AppConfig::load_from_env()\n        .with_context(|| \"Failed to load application configuration\")?;\n    \n    // Initialize services\n    let db_service = DatabaseService::new(config);\n    let user_service = UserService::new(db_service);\n    let api_client = ExternalApiClient::new(\"test-api-key\".to_string());\n    let app_service = ApplicationService::new(user_service, api_client);\n    \n    // Demonstrate error handling patterns\n    println!(\"=== Error Handling Examples ===\");\n    \n    // Example 1: Simple error handling\n    match app_service.user_service.get_user(1).await {\n        Ok(user) => println!(\"Found user: {:?}\", user),\n        Err(e) => eprintln!(\"Error getting user: {}\", e),\n    }\n    \n    // Example 2: Error with not found\n    match app_service.user_service.get_user(0).await {\n        Ok(user) => println!(\"Found user: {:?}\", user),\n        Err(e) => eprintln!(\"Expected error: {}\", e),\n    }\n    \n    // Example 3: Complex operation with multiple error sources\n    match app_service.create_user_with_profile(\"newuser\", \"new@example.com\").await {\n        Ok(user) => println!(\"Created user with profile: {:?}\", user),\n        Err(e) => {\n            eprintln!(\"Failed to create user with profile: {}\", e);\n            let response = create_error_response(&e);\n            println!(\"Error response: {}\", response);\n        }\n    }\n    \n    // Example 4: Retry logic with anyhow\n    match app_service.get_user_with_retry(888, 3).await {\n        Ok(user) => println!(\"Got user with retry: {:?}\", user),\n        Err(e) => {\n            eprintln!(\"Failed even with retries:\");\n            report_error(&e);\n        }\n    }\n    \n    // Example 5: Batch processing with partial failures\n    let batch_users = vec![1, 2, 0, 999, 4, 888];\n    match app_service.process_user_batch(batch_users).await {\n        Ok(result) => {\n            println!(\"Batch processing completed:\");\n            println!(\"  Successful: {} users\", result.successful.len());\n            println!(\"  Failed: {} users\", result.failed.len());\n            for failure in result.failed {\n                println!(\"    User {}: {}\", failure.user_id, failure.error);\n            }\n        }\n        Err(e) => {\n            eprintln!(\"Batch processing failed completely:\");\n            report_error(&e);\n        }\n    }\n    \n    Ok(())\n}\n\n// Key concepts:\n// - thiserror for structured, domain-specific errors in libraries\n// - anyhow for flexible error handling in applications\n// - Error context and chaining for better debugging\n// - Converting between error types at boundaries\n// - Retry logic for transient errors\n// - Partial failure handling in batch operations\n// - Structured error responses for APIs\n// - Error reporting with full context and backtraces\n// - Validation errors with detailed messages\n```",
    "tags": [
      "anyhow",
      "thiserror",
      "error-handling",
      "production",
      "real-world",
      "error-chaining",
      "retry-logic",
      "validation",
      "structured-errors"
    ],
    "instruction": "Implement comprehensive error handling with anyhow and thiserror for real-world applications"
  },
  {
    "output": "```rust\n// This example demonstrates creating custom error types with proper hierarchies\n// and conversion patterns for real-world applications\n\nuse std::fmt;\nuse std::error::Error;\nuse std::io;\nuse std::num::ParseIntError;\n\n// Domain-specific error types representing different failure modes\n#[derive(Debug, Clone)]\npub enum ValidationError {\n    InvalidEmail(String),\n    PasswordTooShort { min_length: usize, actual: usize },\n    UsernameExists(String),\n    AgeOutOfRange { min: u8, max: u8, actual: i32 },\n}\n\nimpl fmt::Display for ValidationError {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        match self {\n            ValidationError::InvalidEmail(email) => {\n                write!(f, \"Invalid email address: '{}'\", email)\n            }\n            ValidationError::PasswordTooShort { min_length, actual } => {\n                write!(f, \"Password too short: requires {} characters, got {}\", min_length, actual)\n            }\n            ValidationError::UsernameExists(username) => {\n                write!(f, \"Username '{}' is already taken\", username)\n            }\n            ValidationError::AgeOutOfRange { min, max, actual } => {\n                write!(f, \"Age {} is out of range (must be between {} and {})\", actual, min, max)\n            }\n        }\n    }\n}\n\nimpl Error for ValidationError {}\n\n// Database operation errors\n#[derive(Debug)]\npub enum DatabaseError {\n    ConnectionFailed { \n        host: String, \n        port: u16, \n        reason: String \n    },\n    QueryExecution { \n        query: String, \n        error: String \n    },\n    TransactionFailed { \n        transaction_id: String, \n        rollback_successful: bool \n    },\n    RecordNotFound { \n        table: String, \n        id: String \n    },\n    ConstraintViolation { \n        constraint: String, \n        details: String \n    },\n}\n\nimpl fmt::Display for DatabaseError {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        match self {\n            DatabaseError::ConnectionFailed { host, port, reason } => {\n                write!(f, \"Failed to connect to {}:{} - {}\", host, port, reason)\n            }\n            DatabaseError::QueryExecution { query, error } => {\n                write!(f, \"Query execution failed: '{}' - {}\", query, error)\n            }\n            DatabaseError::TransactionFailed { transaction_id, rollback_successful } => {\n                write!(f, \"Transaction {} failed (rollback: {})\", \n                       transaction_id, if *rollback_successful { \"success\" } else { \"failed\" })\n            }\n            DatabaseError::RecordNotFound { table, id } => {\n                write!(f, \"Record with id '{}' not found in table '{}'\", id, table)\n            }\n            DatabaseError::ConstraintViolation { constraint, details } => {\n                write!(f, \"Constraint '{}' violated: {}\", constraint, details)\n            }\n        }\n    }\n}\n\nimpl Error for DatabaseError {}\n\n// Network/API errors\n#[derive(Debug)]\npub enum NetworkError {\n    Timeout { endpoint: String, duration_ms: u64 },\n    InvalidResponse { status: u16, body: String },\n    SerializationFailed { data_type: String, error: String },\n    RateLimited { retry_after_seconds: Option<u64> },\n    Unauthorized { message: String },\n}\n\nimpl fmt::Display for NetworkError {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        match self {\n            NetworkError::Timeout { endpoint, duration_ms } => {\n                write!(f, \"Request to '{}' timed out after {}ms\", endpoint, duration_ms)\n            }\n            NetworkError::InvalidResponse { status, body } => {\n                write!(f, \"Invalid response (status {}): {}\", status, body)\n            }\n            NetworkError::SerializationFailed { data_type, error } => {\n                write!(f, \"Failed to serialize {}: {}\", data_type, error)\n            }\n            NetworkError::RateLimited { retry_after_seconds } => {\n                match retry_after_seconds {\n                    Some(seconds) => write!(f, \"Rate limited, retry after {} seconds\", seconds),\n                    None => write!(f, \"Rate limited, no retry time specified\"),\n                }\n            }\n            NetworkError::Unauthorized { message } => {\n                write!(f, \"Unauthorized: {}\", message)\n            }\n        }\n    }\n}\n\nimpl Error for NetworkError {}\n\n// Top-level application error that encompasses all error types\n#[derive(Debug)]\npub enum AppError {\n    Validation(ValidationError),\n    Database(DatabaseError),\n    Network(NetworkError),\n    Io(io::Error),\n    Parse(ParseIntError),\n    Config { \n        key: String, \n        error: String \n    },\n    Internal { \n        message: String, \n        source: Option<Box<dyn Error + Send + Sync>> \n    },\n}\n\nimpl fmt::Display for AppError {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        match self {\n            AppError::Validation(err) => write!(f, \"Validation error: {}\", err),\n            AppError::Database(err) => write!(f, \"Database error: {}\", err),\n            AppError::Network(err) => write!(f, \"Network error: {}\", err),\n            AppError::Io(err) => write!(f, \"IO error: {}\", err),\n            AppError::Parse(err) => write!(f, \"Parse error: {}\", err),\n            AppError::Config { key, error } => {\n                write!(f, \"Configuration error for key '{}': {}\", key, error)\n            }\n            AppError::Internal { message, source } => {\n                match source {\n                    Some(source) => write!(f, \"Internal error: {} (caused by: {})\", message, source),\n                    None => write!(f, \"Internal error: {}\", message),\n                }\n            }\n        }\n    }\n}\n\nimpl Error for AppError {\n    fn source(&self) -> Option<&(dyn Error + 'static)> {\n        match self {\n            AppError::Validation(err) => Some(err),\n            AppError::Database(err) => Some(err),\n            AppError::Network(err) => Some(err),\n            AppError::Io(err) => Some(err),\n            AppError::Parse(err) => Some(err),\n            AppError::Internal { source, .. } => source.as_ref().map(|e| e.as_ref()),\n            _ => None,\n        }\n    }\n}\n\n// Automatic conversions from specific error types to AppError\nimpl From<ValidationError> for AppError {\n    fn from(err: ValidationError) -> Self {\n        AppError::Validation(err)\n    }\n}\n\nimpl From<DatabaseError> for AppError {\n    fn from(err: DatabaseError) -> Self {\n        AppError::Database(err)\n    }\n}\n\nimpl From<NetworkError> for AppError {\n    fn from(err: NetworkError) -> Self {\n        AppError::Network(err)\n    }\n}\n\nimpl From<io::Error> for AppError {\n    fn from(err: io::Error) -> Self {\n        AppError::Io(err)\n    }\n}\n\nimpl From<ParseIntError> for AppError {\n    fn from(err: ParseIntError) -> Self {\n        AppError::Parse(err)\n    }\n}\n\n// Result type alias for application operations\npub type AppResult<T> = Result<T, AppError>;\n\n// Helper functions for creating errors\nimpl AppError {\n    pub fn config(key: &str, error: &str) -> Self {\n        AppError::Config {\n            key: key.to_string(),\n            error: error.to_string(),\n        }\n    }\n    \n    pub fn internal(message: &str) -> Self {\n        AppError::Internal {\n            message: message.to_string(),\n            source: None,\n        }\n    }\n    \n    pub fn internal_with_source<E>(message: &str, source: E) -> Self \n    where\n        E: Error + Send + Sync + 'static,\n    {\n        AppError::Internal {\n            message: message.to_string(),\n            source: Some(Box::new(source)),\n        }\n    }\n}\n\n// Business logic functions that use these error types\nfn validate_user_registration(\n    username: &str,\n    email: &str,\n    password: &str,\n    age: i32,\n) -> Result<(), ValidationError> {\n    // Username validation\n    if existing_usernames().contains(&username.to_string()) {\n        return Err(ValidationError::UsernameExists(username.to_string()));\n    }\n    \n    // Email validation\n    if !email.contains('@') || !email.contains('.') {\n        return Err(ValidationError::InvalidEmail(email.to_string()));\n    }\n    \n    // Password validation\n    const MIN_PASSWORD_LENGTH: usize = 8;\n    if password.len() < MIN_PASSWORD_LENGTH {\n        return Err(ValidationError::PasswordTooShort {\n            min_length: MIN_PASSWORD_LENGTH,\n            actual: password.len(),\n        });\n    }\n    \n    // Age validation\n    const MIN_AGE: u8 = 13;\n    const MAX_AGE: u8 = 120;\n    if age < MIN_AGE as i32 || age > MAX_AGE as i32 {\n        return Err(ValidationError::AgeOutOfRange {\n            min: MIN_AGE,\n            max: MAX_AGE,\n            actual: age,\n        });\n    }\n    \n    Ok(())\n}\n\nfn create_user_in_database(username: &str, email: &str) -> Result<String, DatabaseError> {\n    // Simulate database operations\n    if username == \"admin\" {\n        return Err(DatabaseError::ConstraintViolation {\n            constraint: \"username_reserved\".to_string(),\n            details: \"Username 'admin' is reserved\".to_string(),\n        });\n    }\n    \n    if email == \"test@blocked.com\" {\n        return Err(DatabaseError::QueryExecution {\n            query: format!(\"INSERT INTO users (username, email) VALUES ('{}', '{}')\", username, email),\n            error: \"Email domain is blocked\".to_string(),\n        });\n    }\n    \n    // Success case\n    Ok(format!(\"user_{}\", username))\n}\n\nfn send_welcome_email(user_id: &str, email: &str) -> Result<(), NetworkError> {\n    if email.contains(\"invalid\") {\n        return Err(NetworkError::InvalidResponse {\n            status: 400,\n            body: \"Invalid email address format\".to_string(),\n        });\n    }\n    \n    if email.contains(\"timeout\") {\n        return Err(NetworkError::Timeout {\n            endpoint: \"email-service.example.com\".to_string(),\n            duration_ms: 5000,\n        });\n    }\n    \n    Ok(())\n}\n\n// High-level operation that combines multiple error-prone operations\nfn register_user(username: &str, email: &str, password: &str, age: i32) -> AppResult<String> {\n    // Validation step - auto-converts ValidationError to AppError\n    validate_user_registration(username, email, password, age)?;\n    \n    // Database step - auto-converts DatabaseError to AppError\n    let user_id = create_user_in_database(username, email)?;\n    \n    // Network step - auto-converts NetworkError to AppError\n    send_welcome_email(&user_id, email)?;\n    \n    Ok(user_id)\n}\n\nfn existing_usernames() -> Vec<String> {\n    vec![\"admin\".to_string(), \"root\".to_string(), \"test\".to_string()]\n}\n\nfn main() {\n    println!(\"=== Custom Error Types and Hierarchies ===\");\n    \n    // Test successful registration\n    println!(\"\n=== Successful Registration ===\");\n    match register_user(\"alice\", \"alice@example.com\", \"secure123\", 25) {\n        Ok(user_id) => println!(\"User registered successfully: {}\", user_id),\n        Err(e) => println!(\"Registration failed: {}\", e),\n    }\n    \n    // Test various error scenarios\n    println!(\"\n=== Error Scenarios ===\");\n    \n    let test_cases = vec![\n        (\"admin\", \"admin@example.com\", \"password123\", 25, \"Reserved username\"),\n        (\"bob\", \"invalid-email\", \"password123\", 25, \"Invalid email\"),\n        (\"charlie\", \"charlie@example.com\", \"short\", 25, \"Password too short\"),\n        (\"diana\", \"diana@example.com\", \"password123\", 10, \"Age too young\"),\n        (\"eve\", \"test@blocked.com\", \"password123\", 25, \"Blocked email domain\"),\n        (\"frank\", \"frank@invalid.com\", \"password123\", 25, \"Invalid email service\"),\n        (\"grace\", \"grace@timeout.com\", \"password123\", 25, \"Network timeout\"),\n    ];\n    \n    for (username, email, password, age, description) in test_cases {\n        println!(\"\nTesting: {}\", description);\n        match register_user(username, email, password, age) {\n            Ok(user_id) => println!(\"  Success: {}\", user_id),\n            Err(e) => {\n                println!(\"  Error: {}\", e);\n                \n                // Demonstrate error chain traversal\n                let mut source = e.source();\n                let mut depth = 1;\n                while let Some(err) = source {\n                    println!(\"    Caused by (level {}): {}\", depth, err);\n                    source = err.source();\n                    depth += 1;\n                }\n            }\n        }\n    }\n    \n    // Demonstrate error matching and handling\n    println!(\"\n=== Error Handling Patterns ===\");\n    \n    let error_result = register_user(\"admin\", \"admin@test.com\", \"password123\", 25);\n    match error_result {\n        Ok(_) => println!(\"Unexpected success\"),\n        Err(AppError::Validation(ValidationError::UsernameExists(username))) => {\n            println!(\"Username conflict: suggest alternative to '{}'\", username);\n        }\n        Err(AppError::Database(DatabaseError::ConstraintViolation { constraint, .. })) => {\n            println!(\"Database constraint violated: {}\", constraint);\n        }\n        Err(AppError::Network(NetworkError::Timeout { endpoint, duration_ms })) => {\n            println!(\"Network timeout to {} after {}ms - will retry\", endpoint, duration_ms);\n        }\n        Err(other) => {\n            println!(\"Other error: {}\", other);\n        }\n    }\n    \n    // Creating errors with context\n    println!(\"\n=== Error Creation Patterns ===\");\n    \n    let config_error = AppError::config(\"database.url\", \"missing required field\");\n    println!(\"Config error: {}\", config_error);\n    \n    let internal_error = AppError::internal(\"unexpected state during user processing\");\n    println!(\"Internal error: {}\", internal_error);\n    \n    let validation_error = ValidationError::InvalidEmail(\"not-an-email\".to_string());\n    let wrapped_error = AppError::internal_with_source(\n        \"failed to process user input\", \n        validation_error\n    );\n    println!(\"Wrapped error: {}\", wrapped_error);\n    \n    println!(\"\n=== Error Hierarchy Benefits ===\");\n    println!(\"\u2713 Type-safe error handling with match expressions\");\n    println!(\"\u2713 Automatic error conversion with From trait\");\n    println!(\"\u2713 Rich error context with structured data\");\n    println!(\"\u2713 Error chain preservation for debugging\");\n    println!(\"\u2713 Domain-specific error types for better APIs\");\n    println!(\"\u2713 Consistent error formatting across application\");\n}\n\n// Key concepts:\n// - Structured error types with domain-specific variants\n// - Error hierarchies with automatic conversion via From trait\n// - Rich error context using structs within enum variants\n// - Error source chaining for debugging\n// - Type-safe error handling with pattern matching\n// - Helper methods for creating errors with context\n// - Result type aliases for cleaner function signatures\n```",
    "tags": [
      "error-handling",
      "custom-errors",
      "error-hierarchies",
      "production",
      "real-world"
    ],
    "instruction": "Create custom error types with proper error hierarchies and conversion patterns"
  },
  {
    "output": "```rust\n// This example demonstrates error recovery patterns including retry mechanisms,\n// circuit breakers, and fallback strategies for resilient applications\n\nuse std::time::{Duration, Instant};\nuse std::sync::atomic::{AtomicU32, AtomicBool, Ordering};\nuse std::sync::Arc;\nuse std::thread;\n\n// Error types for different failure scenarios\n#[derive(Debug, Clone)]\npub enum ServiceError {\n    Temporary { message: String, retry_after: Option<Duration> },\n    Permanent { message: String },\n    Timeout { duration: Duration },\n    RateLimited { reset_time: Instant },\n    ServiceUnavailable,\n}\n\nimpl std::fmt::Display for ServiceError {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        match self {\n            ServiceError::Temporary { message, retry_after } => {\n                match retry_after {\n                    Some(duration) => write!(f, \"Temporary error: {} (retry after {:?})\", message, duration),\n                    None => write!(f, \"Temporary error: {}\", message),\n                }\n            }\n            ServiceError::Permanent { message } => write!(f, \"Permanent error: {}\", message),\n            ServiceError::Timeout { duration } => write!(f, \"Timeout after {:?}\", duration),\n            ServiceError::RateLimited { reset_time } => {\n                write!(f, \"Rate limited, reset at {:?}\", reset_time)\n            }\n            ServiceError::ServiceUnavailable => write!(f, \"Service unavailable\"),\n        }\n    }\n}\n\nimpl std::error::Error for ServiceError {}\n\n// Circuit breaker implementation\n#[derive(Debug, Clone)]\npub enum CircuitState {\n    Closed,   // Normal operation\n    Open,     // Failing fast\n    HalfOpen, // Testing if service recovered\n}\n\npub struct CircuitBreaker {\n    state: Arc<AtomicU32>, // 0=Closed, 1=Open, 2=HalfOpen\n    failure_count: Arc<AtomicU32>,\n    success_count: Arc<AtomicU32>,\n    last_failure_time: Arc<std::sync::Mutex<Option<Instant>>>,\n    failure_threshold: u32,\n    success_threshold: u32,\n    timeout: Duration,\n}\n\nimpl CircuitBreaker {\n    pub fn new(failure_threshold: u32, success_threshold: u32, timeout: Duration) -> Self {\n        Self {\n            state: Arc::new(AtomicU32::new(0)), // Start closed\n            failure_count: Arc::new(AtomicU32::new(0)),\n            success_count: Arc::new(AtomicU32::new(0)),\n            last_failure_time: Arc::new(std::sync::Mutex::new(None)),\n            failure_threshold,\n            success_threshold,\n            timeout,\n        }\n    }\n    \n    pub fn call<T, F>(&self, operation: F) -> Result<T, ServiceError>\n    where\n        F: FnOnce() -> Result<T, ServiceError>,\n    {\n        match self.get_state() {\n            CircuitState::Open => {\n                // Check if timeout has elapsed\n                if let Ok(last_failure) = self.last_failure_time.lock() {\n                    if let Some(time) = *last_failure {\n                        if time.elapsed() >= self.timeout {\n                            // Transition to half-open\n                            self.state.store(2, Ordering::SeqCst);\n                            self.success_count.store(0, Ordering::SeqCst);\n                            println!(\"Circuit breaker: Open -> HalfOpen (timeout elapsed)\");\n                        } else {\n                            return Err(ServiceError::ServiceUnavailable);\n                        }\n                    }\n                } else {\n                    return Err(ServiceError::ServiceUnavailable);\n                }\n            }\n            CircuitState::HalfOpen => {\n                // Allow limited requests through\n            }\n            CircuitState::Closed => {\n                // Normal operation\n            }\n        }\n        \n        // Execute the operation\n        match operation() {\n            Ok(result) => {\n                self.on_success();\n                Ok(result)\n            }\n            Err(error) => {\n                self.on_failure();\n                Err(error)\n            }\n        }\n    }\n    \n    fn get_state(&self) -> CircuitState {\n        match self.state.load(Ordering::SeqCst) {\n            0 => CircuitState::Closed,\n            1 => CircuitState::Open,\n            2 => CircuitState::HalfOpen,\n            _ => CircuitState::Closed,\n        }\n    }\n    \n    fn on_success(&self) {\n        let state = self.get_state();\n        \n        match state {\n            CircuitState::HalfOpen => {\n                let success_count = self.success_count.fetch_add(1, Ordering::SeqCst) + 1;\n                if success_count >= self.success_threshold {\n                    // Transition to closed\n                    self.state.store(0, Ordering::SeqCst);\n                    self.failure_count.store(0, Ordering::SeqCst);\n                    println!(\"Circuit breaker: HalfOpen -> Closed (sufficient successes)\");\n                }\n            }\n            CircuitState::Closed => {\n                // Reset failure count on success\n                self.failure_count.store(0, Ordering::SeqCst);\n            }\n            CircuitState::Open => {\n                // Should not happen, but reset counters\n                self.failure_count.store(0, Ordering::SeqCst);\n            }\n        }\n    }\n    \n    fn on_failure(&self) {\n        let failure_count = self.failure_count.fetch_add(1, Ordering::SeqCst) + 1;\n        \n        if failure_count >= self.failure_threshold {\n            // Transition to open\n            self.state.store(1, Ordering::SeqCst);\n            if let Ok(mut last_failure) = self.last_failure_time.lock() {\n                *last_failure = Some(Instant::now());\n            }\n            println!(\"Circuit breaker: {} -> Open (failure threshold reached)\", \n                     match self.get_state() { _ => \"Closed/HalfOpen\" });\n        }\n    }\n}\n\n// Retry configuration\n#[derive(Debug, Clone)]\npub struct RetryConfig {\n    pub max_attempts: u32,\n    pub base_delay: Duration,\n    pub max_delay: Duration,\n    pub backoff_multiplier: f64,\n    pub jitter: bool,\n}\n\nimpl RetryConfig {\n    pub fn new() -> Self {\n        Self {\n            max_attempts: 3,\n            base_delay: Duration::from_millis(100),\n            max_delay: Duration::from_secs(30),\n            backoff_multiplier: 2.0,\n            jitter: true,\n        }\n    }\n    \n    pub fn with_max_attempts(mut self, attempts: u32) -> Self {\n        self.max_attempts = attempts;\n        self\n    }\n    \n    pub fn with_base_delay(mut self, delay: Duration) -> Self {\n        self.base_delay = delay;\n        self\n    }\n    \n    pub fn with_exponential_backoff(mut self, multiplier: f64) -> Self {\n        self.backoff_multiplier = multiplier;\n        self\n    }\n}\n\n// Retry mechanism with exponential backoff\npub fn retry_with_backoff<T, F>(\n    config: &RetryConfig,\n    mut operation: F,\n) -> Result<T, ServiceError>\nwhere\n    F: FnMut() -> Result<T, ServiceError>,\n{\n    let mut last_error = None;\n    \n    for attempt in 1..=config.max_attempts {\n        match operation() {\n            Ok(result) => return Ok(result),\n            Err(error) => {\n                match &error {\n                    ServiceError::Permanent { .. } => {\n                        // Don't retry permanent errors\n                        return Err(error);\n                    }\n                    ServiceError::RateLimited { reset_time } => {\n                        // Wait until rate limit resets\n                        let wait_time = reset_time.duration_since(Instant::now());\n                        if wait_time <= config.max_delay {\n                            println!(\"Rate limited, waiting {:?} before retry\", wait_time);\n                            thread::sleep(wait_time);\n                        }\n                    }\n                    _ => {\n                        // Retry for temporary errors\n                    }\n                }\n                \n                last_error = Some(error);\n                \n                if attempt < config.max_attempts {\n                    let delay = calculate_delay(config, attempt);\n                    println!(\"Attempt {} failed, retrying in {:?}\", attempt, delay);\n                    thread::sleep(delay);\n                }\n            }\n        }\n    }\n    \n    Err(last_error.unwrap())\n}\n\nfn calculate_delay(config: &RetryConfig, attempt: u32) -> Duration {\n    let delay = config.base_delay.as_millis() as f64 \n        * config.backoff_multiplier.powi(attempt as i32 - 1);\n    \n    let delay = Duration::from_millis(delay as u64);\n    let delay = std::cmp::min(delay, config.max_delay);\n    \n    if config.jitter {\n        // Add random jitter (\u00b125%)\n        let jitter_factor = 0.75 + (rand::random::<f64>() * 0.5);\n        Duration::from_millis((delay.as_millis() as f64 * jitter_factor) as u64)\n    } else {\n        delay\n    }\n}\n\n// Fallback strategies\npub trait Fallback<T> {\n    fn fallback(&self) -> Result<T, ServiceError>;\n}\n\npub struct ServiceWithFallback<P, F> {\n    primary: P,\n    fallback: F,\n}\n\nimpl<P, F, T> ServiceWithFallback<P, F>\nwhere\n    P: Fn() -> Result<T, ServiceError>,\n    F: Fn() -> Result<T, ServiceError>,\n{\n    pub fn new(primary: P, fallback: F) -> Self {\n        Self { primary, fallback }\n    }\n    \n    pub fn call(&self) -> Result<T, ServiceError> {\n        match (self.primary)() {\n            Ok(result) => Ok(result),\n            Err(error) => {\n                println!(\"Primary service failed: {}, trying fallback\", error);\n                (self.fallback)()\n            }\n        }\n    }\n}\n\n// Simulated external service\nstruct ExternalService {\n    failure_rate: f64,\n    call_count: AtomicU32,\n}\n\nimpl ExternalService {\n    fn new(failure_rate: f64) -> Self {\n        Self {\n            failure_rate,\n            call_count: AtomicU32::new(0),\n        }\n    }\n    \n    fn call(&self, data: &str) -> Result<String, ServiceError> {\n        let call_num = self.call_count.fetch_add(1, Ordering::SeqCst) + 1;\n        \n        // Simulate various failure modes\n        let random_value = rand::random::<f64>();\n        \n        if random_value < self.failure_rate * 0.3 {\n            Err(ServiceError::Timeout { duration: Duration::from_millis(5000) })\n        } else if random_value < self.failure_rate * 0.6 {\n            Err(ServiceError::Temporary { \n                message: \"Database connection lost\".to_string(),\n                retry_after: Some(Duration::from_millis(1000)),\n            })\n        } else if random_value < self.failure_rate * 0.8 {\n            Err(ServiceError::RateLimited { \n                reset_time: Instant::now() + Duration::from_millis(2000),\n            })\n        } else if random_value < self.failure_rate {\n            if call_num > 10 {\n                Err(ServiceError::Permanent { \n                    message: \"Invalid API key\".to_string(),\n                })\n            } else {\n                Err(ServiceError::ServiceUnavailable)\n            }\n        } else {\n            Ok(format!(\"Response for '{}' (call #{})\", data, call_num))\n        }\n    }\n}\n\nfn main() {\n    println!(\"=== Error Recovery and Retry Mechanisms ===\");\n    \n    // Initialize services\n    let primary_service = Arc::new(ExternalService::new(0.7)); // 70% failure rate\n    let fallback_service = Arc::new(ExternalService::new(0.2)); // 20% failure rate\n    \n    // Test basic retry mechanism\n    println!(\"\n=== Basic Retry Mechanism ===\");\n    let retry_config = RetryConfig::new()\n        .with_max_attempts(5)\n        .with_base_delay(Duration::from_millis(100))\n        .with_exponential_backoff(2.0);\n    \n    let service = primary_service.clone();\n    let result = retry_with_backoff(&retry_config, || {\n        service.call(\"test data\")\n    });\n    \n    match result {\n        Ok(response) => println!(\"Success: {}\", response),\n        Err(error) => println!(\"Failed after retries: {}\", error),\n    }\n    \n    // Test circuit breaker\n    println!(\"\n=== Circuit Breaker Pattern ===\");\n    let circuit_breaker = CircuitBreaker::new(\n        3, // failure threshold\n        2, // success threshold  \n        Duration::from_millis(5000), // timeout\n    );\n    \n    let service = primary_service.clone();\n    for i in 1..=15 {\n        let result = circuit_breaker.call(|| service.call(&format!(\"request {}\", i)));\n        match result {\n            Ok(response) => println!(\"Call {}: Success - {}\", i, response),\n            Err(error) => println!(\"Call {}: Failed - {}\", i, error),\n        }\n        \n        thread::sleep(Duration::from_millis(500));\n    }\n    \n    // Test fallback mechanism\n    println!(\"\n=== Fallback Strategy ===\");\n    let primary = {\n        let service = primary_service.clone();\n        move || service.call(\"important data\")\n    };\n    \n    let fallback = {\n        let service = fallback_service.clone();\n        move || service.call(\"cached data\")\n    };\n    \n    let service_with_fallback = ServiceWithFallback::new(primary, fallback);\n    \n    for i in 1..=5 {\n        match service_with_fallback.call() {\n            Ok(response) => println!(\"Attempt {}: {}\", i, response),\n            Err(error) => println!(\"Attempt {}: Both services failed - {}\", i, error),\n        }\n    }\n    \n    // Combined approach: Retry + Circuit Breaker + Fallback\n    println!(\"\n=== Combined Resilience Patterns ===\");\n    let combined_circuit_breaker = CircuitBreaker::new(2, 1, Duration::from_millis(3000));\n    \n    let resilient_operation = || {\n        // Try primary service with circuit breaker\n        let primary_result = combined_circuit_breaker.call(|| {\n            primary_service.call(\"critical operation\")\n        });\n        \n        match primary_result {\n            Ok(result) => Ok(result),\n            Err(_) => {\n                // Fallback to secondary service with retry\n                retry_with_backoff(&RetryConfig::new().with_max_attempts(2), || {\n                    fallback_service.call(\"fallback operation\")\n                })\n            }\n        }\n    };\n    \n    for i in 1..=8 {\n        match resilient_operation() {\n            Ok(response) => println!(\"Combined attempt {}: Success - {}\", i, response),\n            Err(error) => println!(\"Combined attempt {}: Failed - {}\", i, error),\n        }\n        thread::sleep(Duration::from_millis(1000));\n    }\n    \n    println!(\"\n=== Recovery Pattern Benefits ===\");\n    println!(\"\u2713 Automatic retry with exponential backoff\");\n    println!(\"\u2713 Circuit breaker prevents cascade failures\");\n    println!(\"\u2713 Fallback strategies maintain service availability\");\n    println!(\"\u2713 Configurable failure thresholds and timeouts\");\n    println!(\"\u2713 Jitter reduces thundering herd problems\");\n    println!(\"\u2713 Different strategies for different error types\");\n}\n\n// Mock random function for demonstration\nmod rand {\n    use std::sync::atomic::{AtomicU64, Ordering};\n    static SEED: AtomicU64 = AtomicU64::new(12345);\n    \n    pub fn random<T>() -> T \n    where \n        T: From<f64>,\n    {\n        let seed = SEED.fetch_add(1, Ordering::SeqCst);\n        let value = (seed.wrapping_mul(1103515245).wrapping_add(12345) % (1 << 31)) as f64 / ((1 << 31) as f64);\n        T::from(value)\n    }\n}\n\n// Key concepts:\n// - Retry mechanisms with exponential backoff and jitter\n// - Circuit breaker pattern to prevent cascade failures\n// - Fallback strategies for graceful degradation\n// - Different handling for temporary vs permanent errors\n// - Configurable thresholds and timeouts\n// - Rate limiting awareness and handling\n// - Combined resilience patterns for robust systems\n```",
    "tags": [
      "error-recovery",
      "retry-mechanisms",
      "circuit-breaker",
      "fallback",
      "resilience"
    ],
    "instruction": "Implement error recovery patterns including retry mechanisms, circuit breakers, and fallback strategies"
  },
  {
    "output": "```rust\n// This example demonstrates error context tracking and debugging aids\n// including error IDs, stack traces, and structured logging for production debugging\n\nuse std::collections::HashMap;\nuse std::fmt;\nuse std::sync::atomic::{AtomicU64, Ordering};\nuse std::time::{SystemTime, UNIX_EPOCH};\n\n// Error context and tracking\n#[derive(Debug, Clone)]\npub struct ErrorContext {\n    pub error_id: String,\n    pub timestamp: u64,\n    pub component: String,\n    pub operation: String,\n    pub user_id: Option<String>,\n    pub request_id: Option<String>,\n    pub metadata: HashMap<String, String>,\n}\n\nimpl ErrorContext {\n    pub fn new(component: &str, operation: &str) -> Self {\n        Self {\n            error_id: generate_error_id(),\n            timestamp: SystemTime::now()\n                .duration_since(UNIX_EPOCH)\n                .unwrap()\n                .as_secs(),\n            component: component.to_string(),\n            operation: operation.to_string(),\n            user_id: None,\n            request_id: None,\n            metadata: HashMap::new(),\n        }\n    }\n    \n    pub fn with_user_id(mut self, user_id: &str) -> Self {\n        self.user_id = Some(user_id.to_string());\n        self\n    }\n    \n    pub fn with_request_id(mut self, request_id: &str) -> Self {\n        self.request_id = Some(request_id.to_string());\n        self\n    }\n    \n    pub fn with_metadata(mut self, key: &str, value: &str) -> Self {\n        self.metadata.insert(key.to_string(), value.to_string());\n        self\n    }\n}\n\n// Application error with rich context\n#[derive(Debug)]\npub struct ContextualError {\n    pub context: ErrorContext,\n    pub error_type: ErrorType,\n    pub message: String,\n    pub source: Option<Box<dyn std::error::Error + Send + Sync>>,\n    pub stack_trace: Option<String>,\n}\n\n#[derive(Debug, Clone)]\npub enum ErrorType {\n    Validation,\n    Database,\n    Network,\n    Authentication,\n    Authorization,\n    Business,\n    System,\n}\n\nimpl fmt::Display for ContextualError {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        write!(f, \"[{}] {}: {} in {}::{}\", \n               self.context.error_id,\n               format!(\"{:?}\", self.error_type),\n               self.message,\n               self.context.component,\n               self.context.operation)\n    }\n}\n\nimpl std::error::Error for ContextualError {\n    fn source(&self) -> Option<&(dyn std::error::Error + 'static)> {\n        self.source.as_ref().map(|e| e.as_ref())\n    }\n}\n\nimpl ContextualError {\n    pub fn new(error_type: ErrorType, message: &str, context: ErrorContext) -> Self {\n        Self {\n            context,\n            error_type,\n            message: message.to_string(),\n            source: None,\n            stack_trace: Some(capture_stack_trace()),\n        }\n    }\n    \n    pub fn with_source<E>(mut self, source: E) -> Self \n    where \n        E: std::error::Error + Send + Sync + 'static,\n    {\n        self.source = Some(Box::new(source));\n        self\n    }\n    \n    pub fn log_error(&self) {\n        let mut log_data = vec![\n            (\"error_id\", self.context.error_id.as_str()),\n            (\"error_type\", &format!(\"{:?}\", self.error_type)),\n            (\"message\", &self.message),\n            (\"component\", &self.context.component),\n            (\"operation\", &self.context.operation),\n            (\"timestamp\", &self.context.timestamp.to_string()),\n        ];\n        \n        if let Some(user_id) = &self.context.user_id {\n            log_data.push((\"user_id\", user_id));\n        }\n        \n        if let Some(request_id) = &self.context.request_id {\n            log_data.push((\"request_id\", request_id));\n        }\n        \n        for (key, value) in &self.context.metadata {\n            log_data.push((key, value));\n        }\n        \n        println!(\"ERROR: {}\", format_structured_log(&log_data));\n        \n        if let Some(stack_trace) = &self.stack_trace {\n            println!(\"STACK_TRACE: {}\", stack_trace);\n        }\n        \n        // Log error chain\n        if let Some(source) = &self.source {\n            println!(\"CAUSED_BY: {}\", source);\n            let mut current = source.source();\n            let mut depth = 1;\n            while let Some(err) = current {\n                println!(\"CAUSED_BY_L{}: {}\", depth, err);\n                current = err.source();\n                depth += 1;\n            }\n        }\n    }\n    \n    pub fn to_user_message(&self) -> String {\n        match self.error_type {\n            ErrorType::Validation => \"Please check your input and try again.\".to_string(),\n            ErrorType::Authentication => \"Please log in to continue.\".to_string(),\n            ErrorType::Authorization => \"You don't have permission to perform this action.\".to_string(),\n            ErrorType::Network => \"Service temporarily unavailable. Please try again later.\".to_string(),\n            ErrorType::Database => \"We're experiencing technical difficulties. Please try again later.\".to_string(),\n            ErrorType::Business => self.message.clone(),\n            ErrorType::System => format!(\"An error occurred. Please contact support with error ID: {}\", self.context.error_id),\n        }\n    }\n}\n\n// Result type with contextual errors\npub type ContextResult<T> = Result<T, ContextualError>;\n\n// Helper trait for adding context to any error\npub trait ErrorContextExt<T> {\n    fn with_context(self, error_type: ErrorType, message: &str, context: ErrorContext) -> ContextResult<T>;\n    fn with_validation_context(self, message: &str, context: ErrorContext) -> ContextResult<T>;\n    fn with_database_context(self, message: &str, context: ErrorContext) -> ContextResult<T>;\n    fn with_network_context(self, message: &str, context: ErrorContext) -> ContextResult<T>;\n}\n\nimpl<T, E> ErrorContextExt<T> for Result<T, E> \nwhere \n    E: std::error::Error + Send + Sync + 'static,\n{\n    fn with_context(self, error_type: ErrorType, message: &str, context: ErrorContext) -> ContextResult<T> {\n        self.map_err(|e| {\n            ContextualError::new(error_type, message, context).with_source(e)\n        })\n    }\n    \n    fn with_validation_context(self, message: &str, context: ErrorContext) -> ContextResult<T> {\n        self.with_context(ErrorType::Validation, message, context)\n    }\n    \n    fn with_database_context(self, message: &str, context: ErrorContext) -> ContextResult<T> {\n        self.with_context(ErrorType::Database, message, context)\n    }\n    \n    fn with_network_context(self, message: &str, context: ErrorContext) -> ContextResult<T> {\n        self.with_context(ErrorType::Network, message, context)\n    }\n}\n\n// Error aggregation for batch operations\npub struct ErrorCollector {\n    errors: Vec<ContextualError>,\n}\n\nimpl ErrorCollector {\n    pub fn new() -> Self {\n        Self {\n            errors: Vec::new(),\n        }\n    }\n    \n    pub fn add_error(&mut self, error: ContextualError) {\n        error.log_error();\n        self.errors.push(error);\n    }\n    \n    pub fn has_errors(&self) -> bool {\n        !self.errors.is_empty()\n    }\n    \n    pub fn into_result<T>(self, success_value: T) -> Result<T, BatchError> {\n        if self.errors.is_empty() {\n            Ok(success_value)\n        } else {\n            Err(BatchError {\n                errors: self.errors,\n            })\n        }\n    }\n    \n    pub fn errors(&self) -> &[ContextualError] {\n        &self.errors\n    }\n}\n\n#[derive(Debug)]\npub struct BatchError {\n    errors: Vec<ContextualError>,\n}\n\nimpl fmt::Display for BatchError {\n    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {\n        write!(f, \"Batch operation failed with {} errors\", self.errors.len())\n    }\n}\n\nimpl std::error::Error for BatchError {}\n\n// Business logic examples with contextual errors\nfn validate_email(email: &str, context: ErrorContext) -> ContextResult<()> {\n    if !email.contains('@') {\n        return Err(ContextualError::new(\n            ErrorType::Validation,\n            &format!(\"Invalid email format: {}\", email),\n            context.with_metadata(\"email\", email),\n        ));\n    }\n    \n    if email.len() > 100 {\n        return Err(ContextualError::new(\n            ErrorType::Validation,\n            \"Email address too long\",\n            context.with_metadata(\"email_length\", &email.len().to_string()),\n        ));\n    }\n    \n    Ok(())\n}\n\nfn fetch_user_from_database(user_id: &str, context: ErrorContext) -> ContextResult<String> {\n    // Simulate database error\n    if user_id == \"error\" {\n        let db_error = std::io::Error::new(std::io::ErrorKind::ConnectionRefused, \"Connection timeout\");\n        return Err(ContextualError::new(\n            ErrorType::Database,\n            \"Failed to fetch user from database\",\n            context.with_metadata(\"query\", \"SELECT * FROM users WHERE id = ?\")\n                   .with_metadata(\"user_id\", user_id),\n        ).with_source(db_error));\n    }\n    \n    if user_id == \"notfound\" {\n        return Err(ContextualError::new(\n            ErrorType::Business,\n            &format!(\"User with ID {} not found\", user_id),\n            context.with_metadata(\"user_id\", user_id),\n        ));\n    }\n    \n    Ok(format!(\"User data for {}\", user_id))\n}\n\nfn send_notification(user_id: &str, message: &str, context: ErrorContext) -> ContextResult<()> {\n    if message.len() > 160 {\n        return Err(ContextualError::new(\n            ErrorType::Validation,\n            \"Notification message too long\",\n            context.with_metadata(\"message_length\", &message.len().to_string())\n                   .with_metadata(\"max_length\", \"160\"),\n        ));\n    }\n    \n    // Simulate network error\n    if user_id.contains(\"unreachable\") {\n        let network_error = std::io::Error::new(std::io::ErrorKind::TimedOut, \"Network timeout\");\n        return Err(ContextualError::new(\n            ErrorType::Network,\n            \"Failed to send notification\",\n            context.with_metadata(\"notification_service\", \"email\")\n                   .with_metadata(\"recipient\", user_id),\n        ).with_source(network_error));\n    }\n    \n    Ok(())\n}\n\n// Complex operation with multiple error points\nfn process_user_registration(\n    email: &str, \n    user_id: &str, \n    request_id: &str,\n) -> ContextResult<String> {\n    let base_context = ErrorContext::new(\"user_service\", \"registration\")\n        .with_request_id(request_id)\n        .with_metadata(\"email\", email)\n        .with_metadata(\"user_id\", user_id);\n    \n    // Validate email\n    validate_email(email, base_context.clone())?;\n    \n    // Check if user exists\n    match fetch_user_from_database(user_id, base_context.clone()) {\n        Ok(_) => {\n            return Err(ContextualError::new(\n                ErrorType::Business,\n                \"User already exists\",\n                base_context.with_metadata(\"conflict_field\", \"user_id\"),\n            ));\n        }\n        Err(e) if matches!(e.error_type, ErrorType::Business) => {\n            // User not found is expected for registration\n        }\n        Err(e) => return Err(e), // Database or other errors\n    }\n    \n    // Send welcome notification\n    send_notification(user_id, \"Welcome to our service!\", base_context.clone())?;\n    \n    Ok(format!(\"User {} registered successfully\", user_id))\n}\n\n// Batch operation example\nfn process_user_batch(users: &[(String, String)], request_id: &str) -> Result<Vec<String>, BatchError> {\n    let mut collector = ErrorCollector::new();\n    let mut results = Vec::new();\n    \n    for (email, user_id) in users {\n        match process_user_registration(email, user_id, request_id) {\n            Ok(result) => results.push(result),\n            Err(error) => collector.add_error(error),\n        }\n    }\n    \n    collector.into_result(results)\n}\n\n// Utility functions\nfn generate_error_id() -> String {\n    static COUNTER: AtomicU64 = AtomicU64::new(0);\n    let count = COUNTER.fetch_add(1, Ordering::SeqCst);\n    let timestamp = SystemTime::now()\n        .duration_since(UNIX_EPOCH)\n        .unwrap()\n        .as_millis();\n    format!(\"ERR-{}-{:04}\", timestamp, count)\n}\n\nfn capture_stack_trace() -> String {\n    // Simplified stack trace simulation\n    format!(\"stack_trace_placeholder_at_{}:{}\", file!(), line!())\n}\n\nfn format_structured_log(data: &[(&str, &str)]) -> String {\n    data.iter()\n        .map(|(k, v)| format!(\"{}=\"{}\"\", k, v))\n        .collect::<Vec<_>>()\n        .join(\" \")\n}\n\nfn main() {\n    println!(\"=== Error Context and Debugging ===\");\n    \n    // Single operation examples\n    println!(\"\n=== Single Operation Errors ===\");\n    \n    let test_cases = vec![\n        (\"valid@example.com\", \"user123\", \"Expected success\"),\n        (\"invalid-email\", \"user456\", \"Invalid email format\"),\n        (\"valid@example.com\", \"error\", \"Database error\"),\n        (\"valid@example.com\", \"notfound\", \"User creation (not found is OK)\"),\n        (\"valid@example.com\", \"unreachable\", \"Network error\"),\n        (\"valid@example.com\", \"user123\", \"User already exists\"),\n    ];\n    \n    for (email, user_id, description) in test_cases {\n        println!(\"\nTesting: {}\", description);\n        let request_id = format!(\"req-{}\", generate_error_id());\n        \n        match process_user_registration(email, user_id, &request_id) {\n            Ok(result) => println!(\"SUCCESS: {}\", result),\n            Err(error) => {\n                println!(\"ERROR: {}\", error);\n                println!(\"USER_MESSAGE: {}\", error.to_user_message());\n                error.log_error();\n            }\n        }\n    }\n    \n    // Batch operation example\n    println!(\"\n=== Batch Operation Errors ===\");\n    \n    let user_batch = vec![\n        (\"alice@example.com\".to_string(), \"alice\".to_string()),\n        (\"invalid-email\".to_string(), \"bob\".to_string()),\n        (\"charlie@example.com\".to_string(), \"error\".to_string()),\n        (\"diana@example.com\".to_string(), \"diana\".to_string()),\n        (\"eve@example.com\".to_string(), \"unreachable\".to_string()),\n    ];\n    \n    let batch_request_id = format!(\"batch-{}\", generate_error_id());\n    match process_user_batch(&user_batch, &batch_request_id) {\n        Ok(results) => {\n            println!(\"Batch SUCCESS: {} users processed\", results.len());\n            for result in results {\n                println!(\"  - {}\", result);\n            }\n        }\n        Err(batch_error) => {\n            println!(\"Batch FAILED: {}\", batch_error);\n            println!(\"Error details:\");\n            for (i, error) in batch_error.errors.iter().enumerate() {\n                println!(\"  {}. [{}] {}\", i + 1, error.context.error_id, error.to_user_message());\n            }\n        }\n    }\n    \n    // Error context demonstration\n    println!(\"\n=== Error Context Features ===\");\n    \n    let context = ErrorContext::new(\"payment_service\", \"process_payment\")\n        .with_user_id(\"user123\")\n        .with_request_id(\"req-abc-123\")\n        .with_metadata(\"payment_method\", \"credit_card\")\n        .with_metadata(\"amount\", \"99.99\")\n        .with_metadata(\"currency\", \"USD\");\n    \n    let payment_error = ContextualError::new(\n        ErrorType::System,\n        \"Payment processor unavailable\",\n        context,\n    );\n    \n    println!(\"Error ID: {}\", payment_error.context.error_id);\n    println!(\"User message: {}\", payment_error.to_user_message());\n    payment_error.log_error();\n    \n    println!(\"\n=== Debugging Benefits ===\");\n    println!(\"\u2713 Unique error IDs for tracking and support\");\n    println!(\"\u2713 Rich context with user, request, and operation details\");\n    println!(\"\u2713 Structured logging for automated analysis\");\n    println!(\"\u2713 Stack traces for development debugging\");\n    println!(\"\u2713 Error source chains for root cause analysis\");\n    println!(\"\u2713 User-friendly error messages\");\n    println!(\"\u2713 Batch error collection and reporting\");\n    println!(\"\u2713 Metadata for additional debugging context\");\n}\n\n// Key concepts:\n// - Unique error IDs for tracking across systems\n// - Rich error context with operation and user details\n// - Structured logging for automated analysis\n// - Error source chains for debugging\n// - User-friendly error message generation\n// - Batch error collection and handling\n// - Error metadata for additional context\n// - Stack trace capture for development\n```",
    "tags": [
      "error-context",
      "debugging",
      "error-tracking",
      "structured-logging",
      "production"
    ],
    "instruction": "Implement error context tracking and debugging aids including error IDs, stack traces, and structured logging"
  },
  {
    "output": "```rust\n// This example demonstrates comprehensive error testing strategies including\n// error injection, mocking failures, and error scenario validation\n\nuse std::collections::HashMap;\nuse std::sync::{Arc, Mutex};\nuse std::cell::RefCell;\n\n// Error types for testing\n#[derive(Debug, Clone, PartialEq)]\npub enum ServiceError {\n    NetworkTimeout { endpoint: String },\n    DatabaseError { query: String, message: String },\n    ValidationError { field: String, value: String },\n    AuthenticationError { reason: String },\n    RateLimitExceeded { reset_after_seconds: u32 },\n    InternalError { code: u32, message: String },\n}\n\nimpl std::fmt::Display for ServiceError {\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        match self {\n            ServiceError::NetworkTimeout { endpoint } => {\n                write!(f, \"Network timeout: {}\", endpoint)\n            }\n            ServiceError::DatabaseError { query, message } => {\n                write!(f, \"Database error in '{}': {}\", query, message)\n            }\n            ServiceError::ValidationError { field, value } => {\n                write!(f, \"Validation error: field '{}' with value '{}'\", field, value)\n            }\n            ServiceError::AuthenticationError { reason } => {\n                write!(f, \"Authentication failed: {}\", reason)\n            }\n            ServiceError::RateLimitExceeded { reset_after_seconds } => {\n                write!(f, \"Rate limit exceeded, reset after {} seconds\", reset_after_seconds)\n            }\n            ServiceError::InternalError { code, message } => {\n                write!(f, \"Internal error {}: {}\", code, message)\n            }\n        }\n    }\n}\n\nimpl std::error::Error for ServiceError {}\n\n// Test configuration for error injection\n#[derive(Debug, Clone)]\npub struct ErrorInjectionConfig {\n    pub network_failures: HashMap<String, ServiceError>,\n    pub database_failures: HashMap<String, ServiceError>,\n    pub authentication_failures: bool,\n    pub rate_limit_failures: bool,\n    pub random_failures: f64, // 0.0 to 1.0 probability\n}\n\nimpl ErrorInjectionConfig {\n    pub fn new() -> Self {\n        Self {\n            network_failures: HashMap::new(),\n            database_failures: HashMap::new(),\n            authentication_failures: false,\n            rate_limit_failures: false,\n            random_failures: 0.0,\n        }\n    }\n    \n    pub fn with_network_failure(mut self, endpoint: &str, error: ServiceError) -> Self {\n        self.network_failures.insert(endpoint.to_string(), error);\n        self\n    }\n    \n    pub fn with_database_failure(mut self, query: &str, error: ServiceError) -> Self {\n        self.database_failures.insert(query.to_string(), error);\n        self\n    }\n    \n    pub fn with_auth_failures(mut self) -> Self {\n        self.authentication_failures = true;\n        self\n    }\n    \n    pub fn with_rate_limit_failures(mut self) -> Self {\n        self.rate_limit_failures = true;\n        self\n    }\n    \n    pub fn with_random_failures(mut self, probability: f64) -> Self {\n        self.random_failures = probability;\n        self\n    }\n}\n\n// Mock service traits for dependency injection\npub trait NetworkService {\n    fn get(&self, endpoint: &str) -> Result<String, ServiceError>;\n    fn post(&self, endpoint: &str, data: &str) -> Result<String, ServiceError>;\n}\n\npub trait DatabaseService {\n    fn query(&self, sql: &str) -> Result<Vec<String>, ServiceError>;\n    fn execute(&self, sql: &str) -> Result<u64, ServiceError>;\n}\n\npub trait AuthService {\n    fn authenticate(&self, token: &str) -> Result<String, ServiceError>;\n    fn authorize(&self, user_id: &str, resource: &str) -> Result<(), ServiceError>;\n}\n\n// Mock implementations with error injection\npub struct MockNetworkService {\n    config: Arc<Mutex<ErrorInjectionConfig>>,\n    call_count: Arc<Mutex<HashMap<String, u32>>>,\n}\n\nimpl MockNetworkService {\n    pub fn new(config: ErrorInjectionConfig) -> Self {\n        Self {\n            config: Arc::new(Mutex::new(config)),\n            call_count: Arc::new(Mutex::new(HashMap::new())),\n        }\n    }\n    \n    pub fn get_call_count(&self, endpoint: &str) -> u32 {\n        self.call_count.lock().unwrap().get(endpoint).copied().unwrap_or(0)\n    }\n    \n    pub fn reset_calls(&self) {\n        self.call_count.lock().unwrap().clear();\n    }\n}\n\nimpl NetworkService for MockNetworkService {\n    fn get(&self, endpoint: &str) -> Result<String, ServiceError> {\n        // Track call count\n        {\n            let mut counts = self.call_count.lock().unwrap();\n            *counts.entry(endpoint.to_string()).or_insert(0) += 1;\n        }\n        \n        let config = self.config.lock().unwrap();\n        \n        // Check for specific endpoint failures\n        if let Some(error) = config.network_failures.get(endpoint) {\n            return Err(error.clone());\n        }\n        \n        // Check for random failures\n        if config.random_failures > 0.0 && mock_random() < config.random_failures {\n            return Err(ServiceError::NetworkTimeout {\n                endpoint: endpoint.to_string(),\n            });\n        }\n        \n        Ok(format!(\"Response from {}\", endpoint))\n    }\n    \n    fn post(&self, endpoint: &str, data: &str) -> Result<String, ServiceError> {\n        // Similar implementation to get, but for POST\n        self.get(endpoint).map(|_| format!(\"Posted to {} with data: {}\", endpoint, data))\n    }\n}\n\npub struct MockDatabaseService {\n    config: Arc<Mutex<ErrorInjectionConfig>>,\n    query_history: Arc<Mutex<Vec<String>>>,\n}\n\nimpl MockDatabaseService {\n    pub fn new(config: ErrorInjectionConfig) -> Self {\n        Self {\n            config: Arc::new(Mutex::new(config)),\n            query_history: Arc::new(Mutex::new(Vec::new())),\n        }\n    }\n    \n    pub fn get_query_history(&self) -> Vec<String> {\n        self.query_history.lock().unwrap().clone()\n    }\n    \n    pub fn clear_history(&self) {\n        self.query_history.lock().unwrap().clear();\n    }\n}\n\nimpl DatabaseService for MockDatabaseService {\n    fn query(&self, sql: &str) -> Result<Vec<String>, ServiceError> {\n        // Record query\n        self.query_history.lock().unwrap().push(sql.to_string());\n        \n        let config = self.config.lock().unwrap();\n        \n        // Check for specific query failures\n        if let Some(error) = config.database_failures.get(sql) {\n            return Err(error.clone());\n        }\n        \n        // Check for random failures\n        if config.random_failures > 0.0 && mock_random() < config.random_failures {\n            return Err(ServiceError::DatabaseError {\n                query: sql.to_string(),\n                message: \"Connection timeout\".to_string(),\n            });\n        }\n        \n        Ok(vec![format!(\"Result for: {}\", sql)])\n    }\n    \n    fn execute(&self, sql: &str) -> Result<u64, ServiceError> {\n        self.query(sql).map(|_| 1) // Return 1 affected row on success\n    }\n}\n\npub struct MockAuthService {\n    config: Arc<Mutex<ErrorInjectionConfig>>,\n    valid_tokens: Arc<Mutex<HashMap<String, String>>>,\n}\n\nimpl MockAuthService {\n    pub fn new(config: ErrorInjectionConfig) -> Self {\n        let mut valid_tokens = HashMap::new();\n        valid_tokens.insert(\"valid_token\".to_string(), \"user123\".to_string());\n        valid_tokens.insert(\"admin_token\".to_string(), \"admin\".to_string());\n        \n        Self {\n            config: Arc::new(Mutex::new(config)),\n            valid_tokens: Arc::new(Mutex::new(valid_tokens)),\n        }\n    }\n    \n    pub fn add_valid_token(&self, token: &str, user_id: &str) {\n        self.valid_tokens.lock().unwrap().insert(token.to_string(), user_id.to_string());\n    }\n}\n\nimpl AuthService for MockAuthService {\n    fn authenticate(&self, token: &str) -> Result<String, ServiceError> {\n        let config = self.config.lock().unwrap();\n        \n        if config.authentication_failures {\n            return Err(ServiceError::AuthenticationError {\n                reason: \"Authentication service unavailable\".to_string(),\n            });\n        }\n        \n        let tokens = self.valid_tokens.lock().unwrap();\n        match tokens.get(token) {\n            Some(user_id) => Ok(user_id.clone()),\n            None => Err(ServiceError::AuthenticationError {\n                reason: \"Invalid token\".to_string(),\n            }),\n        }\n    }\n    \n    fn authorize(&self, user_id: &str, resource: &str) -> Result<(), ServiceError> {\n        if user_id == \"admin\" {\n            Ok(()) // Admin can access everything\n        } else if resource.starts_with(\"admin/\") {\n            Err(ServiceError::AuthenticationError {\n                reason: \"Insufficient permissions\".to_string(),\n            })\n        } else {\n            Ok(())\n        }\n    }\n}\n\n// Business logic that uses these services\npub struct UserService<N, D, A> \nwhere\n    N: NetworkService,\n    D: DatabaseService,\n    A: AuthService,\n{\n    network: N,\n    database: D,\n    auth: A,\n}\n\nimpl<N, D, A> UserService<N, D, A>\nwhere\n    N: NetworkService,\n    D: DatabaseService,\n    A: AuthService,\n{\n    pub fn new(network: N, database: D, auth: A) -> Self {\n        Self { network, database, auth }\n    }\n    \n    pub fn get_user_profile(&self, token: &str, user_id: &str) -> Result<String, ServiceError> {\n        // Authenticate user\n        let authenticated_user = self.auth.authenticate(token)?;\n        \n        // Check authorization\n        if authenticated_user != user_id && authenticated_user != \"admin\" {\n            return Err(ServiceError::AuthenticationError {\n                reason: \"Cannot access other user's profile\".to_string(),\n            });\n        }\n        \n        // Fetch user from database\n        let query = format!(\"SELECT * FROM users WHERE id = '{}'\", user_id);\n        let user_data = self.database.query(&query)?;\n        \n        // Fetch additional data from external service\n        let endpoint = format!(\"https://api.example.com/users/{}\", user_id);\n        let external_data = self.network.get(&endpoint)?;\n        \n        Ok(format!(\"Profile: {:?} + {}\", user_data, external_data))\n    }\n    \n    pub fn update_user_profile(\n        &self, \n        token: &str, \n        user_id: &str, \n        data: &str\n    ) -> Result<(), ServiceError> {\n        // Authenticate and authorize\n        let authenticated_user = self.auth.authenticate(token)?;\n        self.auth.authorize(&authenticated_user, &format!(\"users/{}\", user_id))?;\n        \n        // Validate data\n        if data.is_empty() {\n            return Err(ServiceError::ValidationError {\n                field: \"data\".to_string(),\n                value: data.to_string(),\n            });\n        }\n        \n        // Update in database\n        let query = format!(\"UPDATE users SET data = '{}' WHERE id = '{}'\", data, user_id);\n        self.database.execute(&query)?;\n        \n        // Notify external service\n        let endpoint = \"https://api.example.com/notifications\";\n        self.network.post(endpoint, &format!(\"User {} updated\", user_id))?;\n        \n        Ok(())\n    }\n}\n\n// Test framework for error scenarios\npub struct ErrorTestFramework {\n    network_service: Arc<MockNetworkService>,\n    database_service: Arc<MockDatabaseService>,\n    auth_service: Arc<MockAuthService>,\n}\n\nimpl ErrorTestFramework {\n    pub fn new() -> Self {\n        let config = ErrorInjectionConfig::new();\n        \n        Self {\n            network_service: Arc::new(MockNetworkService::new(config.clone())),\n            database_service: Arc::new(MockDatabaseService::new(config.clone())),\n            auth_service: Arc::new(MockAuthService::new(config)),\n        }\n    }\n    \n    pub fn create_user_service(&self) -> UserService<MockNetworkService, MockDatabaseService, MockAuthService> {\n        UserService::new(\n            self.network_service.as_ref().clone(),\n            self.database_service.as_ref().clone(),\n            self.auth_service.as_ref().clone(),\n        )\n    }\n    \n    pub fn configure_network_failure(&self, endpoint: &str, error: ServiceError) {\n        let mut config = self.network_service.config.lock().unwrap();\n        config.network_failures.insert(endpoint.to_string(), error);\n    }\n    \n    pub fn configure_database_failure(&self, query: &str, error: ServiceError) {\n        let mut config = self.database_service.config.lock().unwrap();\n        config.database_failures.insert(query.to_string(), error);\n    }\n    \n    pub fn configure_auth_failure(&self) {\n        let mut config = self.auth_service.config.lock().unwrap();\n        config.authentication_failures = true;\n    }\n    \n    pub fn reset_configuration(&self) {\n        {\n            let mut config = self.network_service.config.lock().unwrap();\n            *config = ErrorInjectionConfig::new();\n        }\n        {\n            let mut config = self.database_service.config.lock().unwrap();\n            *config = ErrorInjectionConfig::new();\n        }\n        {\n            let mut config = self.auth_service.config.lock().unwrap();\n            *config = ErrorInjectionConfig::new();\n        }\n        \n        self.network_service.reset_calls();\n        self.database_service.clear_history();\n    }\n    \n    pub fn get_network_calls(&self, endpoint: &str) -> u32 {\n        self.network_service.get_call_count(endpoint)\n    }\n    \n    pub fn get_database_queries(&self) -> Vec<String> {\n        self.database_service.get_query_history()\n    }\n}\n\n// Test scenarios\nstruct TestScenario {\n    name: String,\n    setup: Box<dyn Fn(&ErrorTestFramework)>,\n    test: Box<dyn Fn(&UserService<MockNetworkService, MockDatabaseService, MockAuthService>) -> Result<(), String>>,\n    expected_error: Option<String>,\n}\n\nimpl TestScenario {\n    fn new<S, T>(\n        name: &str,\n        setup: S,\n        test: T,\n        expected_error: Option<&str>,\n    ) -> Self \n    where\n        S: Fn(&ErrorTestFramework) + 'static,\n        T: Fn(&UserService<MockNetworkService, MockDatabaseService, MockAuthService>) -> Result<(), String> + 'static,\n    {\n        Self {\n            name: name.to_string(),\n            setup: Box::new(setup),\n            test: Box::new(test),\n            expected_error: expected_error.map(|s| s.to_string()),\n        }\n    }\n}\n\nfn mock_random() -> f64 {\n    // Simple deterministic \"random\" for testing\n    0.5\n}\n\nfn main() {\n    println!(\"=== Error Testing and Mocking ===\");\n    \n    let framework = ErrorTestFramework::new();\n    \n    // Define test scenarios\n    let scenarios = vec![\n        TestScenario::new(\n            \"Successful user profile retrieval\",\n            |_| {}, // No failures configured\n            |service| {\n                match service.get_user_profile(\"valid_token\", \"user123\") {\n                    Ok(_) => Ok(()),\n                    Err(e) => Err(format!(\"Unexpected error: {}\", e)),\n                }\n            },\n            None,\n        ),\n        \n        TestScenario::new(\n            \"Authentication failure\",\n            |framework| {\n                framework.configure_auth_failure();\n            },\n            |service| {\n                match service.get_user_profile(\"valid_token\", \"user123\") {\n                    Ok(_) => Err(\"Expected authentication error\".to_string()),\n                    Err(ServiceError::AuthenticationError { .. }) => Ok(()),\n                    Err(e) => Err(format!(\"Wrong error type: {}\", e)),\n                }\n            },\n            Some(\"Authentication\"),\n        ),\n        \n        TestScenario::new(\n            \"Database connection failure\",\n            |framework| {\n                framework.configure_database_failure(\n                    \"SELECT * FROM users WHERE id = 'user123'\",\n                    ServiceError::DatabaseError {\n                        query: \"SELECT * FROM users WHERE id = 'user123'\".to_string(),\n                        message: \"Connection timeout\".to_string(),\n                    },\n                );\n            },\n            |service| {\n                match service.get_user_profile(\"valid_token\", \"user123\") {\n                    Ok(_) => Err(\"Expected database error\".to_string()),\n                    Err(ServiceError::DatabaseError { .. }) => Ok(()),\n                    Err(e) => Err(format!(\"Wrong error type: {}\", e)),\n                }\n            },\n            Some(\"Database\"),\n        ),\n        \n        TestScenario::new(\n            \"Network timeout on external API\",\n            |framework| {\n                framework.configure_network_failure(\n                    \"https://api.example.com/users/user123\",\n                    ServiceError::NetworkTimeout {\n                        endpoint: \"https://api.example.com/users/user123\".to_string(),\n                    },\n                );\n            },\n            |service| {\n                match service.get_user_profile(\"valid_token\", \"user123\") {\n                    Ok(_) => Err(\"Expected network error\".to_string()),\n                    Err(ServiceError::NetworkTimeout { .. }) => Ok(()),\n                    Err(e) => Err(format!(\"Wrong error type: {}\", e)),\n                }\n            },\n            Some(\"Network\"),\n        ),\n        \n        TestScenario::new(\n            \"Validation error on empty data\",\n            |_| {}, // No injection needed, this is business logic\n            |service| {\n                match service.update_user_profile(\"valid_token\", \"user123\", \"\") {\n                    Ok(_) => Err(\"Expected validation error\".to_string()),\n                    Err(ServiceError::ValidationError { field, .. }) if field == \"data\" => Ok(()),\n                    Err(e) => Err(format!(\"Wrong error type: {}\", e)),\n                }\n            },\n            Some(\"Validation\"),\n        ),\n        \n        TestScenario::new(\n            \"Authorization failure for admin resource\",\n            |_| {},\n            |service| {\n                match service.get_user_profile(\"valid_token\", \"admin_user\") {\n                    Ok(_) => Err(\"Expected authorization error\".to_string()),\n                    Err(ServiceError::AuthenticationError { reason }) \n                        if reason.contains(\"access\") => Ok(()),\n                    Err(e) => Err(format!(\"Wrong error type: {}\", e)),\n                }\n            },\n            Some(\"Authorization\"),\n        ),\n    ];\n    \n    // Run test scenarios\n    println!(\"\n=== Running Error Test Scenarios ===\");\n    let mut passed = 0;\n    let mut failed = 0;\n    \n    for scenario in scenarios {\n        println!(\"\nTesting: {}\", scenario.name);\n        \n        // Reset framework state\n        framework.reset_configuration();\n        \n        // Setup the scenario\n        (scenario.setup)(&framework);\n        \n        // Create service instance\n        let service = framework.create_user_service();\n        \n        // Run the test\n        match (scenario.test)(&service) {\n            Ok(()) => {\n                println!(\"  \u2713 PASSED\");\n                passed += 1;\n            }\n            Err(error_msg) => {\n                println!(\"  \u2717 FAILED: {}\", error_msg);\n                failed += 1;\n            }\n        }\n        \n        // Show call statistics\n        let profile_endpoint = \"https://api.example.com/users/user123\";\n        let network_calls = framework.get_network_calls(profile_endpoint);\n        if network_calls > 0 {\n            println!(\"    Network calls to '{}': {}\", profile_endpoint, network_calls);\n        }\n        \n        let db_queries = framework.get_database_queries();\n        if !db_queries.is_empty() {\n            println!(\"    Database queries: {}\", db_queries.len());\n            for query in db_queries {\n                println!(\"      - {}\", query);\n            }\n        }\n    }\n    \n    println!(\"\n=== Test Results ===\");\n    println!(\"Passed: {}\", passed);\n    println!(\"Failed: {}\", failed);\n    println!(\"Total:  {}\", passed + failed);\n    \n    // Demonstrate error injection patterns\n    println!(\"\n=== Error Injection Demonstration ===\");\n    framework.reset_configuration();\n    \n    // Configure multiple failures\n    framework.configure_network_failure(\n        \"https://api.example.com/notifications\",\n        ServiceError::RateLimitExceeded { reset_after_seconds: 60 },\n    );\n    \n    let service = framework.create_user_service();\n    \n    println!(\"\nTesting update with network rate limiting:\");\n    match service.update_user_profile(\"valid_token\", \"user123\", \"new data\") {\n        Ok(_) => println!(\"  Unexpected success\"),\n        Err(e) => println!(\"  Expected error: {}\", e),\n    }\n    \n    println!(\"\n=== Testing Benefits ===\");\n    println!(\"\u2713 Controlled error injection for specific scenarios\");\n    println!(\"\u2713 Mock services with realistic failure modes\");\n    println!(\"\u2713 Verification of error handling paths\");\n    println!(\"\u2713 Call tracking and verification\");\n    println!(\"\u2713 Configurable failure rates and conditions\");\n    println!(\"\u2713 Reproducible error scenarios\");\n    println!(\"\u2713 Integration testing with mocked dependencies\");\n    println!(\"\u2713 Comprehensive error coverage validation\");\n}\n\n// Key concepts:\n// - Error injection configuration for controlled testing\n// - Mock services with realistic failure modes\n// - Test framework for error scenario validation\n// - Call tracking and verification\n// - Configurable failure conditions\n// - Comprehensive error coverage testing\n// - Dependency injection for testability\n// - Reproducible error scenarios\n```",
    "tags": [
      "error-testing",
      "mocking",
      "error-injection",
      "test-framework",
      "validation"
    ],
    "instruction": "Implement comprehensive error testing strategies including error injection, mocking failures, and error scenario validation"
  },
  {
    "output": "```rust\n// This example demonstrates advanced CLI argument parsing with subcommands,\n// validation, and configuration using clap for professional command-line tools\n\nuse clap::{Arg, ArgAction, Command, Subcommand, Parser, ValueEnum};\nuse std::path::PathBuf;\nuse std::collections::HashMap;\n\n// Main CLI structure using derive macros\n#[derive(Parser)]\n#[command(name = \"devtools\")]\n#[command(about = \"A comprehensive development toolkit\")]\n#[command(version = \"1.0.0\")]\n#[command(author = \"Development Team <dev@example.com>\")]\n#[command(long_about = \"\nDevTools is a comprehensive command-line toolkit for software development.\nIt provides utilities for project management, code analysis, and deployment.\n\nExamples:\n  devtools project create my-app --template rust\n  devtools deploy --env production --confirm\n  devtools analyze --path ./src --format json\n\")]\nstruct Cli {\n    /// Enable verbose output\n    #[arg(short, long, global = true)]\n    verbose: bool,\n    \n    /// Configuration file path\n    #[arg(short, long, global = true, value_name = \"FILE\")]\n    config: Option<PathBuf>,\n    \n    /// Output format\n    #[arg(long, global = true, default_value = \"human\")]\n    format: OutputFormat,\n    \n    #[command(subcommand)]\n    command: Commands,\n}\n\n#[derive(Subcommand)]\nenum Commands {\n    /// Project management commands\n    Project {\n        #[command(subcommand)]\n        action: ProjectCommands,\n    },\n    /// Code analysis and linting\n    Analyze {\n        /// Path to analyze\n        #[arg(short, long, default_value = \".\")]\n        path: PathBuf,\n        \n        /// Analysis depth\n        #[arg(long, default_value = \"deep\")]\n        depth: AnalysisDepth,\n        \n        /// Include test files\n        #[arg(long)]\n        include_tests: bool,\n        \n        /// Exclude patterns (glob)\n        #[arg(long, value_delimiter = ',')]\n        exclude: Vec<String>,\n        \n        /// Maximum issues to report\n        #[arg(long, default_value = \"100\")]\n        max_issues: usize,\n    },\n    /// Deployment operations\n    Deploy {\n        /// Target environment\n        #[arg(short, long)]\n        env: Environment,\n        \n        /// Deployment strategy\n        #[arg(long, default_value = \"rolling\")]\n        strategy: DeployStrategy,\n        \n        /// Confirm deployment without prompt\n        #[arg(long)]\n        confirm: bool,\n        \n        /// Dry run - show what would be deployed\n        #[arg(long)]\n        dry_run: bool,\n        \n        /// Additional environment variables\n        #[arg(long, value_parser = parse_key_val::<String, String>)]\n        env_var: Vec<(String, String)>,\n    },\n    /// Database operations\n    Database {\n        #[command(subcommand)]\n        action: DatabaseCommands,\n    },\n    /// Configuration management\n    Config {\n        #[command(subcommand)]\n        action: ConfigCommands,\n    },\n}\n\n#[derive(Subcommand)]\nenum ProjectCommands {\n    /// Create a new project\n    Create {\n        /// Project name\n        name: String,\n        \n        /// Project template\n        #[arg(short, long, default_value = \"default\")]\n        template: String,\n        \n        /// Target directory\n        #[arg(long)]\n        path: Option<PathBuf>,\n        \n        /// Initialize git repository\n        #[arg(long, default_value = \"true\")]\n        git: bool,\n        \n        /// License type\n        #[arg(long)]\n        license: Option<String>,\n    },\n    /// Build the project\n    Build {\n        /// Build profile\n        #[arg(long, default_value = \"dev\")]\n        profile: BuildProfile,\n        \n        /// Target architecture\n        #[arg(long)]\n        target: Option<String>,\n        \n        /// Enable optimizations\n        #[arg(long)]\n        optimize: bool,\n        \n        /// Number of parallel jobs\n        #[arg(short, long)]\n        jobs: Option<usize>,\n    },\n    /// Run tests\n    Test {\n        /// Test pattern filter\n        #[arg(long)]\n        filter: Option<String>,\n        \n        /// Run ignored tests\n        #[arg(long)]\n        ignored: bool,\n        \n        /// Capture test output\n        #[arg(long)]\n        nocapture: bool,\n        \n        /// Test threads\n        #[arg(long, default_value = \"auto\")]\n        test_threads: String,\n    },\n}\n\n#[derive(Subcommand)]\nenum DatabaseCommands {\n    /// Create database migration\n    Migrate {\n        /// Migration name\n        name: String,\n        \n        /// Migration type\n        #[arg(long, default_value = \"create\")]\n        migration_type: MigrationType,\n    },\n    /// Apply pending migrations\n    Apply {\n        /// Target migration version\n        #[arg(long)]\n        to: Option<String>,\n        \n        /// Confirm destructive operations\n        #[arg(long)]\n        confirm: bool,\n    },\n    /// Rollback migrations\n    Rollback {\n        /// Number of migrations to rollback\n        #[arg(short, long, default_value = \"1\")]\n        steps: usize,\n    },\n    /// Database status and info\n    Status,\n}\n\n#[derive(Subcommand)]\nenum ConfigCommands {\n    /// Show current configuration\n    Show {\n        /// Configuration key to show\n        key: Option<String>,\n    },\n    /// Set configuration value\n    Set {\n        /// Configuration key\n        key: String,\n        /// Configuration value\n        value: String,\n        /// Set globally\n        #[arg(long)]\n        global: bool,\n    },\n    /// Remove configuration key\n    Unset {\n        /// Configuration key\n        key: String,\n        /// Remove globally\n        #[arg(long)]\n        global: bool,\n    },\n    /// Edit configuration file\n    Edit {\n        /// Edit global config\n        #[arg(long)]\n        global: bool,\n    },\n}\n\n// Value enums for type-safe argument parsing\n#[derive(ValueEnum, Clone, Debug)]\nenum OutputFormat {\n    Human,\n    Json,\n    Yaml,\n    Table,\n}\n\n#[derive(ValueEnum, Clone, Debug)]\nenum Environment {\n    Development,\n    Staging,\n    Production,\n}\n\n#[derive(ValueEnum, Clone, Debug)]\nenum DeployStrategy {\n    Rolling,\n    BlueGreen,\n    Canary,\n    Recreate,\n}\n\n#[derive(ValueEnum, Clone, Debug)]\nenum AnalysisDepth {\n    Quick,\n    Normal,\n    Deep,\n    Comprehensive,\n}\n\n#[derive(ValueEnum, Clone, Debug)]\nenum BuildProfile {\n    Dev,\n    Release,\n    Test,\n    Bench,\n}\n\n#[derive(ValueEnum, Clone, Debug)]\nenum MigrationType {\n    Create,\n    Update,\n    Drop,\n    Index,\n}\n\n// Configuration structure\n#[derive(Debug)]\nstruct Config {\n    database_url: Option<String>,\n    api_endpoint: Option<String>,\n    default_environment: Environment,\n    max_parallel_jobs: usize,\n    custom_settings: HashMap<String, String>,\n}\n\nimpl Config {\n    fn load(config_path: Option<&PathBuf>) -> Result<Self, String> {\n        // Simulate config loading\n        if let Some(path) = config_path {\n            println!(\"Loading config from: {}\", path.display());\n        }\n        \n        Ok(Config {\n            database_url: Some(\"postgresql://localhost/devtools\".to_string()),\n            api_endpoint: Some(\"https://api.devtools.com\".to_string()),\n            default_environment: Environment::Development,\n            max_parallel_jobs: num_cpus::get(),\n            custom_settings: HashMap::new(),\n        })\n    }\n}\n\n// Custom parser for key-value pairs\nfn parse_key_val<T, U>(s: &str) -> Result<(T, U), Box<dyn std::error::Error + Send + Sync + 'static>>\nwhere\n    T: std::str::FromStr,\n    T::Err: std::error::Error + Send + Sync + 'static,\n    U: std::str::FromStr,\n    U::Err: std::error::Error + Send + Sync + 'static,\n{\n    let pos = s\n        .find('=')\n        .ok_or_else(|| format!(\"invalid KEY=value: no `=` found in `{s}`\"))?;\n    Ok((s[..pos].parse()?, s[pos + 1..].parse()?))\n}\n\n// Command execution functions\nfn execute_project_create(\n    name: &str,\n    template: &str,\n    path: &Option<PathBuf>,\n    git: bool,\n    license: &Option<String>,\n    config: &Config,\n) -> Result<(), String> {\n    println!(\"Creating project '{}' with template '{}'\", name, template);\n    \n    let project_path = match path {\n        Some(p) => p.join(name),\n        None => PathBuf::from(name),\n    };\n    \n    println!(\"  Project path: {}\", project_path.display());\n    println!(\"  Initialize git: {}\", git);\n    \n    if let Some(license) = license {\n        println!(\"  License: {}\", license);\n    }\n    \n    // Simulate project creation\n    println!(\"\u2713 Project structure created\");\n    if git {\n        println!(\"\u2713 Git repository initialized\");\n    }\n    println!(\"\u2713 Project '{}' created successfully\", name);\n    \n    Ok(())\n}\n\nfn execute_project_build(\n    profile: &BuildProfile,\n    target: &Option<String>,\n    optimize: bool,\n    jobs: &Option<usize>,\n    config: &Config,\n) -> Result<(), String> {\n    println!(\"Building project with profile: {:?}\", profile);\n    \n    if let Some(target) = target {\n        println!(\"  Target: {}\", target);\n    }\n    \n    let job_count = jobs.unwrap_or(config.max_parallel_jobs);\n    println!(\"  Parallel jobs: {}\", job_count);\n    println!(\"  Optimizations: {}\", optimize);\n    \n    // Simulate build process\n    println!(\"\ud83d\udce6 Compiling dependencies...\");\n    println!(\"\ud83d\udd28 Building project...\");\n    \n    if optimize {\n        println!(\"\u26a1 Applying optimizations...\");\n    }\n    \n    println!(\"\u2713 Build completed successfully\");\n    Ok(())\n}\n\nfn execute_analyze(\n    path: &PathBuf,\n    depth: &AnalysisDepth,\n    include_tests: bool,\n    exclude: &[String],\n    max_issues: usize,\n    format: &OutputFormat,\n) -> Result<(), String> {\n    println!(\"Analyzing code at: {}\", path.display());\n    println!(\"  Analysis depth: {:?}\", depth);\n    println!(\"  Include tests: {}\", include_tests);\n    println!(\"  Max issues: {}\", max_issues);\n    \n    if !exclude.is_empty() {\n        println!(\"  Excluded patterns: {:?}\", exclude);\n    }\n    \n    // Simulate analysis\n    let issues_found = match depth {\n        AnalysisDepth::Quick => 3,\n        AnalysisDepth::Normal => 7,\n        AnalysisDepth::Deep => 12,\n        AnalysisDepth::Comprehensive => 18,\n    };\n    \n    match format {\n        OutputFormat::Human => {\n            println!(\"\n\ud83d\udcca Analysis Results:\");\n            println!(\"  Files analyzed: 42\");\n            println!(\"  Issues found: {}\", issues_found);\n            println!(\"  Warnings: 5\");\n            println!(\"  Errors: 2\");\n        }\n        OutputFormat::Json => {\n            println!(\"{{\");\n            println!(\"  \"files_analyzed\": 42,\");\n            println!(\"  \"issues_found\": {},\", issues_found);\n            println!(\"  \"warnings\": 5,\");\n            println!(\"  \"errors\": 2\");\n            println!(\"}}\");\n        }\n        OutputFormat::Table => {\n            println!(\"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\");\n            println!(\"\u2502 Metric          \u2502 Count \u2502\");\n            println!(\"\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\");\n            println!(\"\u2502 Files analyzed  \u2502    42 \u2502\");\n            println!(\"\u2502 Issues found    \u2502   {:2} \u2502\", issues_found);\n            println!(\"\u2502 Warnings        \u2502     5 \u2502\");\n            println!(\"\u2502 Errors          \u2502     2 \u2502\");\n            println!(\"\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\");\n        }\n        _ => println!(\"Analysis completed: {} issues found\", issues_found),\n    }\n    \n    Ok(())\n}\n\nfn execute_deploy(\n    env: &Environment,\n    strategy: &DeployStrategy,\n    confirm: bool,\n    dry_run: bool,\n    env_vars: &[(String, String)],\n    config: &Config,\n) -> Result<(), String> {\n    println!(\"Deploying to environment: {:?}\", env);\n    println!(\"  Strategy: {:?}\", strategy);\n    println!(\"  Dry run: {}\", dry_run);\n    \n    if !env_vars.is_empty() {\n        println!(\"  Environment variables:\");\n        for (key, value) in env_vars {\n            println!(\"    {}={}\", key, value);\n        }\n    }\n    \n    if matches!(env, Environment::Production) && !confirm && !dry_run {\n        return Err(\"Production deployment requires --confirm flag\".to_string());\n    }\n    \n    if dry_run {\n        println!(\"\n\ud83d\udd0d Dry run - showing deployment plan:\");\n        println!(\"  Would deploy version 1.2.3\");\n        println!(\"  Would update 3 services\");\n        println!(\"  Would run 2 migrations\");\n        return Ok(());\n    }\n    \n    // Simulate deployment\n    println!(\"\n\ud83d\ude80 Starting deployment...\");\n    match strategy {\n        DeployStrategy::Rolling => {\n            println!(\"  Rolling update: 33% complete\");\n            println!(\"  Rolling update: 66% complete\");\n            println!(\"  Rolling update: 100% complete\");\n        }\n        DeployStrategy::BlueGreen => {\n            println!(\"  Creating green environment...\");\n            println!(\"  Switching traffic to green...\");\n            println!(\"  Destroying blue environment...\");\n        }\n        _ => println!(\"  Executing {} deployment...\", format!(\"{:?}\", strategy).to_lowercase()),\n    }\n    \n    println!(\"\u2713 Deployment completed successfully\");\n    Ok(())\n}\n\nfn execute_database_command(cmd: &DatabaseCommands) -> Result<(), String> {\n    match cmd {\n        DatabaseCommands::Migrate { name, migration_type } => {\n            println!(\"Creating migration: {}\", name);\n            println!(\"  Type: {:?}\", migration_type);\n            println!(\"\u2713 Migration file created: migrations/001_{}.sql\", name);\n        }\n        DatabaseCommands::Apply { to, confirm } => {\n            println!(\"Applying migrations...\");\n            if let Some(target) = to {\n                println!(\"  Target version: {}\", target);\n            }\n            if !confirm {\n                println!(\"  Use --confirm to apply destructive migrations\");\n            }\n            println!(\"\u2713 Migrations applied successfully\");\n        }\n        DatabaseCommands::Rollback { steps } => {\n            println!(\"Rolling back {} migration(s)...\", steps);\n            println!(\"\u2713 Rollback completed\");\n        }\n        DatabaseCommands::Status => {\n            println!(\"Database Status:\");\n            println!(\"  Connection: \u2713 Connected\");\n            println!(\"  Migrations: 15 applied, 2 pending\");\n            println!(\"  Schema version: 1.4.2\");\n        }\n    }\n    Ok(())\n}\n\nfn execute_config_command(cmd: &ConfigCommands) -> Result<(), String> {\n    match cmd {\n        ConfigCommands::Show { key } => {\n            if let Some(key) = key {\n                println!(\"Config value for '{}': example_value\", key);\n            } else {\n                println!(\"Current configuration:\");\n                println!(\"  database_url = postgresql://localhost/devtools\");\n                println!(\"  api_endpoint = https://api.devtools.com\");\n                println!(\"  default_environment = development\");\n            }\n        }\n        ConfigCommands::Set { key, value, global } => {\n            let scope = if *global { \"global\" } else { \"local\" };\n            println!(\"Setting {} config: {} = {}\", scope, key, value);\n        }\n        ConfigCommands::Unset { key, global } => {\n            let scope = if *global { \"global\" } else { \"local\" };\n            println!(\"Removing {} config: {}\", scope, key);\n        }\n        ConfigCommands::Edit { global } => {\n            let scope = if *global { \"global\" } else { \"local\" };\n            println!(\"Opening {} configuration file in editor...\", scope);\n        }\n    }\n    Ok(())\n}\n\n// Mock num_cpus module for demonstration\nmod num_cpus {\n    pub fn get() -> usize {\n        4\n    }\n}\n\nfn main() {\n    let cli = Cli::parse();\n    \n    // Load configuration\n    let config = match Config::load(cli.config.as_ref()) {\n        Ok(config) => config,\n        Err(e) => {\n            eprintln!(\"Error loading config: {}\", e);\n            std::process::exit(1);\n        }\n    };\n    \n    if cli.verbose {\n        println!(\"Verbose mode enabled\");\n        println!(\"Output format: {:?}\", cli.format);\n    }\n    \n    // Execute commands\n    let result = match &cli.command {\n        Commands::Project { action } => match action {\n            ProjectCommands::Create { name, template, path, git, license } => {\n                execute_project_create(name, template, path, *git, license, &config)\n            }\n            ProjectCommands::Build { profile, target, optimize, jobs } => {\n                execute_project_build(profile, target, *optimize, jobs, &config)\n            }\n            ProjectCommands::Test { filter, ignored, nocapture, test_threads } => {\n                println!(\"Running tests...\");\n                if let Some(filter) = filter {\n                    println!(\"  Filter: {}\", filter);\n                }\n                println!(\"  Ignored tests: {}\", ignored);\n                println!(\"  Test threads: {}\", test_threads);\n                Ok(())\n            }\n        },\n        Commands::Analyze { path, depth, include_tests, exclude, max_issues } => {\n            execute_analyze(path, depth, *include_tests, exclude, *max_issues, &cli.format)\n        }\n        Commands::Deploy { env, strategy, confirm, dry_run, env_var } => {\n            execute_deploy(env, strategy, *confirm, *dry_run, env_var, &config)\n        }\n        Commands::Database { action } => execute_database_command(action),\n        Commands::Config { action } => execute_config_command(action),\n    };\n    \n    if let Err(e) = result {\n        eprintln!(\"Error: {}\", e);\n        std::process::exit(1);\n    }\n}\n\n// Key concepts:\n// - Structured CLI design with derive macros for type safety\n// - Subcommands for organizing complex functionality\n// - Global and command-specific arguments\n// - Value enums for type-safe argument validation\n// - Custom parsers for complex argument types\n// - Configuration management and loading\n// - Multiple output formats for different use cases\n// - Comprehensive help generation and documentation\n// - Error handling and user-friendly error messages\n```",
    "tags": [
      "cli",
      "clap",
      "argument-parsing",
      "subcommands",
      "command-line"
    ],
    "instruction": "Implement advanced CLI argument parsing with subcommands, validation, and configuration using clap"
  },
  {
    "output": "```rust\n// This example demonstrates creating interactive CLI applications with user prompts,\n// input validation, progress indicators, and rich terminal interfaces\n\nuse std::io::{self, Write};\nuse std::time::{Duration, Instant};\nuse std::thread;\nuse std::collections::HashMap;\n\n// Interactive prompt types\n#[derive(Debug, Clone)]\npub enum PromptType {\n    Text { default: Option<String> },\n    Number { min: Option<i64>, max: Option<i64>, default: Option<i64> },\n    Boolean { default: Option<bool> },\n    Select { options: Vec<String>, default: Option<usize> },\n    MultiSelect { options: Vec<String>, default: Vec<usize> },\n    Password,\n    Path { must_exist: bool },\n}\n\n// Input validation result\n#[derive(Debug)]\npub enum ValidationResult {\n    Valid(String),\n    Invalid(String),\n}\n\n// Progress indicator types\n#[derive(Debug)]\npub enum ProgressStyle {\n    Bar { width: usize },\n    Spinner,\n    Dots,\n    Counter,\n}\n\n// Interactive CLI framework\npub struct InteractiveCli {\n    prompt_prefix: String,\n    error_prefix: String,\n    success_prefix: String,\n    use_colors: bool,\n}\n\nimpl InteractiveCli {\n    pub fn new() -> Self {\n        Self {\n            prompt_prefix: \"?\".to_string(),\n            error_prefix: \"\u2717\".to_string(),\n            success_prefix: \"\u2713\".to_string(),\n            use_colors: true,\n        }\n    }\n    \n    pub fn with_colors(mut self, use_colors: bool) -> Self {\n        self.use_colors = use_colors;\n        self\n    }\n    \n    // Text input with validation\n    pub fn prompt_text(&self, message: &str, prompt_type: &PromptType) -> Result<String, String> {\n        loop {\n            match prompt_type {\n                PromptType::Text { default } => {\n                    let prompt = if let Some(def) = default {\n                        format!(\"{} {} ({}): \", self.prompt_prefix, message, def)\n                    } else {\n                        format!(\"{} {}: \", self.prompt_prefix, message)\n                    };\n                    \n                    let input = self.read_input(&prompt)?;\n                    \n                    if input.trim().is_empty() {\n                        if let Some(def) = default {\n                            return Ok(def.clone());\n                        } else {\n                            self.print_error(\"Input cannot be empty\");\n                            continue;\n                        }\n                    }\n                    \n                    return Ok(input.trim().to_string());\n                }\n                PromptType::Number { min, max, default } => {\n                    let prompt = if let Some(def) = default {\n                        format!(\"{} {} ({}): \", self.prompt_prefix, message, def)\n                    } else {\n                        format!(\"{} {}: \", self.prompt_prefix, message)\n                    };\n                    \n                    let input = self.read_input(&prompt)?;\n                    \n                    if input.trim().is_empty() {\n                        if let Some(def) = default {\n                            return Ok(def.to_string());\n                        } else {\n                            self.print_error(\"Input cannot be empty\");\n                            continue;\n                        }\n                    }\n                    \n                    match input.trim().parse::<i64>() {\n                        Ok(num) => {\n                            if let Some(min_val) = min {\n                                if num < *min_val {\n                                    self.print_error(&format!(\"Value must be at least {}\", min_val));\n                                    continue;\n                                }\n                            }\n                            if let Some(max_val) = max {\n                                if num > *max_val {\n                                    self.print_error(&format!(\"Value must be at most {}\", max_val));\n                                    continue;\n                                }\n                            }\n                            return Ok(num.to_string());\n                        }\n                        Err(_) => {\n                            self.print_error(\"Please enter a valid number\");\n                            continue;\n                        }\n                    }\n                }\n                PromptType::Boolean { default } => {\n                    let default_text = match default {\n                        Some(true) => \" (Y/n)\",\n                        Some(false) => \" (y/N)\",\n                        None => \" (y/n)\",\n                    };\n                    \n                    let prompt = format!(\"{} {}{}: \", self.prompt_prefix, message, default_text);\n                    let input = self.read_input(&prompt)?;\n                    \n                    match input.trim().to_lowercase().as_str() {\n                        \"y\" | \"yes\" | \"true\" => return Ok(\"true\".to_string()),\n                        \"n\" | \"no\" | \"false\" => return Ok(\"false\".to_string()),\n                        \"\" => {\n                            if let Some(def) = default {\n                                return Ok(def.to_string());\n                            } else {\n                                self.print_error(\"Please enter y or n\");\n                                continue;\n                            }\n                        }\n                        _ => {\n                            self.print_error(\"Please enter y or n\");\n                            continue;\n                        }\n                    }\n                }\n                PromptType::Select { options, default } => {\n                    println!(\"{} {}\", self.prompt_prefix, message);\n                    for (i, option) in options.iter().enumerate() {\n                        let marker = if Some(i) == *default { \">\" } else { \" \" };\n                        println!(\"  {} {}. {}\", marker, i + 1, option);\n                    }\n                    \n                    let prompt = if let Some(def) = default {\n                        format!(\"Select option ({}): \", def + 1)\n                    } else {\n                        \"Select option: \".to_string()\n                    };\n                    \n                    let input = self.read_input(&prompt)?;\n                    \n                    if input.trim().is_empty() {\n                        if let Some(def) = default {\n                            return Ok(options[*def].clone());\n                        } else {\n                            self.print_error(\"Please select an option\");\n                            continue;\n                        }\n                    }\n                    \n                    match input.trim().parse::<usize>() {\n                        Ok(num) if num > 0 && num <= options.len() => {\n                            return Ok(options[num - 1].clone());\n                        }\n                        _ => {\n                            self.print_error(&format!(\"Please enter a number between 1 and {}\", options.len()));\n                            continue;\n                        }\n                    }\n                }\n                PromptType::Password => {\n                    let prompt = format!(\"{} {}: \", self.prompt_prefix, message);\n                    print!(\"{}\", prompt);\n                    io::stdout().flush().unwrap();\n                    \n                    // Simulate password input (in real implementation, use a library like rpassword)\n                    let input = self.read_input(\"\")?;\n                    \n                    if input.trim().is_empty() {\n                        self.print_error(\"Password cannot be empty\");\n                        continue;\n                    }\n                    \n                    return Ok(input.trim().to_string());\n                }\n                _ => return Err(\"Unsupported prompt type\".to_string()),\n            }\n        }\n    }\n    \n    // Multi-step form\n    pub fn prompt_form(&self, fields: &[(&str, PromptType)]) -> Result<HashMap<String, String>, String> {\n        let mut results = HashMap::new();\n        \n        println!(\"\n{} Please fill out the following information:\n\", self.prompt_prefix);\n        \n        for (i, (field_name, prompt_type)) in fields.iter().enumerate() {\n            println!(\"Step {} of {}\", i + 1, fields.len());\n            let result = self.prompt_text(field_name, prompt_type)?;\n            results.insert(field_name.to_string(), result);\n            println!();\n        }\n        \n        Ok(results)\n    }\n    \n    // Confirmation prompt\n    pub fn confirm(&self, message: &str, default: bool) -> Result<bool, String> {\n        let result = self.prompt_text(message, &PromptType::Boolean { default: Some(default) })?;\n        Ok(result == \"true\")\n    }\n    \n    // Progress indicators\n    pub fn progress_bar(&self, total: usize, message: &str) -> ProgressBar {\n        ProgressBar::new(total, message.to_string(), ProgressStyle::Bar { width: 40 })\n    }\n    \n    pub fn spinner(&self, message: &str) -> Spinner {\n        Spinner::new(message.to_string())\n    }\n    \n    // Helper methods\n    fn read_input(&self, prompt: &str) -> Result<String, String> {\n        print!(\"{}\", prompt);\n        io::stdout().flush().map_err(|e| format!(\"IO error: {}\", e))?;\n        \n        let mut input = String::new();\n        io::stdin().read_line(&mut input).map_err(|e| format!(\"IO error: {}\", e))?;\n        \n        Ok(input)\n    }\n    \n    fn print_error(&self, message: &str) {\n        if self.use_colors {\n            println!(\"\u001b[31m{} {}\u001b[0m\", self.error_prefix, message);\n        } else {\n            println!(\"{} {}\", self.error_prefix, message);\n        }\n    }\n    \n    fn print_success(&self, message: &str) {\n        if self.use_colors {\n            println!(\"\u001b[32m{} {}\u001b[0m\", self.success_prefix, message);\n        } else {\n            println!(\"{} {}\", self.success_prefix, message);\n        }\n    }\n}\n\n// Progress bar implementation\npub struct ProgressBar {\n    total: usize,\n    current: usize,\n    message: String,\n    style: ProgressStyle,\n    start_time: Instant,\n}\n\nimpl ProgressBar {\n    pub fn new(total: usize, message: String, style: ProgressStyle) -> Self {\n        Self {\n            total,\n            current: 0,\n            message,\n            style,\n            start_time: Instant::now(),\n        }\n    }\n    \n    pub fn increment(&mut self) {\n        self.current = (self.current + 1).min(self.total);\n        self.render();\n    }\n    \n    pub fn set_progress(&mut self, current: usize) {\n        self.current = current.min(self.total);\n        self.render();\n    }\n    \n    pub fn finish(&mut self) {\n        self.current = self.total;\n        self.render();\n        println!();\n    }\n    \n    fn render(&self) {\n        match &self.style {\n            ProgressStyle::Bar { width } => {\n                let percentage = if self.total > 0 {\n                    (self.current * 100) / self.total\n                } else {\n                    100\n                };\n                \n                let filled = if self.total > 0 {\n                    (self.current * width) / self.total\n                } else {\n                    *width\n                };\n                \n                let bar = \"\u2588\".repeat(filled) + &\"\u2591\".repeat(width - filled);\n                let elapsed = self.start_time.elapsed();\n                \n                print!(\"\r{} [{}] {}% ({}/{}) - {:?}\", \n                       self.message, bar, percentage, self.current, self.total, elapsed);\n                io::stdout().flush().unwrap();\n            }\n            ProgressStyle::Counter => {\n                print!(\"\r{} ({}/{})\", self.message, self.current, self.total);\n                io::stdout().flush().unwrap();\n            }\n            _ => {}\n        }\n    }\n}\n\n// Spinner implementation\npub struct Spinner {\n    message: String,\n    frames: Vec<&'static str>,\n    current_frame: usize,\n    active: bool,\n}\n\nimpl Spinner {\n    pub fn new(message: String) -> Self {\n        Self {\n            message,\n            frames: vec![\"\u280b\", \"\u2819\", \"\u2839\", \"\u2838\", \"\u283c\", \"\u2834\", \"\u2826\", \"\u2827\", \"\u2807\", \"\u280f\"],\n            current_frame: 0,\n            active: false,\n        }\n    }\n    \n    pub fn start(&mut self) {\n        self.active = true;\n        self.render();\n    }\n    \n    pub fn stop(&mut self) {\n        self.active = false;\n        print!(\"\r{} \u2713 {}\n\", \" \".repeat(self.message.len() + 4), self.message);\n        io::stdout().flush().unwrap();\n    }\n    \n    pub fn tick(&mut self) {\n        if self.active {\n            self.current_frame = (self.current_frame + 1) % self.frames.len();\n            self.render();\n        }\n    }\n    \n    fn render(&self) {\n        if self.active {\n            print!(\"\r{} {}\", self.frames[self.current_frame], self.message);\n            io::stdout().flush().unwrap();\n        }\n    }\n}\n\n// Application setup wizard\npub struct SetupWizard {\n    cli: InteractiveCli,\n}\n\nimpl SetupWizard {\n    pub fn new() -> Self {\n        Self {\n            cli: InteractiveCli::new(),\n        }\n    }\n    \n    pub fn run(&self) -> Result<AppConfig, String> {\n        println!(\"\ud83d\ude80 Welcome to the Application Setup Wizard!\");\n        println!(\"This wizard will help you configure your application.\n\");\n        \n        // Basic information\n        let app_name = self.cli.prompt_text(\n            \"What is your application name?\",\n            &PromptType::Text { default: Some(\"my-app\".to_string()) }\n        )?;\n        \n        let port = self.cli.prompt_text(\n            \"What port should the application run on?\",\n            &PromptType::Number { min: Some(1), max: Some(65535), default: Some(8080) }\n        )?;\n        \n        // Environment selection\n        let environment = self.cli.prompt_text(\n            \"Select your environment\",\n            &PromptType::Select {\n                options: vec![\n                    \"Development\".to_string(),\n                    \"Staging\".to_string(),\n                    \"Production\".to_string(),\n                ],\n                default: Some(0),\n            }\n        )?;\n        \n        // Database configuration\n        let use_database = self.cli.confirm(\"Do you want to configure a database?\", true)?;\n        \n        let database_config = if use_database {\n            let db_type = self.cli.prompt_text(\n                \"Select database type\",\n                &PromptType::Select {\n                    options: vec![\n                        \"PostgreSQL\".to_string(),\n                        \"MySQL\".to_string(),\n                        \"SQLite\".to_string(),\n                    ],\n                    default: Some(0),\n                }\n            )?;\n            \n            let db_host = self.cli.prompt_text(\n                \"Database host\",\n                &PromptType::Text { default: Some(\"localhost\".to_string()) }\n            )?;\n            \n            let db_port = self.cli.prompt_text(\n                \"Database port\",\n                &PromptType::Number { min: Some(1), max: Some(65535), default: Some(5432) }\n            )?;\n            \n            let db_name = self.cli.prompt_text(\n                \"Database name\",\n                &PromptType::Text { default: Some(app_name.clone()) }\n            )?;\n            \n            Some(DatabaseConfig {\n                db_type,\n                host: db_host,\n                port: db_port.parse().unwrap(),\n                name: db_name,\n            })\n        } else {\n            None\n        };\n        \n        // Feature selection\n        let features = self.cli.prompt_text(\n            \"Select features to enable\",\n            &PromptType::MultiSelect {\n                options: vec![\n                    \"Authentication\".to_string(),\n                    \"Logging\".to_string(),\n                    \"Metrics\".to_string(),\n                    \"Rate Limiting\".to_string(),\n                    \"Caching\".to_string(),\n                ],\n                default: vec![0, 1],\n            }\n        )?;\n        \n        // Confirmation\n        println!(\"\n\ud83d\udccb Configuration Summary:\");\n        println!(\"  Application: {}\", app_name);\n        println!(\"  Port: {}\", port);\n        println!(\"  Environment: {}\", environment);\n        \n        if let Some(ref db_config) = database_config {\n            println!(\"  Database: {} on {}:{}\", db_config.db_type, db_config.host, db_config.port);\n        }\n        \n        println!(\"  Features: {}\", features);\n        \n        let confirmed = self.cli.confirm(\"\nDo you want to create the configuration with these settings?\", true)?;\n        \n        if !confirmed {\n            return Err(\"Configuration cancelled by user\".to_string());\n        }\n        \n        // Simulate configuration creation with progress\n        let mut progress = self.cli.progress_bar(5, \"Creating configuration\");\n        \n        progress.increment();\n        thread::sleep(Duration::from_millis(500));\n        \n        progress.increment();\n        thread::sleep(Duration::from_millis(500));\n        \n        progress.increment();\n        thread::sleep(Duration::from_millis(500));\n        \n        progress.increment();\n        thread::sleep(Duration::from_millis(500));\n        \n        progress.increment();\n        progress.finish();\n        \n        println!(\"\u2705 Configuration created successfully!\");\n        \n        Ok(AppConfig {\n            app_name,\n            port: port.parse().unwrap(),\n            environment,\n            database: database_config,\n            features: vec![features],\n        })\n    }\n}\n\n// Configuration structures\n#[derive(Debug)]\npub struct AppConfig {\n    pub app_name: String,\n    pub port: u16,\n    pub environment: String,\n    pub database: Option<DatabaseConfig>,\n    pub features: Vec<String>,\n}\n\n#[derive(Debug)]\npub struct DatabaseConfig {\n    pub db_type: String,\n    pub host: String,\n    pub port: u16,\n    pub name: String,\n}\n\n// Task runner with progress\npub struct TaskRunner {\n    cli: InteractiveCli,\n}\n\nimpl TaskRunner {\n    pub fn new() -> Self {\n        Self {\n            cli: InteractiveCli::new(),\n        }\n    }\n    \n    pub fn run_deployment(&self) -> Result<(), String> {\n        let tasks = vec![\n            \"Building application\",\n            \"Running tests\", \n            \"Creating Docker image\",\n            \"Pushing to registry\",\n            \"Deploying to cluster\",\n            \"Running health checks\",\n        ];\n        \n        println!(\"\ud83d\ude80 Starting deployment process...\n\");\n        \n        let mut overall_progress = self.cli.progress_bar(tasks.len(), \"Overall Progress\");\n        \n        for (i, task) in tasks.iter().enumerate() {\n            println!(\"\nStep {}: {}\", i + 1, task);\n            \n            // Simulate task with spinner\n            let mut spinner = self.cli.spinner(format!(\"Executing: {}\", task));\n            spinner.start();\n            \n            // Simulate work\n            for _ in 0..10 {\n                spinner.tick();\n                thread::sleep(Duration::from_millis(200));\n            }\n            \n            spinner.stop();\n            overall_progress.increment();\n        }\n        \n        overall_progress.finish();\n        println!(\"\n\u2705 Deployment completed successfully!\");\n        \n        Ok(())\n    }\n}\n\nfn main() {\n    println!(\"Interactive CLI Demo\n\");\n    \n    // Setup wizard example\n    println!(\"=== Setup Wizard ===\");\n    let wizard = SetupWizard::new();\n    \n    match wizard.run() {\n        Ok(config) => {\n            println!(\"\nGenerated configuration: {:#?}\", config);\n        }\n        Err(e) => {\n            eprintln!(\"Setup failed: {}\", e);\n            return;\n        }\n    }\n    \n    // Task runner example\n    println!(\"\n=== Task Runner ===\");\n    let runner = TaskRunner::new();\n    \n    if let Err(e) = runner.run_deployment() {\n        eprintln!(\"Deployment failed: {}\", e);\n    }\n    \n    println!(\"\n=== Interactive CLI Benefits ===\");\n    println!(\"\u2713 User-friendly prompts with validation\");\n    println!(\"\u2713 Progress indicators for long-running tasks\");\n    println!(\"\u2713 Rich terminal interfaces with colors\");\n    println!(\"\u2713 Multi-step wizards and forms\");\n    println!(\"\u2713 Confirmation dialogs for destructive actions\");\n    println!(\"\u2713 Flexible input types and validation\");\n    println!(\"\u2713 Improved user experience over static CLIs\");\n}\n\n// Key concepts:\n// - Interactive prompts with different input types\n// - Input validation and error handling\n// - Progress bars and spinners for visual feedback\n// - Multi-step wizards and configuration forms\n// - Rich terminal interfaces with colors and symbols\n// - User confirmation for important actions\n// - Flexible prompt system with defaults and validation\n// - Real-time progress updates for long operations\n```",
    "tags": [
      "interactive-cli",
      "prompts",
      "progress-indicators",
      "user-input",
      "terminal-ui"
    ],
    "instruction": "Create an interactive CLI application with user prompts, input validation, and progress indicators"
  },
  {
    "output": "```rust\n// This example demonstrates comprehensive CLI testing strategies including\n// command testing, output validation, and mock integrations\n\nuse std::collections::HashMap;\nuse std::process::{Command, Stdio};\nuse std::io::{self, Write};\nuse std::path::PathBuf;\nuse std::sync::{Arc, Mutex};\n\n// Test framework for CLI applications\npub struct CliTestFramework {\n    binary_path: PathBuf,\n    environment: HashMap<String, String>,\n    temp_dir: Option<PathBuf>,\n    mock_services: Arc<Mutex<HashMap<String, MockService>>>,\n}\n\nimpl CliTestFramework {\n    pub fn new(binary_path: PathBuf) -> Self {\n        Self {\n            binary_path,\n            environment: HashMap::new(),\n            temp_dir: None,\n            mock_services: Arc::new(Mutex::new(HashMap::new())),\n        }\n    }\n    \n    pub fn with_env(mut self, key: &str, value: &str) -> Self {\n        self.environment.insert(key.to_string(), value.to_string());\n        self\n    }\n    \n    pub fn with_temp_dir(mut self, temp_dir: PathBuf) -> Self {\n        self.temp_dir = Some(temp_dir);\n        self\n    }\n    \n    pub fn add_mock_service(&self, name: &str, service: MockService) {\n        self.mock_services.lock().unwrap().insert(name.to_string(), service);\n    }\n    \n    // Execute CLI command and capture output\n    pub fn run_command(&self, args: &[&str]) -> CliTestResult {\n        let mut cmd = Command::new(&self.binary_path);\n        cmd.args(args);\n        \n        // Set environment variables\n        for (key, value) in &self.environment {\n            cmd.env(key, value);\n        }\n        \n        // Set working directory if temp_dir is specified\n        if let Some(ref temp_dir) = self.temp_dir {\n            cmd.current_dir(temp_dir);\n        }\n        \n        // Capture output\n        cmd.stdout(Stdio::piped());\n        cmd.stderr(Stdio::piped());\n        \n        let start_time = std::time::Instant::now();\n        let output = cmd.output().expect(\"Failed to execute command\");\n        let duration = start_time.elapsed();\n        \n        CliTestResult {\n            exit_code: output.status.code().unwrap_or(-1),\n            stdout: String::from_utf8_lossy(&output.stdout).to_string(),\n            stderr: String::from_utf8_lossy(&output.stderr).to_string(),\n            duration,\n        }\n    }\n    \n    // Execute command with input\n    pub fn run_command_with_input(&self, args: &[&str], input: &str) -> CliTestResult {\n        let mut cmd = Command::new(&self.binary_path);\n        cmd.args(args);\n        \n        for (key, value) in &self.environment {\n            cmd.env(key, value);\n        }\n        \n        if let Some(ref temp_dir) = self.temp_dir {\n            cmd.current_dir(temp_dir);\n        }\n        \n        cmd.stdin(Stdio::piped());\n        cmd.stdout(Stdio::piped());\n        cmd.stderr(Stdio::piped());\n        \n        let start_time = std::time::Instant::now();\n        let mut child = cmd.spawn().expect(\"Failed to start command\");\n        \n        // Send input\n        if let Some(stdin) = child.stdin.take() {\n            let mut stdin = stdin;\n            stdin.write_all(input.as_bytes()).expect(\"Failed to write to stdin\");\n        }\n        \n        let output = child.wait_with_output().expect(\"Failed to wait for command\");\n        let duration = start_time.elapsed();\n        \n        CliTestResult {\n            exit_code: output.status.code().unwrap_or(-1),\n            stdout: String::from_utf8_lossy(&output.stdout).to_string(),\n            stderr: String::from_utf8_lossy(&output.stderr).to_string(),\n            duration,\n        }\n    }\n}\n\n// Test result structure\n#[derive(Debug, Clone)]\npub struct CliTestResult {\n    pub exit_code: i32,\n    pub stdout: String,\n    pub stderr: String,\n    pub duration: std::time::Duration,\n}\n\nimpl CliTestResult {\n    // Assertion methods for fluent testing\n    pub fn assert_success(&self) -> &Self {\n        assert_eq!(self.exit_code, 0, \"Command failed with exit code {}\nStderr: {}\", \n                   self.exit_code, self.stderr);\n        self\n    }\n    \n    pub fn assert_failure(&self) -> &Self {\n        assert_ne!(self.exit_code, 0, \"Command succeeded but was expected to fail\");\n        self\n    }\n    \n    pub fn assert_exit_code(&self, expected: i32) -> &Self {\n        assert_eq!(self.exit_code, expected, \"Unexpected exit code\");\n        self\n    }\n    \n    pub fn assert_stdout_contains(&self, expected: &str) -> &Self {\n        assert!(self.stdout.contains(expected), \n                \"Stdout did not contain '{}'\nActual stdout: {}\", expected, self.stdout);\n        self\n    }\n    \n    pub fn assert_stderr_contains(&self, expected: &str) -> &Self {\n        assert!(self.stderr.contains(expected), \n                \"Stderr did not contain '{}'\nActual stderr: {}\", expected, self.stderr);\n        self\n    }\n    \n    pub fn assert_stdout_matches(&self, pattern: &str) -> &Self {\n        // Simple pattern matching (in real implementation, use regex)\n        let matches = if pattern.contains(\"*\") {\n            self.stdout.contains(&pattern.replace(\"*\", \"\"))\n        } else {\n            self.stdout.contains(pattern)\n        };\n        \n        assert!(matches, \"Stdout did not match pattern '{}'\nActual stdout: {}\", \n                pattern, self.stdout);\n        self\n    }\n    \n    pub fn assert_json_output(&self) -> JsonAssertions {\n        // Parse JSON output for testing\n        JsonAssertions::new(&self.stdout)\n    }\n    \n    pub fn assert_duration_less_than(&self, max_duration: std::time::Duration) -> &Self {\n        assert!(self.duration < max_duration, \n                \"Command took {:?} but should be less than {:?}\", self.duration, max_duration);\n        self\n    }\n}\n\n// JSON output assertions\npub struct JsonAssertions {\n    json_str: String,\n}\n\nimpl JsonAssertions {\n    pub fn new(json_str: &str) -> Self {\n        Self {\n            json_str: json_str.to_string(),\n        }\n    }\n    \n    pub fn has_field(&self, field: &str) -> &Self {\n        assert!(self.json_str.contains(&format!(\"\"{}\":\", field)), \n                \"JSON output does not contain field '{}'\", field);\n        self\n    }\n    \n    pub fn field_equals(&self, field: &str, expected: &str) -> &Self {\n        let pattern = format!(\"\"{}\":\"{}\", field, expected);\n        assert!(self.json_str.contains(&pattern), \n                \"JSON field '{}' does not equal '{}'\", field, expected);\n        self\n    }\n}\n\n// Mock service for testing external dependencies\n#[derive(Debug, Clone)]\npub struct MockService {\n    pub responses: HashMap<String, MockResponse>,\n    pub call_count: HashMap<String, usize>,\n}\n\n#[derive(Debug, Clone)]\npub struct MockResponse {\n    pub status_code: u16,\n    pub body: String,\n    pub delay_ms: Option<u64>,\n}\n\nimpl MockService {\n    pub fn new() -> Self {\n        Self {\n            responses: HashMap::new(),\n            call_count: HashMap::new(),\n        }\n    }\n    \n    pub fn add_response(mut self, endpoint: &str, response: MockResponse) -> Self {\n        self.responses.insert(endpoint.to_string(), response);\n        self\n    }\n    \n    pub fn get_call_count(&self, endpoint: &str) -> usize {\n        self.call_count.get(endpoint).copied().unwrap_or(0)\n    }\n}\n\n// Test suite builder\npub struct CliTestSuite {\n    name: String,\n    framework: CliTestFramework,\n    tests: Vec<CliTest>,\n}\n\n#[derive(Clone)]\npub struct CliTest {\n    pub name: String,\n    pub args: Vec<String>,\n    pub input: Option<String>,\n    pub setup: Option<fn(&CliTestFramework)>,\n    pub assertions: Vec<Box<dyn Fn(&CliTestResult) + Send + Sync>>,\n}\n\nimpl CliTestSuite {\n    pub fn new(name: &str, framework: CliTestFramework) -> Self {\n        Self {\n            name: name.to_string(),\n            framework,\n            tests: Vec::new(),\n        }\n    }\n    \n    pub fn add_test(mut self, test: CliTest) -> Self {\n        self.tests.push(test);\n        self\n    }\n    \n    pub fn run(&self) -> TestResults {\n        let mut results = TestResults::new(&self.name);\n        \n        println!(\"Running test suite: {}\", self.name);\n        println!(\"=================={}\", \"=\".repeat(self.name.len()));\n        \n        for test in &self.tests {\n            print!(\"  {} ... \", test.name);\n            io::stdout().flush().unwrap();\n            \n            // Run setup if provided\n            if let Some(setup) = test.setup {\n                setup(&self.framework);\n            }\n            \n            // Execute command\n            let result = if let Some(ref input) = test.input {\n                self.framework.run_command_with_input(\n                    &test.args.iter().map(|s| s.as_str()).collect::<Vec<_>>(),\n                    input\n                )\n            } else {\n                self.framework.run_command(\n                    &test.args.iter().map(|s| s.as_str()).collect::<Vec<_>>()\n                )\n            };\n            \n            // Run assertions\n            let mut test_passed = true;\n            let mut error_message = None;\n            \n            for assertion in &test.assertions {\n                // Note: In a real implementation, you'd catch panics here\n                // For this example, we'll simulate assertion checking\n                if test.name.contains(\"fail\") && result.exit_code == 0 {\n                    test_passed = false;\n                    error_message = Some(\"Test was expected to fail but succeeded\".to_string());\n                    break;\n                }\n            }\n            \n            if test_passed {\n                println!(\"PASS\");\n                results.add_pass(&test.name);\n            } else {\n                println!(\"FAIL\");\n                if let Some(error) = error_message {\n                    println!(\"    Error: {}\", error);\n                }\n                results.add_fail(&test.name, error_message.unwrap_or(\"Assertion failed\".to_string()));\n            }\n        }\n        \n        results.print_summary();\n        results\n    }\n}\n\n// Test results tracking\npub struct TestResults {\n    suite_name: String,\n    passed: Vec<String>,\n    failed: Vec<(String, String)>,\n}\n\nimpl TestResults {\n    pub fn new(suite_name: &str) -> Self {\n        Self {\n            suite_name: suite_name.to_string(),\n            passed: Vec::new(),\n            failed: Vec::new(),\n        }\n    }\n    \n    pub fn add_pass(&mut self, test_name: &str) {\n        self.passed.push(test_name.to_string());\n    }\n    \n    pub fn add_fail(&mut self, test_name: &str, error: String) {\n        self.failed.push((test_name.to_string(), error));\n    }\n    \n    pub fn print_summary(&self) {\n        println!(\"\n{} Results:\", self.suite_name);\n        println!(\"  Passed: {}\", self.passed.len());\n        println!(\"  Failed: {}\", self.failed.len());\n        println!(\"  Total:  {}\", self.passed.len() + self.failed.len());\n        \n        if !self.failed.is_empty() {\n            println!(\"\nFailures:\");\n            for (test_name, error) in &self.failed {\n                println!(\"  - {}: {}\", test_name, error);\n            }\n        }\n    }\n    \n    pub fn is_success(&self) -> bool {\n        self.failed.is_empty()\n    }\n}\n\n// Helper functions for creating tests\npub fn create_basic_test(name: &str, args: Vec<&str>) -> CliTest {\n    CliTest {\n        name: name.to_string(),\n        args: args.into_iter().map(|s| s.to_string()).collect(),\n        input: None,\n        setup: None,\n        assertions: Vec::new(),\n    }\n}\n\npub fn create_interactive_test(name: &str, args: Vec<&str>, input: &str) -> CliTest {\n    CliTest {\n        name: name.to_string(),\n        args: args.into_iter().map(|s| s.to_string()).collect(),\n        input: Some(input.to_string()),\n        setup: None,\n        assertions: Vec::new(),\n    }\n}\n\n// Integration test examples\nfn run_integration_tests() {\n    // Mock CLI binary path (in real tests, this would be the actual binary)\n    let framework = CliTestFramework::new(PathBuf::from(\"target/debug/myapp\"))\n        .with_env(\"RUST_LOG\", \"debug\")\n        .with_env(\"TEST_MODE\", \"true\");\n    \n    // Create test suite\n    let suite = CliTestSuite::new(\"CLI Integration Tests\", framework)\n        .add_test(create_basic_test(\"help_command\", vec![\"--help\"]))\n        .add_test(create_basic_test(\"version_command\", vec![\"--version\"]))\n        .add_test(create_basic_test(\"invalid_command\", vec![\"invalid\"]))\n        .add_test(create_interactive_test(\n            \"interactive_setup\", \n            vec![\"setup\", \"--interactive\"],\n            \"my-app\n8080\ny\npostgresql\nlocalhost\n5432\nmy_db\n\"\n        ));\n    \n    let results = suite.run();\n    \n    if !results.is_success() {\n        std::process::exit(1);\n    }\n}\n\n// Unit test example for CLI components\n#[cfg(test)]\nmod tests {\n    use super::*;\n    \n    #[test]\n    fn test_cli_test_result_assertions() {\n        let result = CliTestResult {\n            exit_code: 0,\n            stdout: \"Hello, World!\n\".to_string(),\n            stderr: \"\".to_string(),\n            duration: std::time::Duration::from_millis(100),\n        };\n        \n        result\n            .assert_success()\n            .assert_stdout_contains(\"Hello\")\n            .assert_duration_less_than(std::time::Duration::from_secs(1));\n    }\n    \n    #[test]\n    fn test_json_assertions() {\n        let json_output = r#\"{\"status\": \"success\", \"count\": 42}\"#;\n        let assertions = JsonAssertions::new(json_output);\n        \n        assertions\n            .has_field(\"status\")\n            .has_field(\"count\")\n            .field_equals(\"status\", \"success\");\n    }\n    \n    #[test]\n    fn test_mock_service() {\n        let mock = MockService::new()\n            .add_response(\"/api/users\", MockResponse {\n                status_code: 200,\n                body: r#\"{\"users\": []}\"#.to_string(),\n                delay_ms: Some(100),\n            });\n        \n        assert!(mock.responses.contains_key(\"/api/users\"));\n    }\n}\n\n// Performance testing\npub struct PerformanceTest {\n    framework: CliTestFramework,\n}\n\nimpl PerformanceTest {\n    pub fn new(framework: CliTestFramework) -> Self {\n        Self { framework }\n    }\n    \n    pub fn benchmark_command(&self, args: &[&str], iterations: usize) -> BenchmarkResult {\n        let mut durations = Vec::new();\n        \n        println!(\"Benchmarking command: {:?}\", args);\n        print!(\"Running {} iterations: \", iterations);\n        \n        for i in 0..iterations {\n            if i % 10 == 0 {\n                print!(\".\");\n                io::stdout().flush().unwrap();\n            }\n            \n            let result = self.framework.run_command(args);\n            durations.push(result.duration);\n        }\n        \n        println!(\" done\");\n        \n        BenchmarkResult::new(durations)\n    }\n}\n\npub struct BenchmarkResult {\n    durations: Vec<std::time::Duration>,\n}\n\nimpl BenchmarkResult {\n    pub fn new(durations: Vec<std::time::Duration>) -> Self {\n        Self { durations }\n    }\n    \n    pub fn average(&self) -> std::time::Duration {\n        let total: std::time::Duration = self.durations.iter().sum();\n        total / self.durations.len() as u32\n    }\n    \n    pub fn min(&self) -> std::time::Duration {\n        *self.durations.iter().min().unwrap()\n    }\n    \n    pub fn max(&self) -> std::time::Duration {\n        *self.durations.iter().max().unwrap()\n    }\n    \n    pub fn print_stats(&self) {\n        println!(\"Benchmark Results:\");\n        println!(\"  Average: {:?}\", self.average());\n        println!(\"  Min:     {:?}\", self.min());\n        println!(\"  Max:     {:?}\", self.max());\n        println!(\"  Samples: {}\", self.durations.len());\n    }\n}\n\nfn main() {\n    println!(\"=== CLI Testing Framework Demo ===\");\n    \n    // Create mock framework for demonstration\n    let framework = CliTestFramework::new(PathBuf::from(\"echo\"))\n        .with_env(\"TEST_MODE\", \"true\");\n    \n    // Basic command test\n    println!(\"\n--- Basic Command Test ---\");\n    let result = framework.run_command(&[\"Hello, World!\"]);\n    \n    result\n        .assert_success()\n        .assert_stdout_contains(\"Hello\");\n    \n    println!(\"\u2713 Basic test passed\");\n    \n    // Interactive test simulation\n    println!(\"\n--- Interactive Test ---\");\n    let result = framework.run_command_with_input(&[\"\"], \"test input\n\");\n    \n    result\n        .assert_success()\n        .assert_stdout_contains(\"test input\");\n    \n    println!(\"\u2713 Interactive test passed\");\n    \n    // JSON output test\n    println!(\"\n--- JSON Output Test ---\");\n    let json_result = framework.run_command(&[r#\"{\"status\":\"ok\",\"count\":5}\"#]);\n    \n    json_result\n        .assert_success()\n        .assert_json_output()\n        .has_field(\"status\")\n        .field_equals(\"status\", \"ok\");\n    \n    println!(\"\u2713 JSON test passed\");\n    \n    // Performance benchmark\n    println!(\"\n--- Performance Benchmark ---\");\n    let perf_test = PerformanceTest::new(framework);\n    let benchmark = perf_test.benchmark_command(&[\"performance test\"], 5);\n    benchmark.print_stats();\n    \n    // Integration tests would be run here\n    // run_integration_tests();\n    \n    println!(\"\n=== CLI Testing Benefits ===\");\n    println!(\"\u2713 Automated command-line interface testing\");\n    println!(\"\u2713 Output validation and assertion framework\");\n    println!(\"\u2713 Interactive command testing with input simulation\");\n    println!(\"\u2713 JSON and structured output validation\");\n    println!(\"\u2713 Performance benchmarking capabilities\");\n    println!(\"\u2713 Mock service integration for external dependencies\");\n    println!(\"\u2713 Comprehensive test suite organization\");\n    println!(\"\u2713 Environment variable and configuration testing\");\n}\n\n// Key concepts:\n// - CLI command execution and output capture\n// - Fluent assertion API for test validation\n// - Interactive command testing with input simulation\n// - JSON and structured output parsing and validation\n// - Mock services for external dependency testing\n// - Performance benchmarking and timing analysis\n// - Test suite organization and result reporting\n// - Environment configuration and temp directory management\n```",
    "tags": [
      "cli-testing",
      "command-testing",
      "output-validation",
      "mocking",
      "integration-tests"
    ],
    "instruction": "Implement comprehensive CLI testing strategies including command testing, output validation, and mock integrations"
  },
  {
    "output": "```rust\n// This example demonstrates building rich terminal user interfaces with tables,\n// menus, and real-time updates using terminal UI concepts and patterns\n\nuse std::collections::HashMap;\nuse std::time::{Duration, Instant};\nuse std::sync::{Arc, Mutex};\nuse std::thread;\nuse std::io::{self, Write};\n\n// Terminal UI framework components\npub struct TerminalUI {\n    width: usize,\n    height: usize,\n    buffer: Vec<Vec<char>>,\n    cursor_x: usize,\n    cursor_y: usize,\n    use_colors: bool,\n}\n\nimpl TerminalUI {\n    pub fn new(width: usize, height: usize) -> Self {\n        Self {\n            width,\n            height,\n            buffer: vec![vec![' '; width]; height],\n            cursor_x: 0,\n            cursor_y: 0,\n            use_colors: true,\n        }\n    }\n    \n    pub fn clear(&mut self) {\n        for row in &mut self.buffer {\n            for cell in row {\n                *cell = ' ';\n            }\n        }\n        self.cursor_x = 0;\n        self.cursor_y = 0;\n    }\n    \n    pub fn set_cursor(&mut self, x: usize, y: usize) {\n        self.cursor_x = x.min(self.width - 1);\n        self.cursor_y = y.min(self.height - 1);\n    }\n    \n    pub fn write_text(&mut self, text: &str) {\n        for ch in text.chars() {\n            if ch == '\n' {\n                self.cursor_y += 1;\n                self.cursor_x = 0;\n            } else if self.cursor_x < self.width && self.cursor_y < self.height {\n                self.buffer[self.cursor_y][self.cursor_x] = ch;\n                self.cursor_x += 1;\n            }\n        }\n    }\n    \n    pub fn draw_border(&mut self, x: usize, y: usize, width: usize, height: usize, title: Option<&str>) {\n        // Top border\n        self.set_cursor(x, y);\n        self.write_text(\"\u250c\");\n        if let Some(title) = title {\n            self.write_text(&format!(\" {} \", title));\n            let remaining = width.saturating_sub(title.len() + 4);\n            self.write_text(&\"\u2500\".repeat(remaining));\n        } else {\n            self.write_text(&\"\u2500\".repeat(width - 2));\n        }\n        self.write_text(\"\u2510\");\n        \n        // Side borders\n        for i in 1..height - 1 {\n            self.set_cursor(x, y + i);\n            self.write_text(\"\u2502\");\n            self.set_cursor(x + width - 1, y + i);\n            self.write_text(\"\u2502\");\n        }\n        \n        // Bottom border\n        self.set_cursor(x, y + height - 1);\n        self.write_text(\"\u2514\");\n        self.write_text(&\"\u2500\".repeat(width - 2));\n        self.write_text(\"\u2518\");\n    }\n    \n    pub fn render(&self) {\n        // Clear screen (simplified)\n        print!(\"\u001b[2J\u001b[H\");\n        \n        for row in &self.buffer {\n            for &ch in row {\n                print!(\"{}\", ch);\n            }\n            println!();\n        }\n        \n        io::stdout().flush().unwrap();\n    }\n}\n\n// Table widget for displaying tabular data\npub struct Table {\n    headers: Vec<String>,\n    rows: Vec<Vec<String>>,\n    column_widths: Vec<usize>,\n    selected_row: Option<usize>,\n    scroll_offset: usize,\n    max_visible_rows: usize,\n}\n\nimpl Table {\n    pub fn new(headers: Vec<String>) -> Self {\n        let column_widths = headers.iter().map(|h| h.len()).collect();\n        \n        Self {\n            headers,\n            rows: Vec::new(),\n            column_widths,\n            selected_row: None,\n            scroll_offset: 0,\n            max_visible_rows: 10,\n        }\n    }\n    \n    pub fn add_row(&mut self, row: Vec<String>) {\n        // Update column widths\n        for (i, cell) in row.iter().enumerate() {\n            if i < self.column_widths.len() {\n                self.column_widths[i] = self.column_widths[i].max(cell.len());\n            }\n        }\n        self.rows.push(row);\n    }\n    \n    pub fn set_selected(&mut self, row: Option<usize>) {\n        self.selected_row = row;\n    }\n    \n    pub fn scroll_up(&mut self) {\n        if self.scroll_offset > 0 {\n            self.scroll_offset -= 1;\n        }\n    }\n    \n    pub fn scroll_down(&mut self) {\n        let max_scroll = self.rows.len().saturating_sub(self.max_visible_rows);\n        if self.scroll_offset < max_scroll {\n            self.scroll_offset += 1;\n        }\n    }\n    \n    pub fn render(&self, ui: &mut TerminalUI, x: usize, y: usize) {\n        let total_width = self.column_widths.iter().sum::<usize>() + (self.headers.len() - 1) * 3 + 4;\n        let total_height = self.max_visible_rows + 3; // Header + borders\n        \n        ui.draw_border(x, y, total_width, total_height, Some(\"Data Table\"));\n        \n        // Render headers\n        ui.set_cursor(x + 1, y + 1);\n        for (i, header) in self.headers.iter().enumerate() {\n            ui.write_text(&format!(\"{:width$}\", header, width = self.column_widths[i]));\n            if i < self.headers.len() - 1 {\n                ui.write_text(\" \u2502 \");\n            }\n        }\n        \n        // Header separator\n        ui.set_cursor(x + 1, y + 2);\n        for (i, &width) in self.column_widths.iter().enumerate() {\n            ui.write_text(&\"\u2500\".repeat(width));\n            if i < self.column_widths.len() - 1 {\n                ui.write_text(\"\u2500\u253c\u2500\");\n            }\n        }\n        \n        // Render visible rows\n        let visible_rows = self.rows.iter()\n            .skip(self.scroll_offset)\n            .take(self.max_visible_rows);\n        \n        for (display_idx, row) in visible_rows.enumerate() {\n            let actual_idx = self.scroll_offset + display_idx;\n            ui.set_cursor(x + 1, y + 3 + display_idx);\n            \n            // Highlight selected row\n            let is_selected = self.selected_row == Some(actual_idx);\n            if is_selected {\n                ui.write_text(\"\u25b6 \");\n            } else {\n                ui.write_text(\"  \");\n            }\n            \n            for (i, cell) in row.iter().enumerate() {\n                if i < self.column_widths.len() {\n                    ui.write_text(&format!(\"{:width$}\", cell, width = self.column_widths[i] - 2));\n                    if i < row.len() - 1 {\n                        ui.write_text(\" \u2502 \");\n                    }\n                }\n            }\n        }\n        \n        // Scroll indicator\n        if self.rows.len() > self.max_visible_rows {\n            ui.set_cursor(x + total_width - 2, y + total_height / 2);\n            ui.write_text(\"\u2195\");\n        }\n    }\n}\n\n// Menu widget for navigation\npub struct Menu {\n    items: Vec<MenuItem>,\n    selected_index: usize,\n    title: String,\n}\n\n#[derive(Clone)]\npub struct MenuItem {\n    pub label: String,\n    pub action: MenuAction,\n    pub enabled: bool,\n}\n\n#[derive(Clone)]\npub enum MenuAction {\n    Command(String),\n    SubMenu(Vec<MenuItem>),\n    Exit,\n}\n\nimpl Menu {\n    pub fn new(title: String, items: Vec<MenuItem>) -> Self {\n        Self {\n            items,\n            selected_index: 0,\n            title,\n        }\n    }\n    \n    pub fn select_next(&mut self) {\n        if self.selected_index < self.items.len() - 1 {\n            self.selected_index += 1;\n        }\n    }\n    \n    pub fn select_previous(&mut self) {\n        if self.selected_index > 0 {\n            self.selected_index -= 1;\n        }\n    }\n    \n    pub fn get_selected(&self) -> Option<&MenuItem> {\n        self.items.get(self.selected_index)\n    }\n    \n    pub fn render(&self, ui: &mut TerminalUI, x: usize, y: usize) {\n        let max_width = self.items.iter()\n            .map(|item| item.label.len())\n            .max()\n            .unwrap_or(10) + 4;\n        let height = self.items.len() + 2;\n        \n        ui.draw_border(x, y, max_width, height, Some(&self.title));\n        \n        for (i, item) in self.items.iter().enumerate() {\n            ui.set_cursor(x + 1, y + 1 + i);\n            \n            if i == self.selected_index {\n                ui.write_text(\"\u25b6 \");\n            } else {\n                ui.write_text(\"  \");\n            }\n            \n            if item.enabled {\n                ui.write_text(&item.label);\n            } else {\n                ui.write_text(&format!(\"({})\", item.label));\n            }\n        }\n    }\n}\n\n// Progress widget\npub struct ProgressWidget {\n    current: usize,\n    total: usize,\n    label: String,\n    width: usize,\n}\n\nimpl ProgressWidget {\n    pub fn new(total: usize, label: String, width: usize) -> Self {\n        Self {\n            current: 0,\n            total,\n            label,\n            width,\n        }\n    }\n    \n    pub fn set_progress(&mut self, current: usize) {\n        self.current = current.min(self.total);\n    }\n    \n    pub fn increment(&mut self) {\n        self.current = (self.current + 1).min(self.total);\n    }\n    \n    pub fn render(&self, ui: &mut TerminalUI, x: usize, y: usize) {\n        ui.set_cursor(x, y);\n        ui.write_text(&format!(\"{}: \", self.label));\n        \n        let progress_width = self.width - self.label.len() - 2;\n        let filled = if self.total > 0 {\n            (self.current * progress_width) / self.total\n        } else {\n            progress_width\n        };\n        \n        ui.write_text(\"[\");\n        ui.write_text(&\"\u2588\".repeat(filled));\n        ui.write_text(&\"\u2591\".repeat(progress_width - filled));\n        ui.write_text(\"]\");\n        \n        let percentage = if self.total > 0 {\n            (self.current * 100) / self.total\n        } else {\n            100\n        };\n        ui.write_text(&format!(\" {}%\", percentage));\n    }\n}\n\n// Real-time dashboard\npub struct Dashboard {\n    ui: TerminalUI,\n    metrics: Arc<Mutex<HashMap<String, f64>>>,\n    start_time: Instant,\n    running: Arc<Mutex<bool>>,\n}\n\nimpl Dashboard {\n    pub fn new(width: usize, height: usize) -> Self {\n        Self {\n            ui: TerminalUI::new(width, height),\n            metrics: Arc::new(Mutex::new(HashMap::new())),\n            start_time: Instant::now(),\n            running: Arc::new(Mutex::new(false)),\n        }\n    }\n    \n    pub fn update_metric(&self, name: &str, value: f64) {\n        self.metrics.lock().unwrap().insert(name.to_string(), value);\n    }\n    \n    pub fn start(&mut self) {\n        *self.running.lock().unwrap() = true;\n        \n        // Simulate real-time data updates\n        let metrics = Arc::clone(&self.metrics);\n        let running = Arc::clone(&self.running);\n        \n        thread::spawn(move || {\n            let mut counter = 0;\n            while *running.lock().unwrap() {\n                // Simulate metrics updates\n                {\n                    let mut m = metrics.lock().unwrap();\n                    m.insert(\"CPU Usage\".to_string(), 20.0 + (counter as f64 * 0.5) % 60.0);\n                    m.insert(\"Memory Usage\".to_string(), 45.0 + (counter as f64 * 0.3) % 40.0);\n                    m.insert(\"Network I/O\".to_string(), 10.0 + (counter as f64 * 0.8) % 80.0);\n                    m.insert(\"Disk Usage\".to_string(), 65.0 + (counter as f64 * 0.1) % 20.0);\n                }\n                \n                counter += 1;\n                thread::sleep(Duration::from_millis(500));\n            }\n        });\n    }\n    \n    pub fn stop(&self) {\n        *self.running.lock().unwrap() = false;\n    }\n    \n    pub fn render(&mut self) {\n        self.ui.clear();\n        \n        // Title\n        self.ui.set_cursor(2, 1);\n        self.ui.write_text(\"System Monitoring Dashboard\");\n        \n        // Uptime\n        let uptime = self.start_time.elapsed();\n        self.ui.set_cursor(2, 2);\n        self.ui.write_text(&format!(\"Uptime: {:?}\", uptime));\n        \n        // Metrics section\n        self.ui.draw_border(1, 4, 60, 15, Some(\"System Metrics\"));\n        \n        let metrics = self.metrics.lock().unwrap();\n        let mut y_offset = 5;\n        \n        for (name, &value) in metrics.iter() {\n            self.ui.set_cursor(3, y_offset);\n            self.ui.write_text(&format!(\"{:15}: {:6.1}%\", name, value));\n            \n            // Simple bar chart\n            let bar_width = 20;\n            let filled = ((value / 100.0) * bar_width as f64) as usize;\n            self.ui.set_cursor(25, y_offset);\n            self.ui.write_text(\"[\");\n            self.ui.write_text(&\"\u2588\".repeat(filled.min(bar_width)));\n            self.ui.write_text(&\"\u2591\".repeat(bar_width - filled.min(bar_width)));\n            self.ui.write_text(\"]\");\n            \n            y_offset += 1;\n        }\n        \n        // Log section\n        self.ui.draw_border(1, 20, 60, 8, Some(\"Recent Events\"));\n        let log_entries = vec![\n            \"INFO: System started\",\n            \"INFO: Monitoring enabled\", \n            \"WARN: High CPU usage detected\",\n            \"INFO: Network connection established\",\n            \"DEBUG: Metrics updated\",\n        ];\n        \n        for (i, entry) in log_entries.iter().enumerate() {\n            self.ui.set_cursor(3, 21 + i);\n            self.ui.write_text(entry);\n        }\n        \n        // Instructions\n        self.ui.set_cursor(2, self.ui.height - 2);\n        self.ui.write_text(\"Press 'q' to quit, 'r' to refresh\");\n        \n        self.ui.render();\n    }\n}\n\n// Application coordinator\npub struct TUIApplication {\n    dashboard: Dashboard,\n    table: Table,\n    menu: Menu,\n    current_view: AppView,\n}\n\n#[derive(Debug, PartialEq)]\npub enum AppView {\n    Dashboard,\n    Table,\n    Menu,\n}\n\nimpl TUIApplication {\n    pub fn new() -> Self {\n        // Initialize components\n        let dashboard = Dashboard::new(80, 30);\n        \n        let mut table = Table::new(vec![\n            \"ID\".to_string(),\n            \"Name\".to_string(), \n            \"Status\".to_string(),\n            \"CPU %\".to_string(),\n            \"Memory\".to_string(),\n        ]);\n        \n        // Add sample data\n        table.add_row(vec![\"1\".to_string(), \"web-server\".to_string(), \"Running\".to_string(), \"25.3\".to_string(), \"128MB\".to_string()]);\n        table.add_row(vec![\"2\".to_string(), \"database\".to_string(), \"Running\".to_string(), \"45.7\".to_string(), \"512MB\".to_string()]);\n        table.add_row(vec![\"3\".to_string(), \"cache\".to_string(), \"Stopped\".to_string(), \"0.0\".to_string(), \"0MB\".to_string()]);\n        table.add_row(vec![\"4\".to_string(), \"worker\".to_string(), \"Running\".to_string(), \"12.1\".to_string(), \"64MB\".to_string()]);\n        \n        let menu = Menu::new(\"Main Menu\".to_string(), vec![\n            MenuItem {\n                label: \"View Dashboard\".to_string(),\n                action: MenuAction::Command(\"dashboard\".to_string()),\n                enabled: true,\n            },\n            MenuItem {\n                label: \"Process Table\".to_string(),\n                action: MenuAction::Command(\"table\".to_string()),\n                enabled: true,\n            },\n            MenuItem {\n                label: \"Settings\".to_string(),\n                action: MenuAction::Command(\"settings\".to_string()),\n                enabled: false,\n            },\n            MenuItem {\n                label: \"Exit\".to_string(),\n                action: MenuAction::Exit,\n                enabled: true,\n            },\n        ]);\n        \n        Self {\n            dashboard,\n            table,\n            menu,\n            current_view: AppView::Menu,\n        }\n    }\n    \n    pub fn run(&mut self) {\n        println!(\"Starting Terminal UI Application...\");\n        println!(\"Use arrow keys to navigate, Enter to select, 'q' to quit\");\n        println!(\"Press any key to continue...\");\n        \n        // Simulate user input handling\n        self.dashboard.start();\n        \n        // Main application loop simulation\n        for i in 0..10 {\n            thread::sleep(Duration::from_millis(1000));\n            \n            match i % 3 {\n                0 => {\n                    self.current_view = AppView::Menu;\n                    self.render_menu();\n                }\n                1 => {\n                    self.current_view = AppView::Dashboard;\n                    self.render_dashboard();\n                }\n                2 => {\n                    self.current_view = AppView::Table;\n                    self.render_table();\n                }\n                _ => {}\n            }\n        }\n        \n        self.dashboard.stop();\n        println!(\"\nApplication terminated.\");\n    }\n    \n    fn render_menu(&mut self) {\n        let mut ui = TerminalUI::new(80, 25);\n        ui.clear();\n        \n        ui.set_cursor(2, 1);\n        ui.write_text(\"Terminal UI Application - Menu View\");\n        \n        self.menu.render(&mut ui, 10, 5);\n        \n        // Instructions\n        ui.set_cursor(2, 20);\n        ui.write_text(\"Use \u2191/\u2193 to navigate, Enter to select\");\n        \n        ui.render();\n    }\n    \n    fn render_dashboard(&mut self) {\n        self.dashboard.render();\n    }\n    \n    fn render_table(&mut self) {\n        let mut ui = TerminalUI::new(80, 25);\n        ui.clear();\n        \n        ui.set_cursor(2, 1);\n        ui.write_text(\"Terminal UI Application - Table View\");\n        \n        self.table.set_selected(Some(1)); // Highlight second row\n        self.table.render(&mut ui, 5, 3);\n        \n        // Instructions\n        ui.set_cursor(2, 20);\n        ui.write_text(\"Use \u2191/\u2193 to navigate rows, Page Up/Down to scroll\");\n        \n        ui.render();\n    }\n}\n\nfn main() {\n    println!(\"=== Terminal UI Framework Demo ===\");\n    \n    // Test individual components\n    println!(\"\n--- Testing Table Widget ---\");\n    let mut ui = TerminalUI::new(60, 20);\n    let mut table = Table::new(vec![\"Name\".to_string(), \"Value\".to_string(), \"Status\".to_string()]);\n    table.add_row(vec![\"Item 1\".to_string(), \"100\".to_string(), \"OK\".to_string()]);\n    table.add_row(vec![\"Item 2\".to_string(), \"250\".to_string(), \"Warning\".to_string()]);\n    table.add_row(vec![\"Item 3\".to_string(), \"75\".to_string(), \"OK\".to_string()]);\n    \n    table.render(&mut ui, 1, 1);\n    ui.render();\n    \n    thread::sleep(Duration::from_millis(2000));\n    \n    // Test progress widget\n    println!(\"\n--- Testing Progress Widget ---\");\n    ui.clear();\n    let mut progress = ProgressWidget::new(100, \"Processing\".to_string(), 40);\n    \n    for i in 0..=100 {\n        progress.set_progress(i);\n        ui.clear();\n        progress.render(&mut ui, 5, 5);\n        ui.render();\n        thread::sleep(Duration::from_millis(50));\n    }\n    \n    // Full application demo\n    println!(\"\n--- Running Full TUI Application ---\");\n    let mut app = TUIApplication::new();\n    app.run();\n    \n    println!(\"\n=== Terminal UI Benefits ===\");\n    println!(\"\u2713 Rich interactive terminal interfaces\");\n    println!(\"\u2713 Real-time data visualization and updates\");\n    println!(\"\u2713 Tabular data display with navigation\");\n    println!(\"\u2713 Menu systems and user interaction\");\n    println!(\"\u2713 Progress indicators and status displays\");\n    println!(\"\u2713 Multi-view application architecture\");\n    println!(\"\u2713 Responsive layout and rendering\");\n    println!(\"\u2713 Cross-platform terminal compatibility\");\n}\n\n// Key concepts:\n// - Terminal UI framework with buffer-based rendering\n// - Widget system for reusable UI components (tables, menus, progress bars)\n// - Real-time data visualization and updates\n// - Event handling and user interaction patterns\n// - Multi-view application architecture\n// - Responsive layout and drawing primitives\n// - Unicode box drawing characters for borders\n// - Color and styling support for enhanced UX\n```",
    "tags": [
      "terminal-ui",
      "tui",
      "widgets",
      "real-time-display",
      "interactive-interface"
    ],
    "instruction": "Build rich terminal user interfaces with tables, menus, and real-time updates using terminal UI libraries"
  },
  {
    "prompt": "Create a RESTful API server in Rust using Actix-web with JWT authentication, middleware, request validation, rate limiting, and OpenAPI documentation. Include database integration, error handling, and comprehensive testing.",
    "response": "use actix_web::{web, App, HttpServer, HttpResponse, middleware, Result};\nuse actix_web_httpauth::extractors::bearer::{BearerAuth, Config};\nuse actix_web_httpauth::extractors::AuthenticationError;\nuse actix_web_httpauth::middleware::HttpAuthentication;\nuse actix_governor::{Governor, GovernorConfigBuilder};\nuse actix_cors::Cors;\nuse serde::{Deserialize, Serialize};\nuse sqlx::{PgPool, postgres::PgPoolOptions};\nuse jsonwebtoken::{encode, decode, Header, Algorithm, Validation, EncodingKey, DecodingKey};\nuse validator::Validate;\nuse utoipa::{OpenApi, ToSchema};\nuse utoipa_swagger_ui::SwaggerUi;\nuse chrono::{Utc, Duration};\nuse uuid::Uuid;\nuse thiserror::Error;\nuse std::env;\n\n// Error types\n#[derive(Error, Debug)]\npub enum ApiError {\n    #[error(\"Database error: {0}\")]\n    Database(#[from] sqlx::Error),\n    \n    #[error(\"Validation error: {0}\")]\n    Validation(#[from] validator::ValidationErrors),\n    \n    #[error(\"Authentication error: {0}\")]\n    Auth(String),\n    \n    #[error(\"Not found\")]\n    NotFound,\n    \n    #[error(\"Internal server error\")]\n    Internal,\n}\n\nimpl actix_web::error::ResponseError for ApiError {\n    fn error_response(&self) -> HttpResponse {\n        match self {\n            ApiError::Database(_) => HttpResponse::InternalServerError()\n                .json(json!({ \"error\": \"Database error\" })),\n            ApiError::Validation(e) => HttpResponse::BadRequest()\n                .json(json!({ \"error\": \"Validation error\", \"details\": e })),\n            ApiError::Auth(msg) => HttpResponse::Unauthorized()\n                .json(json!({ \"error\": msg })),\n            ApiError::NotFound => HttpResponse::NotFound()\n                .json(json!({ \"error\": \"Resource not found\" })),\n            ApiError::Internal => HttpResponse::InternalServerError()\n                .json(json!({ \"error\": \"Internal server error\" })),\n        }\n    }\n}\n\n// JWT Claims\n#[derive(Debug, Serialize, Deserialize)]\nstruct Claims {\n    sub: String,\n    exp: usize,\n    iat: usize,\n    user_id: Uuid,\n    roles: Vec<String>,\n}\n\n// Request/Response DTOs\n#[derive(Debug, Serialize, Deserialize, Validate, ToSchema)]\npub struct CreateUserRequest {\n    #[validate(email)]\n    pub email: String,\n    \n    #[validate(length(min = 8))]\n    pub password: String,\n    \n    #[validate(length(min = 1, max = 100))]\n    pub name: String,\n}\n\n#[derive(Debug, Serialize, Deserialize, ToSchema)]\npub struct UserResponse {\n    pub id: Uuid,\n    pub email: String,\n    pub name: String,\n    pub created_at: chrono::DateTime<Utc>,\n}\n\n#[derive(Debug, Serialize, Deserialize, Validate, ToSchema)]\npub struct LoginRequest {\n    #[validate(email)]\n    pub email: String,\n    pub password: String,\n}\n\n#[derive(Debug, Serialize, Deserialize, ToSchema)]\npub struct LoginResponse {\n    pub access_token: String,\n    pub token_type: String,\n    pub expires_in: i64,\n    pub user: UserResponse,\n}\n\n// Database models\n#[derive(Debug, sqlx::FromRow)]\npub struct User {\n    pub id: Uuid,\n    pub email: String,\n    pub password_hash: String,\n    pub name: String,\n    pub created_at: chrono::DateTime<Utc>,\n    pub updated_at: chrono::DateTime<Utc>,\n}\n\n// Application state\npub struct AppState {\n    pub db: PgPool,\n    pub jwt_secret: String,\n}\n\n// JWT validation\nasync fn validator(\n    req: actix_web::dev::ServiceRequest,\n    credentials: BearerAuth,\n) -> Result<actix_web::dev::ServiceRequest, (actix_web::Error, actix_web::dev::ServiceRequest)> {\n    let token = credentials.token();\n    let app_state = req.app_data::<web::Data<AppState>>()\n        .ok_or_else(|| (actix_web::error::ErrorInternalServerError(\"App state not found\"), req.clone()))?;\n    \n    let token_data = decode::<Claims>(\n        token,\n        &DecodingKey::from_secret(app_state.jwt_secret.as_ref()),\n        &Validation::new(Algorithm::HS256),\n    ).map_err(|e| (actix_web::error::ErrorUnauthorized(format!(\"Invalid token: {}\", e)), req.clone()))?;\n    \n    // Store claims in request extensions for later use\n    req.extensions_mut().insert(token_data.claims);\n    Ok(req)\n}\n\n// Handlers\npub async fn register(\n    state: web::Data<AppState>,\n    req: web::Json<CreateUserRequest>,\n) -> Result<HttpResponse, ApiError> {\n    req.validate()?;\n    \n    // Hash password\n    let password_hash = bcrypt::hash(&req.password, bcrypt::DEFAULT_COST)\n        .map_err(|_| ApiError::Internal)?;\n    \n    // Create user\n    let user = sqlx::query_as::<_, User>(\n        \"INSERT INTO users (id, email, password_hash, name, created_at, updated_at)\n         VALUES ($1, $2, $3, $4, $5, $6)\n         RETURNING *\"\n    )\n    .bind(Uuid::new_v4())\n    .bind(&req.email)\n    .bind(password_hash)\n    .bind(&req.name)\n    .bind(Utc::now())\n    .bind(Utc::now())\n    .fetch_one(&state.db)\n    .await?;\n    \n    Ok(HttpResponse::Created().json(UserResponse {\n        id: user.id,\n        email: user.email,\n        name: user.name,\n        created_at: user.created_at,\n    }))\n}\n\npub async fn login(\n    state: web::Data<AppState>,\n    req: web::Json<LoginRequest>,\n) -> Result<HttpResponse, ApiError> {\n    req.validate()?;\n    \n    // Find user\n    let user = sqlx::query_as::<_, User>(\n        \"SELECT * FROM users WHERE email = $1\"\n    )\n    .bind(&req.email)\n    .fetch_optional(&state.db)\n    .await?\n    .ok_or_else(|| ApiError::Auth(\"Invalid credentials\".to_string()))?;\n    \n    // Verify password\n    if !bcrypt::verify(&req.password, &user.password_hash)\n        .map_err(|_| ApiError::Internal)? {\n        return Err(ApiError::Auth(\"Invalid credentials\".to_string()));\n    }\n    \n    // Generate JWT\n    let claims = Claims {\n        sub: user.email.clone(),\n        exp: (Utc::now() + Duration::hours(24)).timestamp() as usize,\n        iat: Utc::now().timestamp() as usize,\n        user_id: user.id,\n        roles: vec![\"user\".to_string()],\n    };\n    \n    let token = encode(\n        &Header::default(),\n        &claims,\n        &EncodingKey::from_secret(state.jwt_secret.as_ref()),\n    ).map_err(|_| ApiError::Internal)?;\n    \n    Ok(HttpResponse::Ok().json(LoginResponse {\n        access_token: token,\n        token_type: \"Bearer\".to_string(),\n        expires_in: 86400,\n        user: UserResponse {\n            id: user.id,\n            email: user.email,\n            name: user.name,\n            created_at: user.created_at,\n        },\n    }))\n}\n\npub async fn get_profile(\n    state: web::Data<AppState>,\n    req: actix_web::HttpRequest,\n) -> Result<HttpResponse, ApiError> {\n    // Extract claims from request extensions\n    let claims = req.extensions()\n        .get::<Claims>()\n        .ok_or_else(|| ApiError::Auth(\"No claims found\".to_string()))?\n        .clone();\n    \n    let user = sqlx::query_as::<_, User>(\n        \"SELECT * FROM users WHERE id = $1\"\n    )\n    .bind(claims.user_id)\n    .fetch_optional(&state.db)\n    .await?\n    .ok_or(ApiError::NotFound)?;\n    \n    Ok(HttpResponse::Ok().json(UserResponse {\n        id: user.id,\n        email: user.email,\n        name: user.name,\n        created_at: user.created_at,\n    }))\n}\n\n// OpenAPI documentation\n#[derive(OpenApi)]\n#[openapi(\n    paths(register, login, get_profile),\n    components(schemas(\n        CreateUserRequest,\n        UserResponse,\n        LoginRequest,\n        LoginResponse,\n    )),\n    tags(\n        (name = \"auth\", description = \"Authentication endpoints\"),\n        (name = \"users\", description = \"User management endpoints\"),\n    ),\n)]\nstruct ApiDoc;\n\n#[actix_web::main]\nasync fn main() -> std::io::Result<()> {\n    env_logger::init();\n    \n    // Load configuration\n    let database_url = env::var(\"DATABASE_URL\")\n        .unwrap_or_else(|_| \"postgres://localhost/myapp\".to_string());\n    let jwt_secret = env::var(\"JWT_SECRET\")\n        .unwrap_or_else(|_| \"your-secret-key\".to_string());\n    let bind_address = env::var(\"BIND_ADDRESS\")\n        .unwrap_or_else(|_| \"127.0.0.1:8080\".to_string());\n    \n    // Create database pool\n    let db = PgPoolOptions::new()\n        .max_connections(5)\n        .connect(&database_url)\n        .await\n        .expect(\"Failed to create pool\");\n    \n    // Run migrations\n    sqlx::migrate!(\"./migrations\")\n        .run(&db)\n        .await\n        .expect(\"Failed to run migrations\");\n    \n    let app_state = web::Data::new(AppState {\n        db,\n        jwt_secret,\n    });\n    \n    println!(\"Starting server at http://{}\", bind_address);\n    \n    HttpServer::new(move || {\n        // Configure rate limiting\n        let governor_conf = GovernorConfigBuilder::default()\n            .per_second(10)\n            .burst_size(30)\n            .finish()\n            .unwrap();\n        \n        App::new()\n            .app_data(app_state.clone())\n            // Middleware\n            .wrap(middleware::Logger::default())\n            .wrap(middleware::Compress::default())\n            .wrap(\n                Cors::default()\n                    .allowed_origin(\"http://localhost:3000\")\n                    .allowed_methods(vec![\"GET\", \"POST\", \"PUT\", \"DELETE\"])\n                    .allowed_headers(vec![\"Authorization\", \"Content-Type\"])\n                    .max_age(3600)\n            )\n            .wrap(Governor::new(&governor_conf))\n            // Public routes\n            .service(\n                web::scope(\"/api/v1\")\n                    .route(\"/register\", web::post().to(register))\n                    .route(\"/login\", web::post().to(login))\n            )\n            // Protected routes\n            .service(\n                web::scope(\"/api/v1\")\n                    .wrap(HttpAuthentication::bearer(validator))\n                    .route(\"/profile\", web::get().to(get_profile))\n            )\n            // Swagger UI\n            .service(\n                SwaggerUi::new(\"/swagger-ui/{_:.*}\")\n                    .url(\"/api-doc/openapi.json\", ApiDoc::openapi())\n            )\n            // Health check\n            .route(\"/health\", web::get().to(|| async { HttpResponse::Ok().json(json!({ \"status\": \"ok\" })) }))\n    })\n    .bind(bind_address)?\n    .run()\n    .await\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use actix_web::{test, web, App};\n    \n    #[actix_web::test]\n    async fn test_health_check() {\n        let app = test::init_service(\n            App::new()\n                .route(\"/health\", web::get().to(|| async { HttpResponse::Ok().json(json!({ \"status\": \"ok\" })) }))\n        ).await;\n        \n        let req = test::TestRequest::get()\n            .uri(\"/health\")\n            .to_request();\n        let resp = test::call_service(&app, req).await;\n        \n        assert!(resp.status().is_success());\n    }\n    \n    #[actix_web::test]\n    async fn test_register_validation() {\n        let app = test::init_service(\n            App::new()\n                .app_data(web::Data::new(AppState {\n                    db: create_test_pool().await,\n                    jwt_secret: \"test-secret\".to_string(),\n                }))\n                .route(\"/api/v1/register\", web::post().to(register))\n        ).await;\n        \n        let invalid_req = CreateUserRequest {\n            email: \"invalid-email\",\n            password: \"short\",\n            name: \"\".to_string(),\n        };\n        \n        let req = test::TestRequest::post()\n            .uri(\"/api/v1/register\")\n            .set_json(&invalid_req)\n            .to_request();\n        let resp = test::call_service(&app, req).await;\n        \n        assert_eq!(resp.status(), 400);\n    }\n}",
    "key_concepts": [
      "RESTful API design",
      "JWT authentication",
      "middleware pipeline",
      "request validation",
      "rate limiting",
      "OpenAPI documentation",
      "database integration",
      "error handling",
      "CORS configuration",
      "testing strategies"
    ]
  },
  {
    "prompt": "Implement a GraphQL API server in Rust with async resolvers, subscriptions, dataloader pattern for N+1 query prevention, custom scalars, and federation support. Include authentication, authorization, and real-time updates.",
    "response": "use async_graphql::{\n    Context, Object, Result, Schema, Subscription, SimpleObject,\n    EmptyMutation, ID, InputObject, Enum, ComplexObject,\n    dataloader::{DataLoader, Loader},\n    extensions::Tracing,\n    http::{playground_source, GraphQLPlaygroundConfig},\n};\nuse async_graphql_actix_web::{GraphQLRequest, GraphQLResponse, GraphQLSubscription};\nuse actix_web::{web, App, HttpServer, HttpResponse, HttpRequest, guard, middleware};\nuse actix_web_actors::ws;\nuse sqlx::{PgPool, postgres::PgPoolOptions};\nuse std::collections::HashMap;\nuse futures_util::stream::{self, StreamExt};\nuse chrono::{DateTime, Utc};\nuse uuid::Uuid;\nuse serde::{Serialize, Deserialize};\nuse std::sync::Arc;\nuse tokio::sync::RwLock;\n\n// Custom scalars\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct DateTimeScalar(DateTime<Utc>);\n\n#[async_graphql::Scalar]\nimpl async_graphql::ScalarType for DateTimeScalar {\n    fn parse(value: async_graphql::Value) -> async_graphql::InputValueResult<Self> {\n        if let async_graphql::Value::String(s) = &value {\n            Ok(DateTimeScalar(\n                DateTime::parse_from_rfc3339(s)\n                    .map_err(|_| async_graphql::InputValueError::custom(\"Invalid datetime\"))?\n                    .with_timezone(&Utc)\n            ))\n        } else {\n            Err(async_graphql::InputValueError::expected_type(value))\n        }\n    }\n    \n    fn to_value(&self) -> async_graphql::Value {\n        async_graphql::Value::String(self.0.to_rfc3339())\n    }\n}\n\n// Domain models\n#[derive(Debug, Clone, SimpleObject)]\n#[graphql(complex)]\npub struct User {\n    pub id: ID,\n    pub username: String,\n    pub email: String,\n    pub created_at: DateTimeScalar,\n    #[graphql(skip)]\n    pub team_id: Option<Uuid>,\n}\n\n#[ComplexObject]\nimpl User {\n    async fn posts(&self, ctx: &Context<'_>) -> Result<Vec<Post>> {\n        let loader = ctx.data::<DataLoader<PostLoader>>()?;\n        let posts = loader.load_one(self.id.parse::<Uuid>().unwrap()).await?;\n        Ok(posts.unwrap_or_default())\n    }\n    \n    async fn team(&self, ctx: &Context<'_>) -> Result<Option<Team>> {\n        if let Some(team_id) = self.team_id {\n            let loader = ctx.data::<DataLoader<TeamLoader>>()?;\n            loader.load_one(team_id).await\n        } else {\n            Ok(None)\n        }\n    }\n}\n\n#[derive(Debug, Clone, SimpleObject)]\npub struct Post {\n    pub id: ID,\n    pub title: String,\n    pub content: String,\n    pub author_id: ID,\n    pub published: bool,\n    pub created_at: DateTimeScalar,\n}\n\n#[derive(Debug, Clone, SimpleObject)]\npub struct Team {\n    pub id: ID,\n    pub name: String,\n    pub description: String,\n}\n\n// Input types\n#[derive(InputObject)]\npub struct CreateUserInput {\n    pub username: String,\n    pub email: String,\n    pub password: String,\n}\n\n#[derive(InputObject)]\npub struct CreatePostInput {\n    pub title: String,\n    pub content: String,\n    pub published: bool,\n}\n\n#[derive(Enum, Copy, Clone, Eq, PartialEq)]\npub enum SortOrder {\n    Asc,\n    Desc,\n}\n\n// DataLoader implementations\npub struct PostLoader {\n    pool: PgPool,\n}\n\n#[async_trait::async_trait]\nimpl Loader<Uuid> for PostLoader {\n    type Value = Vec<Post>;\n    type Error = Arc<sqlx::Error>;\n    \n    async fn load(&self, keys: &[Uuid]) -> Result<HashMap<Uuid, Self::Value>, Self::Error> {\n        let posts = sqlx::query_as::<_, (Uuid, Uuid, String, String, bool, DateTime<Utc>)>(\n            \"SELECT author_id, id, title, content, published, created_at \n             FROM posts \n             WHERE author_id = ANY($1)\"\n        )\n        .bind(keys)\n        .fetch_all(&self.pool)\n        .await\n        .map_err(Arc::new)?;\n        \n        let mut map: HashMap<Uuid, Vec<Post>> = HashMap::new();\n        for (author_id, id, title, content, published, created_at) in posts {\n            map.entry(author_id)\n                .or_insert_with(Vec::new)\n                .push(Post {\n                    id: ID(id.to_string()),\n                    title,\n                    content,\n                    author_id: ID(author_id.to_string()),\n                    published,\n                    created_at: DateTimeScalar(created_at),\n                });\n        }\n        \n        Ok(map)\n    }\n}\n\npub struct TeamLoader {\n    pool: PgPool,\n}\n\n#[async_trait::async_trait]\nimpl Loader<Uuid> for TeamLoader {\n    type Value = Team;\n    type Error = Arc<sqlx::Error>;\n    \n    async fn load(&self, keys: &[Uuid]) -> Result<HashMap<Uuid, Self::Value>, Self::Error> {\n        let teams = sqlx::query_as::<_, (Uuid, String, String)>(\n            \"SELECT id, name, description FROM teams WHERE id = ANY($1)\"\n        )\n        .bind(keys)\n        .fetch_all(&self.pool)\n        .await\n        .map_err(Arc::new)?;\n        \n        Ok(teams\n            .into_iter()\n            .map(|(id, name, description)| {\n                (id, Team {\n                    id: ID(id.to_string()),\n                    name,\n                    description,\n                })\n            })\n            .collect())\n    }\n}\n\n// Authentication context\n#[derive(Debug, Clone)]\npub struct AuthToken {\n    pub user_id: Uuid,\n    pub roles: Vec<String>,\n}\n\n// Query root\npub struct QueryRoot;\n\n#[Object]\nimpl QueryRoot {\n    async fn current_user(&self, ctx: &Context<'_>) -> Result<Option<User>> {\n        let auth = ctx.data::<Option<AuthToken>>()?;\n        \n        if let Some(token) = auth {\n            let pool = ctx.data::<PgPool>()?;\n            \n            let user = sqlx::query_as::<_, (Uuid, String, String, DateTime<Utc>, Option<Uuid>)>(\n                \"SELECT id, username, email, created_at, team_id FROM users WHERE id = $1\"\n            )\n            .bind(token.user_id)\n            .fetch_optional(pool)\n            .await?;\n            \n            Ok(user.map(|(id, username, email, created_at, team_id)| User {\n                id: ID(id.to_string()),\n                username,\n                email,\n                created_at: DateTimeScalar(created_at),\n                team_id,\n            }))\n        } else {\n            Ok(None)\n        }\n    }\n    \n    async fn users(\n        &self,\n        ctx: &Context<'_>,\n        #[graphql(default = 10)] limit: i32,\n        #[graphql(default = 0)] offset: i32,\n        sort_order: Option<SortOrder>,\n    ) -> Result<Vec<User>> {\n        let pool = ctx.data::<PgPool>()?;\n        \n        let order = match sort_order {\n            Some(SortOrder::Desc) => \"DESC\",\n            _ => \"ASC\",\n        };\n        \n        let query = format!(\n            \"SELECT id, username, email, created_at, team_id \n             FROM users \n             ORDER BY created_at {} \n             LIMIT $1 OFFSET $2\",\n            order\n        );\n        \n        let users = sqlx::query_as::<_, (Uuid, String, String, DateTime<Utc>, Option<Uuid>)>(&query)\n            .bind(limit)\n            .bind(offset)\n            .fetch_all(pool)\n            .await?;\n        \n        Ok(users\n            .into_iter()\n            .map(|(id, username, email, created_at, team_id)| User {\n                id: ID(id.to_string()),\n                username,\n                email,\n                created_at: DateTimeScalar(created_at),\n                team_id,\n            })\n            .collect())\n    }\n    \n    #[graphql(entity)]\n    async fn find_user_by_id(&self, ctx: &Context<'_>, id: ID) -> Result<Option<User>> {\n        let pool = ctx.data::<PgPool>()?;\n        let uuid = Uuid::parse_str(&id.0)?;\n        \n        let user = sqlx::query_as::<_, (Uuid, String, String, DateTime<Utc>, Option<Uuid>)>(\n            \"SELECT id, username, email, created_at, team_id FROM users WHERE id = $1\"\n        )\n        .bind(uuid)\n        .fetch_optional(pool)\n        .await?;\n        \n        Ok(user.map(|(id, username, email, created_at, team_id)| User {\n            id: ID(id.to_string()),\n            username,\n            email,\n            created_at: DateTimeScalar(created_at),\n            team_id,\n        }))\n    }\n}\n\n// Mutation root\npub struct MutationRoot;\n\n#[Object]\nimpl MutationRoot {\n    async fn create_user(\n        &self,\n        ctx: &Context<'_>,\n        input: CreateUserInput,\n    ) -> Result<User> {\n        let pool = ctx.data::<PgPool>()?;\n        let id = Uuid::new_v4();\n        let now = Utc::now();\n        \n        // Hash password (simplified for example)\n        let password_hash = format!(\"hashed_{}\", input.password);\n        \n        sqlx::query(\n            \"INSERT INTO users (id, username, email, password_hash, created_at) \n             VALUES ($1, $2, $3, $4, $5)\"\n        )\n        .bind(id)\n        .bind(&input.username)\n        .bind(&input.email)\n        .bind(password_hash)\n        .bind(now)\n        .execute(pool)\n        .await?;\n        \n        // Publish event\n        let events = ctx.data::<Arc<RwLock<EventBus>>>()?;\n        events.write().await.publish(Event::UserCreated {\n            user_id: id,\n            username: input.username.clone(),\n        });\n        \n        Ok(User {\n            id: ID(id.to_string()),\n            username: input.username,\n            email: input.email,\n            created_at: DateTimeScalar(now),\n            team_id: None,\n        })\n    }\n    \n    async fn create_post(\n        &self,\n        ctx: &Context<'_>,\n        input: CreatePostInput,\n    ) -> Result<Post> {\n        let auth = ctx.data::<Option<AuthToken>>()?\n            .as_ref()\n            .ok_or_else(|| async_graphql::Error::new(\"Unauthorized\"))?;\n        \n        let pool = ctx.data::<PgPool>()?;\n        let id = Uuid::new_v4();\n        let now = Utc::now();\n        \n        sqlx::query(\n            \"INSERT INTO posts (id, title, content, author_id, published, created_at) \n             VALUES ($1, $2, $3, $4, $5, $6)\"\n        )\n        .bind(id)\n        .bind(&input.title)\n        .bind(&input.content)\n        .bind(auth.user_id)\n        .bind(input.published)\n        .bind(now)\n        .execute(pool)\n        .await?;\n        \n        Ok(Post {\n            id: ID(id.to_string()),\n            title: input.title,\n            content: input.content,\n            author_id: ID(auth.user_id.to_string()),\n            published: input.published,\n            created_at: DateTimeScalar(now),\n        })\n    }\n}\n\n// Subscription root\n#[derive(Clone)]\npub enum Event {\n    UserCreated { user_id: Uuid, username: String },\n    PostPublished { post_id: Uuid, title: String },\n}\n\npub struct EventBus {\n    subscribers: Vec<tokio::sync::mpsc::UnboundedSender<Event>>,\n}\n\nimpl EventBus {\n    pub fn new() -> Self {\n        Self {\n            subscribers: Vec::new(),\n        }\n    }\n    \n    pub fn subscribe(&mut self) -> tokio::sync::mpsc::UnboundedReceiver<Event> {\n        let (tx, rx) = tokio::sync::mpsc::unbounded_channel();\n        self.subscribers.push(tx);\n        rx\n    }\n    \n    pub fn publish(&self, event: Event) {\n        for subscriber in &self.subscribers {\n            let _ = subscriber.send(event.clone());\n        }\n    }\n}\n\npub struct SubscriptionRoot;\n\n#[Subscription]\nimpl SubscriptionRoot {\n    async fn user_created(&self, ctx: &Context<'_>) -> impl stream::Stream<Item = String> {\n        let events = ctx.data::<Arc<RwLock<EventBus>>>().unwrap();\n        let mut rx = events.write().await.subscribe();\n        \n        stream::unfold(rx, |mut rx| async move {\n            while let Some(event) = rx.recv().await {\n                if let Event::UserCreated { username, .. } = event {\n                    return Some((format!(\"User created: {}\", username), rx));\n                }\n            }\n            None\n        })\n    }\n}\n\n// GraphQL handlers\nasync fn graphql_handler(\n    schema: web::Data<Schema<QueryRoot, MutationRoot, SubscriptionRoot>>,\n    req: HttpRequest,\n    gql_req: GraphQLRequest,\n) -> GraphQLResponse {\n    let mut request = gql_req.into_inner();\n    \n    // Extract auth token from headers\n    if let Some(auth_header) = req.headers().get(\"Authorization\") {\n        if let Ok(auth_str) = auth_header.to_str() {\n            if auth_str.starts_with(\"Bearer \") {\n                // Validate token (simplified)\n                let token = AuthToken {\n                    user_id: Uuid::new_v4(),\n                    roles: vec![\"user\".to_string()],\n                };\n                request = request.data(Some(token));\n            }\n        }\n    }\n    \n    schema.execute(request).await.into()\n}\n\nasync fn graphql_playground() -> HttpResponse {\n    HttpResponse::Ok()\n        .content_type(\"text/html; charset=utf-8\")\n        .body(playground_source(\n            GraphQLPlaygroundConfig::new(\"/graphql\").subscription_endpoint(\"/ws\"),\n        ))\n}\n\nasync fn graphql_ws(\n    schema: web::Data<Schema<QueryRoot, MutationRoot, SubscriptionRoot>>,\n    req: HttpRequest,\n    payload: web::Payload,\n) -> actix_web::Result<HttpResponse> {\n    ws::start_with_protocols(\n        GraphQLSubscription::new(Schema::clone(&*schema)),\n        &[\"graphql-ws\"],\n        &req,\n        payload,\n    )\n}\n\n#[actix_web::main]\nasync fn main() -> std::io::Result<()> {\n    env_logger::init();\n    \n    // Create database pool\n    let pool = PgPoolOptions::new()\n        .max_connections(5)\n        .connect(\"postgres://localhost/graphql_app\")\n        .await\n        .expect(\"Failed to create pool\");\n    \n    // Create event bus\n    let event_bus = Arc::new(RwLock::new(EventBus::new()));\n    \n    // Create data loaders\n    let post_loader = DataLoader::new(\n        PostLoader { pool: pool.clone() },\n        tokio::spawn,\n    );\n    let team_loader = DataLoader::new(\n        TeamLoader { pool: pool.clone() },\n        tokio::spawn,\n    );\n    \n    // Build schema\n    let schema = Schema::build(QueryRoot, MutationRoot, SubscriptionRoot)\n        .data(pool.clone())\n        .data(event_bus.clone())\n        .data(post_loader)\n        .data(team_loader)\n        .extension(Tracing)\n        .finish();\n    \n    println!(\"GraphQL playground: http://localhost:8000\");\n    \n    HttpServer::new(move || {\n        App::new()\n            .app_data(web::Data::new(schema.clone()))\n            .wrap(middleware::Logger::default())\n            .service(\n                web::resource(\"/graphql\")\n                    .guard(guard::Post())\n                    .to(graphql_handler)\n            )\n            .service(\n                web::resource(\"/graphql\")\n                    .guard(guard::Get())\n                    .to(graphql_playground)\n            )\n            .service(\n                web::resource(\"/ws\")\n                    .to(graphql_ws)\n            )\n    })\n    .bind(\"127.0.0.1:8000\")?\n    .run()\n    .await\n}",
    "key_concepts": [
      "GraphQL schema design",
      "async resolvers",
      "subscription system",
      "DataLoader pattern",
      "N+1 query prevention",
      "custom scalars",
      "federation support",
      "authentication context",
      "real-time updates",
      "WebSocket subscriptions"
    ]
  },
  {
    "prompt": "Build a gRPC microservice in Rust with bidirectional streaming, interceptors, health checks, reflection, retry policies, and load balancing. Include protobuf code generation, service discovery, and distributed tracing.",
    "response": "use tonic::{transport::Server, Request, Response, Status, Streaming};\nuse tonic::service::Interceptor;\nuse tonic_health::server::HealthReporter;\nuse tonic_reflection::server::Builder as ReflectionBuilder;\nuse tower::ServiceBuilder;\nuse tower_http::trace::TraceLayer;\nuse opentelemetry::global;\nuse opentelemetry::trace::{Tracer, FutureExt, TraceContextExt};\nuse opentelemetry::sdk::trace as sdktrace;\nuse opentelemetry::sdk::export::trace::stdout;\nuse tracing::{info, error, instrument, Span};\nuse tracing_subscriber::{layer::SubscriberExt, util::SubscriberInitExt};\nuse tracing_opentelemetry::OpenTelemetryLayer;\nuse std::pin::Pin;\nuse futures::{Stream, StreamExt};\nuse tokio::sync::mpsc;\nuse tokio_stream::wrappers::ReceiverStream;\nuse uuid::Uuid;\nuse std::time::Duration;\nuse std::collections::HashMap;\nuse std::sync::Arc;\nuse tokio::sync::RwLock;\n\n// Generated from protobuf\npub mod chat {\n    tonic::include_proto!(\"chat\");\n}\n\nuse chat::{\n    chat_service_server::{ChatService, ChatServiceServer},\n    chat_service_client::ChatServiceClient,\n    Message, SendMessageRequest, JoinRoomRequest,\n    Room, User, StreamRequest, StreamResponse,\n    HealthCheckRequest, HealthCheckResponse,\n};\n\n// Service implementation\n#[derive(Debug, Clone)]\npub struct ChatServer {\n    rooms: Arc<RwLock<HashMap<String, RoomState>>>,\n    users: Arc<RwLock<HashMap<String, UserSession>>>,\n}\n\n#[derive(Debug)]\nstruct RoomState {\n    id: String,\n    name: String,\n    users: Vec<String>,\n    message_history: Vec<Message>,\n}\n\n#[derive(Debug, Clone)]\nstruct UserSession {\n    id: String,\n    username: String,\n    room_id: Option<String>,\n    sender: mpsc::UnboundedSender<Message>,\n}\n\nimpl ChatServer {\n    pub fn new() -> Self {\n        Self {\n            rooms: Arc::new(RwLock::new(HashMap::new())),\n            users: Arc::new(RwLock::new(HashMap::new())),\n        }\n    }\n}\n\n#[tonic::async_trait]\nimpl ChatService for ChatServer {\n    #[instrument(skip(self))]\n    async fn send_message(\n        &self,\n        request: Request<SendMessageRequest>,\n    ) -> Result<Response<Message>, Status> {\n        let span = Span::current();\n        let tracer = global::tracer(\"chat-service\");\n        \n        let message_req = request.into_inner();\n        \n        // Validate request\n        if message_req.content.is_empty() {\n            return Err(Status::invalid_argument(\"Message content cannot be empty\"));\n        }\n        \n        let message = Message {\n            id: Uuid::new_v4().to_string(),\n            user_id: message_req.user_id.clone(),\n            content: message_req.content,\n            timestamp: chrono::Utc::now().timestamp(),\n            room_id: message_req.room_id.clone(),\n        };\n        \n        // Store message and broadcast to room\n        let rooms = self.rooms.read().await;\n        if let Some(room) = rooms.get(&message_req.room_id) {\n            // Broadcast to all users in room\n            let users = self.users.read().await;\n            for user_id in &room.users {\n                if let Some(user) = users.get(user_id) {\n                    let _ = user.sender.send(message.clone());\n                }\n            }\n        } else {\n            return Err(Status::not_found(\"Room not found\"));\n        }\n        \n        // Add to message history\n        drop(rooms);\n        let mut rooms = self.rooms.write().await;\n        if let Some(room) = rooms.get_mut(&message_req.room_id) {\n            room.message_history.push(message.clone());\n        }\n        \n        span.in_scope(|| {\n            info!(\"Message sent successfully\");\n        });\n        \n        Ok(Response::new(message))\n    }\n    \n    #[instrument(skip(self))]\n    async fn join_room(\n        &self,\n        request: Request<JoinRoomRequest>,\n    ) -> Result<Response<Room>, Status> {\n        let join_req = request.into_inner();\n        \n        let mut rooms = self.rooms.write().await;\n        let room = rooms.entry(join_req.room_id.clone())\n            .or_insert_with(|| RoomState {\n                id: join_req.room_id.clone(),\n                name: join_req.room_name.clone(),\n                users: Vec::new(),\n                message_history: Vec::new(),\n            });\n        \n        // Add user to room\n        if !room.users.contains(&join_req.user_id) {\n            room.users.push(join_req.user_id.clone());\n        }\n        \n        let response = Room {\n            id: room.id.clone(),\n            name: room.name.clone(),\n            user_count: room.users.len() as i32,\n        };\n        \n        info!(\"User {} joined room {}\", join_req.user_id, join_req.room_id);\n        \n        Ok(Response::new(response))\n    }\n    \n    // Unary streaming - server sends stream of messages\n    type MessageStreamStream = Pin<Box<dyn Stream<Item = Result<Message, Status>> + Send>>;\n    \n    #[instrument(skip(self))]\n    async fn message_stream(\n        &self,\n        request: Request<StreamRequest>,\n    ) -> Result<Response<Self::MessageStreamStream>, Status> {\n        let stream_req = request.into_inner();\n        let (tx, rx) = mpsc::unbounded_channel();\n        \n        // Register user session\n        let user_session = UserSession {\n            id: stream_req.user_id.clone(),\n            username: stream_req.username,\n            room_id: Some(stream_req.room_id),\n            sender: tx,\n        };\n        \n        self.users.write().await.insert(stream_req.user_id.clone(), user_session);\n        \n        let stream = ReceiverStream::new(rx)\n            .map(|msg| Ok(msg));\n        \n        Ok(Response::new(Box::pin(stream)))\n    }\n    \n    // Bidirectional streaming\n    type ChatStream = Pin<Box<dyn Stream<Item = Result<StreamResponse, Status>> + Send>>;\n    \n    #[instrument(skip(self, stream))]\n    async fn chat(\n        &self,\n        request: Request<Streaming<StreamRequest>>,\n    ) -> Result<Response<Self::ChatStream>, Status> {\n        let mut in_stream = request.into_inner();\n        let (tx, rx) = mpsc::unbounded_channel();\n        let server = self.clone();\n        \n        // Spawn task to handle incoming messages\n        tokio::spawn(async move {\n            while let Some(result) = in_stream.next().await {\n                match result {\n                    Ok(req) => {\n                        info!(\"Received message from {}: {}\", req.user_id, req.username);\n                        \n                        // Echo back with response\n                        let response = StreamResponse {\n                            message: Some(Message {\n                                id: Uuid::new_v4().to_string(),\n                                user_id: req.user_id,\n                                content: format!(\"Echo: {}\", req.username),\n                                timestamp: chrono::Utc::now().timestamp(),\n                                room_id: req.room_id,\n                            }),\n                            status: \"ok\".to_string(),\n                        };\n                        \n                        if tx.send(Ok(response)).is_err() {\n                            break;\n                        }\n                    }\n                    Err(e) => {\n                        error!(\"Error in stream: {}\", e);\n                        break;\n                    }\n                }\n            }\n        });\n        \n        let out_stream = ReceiverStream::new(rx);\n        Ok(Response::new(Box::pin(out_stream)))\n    }\n    \n    #[instrument(skip(self))]\n    async fn health_check(\n        &self,\n        _request: Request<HealthCheckRequest>,\n    ) -> Result<Response<HealthCheckResponse>, Status> {\n        Ok(Response::new(HealthCheckResponse {\n            status: \"healthy\".to_string(),\n            version: env!(\"CARGO_PKG_VERSION\").to_string(),\n        }))\n    }\n}\n\n// Interceptor for authentication\n#[derive(Clone)]\npub struct AuthInterceptor;\n\nimpl Interceptor for AuthInterceptor {\n    fn call(&mut self, mut request: Request<()>) -> Result<Request<()>, Status> {\n        let token = request\n            .metadata()\n            .get(\"authorization\")\n            .and_then(|t| t.to_str().ok());\n        \n        match token {\n            Some(token) if token.starts_with(\"Bearer \") => {\n                // Validate token (simplified)\n                let user_id = \"user123\";\n                request.extensions_mut().insert(user_id.to_string());\n                Ok(request)\n            }\n            _ => Err(Status::unauthenticated(\"Invalid token\")),\n        }\n    }\n}\n\n// Client with retry and load balancing\npub struct ChatClient {\n    client: ChatServiceClient<tonic::transport::Channel>,\n}\n\nimpl ChatClient {\n    pub async fn new(endpoints: Vec<String>) -> Result<Self, Box<dyn std::error::Error>> {\n        // Create channel with load balancing\n        let channel = tonic::transport::Channel::balance_list(\n            endpoints.into_iter().map(|e| {\n                tonic::transport::Channel::from_shared(e)\n                    .unwrap()\n                    .timeout(Duration::from_secs(10))\n                    .rate_limit(100, Duration::from_secs(1))\n                    .concurrency_limit(256)\n            })\n        );\n        \n        let client = ChatServiceClient::new(channel)\n            .max_decoding_message_size(4 * 1024 * 1024);\n        \n        Ok(Self { client })\n    }\n    \n    pub async fn send_message_with_retry(\n        &mut self,\n        request: SendMessageRequest,\n        max_retries: u32,\n    ) -> Result<Message, Status> {\n        let mut retries = 0;\n        let mut delay = Duration::from_millis(100);\n        \n        loop {\n            match self.client.send_message(request.clone()).await {\n                Ok(response) => return Ok(response.into_inner()),\n                Err(e) if retries < max_retries => {\n                    if e.code() == tonic::Code::Unavailable || \n                       e.code() == tonic::Code::DeadlineExceeded {\n                        retries += 1;\n                        tokio::time::sleep(delay).await;\n                        delay *= 2; // Exponential backoff\n                        continue;\n                    }\n                    return Err(e);\n                }\n                Err(e) => return Err(e),\n            }\n        }\n    }\n}\n\n// Initialize tracing\nfn init_tracing() -> Result<sdktrace::Tracer, Box<dyn std::error::Error>> {\n    let tracer = stdout::new_pipeline()\n        .with_trace_config(\n            sdktrace::config()\n                .with_sampler(sdktrace::Sampler::AlwaysOn)\n                .with_id_generator(sdktrace::RandomIdGenerator::default())\n        )\n        .install_batch(opentelemetry::runtime::Tokio)?;\n    \n    let telemetry = OpenTelemetryLayer::new(tracer.clone());\n    \n    tracing_subscriber::registry()\n        .with(tracing_subscriber::fmt::layer())\n        .with(telemetry)\n        .init();\n    \n    Ok(tracer)\n}\n\n#[tokio::main]\nasync fn main() -> Result<(), Box<dyn std::error::Error>> {\n    // Initialize tracing\n    let _tracer = init_tracing()?;\n    \n    let addr = \"[::1]:50051\".parse()?;\n    let chat_server = ChatServer::new();\n    \n    // Health service\n    let (mut health_reporter, health_service) = tonic_health::server::health_reporter();\n    health_reporter\n        .set_serving::<ChatServiceServer<ChatServer>>()\n        .await;\n    \n    // Reflection service\n    let reflection_service = ReflectionBuilder::configure()\n        .register_encoded_file_descriptor_set(chat::FILE_DESCRIPTOR_SET)\n        .build()?;\n    \n    info!(\"gRPC server listening on {}\", addr);\n    \n    Server::builder()\n        .trace_fn(|_| tracing::info_span!(\"grpc_request\"))\n        .layer(ServiceBuilder::new()\n            .layer(TraceLayer::new_for_grpc())\n            .timeout(Duration::from_secs(30))\n            .concurrency_limit(1000)\n            .into_inner())\n        .add_service(health_service)\n        .add_service(reflection_service)\n        .add_service(ChatServiceServer::with_interceptor(\n            chat_server,\n            AuthInterceptor,\n        ))\n        .serve(addr)\n        .await?;\n    \n    Ok(())\n}\n\n// Proto file (chat.proto)\n/*\nsyntax = \"proto3\";\n\npackage chat;\n\nservice ChatService {\n    rpc SendMessage(SendMessageRequest) returns (Message);\n    rpc JoinRoom(JoinRoomRequest) returns (Room);\n    rpc MessageStream(StreamRequest) returns (stream Message);\n    rpc Chat(stream StreamRequest) returns (stream StreamResponse);\n    rpc HealthCheck(HealthCheckRequest) returns (HealthCheckResponse);\n}\n\nmessage Message {\n    string id = 1;\n    string user_id = 2;\n    string content = 3;\n    int64 timestamp = 4;\n    string room_id = 5;\n}\n\nmessage SendMessageRequest {\n    string user_id = 1;\n    string content = 2;\n    string room_id = 3;\n}\n\nmessage JoinRoomRequest {\n    string user_id = 1;\n    string room_id = 2;\n    string room_name = 3;\n}\n\nmessage Room {\n    string id = 1;\n    string name = 2;\n    int32 user_count = 3;\n}\n\nmessage User {\n    string id = 1;\n    string username = 2;\n}\n\nmessage StreamRequest {\n    string user_id = 1;\n    string username = 2;\n    string room_id = 3;\n}\n\nmessage StreamResponse {\n    Message message = 1;\n    string status = 2;\n}\n\nmessage HealthCheckRequest {}\n\nmessage HealthCheckResponse {\n    string status = 1;\n    string version = 2;\n}\n*/",
    "key_concepts": [
      "gRPC service implementation",
      "bidirectional streaming",
      "interceptors",
      "health checks",
      "service reflection",
      "retry policies",
      "load balancing",
      "distributed tracing",
      "protobuf code generation",
      "service discovery"
    ]
  },
  {
    "prompt": "Create a WebSocket server in Rust with room-based chat, presence tracking, message history, reconnection handling, and rate limiting. Include authentication, binary message support, and graceful shutdown.",
    "response": "use actix::{Actor, StreamHandler, AsyncContext, Handler, Addr, Message as ActixMessage};\nuse actix_web::{web, App, HttpServer, HttpRequest, HttpResponse, Error, middleware};\nuse actix_web_actors::ws;\nuse serde::{Deserialize, Serialize};\nuse std::collections::{HashMap, HashSet, VecDeque};\nuse std::sync::Arc;\nuse tokio::sync::RwLock;\nuse uuid::Uuid;\nuse chrono::{DateTime, Utc, Duration};\nuse jsonwebtoken::{decode, DecodingKey, Validation, Algorithm};\nuse futures_util::future;\nuse std::time::{Duration as StdDuration, Instant};\nuse actix::prelude::*;\nuse bincode;\nuse bytes::Bytes;\n\n// Message types\n#[derive(Debug, Clone, Serialize, Deserialize)]\n#[serde(tag = \"type\")]\npub enum ClientMessage {\n    Join { room: String },\n    Leave { room: String },\n    Text { room: String, content: String },\n    Binary { room: String, data: Vec<u8> },\n    Typing { room: String, is_typing: bool },\n    History { room: String, before: Option<DateTime<Utc>>, limit: usize },\n    Ping,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\n#[serde(tag = \"type\")]\npub enum ServerMessage {\n    Welcome { user_id: String, rooms: Vec<String> },\n    Joined { room: String, user_id: String },\n    Left { room: String, user_id: String },\n    Text { room: String, user_id: String, content: String, timestamp: DateTime<Utc> },\n    Binary { room: String, user_id: String, data: Vec<u8>, timestamp: DateTime<Utc> },\n    Typing { room: String, user_id: String, is_typing: bool },\n    History { room: String, messages: Vec<HistoryMessage> },\n    Presence { room: String, users: Vec<UserPresence> },\n    Error { message: String },\n    Pong,\n    RateLimited { retry_after: u64 },\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct HistoryMessage {\n    pub user_id: String,\n    pub content: String,\n    pub timestamp: DateTime<Utc>,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct UserPresence {\n    pub user_id: String,\n    pub username: String,\n    pub status: PresenceStatus,\n    pub last_seen: DateTime<Utc>,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub enum PresenceStatus {\n    Online,\n    Away,\n    Offline,\n}\n\n// Room state\n#[derive(Debug, Clone)]\npub struct Room {\n    pub id: String,\n    pub users: HashSet<String>,\n    pub message_history: VecDeque<HistoryMessage>,\n    pub max_history: usize,\n}\n\nimpl Room {\n    pub fn new(id: String) -> Self {\n        Self {\n            id,\n            users: HashSet::new(),\n            message_history: VecDeque::with_capacity(1000),\n            max_history: 1000,\n        }\n    }\n    \n    pub fn add_message(&mut self, user_id: String, content: String) {\n        if self.message_history.len() >= self.max_history {\n            self.message_history.pop_front();\n        }\n        \n        self.message_history.push_back(HistoryMessage {\n            user_id,\n            content,\n            timestamp: Utc::now(),\n        });\n    }\n    \n    pub fn get_history(&self, before: Option<DateTime<Utc>>, limit: usize) -> Vec<HistoryMessage> {\n        let messages: Vec<_> = if let Some(before_time) = before {\n            self.message_history\n                .iter()\n                .filter(|msg| msg.timestamp < before_time)\n                .cloned()\n                .collect()\n        } else {\n            self.message_history.iter().cloned().collect()\n        };\n        \n        messages\n            .into_iter()\n            .rev()\n            .take(limit)\n            .rev()\n            .collect()\n    }\n}\n\n// Session state\npub struct Session {\n    pub id: String,\n    pub user_id: String,\n    pub username: String,\n    pub rooms: HashSet<String>,\n    pub last_activity: Instant,\n    pub message_count: usize,\n    pub rate_limit_reset: Instant,\n    pub reconnection_token: Option<String>,\n}\n\n// Rate limiter\npub struct RateLimiter {\n    max_messages: usize,\n    window: StdDuration,\n}\n\nimpl RateLimiter {\n    pub fn new(max_messages: usize, window: StdDuration) -> Self {\n        Self { max_messages, window }\n    }\n    \n    pub fn check_rate_limit(&self, session: &mut Session) -> Result<(), u64> {\n        let now = Instant::now();\n        \n        if now >= session.rate_limit_reset {\n            session.message_count = 0;\n            session.rate_limit_reset = now + self.window;\n        }\n        \n        if session.message_count >= self.max_messages {\n            let retry_after = (session.rate_limit_reset - now).as_secs();\n            return Err(retry_after);\n        }\n        \n        session.message_count += 1;\n        Ok(())\n    }\n}\n\n// WebSocket connection actor\npub struct WsConnection {\n    pub session_id: String,\n    pub session: Session,\n    pub server: Arc<RwLock<ChatServer>>,\n    pub rate_limiter: RateLimiter,\n    pub heartbeat: Instant,\n}\n\nimpl WsConnection {\n    pub fn new(user_id: String, username: String, server: Arc<RwLock<ChatServer>>) -> Self {\n        Self {\n            session_id: Uuid::new_v4().to_string(),\n            session: Session {\n                id: Uuid::new_v4().to_string(),\n                user_id: user_id.clone(),\n                username,\n                rooms: HashSet::new(),\n                last_activity: Instant::now(),\n                message_count: 0,\n                rate_limit_reset: Instant::now() + StdDuration::from_secs(60),\n                reconnection_token: Some(Uuid::new_v4().to_string()),\n            },\n            server,\n            rate_limiter: RateLimiter::new(100, StdDuration::from_secs(60)),\n            heartbeat: Instant::now(),\n        }\n    }\n    \n    fn heartbeat(&self, ctx: &mut ws::WebsocketContext<Self>) {\n        ctx.run_interval(StdDuration::from_secs(5), |act, ctx| {\n            if Instant::now().duration_since(act.heartbeat) > StdDuration::from_secs(30) {\n                ctx.stop();\n                return;\n            }\n            \n            ctx.ping(b\"\");\n        });\n    }\n    \n    async fn handle_message(&mut self, msg: ClientMessage, ctx: &mut ws::WebsocketContext<Self>) {\n        // Check rate limit\n        if let Err(retry_after) = self.rate_limiter.check_rate_limit(&mut self.session) {\n            let response = ServerMessage::RateLimited { retry_after };\n            ctx.text(serde_json::to_string(&response).unwrap());\n            return;\n        }\n        \n        self.session.last_activity = Instant::now();\n        \n        match msg {\n            ClientMessage::Join { room } => {\n                self.session.rooms.insert(room.clone());\n                \n                let mut server = self.server.write().await;\n                server.join_room(&room, &self.session.user_id, &self.session.username).await;\n                \n                let response = ServerMessage::Joined {\n                    room: room.clone(),\n                    user_id: self.session.user_id.clone(),\n                };\n                \n                // Broadcast to room\n                server.broadcast_to_room(&room, &response, Some(&self.session.user_id)).await;\n                \n                // Send presence update\n                let presence = server.get_room_presence(&room).await;\n                let presence_msg = ServerMessage::Presence {\n                    room,\n                    users: presence,\n                };\n                ctx.text(serde_json::to_string(&presence_msg).unwrap());\n            }\n            \n            ClientMessage::Leave { room } => {\n                self.session.rooms.remove(&room);\n                \n                let mut server = self.server.write().await;\n                server.leave_room(&room, &self.session.user_id).await;\n                \n                let response = ServerMessage::Left {\n                    room: room.clone(),\n                    user_id: self.session.user_id.clone(),\n                };\n                \n                server.broadcast_to_room(&room, &response, Some(&self.session.user_id)).await;\n            }\n            \n            ClientMessage::Text { room, content } => {\n                if !self.session.rooms.contains(&room) {\n                    let error = ServerMessage::Error {\n                        message: \"Not in room\".to_string(),\n                    };\n                    ctx.text(serde_json::to_string(&error).unwrap());\n                    return;\n                }\n                \n                let mut server = self.server.write().await;\n                server.add_message(&room, &self.session.user_id, &content).await;\n                \n                let response = ServerMessage::Text {\n                    room: room.clone(),\n                    user_id: self.session.user_id.clone(),\n                    content,\n                    timestamp: Utc::now(),\n                };\n                \n                server.broadcast_to_room(&room, &response, None).await;\n            }\n            \n            ClientMessage::Binary { room, data } => {\n                if !self.session.rooms.contains(&room) {\n                    return;\n                }\n                \n                let response = ServerMessage::Binary {\n                    room: room.clone(),\n                    user_id: self.session.user_id.clone(),\n                    data,\n                    timestamp: Utc::now(),\n                };\n                \n                let server = self.server.read().await;\n                server.broadcast_to_room(&room, &response, None).await;\n            }\n            \n            ClientMessage::Typing { room, is_typing } => {\n                if !self.session.rooms.contains(&room) {\n                    return;\n                }\n                \n                let response = ServerMessage::Typing {\n                    room: room.clone(),\n                    user_id: self.session.user_id.clone(),\n                    is_typing,\n                };\n                \n                let server = self.server.read().await;\n                server.broadcast_to_room(&room, &response, Some(&self.session.user_id)).await;\n            }\n            \n            ClientMessage::History { room, before, limit } => {\n                let server = self.server.read().await;\n                let messages = server.get_room_history(&room, before, limit).await;\n                \n                let response = ServerMessage::History {\n                    room,\n                    messages,\n                };\n                \n                ctx.text(serde_json::to_string(&response).unwrap());\n            }\n            \n            ClientMessage::Ping => {\n                ctx.text(serde_json::to_string(&ServerMessage::Pong).unwrap());\n            }\n        }\n    }\n}\n\nimpl Actor for WsConnection {\n    type Context = ws::WebsocketContext<Self>;\n    \n    fn started(&mut self, ctx: &mut Self::Context) {\n        self.heartbeat(ctx);\n        \n        // Send welcome message\n        let welcome = ServerMessage::Welcome {\n            user_id: self.session.user_id.clone(),\n            rooms: self.session.rooms.iter().cloned().collect(),\n        };\n        ctx.text(serde_json::to_string(&welcome).unwrap());\n        \n        // Register session\n        let server = self.server.clone();\n        let session_id = self.session_id.clone();\n        let addr = ctx.address();\n        \n        actix::spawn(async move {\n            let mut srv = server.write().await;\n            srv.sessions.insert(session_id, addr);\n        });\n    }\n    \n    fn stopped(&mut self, _: &mut Self::Context) {\n        // Clean up session\n        let server = self.server.clone();\n        let session_id = self.session_id.clone();\n        let user_id = self.session.user_id.clone();\n        let rooms = self.session.rooms.clone();\n        \n        actix::spawn(async move {\n            let mut srv = server.write().await;\n            srv.sessions.remove(&session_id);\n            \n            for room in rooms {\n                srv.leave_room(&room, &user_id).await;\n            }\n        });\n    }\n}\n\nimpl StreamHandler<Result<ws::Message, ws::ProtocolError>> for WsConnection {\n    fn handle(&mut self, msg: Result<ws::Message, ws::ProtocolError>, ctx: &mut Self::Context) {\n        match msg {\n            Ok(ws::Message::Ping(msg)) => {\n                self.heartbeat = Instant::now();\n                ctx.pong(&msg);\n            }\n            Ok(ws::Message::Pong(_)) => {\n                self.heartbeat = Instant::now();\n            }\n            Ok(ws::Message::Text(text)) => {\n                if let Ok(msg) = serde_json::from_str::<ClientMessage>(&text) {\n                    let fut = self.handle_message(msg, ctx);\n                    let _handle = actix::spawn(fut);\n                }\n            }\n            Ok(ws::Message::Binary(bin)) => {\n                // Handle binary messages\n                if let Ok(msg) = bincode::deserialize::<ClientMessage>(&bin) {\n                    let fut = self.handle_message(msg, ctx);\n                    let _handle = actix::spawn(fut);\n                }\n            }\n            Ok(ws::Message::Close(reason)) => {\n                ctx.close(reason);\n                ctx.stop();\n            }\n            _ => ctx.stop(),\n        }\n    }\n}\n\n// Chat server\npub struct ChatServer {\n    pub rooms: HashMap<String, Room>,\n    pub sessions: HashMap<String, Addr<WsConnection>>,\n    pub user_sessions: HashMap<String, HashSet<String>>,\n}\n\nimpl ChatServer {\n    pub fn new() -> Self {\n        Self {\n            rooms: HashMap::new(),\n            sessions: HashMap::new(),\n            user_sessions: HashMap::new(),\n        }\n    }\n    \n    pub async fn join_room(&mut self, room_id: &str, user_id: &str, username: &str) {\n        let room = self.rooms.entry(room_id.to_string())\n            .or_insert_with(|| Room::new(room_id.to_string()));\n        room.users.insert(user_id.to_string());\n        \n        self.user_sessions.entry(user_id.to_string())\n            .or_insert_with(HashSet::new)\n            .insert(room_id.to_string());\n    }\n    \n    pub async fn leave_room(&mut self, room_id: &str, user_id: &str) {\n        if let Some(room) = self.rooms.get_mut(room_id) {\n            room.users.remove(user_id);\n            \n            if room.users.is_empty() {\n                self.rooms.remove(room_id);\n            }\n        }\n        \n        if let Some(rooms) = self.user_sessions.get_mut(user_id) {\n            rooms.remove(room_id);\n        }\n    }\n    \n    pub async fn add_message(&mut self, room_id: &str, user_id: &str, content: &str) {\n        if let Some(room) = self.rooms.get_mut(room_id) {\n            room.add_message(user_id.to_string(), content.to_string());\n        }\n    }\n    \n    pub async fn get_room_history(&self, room_id: &str, before: Option<DateTime<Utc>>, limit: usize) -> Vec<HistoryMessage> {\n        self.rooms.get(room_id)\n            .map(|room| room.get_history(before, limit))\n            .unwrap_or_default()\n    }\n    \n    pub async fn get_room_presence(&self, room_id: &str) -> Vec<UserPresence> {\n        self.rooms.get(room_id)\n            .map(|room| {\n                room.users.iter()\n                    .map(|user_id| UserPresence {\n                        user_id: user_id.clone(),\n                        username: format!(\"User_{}\", &user_id[..8]),\n                        status: PresenceStatus::Online,\n                        last_seen: Utc::now(),\n                    })\n                    .collect()\n            })\n            .unwrap_or_default()\n    }\n    \n    pub async fn broadcast_to_room(&self, room_id: &str, message: &ServerMessage, exclude: Option<&str>) {\n        if let Some(room) = self.rooms.get(room_id) {\n            let msg_text = serde_json::to_string(message).unwrap();\n            \n            for user_id in &room.users {\n                if exclude.map_or(true, |ex| ex != user_id) {\n                    if let Some(sessions) = self.user_sessions.get(user_id) {\n                        for session_id in sessions {\n                            if let Some(addr) = self.sessions.get(session_id) {\n                                addr.do_send(WsMessage(msg_text.clone()));\n                            }\n                        }\n                    }\n                }\n            }\n        }\n    }\n}\n\n// Message for actor communication\n#[derive(ActixMessage)]\n#[rtype(result = \"()\")]\nstruct WsMessage(String);\n\nimpl Handler<WsMessage> for WsConnection {\n    type Result = ();\n    \n    fn handle(&mut self, msg: WsMessage, ctx: &mut Self::Context) {\n        ctx.text(msg.0);\n    }\n}\n\n// HTTP handlers\nasync fn ws_handler(\n    req: HttpRequest,\n    stream: web::Payload,\n    server: web::Data<Arc<RwLock<ChatServer>>>,\n) -> Result<HttpResponse, Error> {\n    // Extract auth token\n    let auth_header = req.headers()\n        .get(\"Authorization\")\n        .and_then(|h| h.to_str().ok())\n        .and_then(|h| h.strip_prefix(\"Bearer \"));\n    \n    let (user_id, username) = if let Some(token) = auth_header {\n        // Validate JWT token (simplified)\n        (\"user_123\".to_string(), \"TestUser\".to_string())\n    } else {\n        return Ok(HttpResponse::Unauthorized().finish());\n    };\n    \n    let connection = WsConnection::new(user_id, username, server.get_ref().clone());\n    ws::start(connection, &req, stream)\n}\n\n#[actix_web::main]\nasync fn main() -> std::io::Result<()> {\n    env_logger::init();\n    \n    let chat_server = Arc::new(RwLock::new(ChatServer::new()));\n    \n    println!(\"WebSocket server running at ws://localhost:8080/ws\");\n    \n    HttpServer::new(move || {\n        App::new()\n            .app_data(web::Data::new(chat_server.clone()))\n            .wrap(middleware::Logger::default())\n            .route(\"/ws\", web::get().to(ws_handler))\n            .route(\"/health\", web::get().to(|| async { HttpResponse::Ok().body(\"OK\") }))\n    })\n    .bind(\"127.0.0.1:8080\")?\n    .run()\n    .await\n}",
    "key_concepts": [
      "WebSocket protocol",
      "actor model",
      "room-based chat",
      "presence tracking",
      "message history",
      "reconnection handling",
      "rate limiting",
      "binary message support",
      "heartbeat mechanism",
      "graceful shutdown"
    ]
  },
  {
    "prompt": "Demonstrate advanced trait bounds, associated types, higher-ranked trait bounds (HRTB), and trait objects in Rust. Include examples of generic associated types (GATs), impl Trait, and dynamic dispatch optimization.",
    "response": "use std::fmt::{Debug, Display};\nuse std::marker::PhantomData;\nuse std::ops::{Add, Deref};\nuse std::any::Any;\n\n// Generic Associated Types (GATs)\ntrait Container {\n    type Item<'a> where Self: 'a;\n    \n    fn get<'a>(&'a self, index: usize) -> Option<Self::Item<'a>>;\n}\n\nstruct VecContainer<T> {\n    data: Vec<T>,\n}\n\nimpl<T> Container for VecContainer<T> {\n    type Item<'a> = &'a T where Self: 'a;\n    \n    fn get<'a>(&'a self, index: usize) -> Option<Self::Item<'a>> {\n        self.data.get(index)\n    }\n}\n\n// Higher-Ranked Trait Bounds (HRTB)\nfn apply_to_all<F>(f: F) \nwhere\n    F: for<'a> Fn(&'a str) -> &'a str,\n{\n    let result = f(\"hello\");\n    println!(\"Result: {}\", result);\n}\n\n// Advanced trait with associated types and bounds\ntrait Graph {\n    type Node: Clone + Debug;\n    type Edge: Display;\n    type NodeIter<'a>: Iterator<Item = &'a Self::Node> \n        where Self: 'a;\n    \n    fn nodes<'a>(&'a self) -> Self::NodeIter<'a>;\n    fn add_edge(&mut self, from: Self::Node, to: Self::Node, edge: Self::Edge);\n}\n\n// Implementation with phantom types for type safety\nstruct TypedGraph<N, E> {\n    nodes: Vec<N>,\n    edges: Vec<(N, N, E)>,\n}\n\nimpl<N, E> Graph for TypedGraph<N, E>\nwhere\n    N: Clone + Debug,\n    E: Display,\n{\n    type Node = N;\n    type Edge = E;\n    type NodeIter<'a> = std::slice::Iter<'a, N> where Self: 'a;\n    \n    fn nodes<'a>(&'a self) -> Self::NodeIter<'a> {\n        self.nodes.iter()\n    }\n    \n    fn add_edge(&mut self, from: Self::Node, to: Self::Node, edge: Self::Edge) {\n        self.edges.push((from, to, edge));\n    }\n}\n\n// Trait objects with multiple bounds\ntrait DrawableCloneable: Draw + CloneBox {\n    fn as_any(&self) -> &dyn Any;\n}\n\ntrait Draw {\n    fn draw(&self);\n}\n\ntrait CloneBox {\n    fn clone_box(&self) -> Box<dyn DrawableCloneable>;\n}\n\nimpl<T> CloneBox for T\nwhere\n    T: 'static + DrawableCloneable + Clone,\n{\n    fn clone_box(&self) -> Box<dyn DrawableCloneable> {\n        Box::new(self.clone())\n    }\n}\n\n// Advanced impl Trait usage\nfn make_adder(x: i32) -> impl Fn(i32) -> i32 + Clone {\n    move |y| x + y\n}\n\nfn combine_results<T, E>(\n    results: Vec<Result<T, E>>\n) -> Result<Vec<T>, E> \nwhere\n    T: Clone,\n{\n    results.into_iter().collect()\n}\n\n// Trait with complex bounds and default implementations\ntrait AdvancedIterator: Iterator \nwhere\n    Self::Item: Debug + Clone,\n{\n    fn debug_all(&mut self) -> String {\n        self.map(|item| format!(\"{:?}\", item))\n            .collect::<Vec<_>>()\n            .join(\", \")\n    }\n    \n    fn clone_all(&mut self) -> Vec<Self::Item> {\n        self.map(|item| item.clone()).collect()\n    }\n}\n\nimpl<T> AdvancedIterator for T \nwhere\n    T: Iterator,\n    T::Item: Debug + Clone,\n{}\n\n// Type-level programming with phantom types\nstruct Encrypted;\nstruct Decrypted;\n\nstruct Data<State> {\n    content: Vec<u8>,\n    _state: PhantomData<State>,\n}\n\nimpl Data<Decrypted> {\n    fn new(content: Vec<u8>) -> Self {\n        Data {\n            content,\n            _state: PhantomData,\n        }\n    }\n    \n    fn encrypt(self, key: &[u8]) -> Data<Encrypted> {\n        // Encryption logic\n        Data {\n            content: self.content.iter()\n                .zip(key.iter().cycle())\n                .map(|(a, b)| a ^ b)\n                .collect(),\n            _state: PhantomData,\n        }\n    }\n}\n\nimpl Data<Encrypted> {\n    fn decrypt(self, key: &[u8]) -> Data<Decrypted> {\n        // Decryption logic\n        Data {\n            content: self.content.iter()\n                .zip(key.iter().cycle())\n                .map(|(a, b)| a ^ b)\n                .collect(),\n            _state: PhantomData,\n        }\n    }\n}\n\n// Advanced trait implementations with where clauses\nstruct Wrapper<T> {\n    value: T,\n}\n\nimpl<T> Deref for Wrapper<T> {\n    type Target = T;\n    \n    fn deref(&self) -> &Self::Target {\n        &self.value\n    }\n}\n\nimpl<T> Display for Wrapper<T>\nwhere\n    T: Display,\n{\n    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n        write!(f, \"Wrapped({})\", self.value)\n    }\n}\n\nimpl<T> Add for Wrapper<T>\nwhere\n    T: Add<Output = T>,\n{\n    type Output = Self;\n    \n    fn add(self, rhs: Self) -> Self::Output {\n        Wrapper {\n            value: self.value + rhs.value,\n        }\n    }\n}\n\n// Trait aliases (using type aliases as workaround)\ntrait NumericOps: Add<Output = Self> + Sized + Clone + Debug {}\nimpl<T> NumericOps for T where T: Add<Output = T> + Sized + Clone + Debug {}\n\n// Dynamic dispatch optimization\ntrait OptimizedDraw {\n    fn draw(&self);\n    fn draw_many(&self, count: usize) {\n        for _ in 0..count {\n            self.draw();\n        }\n    }\n}\n\nstruct BatchRenderer {\n    objects: Vec<Box<dyn OptimizedDraw>>,\n}\n\nimpl BatchRenderer {\n    fn render_all(&self) {\n        // Group by type for better cache locality\n        for obj in &self.objects {\n            obj.draw();\n        }\n    }\n}\n\n// Example usage with const generics and traits\ntrait Matrix<const ROWS: usize, const COLS: usize> {\n    type Element: Default + Add<Output = Self::Element> + Copy;\n    \n    fn zeros() -> [[Self::Element; COLS]; ROWS] {\n        [[Self::Element::default(); COLS]; ROWS]\n    }\n    \n    fn transpose<const R: usize, const C: usize>(\n        matrix: [[Self::Element; C]; R]\n    ) -> [[Self::Element; R]; C]\n    where\n        [Self::Element; R]: Sized,\n        [Self::Element; C]: Sized,\n    {\n        let mut result = [[Self::Element::default(); R]; C];\n        for i in 0..R {\n            for j in 0..C {\n                result[j][i] = matrix[i][j];\n            }\n        }\n        result\n    }\n}\n\n// Usage example\nfn demonstrate_advanced_traits() {\n    // Using GATs\n    let container = VecContainer {\n        data: vec![1, 2, 3, 4, 5],\n    };\n    if let Some(item) = container.get(2) {\n        println!(\"Item at index 2: {}\", item);\n    }\n    \n    // Using HRTB\n    apply_to_all(|s| s);\n    \n    // Using impl Trait\n    let adder = make_adder(10);\n    let result = adder(5);\n    println!(\"10 + 5 = {}\", result);\n    \n    // Using phantom types for type safety\n    let data = Data::<Decrypted>::new(vec![1, 2, 3]);\n    let encrypted = data.encrypt(&[4, 5, 6]);\n    // let invalid = encrypted.encrypt(&[7, 8, 9]); // Compile error!\n    let decrypted = encrypted.decrypt(&[4, 5, 6]);\n    \n    // Using advanced iterator\n    let numbers = vec![1, 2, 3, 4, 5];\n    let debug_str = numbers.into_iter().debug_all();\n    println!(\"Debug: {}\", debug_str);\n}\n\nfn main() {\n    demonstrate_advanced_traits();\n}",
    "key_concepts": [
      "Generic Associated Types (GATs)",
      "Higher-Ranked Trait Bounds (HRTB)",
      "associated types",
      "trait objects",
      "impl Trait",
      "phantom types",
      "type-level programming",
      "dynamic dispatch",
      "trait bounds",
      "const generics with traits"
    ]
  },
  {
    "prompt": "Implement advanced async Rust patterns including custom futures, pinning, async traits, select! macro usage, cancellation tokens, and async streams. Show proper error handling and timeout management in async contexts.",
    "response": "use std::pin::Pin;\nuse std::task::{Context, Poll, Waker};\nuse std::future::Future;\nuse std::sync::{Arc, Mutex};\nuse std::time::Duration;\nuse tokio::sync::{mpsc, oneshot, watch, Semaphore};\nuse tokio::time::{sleep, timeout, interval, Instant};\nuse tokio_stream::{Stream, StreamExt, wrappers::IntervalStream};\nuse futures::{future::FutureExt, select, pin_mut};\nuse async_trait::async_trait;\nuse pin_project::pin_project;\nuse thiserror::Error;\n\n// Custom error types for async operations\n#[derive(Error, Debug)]\npub enum AsyncError {\n    #[error(\"Operation timed out after {0:?}\")]\n    Timeout(Duration),\n    \n    #[error(\"Operation was cancelled\")]\n    Cancelled,\n    \n    #[error(\"Channel closed\")]\n    ChannelClosed,\n    \n    #[error(\"Resource exhausted\")]\n    ResourceExhausted,\n    \n    #[error(\"Internal error: {0}\")]\n    Internal(String),\n}\n\n// Custom Future implementation\nstruct DelayedValue<T> {\n    value: Option<T>,\n    delay: Pin<Box<sleep>>,\n}\n\nimpl<T> DelayedValue<T> {\n    fn new(value: T, duration: Duration) -> Self {\n        Self {\n            value: Some(value),\n            delay: Box::pin(sleep(duration)),\n        }\n    }\n}\n\nimpl<T: Unpin> Future for DelayedValue<T> {\n    type Output = T;\n    \n    fn poll(mut self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Self::Output> {\n        match self.delay.as_mut().poll(cx) {\n            Poll::Ready(_) => {\n                Poll::Ready(self.value.take().expect(\"polled after completion\"))\n            }\n            Poll::Pending => Poll::Pending,\n        }\n    }\n}\n\n// Async trait with default implementations\n#[async_trait]\ntrait AsyncProcessor: Send + Sync {\n    type Input: Send;\n    type Output: Send;\n    type Error: std::error::Error + Send + Sync;\n    \n    async fn process(&self, input: Self::Input) -> Result<Self::Output, Self::Error>;\n    \n    async fn process_with_timeout(\n        &self,\n        input: Self::Input,\n        duration: Duration,\n    ) -> Result<Self::Output, AsyncError> {\n        match timeout(duration, self.process(input)).await {\n            Ok(Ok(output)) => Ok(output),\n            Ok(Err(_)) => Err(AsyncError::Internal(\"Processing failed\".into())),\n            Err(_) => Err(AsyncError::Timeout(duration)),\n        }\n    }\n    \n    async fn process_batch(\n        &self,\n        inputs: Vec<Self::Input>,\n    ) -> Vec<Result<Self::Output, Self::Error>> {\n        let mut results = Vec::new();\n        for input in inputs {\n            results.push(self.process(input).await);\n        }\n        results\n    }\n}\n\n// Concrete implementation\nstruct DataProcessor {\n    semaphore: Arc<Semaphore>,\n}\n\n#[async_trait]\nimpl AsyncProcessor for DataProcessor {\n    type Input = String;\n    type Output = usize;\n    type Error = AsyncError;\n    \n    async fn process(&self, input: Self::Input) -> Result<Self::Output, Self::Error> {\n        let _permit = self.semaphore\n            .acquire()\n            .await\n            .map_err(|_| AsyncError::ResourceExhausted)?;\n        \n        // Simulate processing\n        sleep(Duration::from_millis(100)).await;\n        Ok(input.len())\n    }\n}\n\n// Cancellation token implementation\n#[derive(Clone)]\nstruct CancellationToken {\n    cancelled: Arc<Mutex<bool>>,\n    waker: Arc<Mutex<Option<Waker>>>,\n}\n\nimpl CancellationToken {\n    fn new() -> Self {\n        Self {\n            cancelled: Arc::new(Mutex::new(false)),\n            waker: Arc::new(Mutex::new(None)),\n        }\n    }\n    \n    fn cancel(&self) {\n        let mut cancelled = self.cancelled.lock().unwrap();\n        *cancelled = true;\n        \n        if let Some(waker) = self.waker.lock().unwrap().take() {\n            waker.wake();\n        }\n    }\n    \n    fn is_cancelled(&self) -> bool {\n        *self.cancelled.lock().unwrap()\n    }\n    \n    async fn cancelled(&self) {\n        CancellationFuture {\n            token: self.clone(),\n        }.await\n    }\n}\n\nstruct CancellationFuture {\n    token: CancellationToken,\n}\n\nimpl Future for CancellationFuture {\n    type Output = ();\n    \n    fn poll(self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Self::Output> {\n        if self.token.is_cancelled() {\n            Poll::Ready(())\n        } else {\n            *self.token.waker.lock().unwrap() = Some(cx.waker().clone());\n            Poll::Pending\n        }\n    }\n}\n\n// Async stream implementation\n#[pin_project]\nstruct AsyncCounter {\n    count: usize,\n    max: usize,\n    #[pin]\n    interval: IntervalStream,\n}\n\nimpl AsyncCounter {\n    fn new(max: usize, duration: Duration) -> Self {\n        Self {\n            count: 0,\n            max,\n            interval: IntervalStream::new(interval(duration)),\n        }\n    }\n}\n\nimpl Stream for AsyncCounter {\n    type Item = usize;\n    \n    fn poll_next(self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Option<Self::Item>> {\n        let mut this = self.project();\n        \n        match this.interval.poll_next(cx) {\n            Poll::Ready(Some(_)) => {\n                if *this.count < *this.max {\n                    let current = *this.count;\n                    *this.count += 1;\n                    Poll::Ready(Some(current))\n                } else {\n                    Poll::Ready(None)\n                }\n            }\n            Poll::Ready(None) => Poll::Ready(None),\n            Poll::Pending => Poll::Pending,\n        }\n    }\n}\n\n// Advanced select! patterns\nasync fn complex_select_example(\n    mut rx1: mpsc::Receiver<String>,\n    mut rx2: mpsc::Receiver<i32>,\n    token: CancellationToken,\n) -> Result<(), AsyncError> {\n    let mut interval = interval(Duration::from_secs(1));\n    let timeout_duration = Duration::from_secs(30);\n    let deadline = Instant::now() + timeout_duration;\n    \n    loop {\n        select! {\n            // Receive from channel 1\n            msg = rx1.recv() => {\n                match msg {\n                    Some(s) => println!(\"Received string: {}\", s),\n                    None => return Err(AsyncError::ChannelClosed),\n                }\n            }\n            \n            // Receive from channel 2\n            num = rx2.recv() => {\n                match num {\n                    Some(n) => println!(\"Received number: {}\", n),\n                    None => return Err(AsyncError::ChannelClosed),\n                }\n            }\n            \n            // Periodic task\n            _ = interval.tick() => {\n                println!(\"Tick\");\n            }\n            \n            // Cancellation\n            _ = token.cancelled() => {\n                println!(\"Operation cancelled\");\n                return Err(AsyncError::Cancelled);\n            }\n            \n            // Timeout\n            _ = sleep_until(deadline) => {\n                return Err(AsyncError::Timeout(timeout_duration));\n            }\n            \n            // Default case with additional future\n            complete => break,\n        }\n    }\n    \n    Ok(())\n}\n\nasync fn sleep_until(deadline: Instant) {\n    sleep(deadline - Instant::now()).await\n}\n\n// Structured concurrency with error handling\nasync fn structured_concurrency_example() -> Result<(), AsyncError> {\n    let (tx, mut rx) = mpsc::channel(100);\n    let token = CancellationToken::new();\n    \n    // Spawn producer tasks\n    let producers: Vec<_> = (0..3)\n        .map(|id| {\n            let tx = tx.clone();\n            let token = token.clone();\n            \n            tokio::spawn(async move {\n                let mut count = 0;\n                loop {\n                    if token.is_cancelled() {\n                        break;\n                    }\n                    \n                    if tx.send(format!(\"Producer {} - Message {}\", id, count)).await.is_err() {\n                        break;\n                    }\n                    \n                    count += 1;\n                    sleep(Duration::from_millis(500)).await;\n                }\n            })\n        })\n        .collect();\n    \n    // Consumer with graceful shutdown\n    let consumer_token = token.clone();\n    let consumer = tokio::spawn(async move {\n        while let Some(msg) = rx.recv().await {\n            if consumer_token.is_cancelled() {\n                break;\n            }\n            println!(\"Consumed: {}\", msg);\n        }\n    });\n    \n    // Run for 5 seconds then cancel\n    sleep(Duration::from_secs(5)).await;\n    token.cancel();\n    \n    // Wait for all tasks to complete\n    for producer in producers {\n        let _ = producer.await;\n    }\n    drop(tx); // Close channel\n    let _ = consumer.await;\n    \n    Ok(())\n}\n\n// Async recursion with boxing\nasync fn async_recursive(n: u32) -> u32 {\n    if n <= 1 {\n        1\n    } else {\n        // Box the recursive call to avoid infinite type\n        Box::pin(async_recursive(n - 1)).await + n\n    }\n}\n\n// Retry logic with exponential backoff\nasync fn retry_with_backoff<F, Fut, T, E>(\n    mut f: F,\n    max_retries: u32,\n) -> Result<T, E>\nwhere\n    F: FnMut() -> Fut,\n    Fut: Future<Output = Result<T, E>>,\n    E: std::fmt::Debug,\n{\n    let mut delay = Duration::from_millis(100);\n    \n    for attempt in 0..max_retries {\n        match f().await {\n            Ok(value) => return Ok(value),\n            Err(e) if attempt < max_retries - 1 => {\n                eprintln!(\"Attempt {} failed: {:?}, retrying in {:?}\", attempt + 1, e, delay);\n                sleep(delay).await;\n                delay *= 2; // Exponential backoff\n            }\n            Err(e) => return Err(e),\n        }\n    }\n    \n    unreachable!()\n}\n\n// Async stream transformation\nasync fn transform_stream<S, T, F, Fut>(\n    mut stream: S,\n    mut f: F,\n) -> impl Stream<Item = T>\nwhere\n    S: Stream + Unpin,\n    F: FnMut(S::Item) -> Fut,\n    Fut: Future<Output = T>,\n{\n    async_stream::stream! {\n        while let Some(item) = stream.next().await {\n            yield f(item).await;\n        }\n    }\n}\n\n#[tokio::main]\nasync fn main() -> Result<(), Box<dyn std::error::Error>> {\n    // Use custom future\n    let value = DelayedValue::new(\"Hello\", Duration::from_secs(1)).await;\n    println!(\"Delayed value: {}\", value);\n    \n    // Use async processor\n    let processor = DataProcessor {\n        semaphore: Arc::new(Semaphore::new(5)),\n    };\n    \n    let result = processor\n        .process_with_timeout(\"test input\".to_string(), Duration::from_secs(1))\n        .await?;\n    println!(\"Processed result: {}\", result);\n    \n    // Use async stream\n    let mut counter = AsyncCounter::new(5, Duration::from_millis(100));\n    while let Some(count) = counter.next().await {\n        println!(\"Count: {}\", count);\n    }\n    \n    // Structured concurrency\n    structured_concurrency_example().await?;\n    \n    // Async recursion\n    let result = async_recursive(10).await;\n    println!(\"Recursive sum: {}\", result);\n    \n    // Retry with backoff\n    let result = retry_with_backoff(\n        || async {\n            // Simulated operation that might fail\n            if rand::random::<f32>() > 0.3 {\n                Ok(\"Success\")\n            } else {\n                Err(\"Random failure\")\n            }\n        },\n        3,\n    ).await;\n    \n    match result {\n        Ok(s) => println!(\"Operation succeeded: {}\", s),\n        Err(e) => println!(\"Operation failed after retries: {}\", e),\n    }\n    \n    Ok(())\n}",
    "key_concepts": [
      "custom futures",
      "pinning",
      "async traits",
      "select! macro",
      "cancellation tokens",
      "async streams",
      "structured concurrency",
      "async recursion",
      "retry logic",
      "timeout management"
    ]
  },
  {
    "prompt": "Demonstrate Rust's advanced macro system including procedural macros, derive macros, attribute macros, and function-like macros. Show macro hygiene, token manipulation, and code generation patterns.",
    "response": "// lib.rs for procedural macro crate\nuse proc_macro::TokenStream;\nuse quote::quote;\nuse syn::{parse_macro_input, DeriveInput, Data, Fields, ItemFn, AttributeArgs, NestedMeta, Lit};\n\n// Derive macro for automatic builder pattern\n#[proc_macro_derive(Builder, attributes(builder))]\npub fn derive_builder(input: TokenStream) -> TokenStream {\n    let input = parse_macro_input!(input as DeriveInput);\n    let name = &input.ident;\n    let builder_name = syn::Ident::new(&format!(\"{}Builder\", name), name.span());\n    \n    let fields = match &input.data {\n        Data::Struct(data) => match &data.fields {\n            Fields::Named(fields) => &fields.named,\n            _ => panic!(\"Builder only supports named fields\"),\n        },\n        _ => panic!(\"Builder only supports structs\"),\n    };\n    \n    let field_names: Vec<_> = fields.iter()\n        .map(|f| &f.ident)\n        .collect();\n    \n    let field_types: Vec<_> = fields.iter()\n        .map(|f| &f.ty)\n        .collect();\n    \n    let builder_fields = field_names.iter().zip(field_types.iter())\n        .map(|(name, ty)| {\n            quote! {\n                #name: Option<#ty>\n            }\n        });\n    \n    let builder_methods = field_names.iter().zip(field_types.iter())\n        .map(|(name, ty)| {\n            quote! {\n                pub fn #name(mut self, value: #ty) -> Self {\n                    self.#name = Some(value);\n                    self\n                }\n            }\n        });\n    \n    let build_fields = field_names.iter()\n        .map(|name| {\n            quote! {\n                #name: self.#name.ok_or(concat!(stringify!(#name), \" is required\"))?\n            }\n        });\n    \n    let expanded = quote! {\n        impl #name {\n            pub fn builder() -> #builder_name {\n                #builder_name {\n                    #(#field_names: None,)*\n                }\n            }\n        }\n        \n        pub struct #builder_name {\n            #(#builder_fields,)*\n        }\n        \n        impl #builder_name {\n            #(#builder_methods)*\n            \n            pub fn build(self) -> Result<#name, &'static str> {\n                Ok(#name {\n                    #(#build_fields,)*\n                })\n            }\n        }\n    };\n    \n    TokenStream::from(expanded)\n}\n\n// Attribute macro for automatic memoization\n#[proc_macro_attribute]\npub fn memoize(args: TokenStream, input: TokenStream) -> TokenStream {\n    let args = parse_macro_input!(args as AttributeArgs);\n    let input_fn = parse_macro_input!(input as ItemFn);\n    \n    let fn_name = &input_fn.sig.ident;\n    let fn_vis = &input_fn.vis;\n    let fn_inputs = &input_fn.sig.inputs;\n    let fn_output = &input_fn.sig.output;\n    let fn_body = &input_fn.block;\n    \n    // Parse cache size from attributes\n    let cache_size = args.iter()\n        .find_map(|arg| match arg {\n            NestedMeta::Lit(Lit::Int(lit)) => Some(lit.base10_parse::<usize>().unwrap()),\n            _ => None,\n        })\n        .unwrap_or(100);\n    \n    let expanded = quote! {\n        #fn_vis fn #fn_name(#fn_inputs) #fn_output {\n            use std::collections::HashMap;\n            use std::cell::RefCell;\n            \n            thread_local! {\n                static CACHE: RefCell<HashMap<String, Box<dyn std::any::Any>>> = \n                    RefCell::new(HashMap::with_capacity(#cache_size));\n            }\n            \n            let key = format!(\"{:?}\", (#fn_inputs));\n            \n            CACHE.with(|cache| {\n                if let Some(cached) = cache.borrow().get(&key) {\n                    if let Some(result) = cached.downcast_ref::<_>() {\n                        return result.clone();\n                    }\n                }\n                \n                let result = #fn_body;\n                \n                let mut cache = cache.borrow_mut();\n                if cache.len() >= #cache_size {\n                    cache.clear();\n                }\n                cache.insert(key, Box::new(result.clone()));\n                \n                result\n            })\n        }\n    };\n    \n    TokenStream::from(expanded)\n}\n\n// Function-like macro for SQL query builder\n#[proc_macro]\npub fn sql(input: TokenStream) -> TokenStream {\n    let input_str = input.to_string();\n    let parts: Vec<&str> = input_str.split_whitespace().collect();\n    \n    let query = match parts.get(0) {\n        Some(&\"SELECT\") => build_select_query(&parts[1..]),\n        Some(&\"INSERT\") => build_insert_query(&parts[1..]),\n        Some(&\"UPDATE\") => build_update_query(&parts[1..]),\n        Some(&\"DELETE\") => build_delete_query(&parts[1..]),\n        _ => panic!(\"Unsupported SQL operation\"),\n    };\n    \n    let expanded = quote! {\n        SqlQuery::new(#query)\n    };\n    \n    TokenStream::from(expanded)\n}\n\nfn build_select_query(parts: &[&str]) -> String {\n    // Simplified SQL building logic\n    format!(\"SELECT {} FROM {}\", parts[0], parts[2])\n}\n\nfn build_insert_query(parts: &[&str]) -> String {\n    format!(\"INSERT INTO {} VALUES\", parts[1])\n}\n\nfn build_update_query(parts: &[&str]) -> String {\n    format!(\"UPDATE {} SET\", parts[0])\n}\n\nfn build_delete_query(parts: &[&str]) -> String {\n    format!(\"DELETE FROM {}\", parts[1])\n}\n\n// main.rs - Usage examples\n// Declarative macros with advanced patterns\nmacro_rules! create_enum_with_traits {\n    (\n        $(#[$meta:meta])*\n        $vis:vis enum $name:ident {\n            $(\n                $(#[$variant_meta:meta])*\n                $variant:ident $(( $($field:ty),* ))? $(= $value:expr)?\n            ),* $(,)?\n        }\n    ) => {\n        $(#[$meta])*\n        $vis enum $name {\n            $(\n                $(#[$variant_meta])*\n                $variant $(( $($field),* ))? $(= $value)?\n            ),*\n        }\n        \n        impl $name {\n            pub fn variant_name(&self) -> &'static str {\n                match self {\n                    $(\n                        Self::$variant $( ( $( stringify!($field) ),* ) )? => stringify!($variant)\n                    ),*\n                }\n            }\n            \n            pub fn all_variants() -> Vec<&'static str> {\n                vec![\n                    $(stringify!($variant)),*\n                ]\n            }\n        }\n    };\n}\n\n// Recursive macro for variadic functions\nmacro_rules! count_args {\n    () => { 0 };\n    ($head:expr) => { 1 };\n    ($head:expr, $($tail:expr),+) => { 1 + count_args!($($tail),+) };\n}\n\nmacro_rules! min {\n    ($x:expr) => { $x };\n    ($x:expr, $($rest:expr),+) => {{\n        let min_rest = min!($($rest),+);\n        if $x < min_rest { $x } else { min_rest }\n    }};\n}\n\n// Macro for creating type-safe state machines\nmacro_rules! state_machine {\n    (\n        $name:ident {\n            states: [$($state:ident),*],\n            transitions: [\n                $($from:ident -> $to:ident: $method:ident),*\n            ],\n            initial: $initial:ident\n        }\n    ) => {\n        mod $name {\n            #[derive(Debug, Clone)]\n            pub struct $name<State> {\n                _state: std::marker::PhantomData<State>,\n                data: SharedData,\n            }\n            \n            #[derive(Debug, Clone)]\n            struct SharedData {\n                // Shared state data\n            }\n            \n            $(\n                #[derive(Debug)]\n                pub struct $state;\n            )*\n            \n            impl $name<$initial> {\n                pub fn new() -> Self {\n                    Self {\n                        _state: std::marker::PhantomData,\n                        data: SharedData {},\n                    }\n                }\n            }\n            \n            $(\n                impl $name<$from> {\n                    pub fn $method(self) -> $name<$to> {\n                        println!(\"Transitioning from {} to {}\", \n                                stringify!($from), stringify!($to));\n                        $name {\n                            _state: std::marker::PhantomData,\n                            data: self.data,\n                        }\n                    }\n                }\n            )*\n        }\n        \n        pub use $name::$name;\n        $(pub use $name::$state;)*\n    };\n}\n\n// Advanced macro with token manipulation\nmacro_rules! implement_ops {\n    ($type:ty => $($op:ident),*) => {\n        $(\n            impl_op!($type, $op);\n        )*\n    };\n}\n\nmacro_rules! impl_op {\n    ($type:ty, Add) => {\n        impl std::ops::Add for $type {\n            type Output = Self;\n            fn add(self, rhs: Self) -> Self::Output {\n                Self(self.0 + rhs.0)\n            }\n        }\n    };\n    ($type:ty, Sub) => {\n        impl std::ops::Sub for $type {\n            type Output = Self;\n            fn sub(self, rhs: Self) -> Self::Output {\n                Self(self.0 - rhs.0)\n            }\n        }\n    };\n    ($type:ty, Mul) => {\n        impl std::ops::Mul for $type {\n            type Output = Self;\n            fn mul(self, rhs: Self) -> Self::Output {\n                Self(self.0 * rhs.0)\n            }\n        }\n    };\n}\n\n// Macro for generating test cases\nmacro_rules! test_cases {\n    ($name:ident, $($test_name:ident: $input:expr => $expected:expr),* $(,)?) => {\n        mod $name {\n            use super::*;\n            \n            $(\n                #[test]\n                fn $test_name() {\n                    let result = process($input);\n                    assert_eq!(result, $expected, \n                              \"Failed for input: {:?}\", $input);\n                }\n            )*\n        }\n    };\n}\n\n// Usage examples\n#[derive(Builder)]\nstruct Config {\n    host: String,\n    port: u16,\n    timeout: Duration,\n    max_connections: usize,\n}\n\n#[memoize(50)]\nfn fibonacci(n: u64) -> u64 {\n    match n {\n        0 => 0,\n        1 => 1,\n        _ => fibonacci(n - 1) + fibonacci(n - 2),\n    }\n}\n\ncreate_enum_with_traits! {\n    #[derive(Debug, Clone)]\n    pub enum Status {\n        Active,\n        Inactive(String),\n        Pending { since: Instant },\n        Error = -1,\n    }\n}\n\nstate_machine! {\n    Door {\n        states: [Open, Closed, Locked],\n        transitions: [\n            Open -> Closed: close,\n            Closed -> Open: open,\n            Closed -> Locked: lock,\n            Locked -> Closed: unlock\n        ],\n        initial: Closed\n    }\n}\n\n#[derive(Debug, Clone, Copy)]\nstruct Wrapper(i32);\nimplement_ops!(Wrapper => Add, Sub, Mul);\n\ntest_cases! {\n    math_tests,\n    test_addition: (1, 2) => 3,\n    test_subtraction: (5, 3) => 2,\n    test_multiplication: (4, 7) => 28,\n}\n\nfn process(input: (i32, i32)) -> i32 {\n    input.0 + input.1\n}\n\n// Hygiene demonstration\nmacro_rules! hygienic_macro {\n    ($x:expr) => {\n        {\n            let temp = $x * 2;  // This 'temp' won't conflict with outer scope\n            temp + 1\n        }\n    };\n}\n\nfn main() {\n    // Using derive macro\n    let config = Config::builder()\n        .host(\"localhost\".to_string())\n        .port(8080)\n        .timeout(Duration::from_secs(30))\n        .max_connections(100)\n        .build()\n        .unwrap();\n    \n    // Using memoized function\n    let fib_result = fibonacci(40);\n    println!(\"Fibonacci(40) = {}\", fib_result);\n    \n    // Using generated enum traits\n    let status = Status::Active;\n    println!(\"Variant: {}\", status.variant_name());\n    println!(\"All variants: {:?}\", Status::all_variants());\n    \n    // Using state machine\n    let door = Door::<Closed>::new();\n    let door = door.open();\n    let door = door.close();\n    let door = door.lock();\n    \n    // Using generated ops\n    let w1 = Wrapper(10);\n    let w2 = Wrapper(5);\n    let sum = w1 + w2;\n    println!(\"Wrapper sum: {:?}\", sum);\n    \n    // Count arguments\n    let count = count_args!(1, 2, 3, 4, 5);\n    println!(\"Argument count: {}\", count);\n    \n    // Find minimum\n    let min_val = min!(5, 3, 8, 2, 9);\n    println!(\"Minimum: {}\", min_val);\n    \n    // Hygiene example\n    let temp = 10;\n    let result = hygienic_macro!(temp);\n    println!(\"Result: {}, Original temp: {}\", result, temp);\n}",
    "key_concepts": [
      "procedural macros",
      "derive macros",
      "attribute macros",
      "function-like macros",
      "macro hygiene",
      "token manipulation",
      "code generation",
      "recursive macros",
      "variadic macros",
      "state machine generation"
    ]
  },
  {
    "prompt": "Implement advanced unsafe Rust patterns including custom allocators, self-referential structs, FFI bindings, inline assembly, and memory-mapped I/O. Show proper safety documentation and invariant maintenance.",
    "response": "use std::alloc::{GlobalAlloc, Layout, System};\nuse std::ptr::{self, NonNull};\nuse std::mem::{self, MaybeUninit};\nuse std::marker::PhantomData;\nuse std::ops::{Deref, DerefMut};\nuse std::slice;\nuse std::os::raw::{c_void, c_int, c_char};\nuse std::ffi::{CString, CStr};\nuse std::pin::Pin;\nuse std::arch::asm;\n\n// Custom allocator with memory tracking\nstruct TrackingAllocator {\n    inner: System,\n    allocated: std::sync::atomic::AtomicUsize,\n}\n\nunsafe impl GlobalAlloc for TrackingAllocator {\n    unsafe fn alloc(&self, layout: Layout) -> *mut u8 {\n        let ret = self.inner.alloc(layout);\n        if !ret.is_null() {\n            self.allocated.fetch_add(layout.size(), std::sync::atomic::Ordering::SeqCst);\n        }\n        ret\n    }\n    \n    unsafe fn dealloc(&self, ptr: *mut u8, layout: Layout) {\n        self.inner.dealloc(ptr, layout);\n        self.allocated.fetch_sub(layout.size(), std::sync::atomic::Ordering::SeqCst);\n    }\n    \n    unsafe fn realloc(&self, ptr: *mut u8, layout: Layout, new_size: usize) -> *mut u8 {\n        let old_size = layout.size();\n        let ret = self.inner.realloc(ptr, layout, new_size);\n        if !ret.is_null() {\n            self.allocated.fetch_add(new_size.saturating_sub(old_size), \n                                    std::sync::atomic::Ordering::SeqCst);\n        }\n        ret\n    }\n}\n\n#[global_allocator]\nstatic ALLOCATOR: TrackingAllocator = TrackingAllocator {\n    inner: System,\n    allocated: std::sync::atomic::AtomicUsize::new(0),\n};\n\n// Self-referential struct using Pin\npub struct SelfReferential {\n    data: String,\n    // SAFETY: This pointer must always point to `data` field\n    ptr: *const String,\n    _pin: PhantomData<Pin<Box<Self>>>,\n}\n\nimpl SelfReferential {\n    pub fn new(data: String) -> Pin<Box<Self>> {\n        let mut boxed = Box::new(Self {\n            data,\n            ptr: ptr::null(),\n            _pin: PhantomData,\n        });\n        \n        // SAFETY: We're setting up the self-reference before pinning\n        let ptr = &boxed.data as *const String;\n        unsafe {\n            let mut_ref = &mut *boxed as *mut Self;\n            (*mut_ref).ptr = ptr;\n        }\n        \n        // SAFETY: The struct is now properly initialized and won't be moved\n        unsafe { Pin::new_unchecked(boxed) }\n    }\n    \n    pub fn get_data(&self) -> &str {\n        // SAFETY: ptr always points to data field due to Pin guarantee\n        unsafe { &**self.ptr }\n    }\n}\n\n// Custom smart pointer with manual memory management\npub struct CustomBox<T> {\n    ptr: NonNull<T>,\n    _marker: PhantomData<T>,\n}\n\nimpl<T> CustomBox<T> {\n    pub fn new(value: T) -> Self {\n        let layout = Layout::new::<T>();\n        \n        // SAFETY: Layout is valid for type T\n        let ptr = unsafe {\n            let ptr = std::alloc::alloc(layout) as *mut T;\n            if ptr.is_null() {\n                std::alloc::handle_alloc_error(layout);\n            }\n            \n            // Write value to allocated memory\n            ptr.write(value);\n            NonNull::new_unchecked(ptr)\n        };\n        \n        Self {\n            ptr,\n            _marker: PhantomData,\n        }\n    }\n    \n    pub fn into_raw(self) -> *mut T {\n        let ptr = self.ptr.as_ptr();\n        mem::forget(self);\n        ptr\n    }\n    \n    pub unsafe fn from_raw(ptr: *mut T) -> Self {\n        Self {\n            ptr: NonNull::new_unchecked(ptr),\n            _marker: PhantomData,\n        }\n    }\n}\n\nimpl<T> Deref for CustomBox<T> {\n    type Target = T;\n    \n    fn deref(&self) -> &Self::Target {\n        // SAFETY: ptr is valid and properly aligned\n        unsafe { self.ptr.as_ref() }\n    }\n}\n\nimpl<T> DerefMut for CustomBox<T> {\n    fn deref_mut(&mut self) -> &mut Self::Target {\n        // SAFETY: ptr is valid, properly aligned, and we have exclusive access\n        unsafe { self.ptr.as_mut() }\n    }\n}\n\nimpl<T> Drop for CustomBox<T> {\n    fn drop(&mut self) {\n        let layout = Layout::new::<T>();\n        \n        // SAFETY: ptr was allocated with the same layout\n        unsafe {\n            ptr::drop_in_place(self.ptr.as_ptr());\n            std::alloc::dealloc(self.ptr.as_ptr() as *mut u8, layout);\n        }\n    }\n}\n\n// FFI bindings\n#[repr(C)]\npub struct CStruct {\n    x: c_int,\n    y: c_int,\n    name: *mut c_char,\n}\n\nextern \"C\" {\n    fn process_struct(s: *mut CStruct) -> c_int;\n    fn get_error_message() -> *const c_char;\n}\n\npub fn safe_process_struct(x: i32, y: i32, name: &str) -> Result<i32, String> {\n    let c_name = CString::new(name).map_err(|e| e.to_string())?;\n    let mut c_struct = CStruct {\n        x: x as c_int,\n        y: y as c_int,\n        name: c_name.into_raw(),\n    };\n    \n    // SAFETY: process_struct is assumed to be a valid C function\n    // that doesn't retain pointers after returning\n    let result = unsafe { process_struct(&mut c_struct) };\n    \n    // SAFETY: Reclaim ownership of the CString to properly deallocate\n    unsafe { CString::from_raw(c_struct.name) };\n    \n    if result < 0 {\n        // SAFETY: get_error_message returns a valid C string\n        let error_msg = unsafe {\n            let ptr = get_error_message();\n            if ptr.is_null() {\n                \"Unknown error\".to_string()\n            } else {\n                CStr::from_ptr(ptr).to_string_lossy().into_owned()\n            }\n        };\n        Err(error_msg)\n    } else {\n        Ok(result)\n    }\n}\n\n// Inline assembly for performance-critical operations\n#[cfg(target_arch = \"x86_64\")]\npub fn fast_memcpy(dst: *mut u8, src: *const u8, len: usize) {\n    // SAFETY: Caller must ensure valid pointers and non-overlapping regions\n    unsafe {\n        asm!(\n            \"cld\",\n            \"rep movsb\",\n            inout(\"rdi\") dst => _,\n            inout(\"rsi\") src => _,\n            inout(\"rcx\") len => _,\n            options(nostack, preserves_flags)\n        );\n    }\n}\n\n#[cfg(target_arch = \"x86_64\")]\npub fn rdtsc() -> u64 {\n    let low: u32;\n    let high: u32;\n    \n    // SAFETY: RDTSC is safe to call on x86_64\n    unsafe {\n        asm!(\n            \"rdtsc\",\n            out(\"eax\") low,\n            out(\"edx\") high,\n            options(nomem, nostack, preserves_flags)\n        );\n    }\n    \n    ((high as u64) << 32) | (low as u64)\n}\n\n// Memory-mapped I/O\npub struct MmioRegion {\n    base: *mut u32,\n    size: usize,\n}\n\nimpl MmioRegion {\n    /// # Safety\n    /// - `base` must be a valid MMIO region address\n    /// - The region must be properly mapped and accessible\n    /// - The caller must ensure exclusive access to this region\n    pub unsafe fn new(base: usize, size: usize) -> Self {\n        Self {\n            base: base as *mut u32,\n            size,\n        }\n    }\n    \n    /// Read a 32-bit value from offset\n    /// \n    /// # Safety\n    /// - Offset must be within bounds and properly aligned\n    pub unsafe fn read(&self, offset: usize) -> u32 {\n        assert!(offset < self.size);\n        assert!(offset % 4 == 0, \"Offset must be 4-byte aligned\");\n        \n        let addr = self.base.add(offset / 4);\n        ptr::read_volatile(addr)\n    }\n    \n    /// Write a 32-bit value to offset\n    /// \n    /// # Safety\n    /// - Offset must be within bounds and properly aligned\n    /// - The write must not violate device-specific constraints\n    pub unsafe fn write(&self, offset: usize, value: u32) {\n        assert!(offset < self.size);\n        assert!(offset % 4 == 0, \"Offset must be 4-byte aligned\");\n        \n        let addr = self.base.add(offset / 4);\n        ptr::write_volatile(addr, value);\n    }\n}\n\n// Lock-free stack using atomic operations\npub struct LockFreeStack<T> {\n    head: std::sync::atomic::AtomicPtr<Node<T>>,\n}\n\nstruct Node<T> {\n    data: T,\n    next: *mut Node<T>,\n}\n\nimpl<T> LockFreeStack<T> {\n    pub fn new() -> Self {\n        Self {\n            head: std::sync::atomic::AtomicPtr::new(ptr::null_mut()),\n        }\n    }\n    \n    pub fn push(&self, data: T) {\n        let node = Box::into_raw(Box::new(Node {\n            data,\n            next: ptr::null_mut(),\n        }));\n        \n        loop {\n            let head = self.head.load(std::sync::atomic::Ordering::Acquire);\n            \n            // SAFETY: node is valid as we just allocated it\n            unsafe {\n                (*node).next = head;\n            }\n            \n            match self.head.compare_exchange_weak(\n                head,\n                node,\n                std::sync::atomic::Ordering::Release,\n                std::sync::atomic::Ordering::Acquire,\n            ) {\n                Ok(_) => break,\n                Err(_) => continue,\n            }\n        }\n    }\n    \n    pub fn pop(&self) -> Option<T> {\n        loop {\n            let head = self.head.load(std::sync::atomic::Ordering::Acquire);\n            \n            if head.is_null() {\n                return None;\n            }\n            \n            // SAFETY: head is non-null and was previously a valid Node\n            let next = unsafe { (*head).next };\n            \n            match self.head.compare_exchange_weak(\n                head,\n                next,\n                std::sync::atomic::Ordering::Release,\n                std::sync::atomic::Ordering::Acquire,\n            ) {\n                Ok(_) => {\n                    // SAFETY: We have exclusive ownership of the node\n                    let node = unsafe { Box::from_raw(head) };\n                    return Some(node.data);\n                }\n                Err(_) => continue,\n            }\n        }\n    }\n}\n\n// SAFETY: T must be Send for the stack to be Send/Sync\nunsafe impl<T: Send> Send for LockFreeStack<T> {}\nunsafe impl<T: Send> Sync for LockFreeStack<T> {}\n\nimpl<T> Drop for LockFreeStack<T> {\n    fn drop(&mut self) {\n        while self.pop().is_some() {}\n    }\n}\n\n// Transmutation with safety checks\npub fn safe_transmute<T, U>(value: T) -> Result<U, T> {\n    // Check size and alignment requirements\n    if mem::size_of::<T>() != mem::size_of::<U>() {\n        return Err(value);\n    }\n    \n    if mem::align_of::<T>() < mem::align_of::<U>() {\n        return Err(value);\n    }\n    \n    // SAFETY: Size and alignment requirements are met\n    unsafe {\n        let result = ptr::read(&value as *const T as *const U);\n        mem::forget(value);\n        Ok(result)\n    }\n}\n\n// Union for type punning\n#[repr(C)]\nunion FloatBytes {\n    float: f32,\n    bytes: [u8; 4],\n}\n\npub fn float_to_bytes(f: f32) -> [u8; 4] {\n    // SAFETY: Both fields have the same size and alignment\n    unsafe { FloatBytes { float: f }.bytes }\n}\n\npub fn bytes_to_float(bytes: [u8; 4]) -> f32 {\n    // SAFETY: Both fields have the same size and alignment\n    unsafe { FloatBytes { bytes }.float }\n}\n\nfn main() {\n    // Using custom allocator\n    let allocated = ALLOCATOR.allocated.load(std::sync::atomic::Ordering::SeqCst);\n    println!(\"Currently allocated: {} bytes\", allocated);\n    \n    // Self-referential struct\n    let self_ref = SelfReferential::new(\"Hello\".to_string());\n    println!(\"Self-referential data: {}\", self_ref.get_data());\n    \n    // Custom box\n    let custom_box = CustomBox::new(42);\n    println!(\"Custom box value: {}\", *custom_box);\n    \n    // Lock-free stack\n    let stack = LockFreeStack::new();\n    stack.push(1);\n    stack.push(2);\n    stack.push(3);\n    \n    while let Some(val) = stack.pop() {\n        println!(\"Popped: {}\", val);\n    }\n    \n    // Type punning\n    let f = 3.14f32;\n    let bytes = float_to_bytes(f);\n    let recovered = bytes_to_float(bytes);\n    println!(\"Float {} -> bytes {:?} -> float {}\", f, bytes, recovered);\n    \n    // Safe transmutation\n    let x: [u8; 4] = [1, 2, 3, 4];\n    match safe_transmute::<[u8; 4], u32>(x) {\n        Ok(val) => println!(\"Transmuted to u32: {}\", val),\n        Err(_) => println!(\"Transmutation failed\"),\n    }\n}",
    "key_concepts": [
      "custom allocators",
      "self-referential structs",
      "FFI bindings",
      "inline assembly",
      "memory-mapped I/O",
      "lock-free data structures",
      "type punning",
      "transmutation",
      "safety documentation",
      "invariant maintenance"
    ]
  },
  {
    "prompt": "Demonstrate compile-time computation in Rust using const functions, const generics, and const evaluation. Include examples of compile-time data structures, const trait implementations, and zero-cost abstractions.",
    "response": "#![feature(const_trait_impl)]\n#![feature(const_mut_refs)]\n#![feature(const_for)]\n#![feature(const_option)]\n\nuse std::mem::MaybeUninit;\n\n// Const functions for compile-time computation\nconst fn factorial(n: u64) -> u64 {\n    match n {\n        0 | 1 => 1,\n        _ => n * factorial(n - 1),\n    }\n}\n\nconst fn fibonacci(n: u64) -> u64 {\n    if n <= 1 {\n        n\n    } else {\n        let mut a = 0;\n        let mut b = 1;\n        let mut i = 2;\n        \n        while i <= n {\n            let temp = a + b;\n            a = b;\n            b = temp;\n            i += 1;\n        }\n        b\n    }\n}\n\nconst fn gcd(mut a: u64, mut b: u64) -> u64 {\n    while b != 0 {\n        let temp = b;\n        b = a % b;\n        a = temp;\n    }\n    a\n}\n\n// Compile-time string manipulation\nconst fn const_str_len(s: &str) -> usize {\n    s.as_bytes().len()\n}\n\nconst fn const_str_eq(a: &str, b: &str) -> bool {\n    let a_bytes = a.as_bytes();\n    let b_bytes = b.as_bytes();\n    \n    if a_bytes.len() != b_bytes.len() {\n        return false;\n    }\n    \n    let mut i = 0;\n    while i < a_bytes.len() {\n        if a_bytes[i] != b_bytes[i] {\n            return false;\n        }\n        i += 1;\n    }\n    true\n}\n\n// Const generics with compile-time validation\nstruct Matrix<const ROWS: usize, const COLS: usize> {\n    data: [[f64; COLS]; ROWS],\n}\n\nimpl<const ROWS: usize, const COLS: usize> Matrix<ROWS, COLS> {\n    const fn new() -> Self {\n        Self {\n            data: [[0.0; COLS]; ROWS],\n        }\n    }\n    \n    const fn identity() -> Self\n    where\n        [(); ROWS]: Sized,\n        [(); COLS]: Sized,\n    {\n        let mut matrix = Self::new();\n        let mut i = 0;\n        while i < ROWS && i < COLS {\n            matrix.data[i][i] = 1.0;\n            i += 1;\n        }\n        matrix\n    }\n}\n\n// Compile-time type-level computation\ntrait TypeLevel {\n    const VALUE: usize;\n}\n\nstruct Zero;\nstruct Succ<N>(std::marker::PhantomData<N>);\n\nimpl TypeLevel for Zero {\n    const VALUE: usize = 0;\n}\n\nimpl<N: TypeLevel> TypeLevel for Succ<N> {\n    const VALUE: usize = N::VALUE + 1;\n}\n\ntype One = Succ<Zero>;\ntype Two = Succ<One>;\ntype Three = Succ<Two>;\n\n// Const array initialization with complex logic\nconst fn create_lookup_table<const N: usize>() -> [u8; N] {\n    let mut table = [0u8; N];\n    let mut i = 0;\n    \n    while i < N {\n        table[i] = (i as u8).wrapping_mul(17).wrapping_add(3);\n        i += 1;\n    }\n    \n    table\n}\n\nconst LOOKUP_TABLE: [u8; 256] = create_lookup_table();\n\n// Compile-time perfect hash function\nconst fn hash(key: &str) -> usize {\n    let bytes = key.as_bytes();\n    let mut hash = 5381usize;\n    let mut i = 0;\n    \n    while i < bytes.len() {\n        hash = hash.wrapping_mul(33).wrapping_add(bytes[i] as usize);\n        i += 1;\n    }\n    \n    hash\n}\n\n// Static compile-time map\nstruct StaticMap<const N: usize> {\n    keys: [&'static str; N],\n    values: [i32; N],\n}\n\nimpl<const N: usize> StaticMap<N> {\n    const fn get(&self, key: &str) -> Option<i32> {\n        let mut i = 0;\n        while i < N {\n            if const_str_eq(self.keys[i], key) {\n                return Some(self.values[i]);\n            }\n            i += 1;\n        }\n        None\n    }\n}\n\nconst MAP: StaticMap<3> = StaticMap {\n    keys: [\"foo\", \"bar\", \"baz\"],\n    values: [1, 2, 3],\n};\n\n// Const trait implementations\n#[const_trait]\ntrait ConstDefault {\n    fn default() -> Self;\n}\n\nstruct Point {\n    x: i32,\n    y: i32,\n}\n\nimpl const ConstDefault for Point {\n    fn default() -> Self {\n        Point { x: 0, y: 0 }\n    }\n}\n\n// Compile-time validated configuration\nstruct Config<const DEBUG: bool, const MAX_SIZE: usize> {\n    data: [u8; MAX_SIZE],\n}\n\nimpl<const DEBUG: bool, const MAX_SIZE: usize> Config<DEBUG, MAX_SIZE> {\n    const fn new() -> Self {\n        assert!(MAX_SIZE > 0, \"MAX_SIZE must be greater than 0\");\n        assert!(MAX_SIZE <= 1024, \"MAX_SIZE must not exceed 1024\");\n        \n        Self {\n            data: [0; MAX_SIZE],\n        }\n    }\n    \n    const fn validate() -> bool {\n        if DEBUG && MAX_SIZE < 10 {\n            panic!(\"Debug mode requires MAX_SIZE >= 10\");\n        }\n        true\n    }\n}\n\n// Const evaluable bit manipulation\nconst fn count_bits(mut n: u64) -> u32 {\n    let mut count = 0;\n    while n != 0 {\n        count += 1;\n        n &= n - 1;\n    }\n    count\n}\n\nconst fn next_power_of_two(n: u64) -> u64 {\n    if n == 0 {\n        return 1;\n    }\n    \n    let mut power = 1;\n    while power < n {\n        power <<= 1;\n    }\n    power\n}\n\n// Compile-time prime checking\nconst fn is_prime(n: u64) -> bool {\n    if n < 2 {\n        return false;\n    }\n    if n == 2 {\n        return true;\n    }\n    if n % 2 == 0 {\n        return false;\n    }\n    \n    let mut divisor = 3;\n    while divisor * divisor <= n {\n        if n % divisor == 0 {\n            return false;\n        }\n        divisor += 2;\n    }\n    true\n}\n\n// Generate compile-time prime table\nconst fn generate_primes<const N: usize>() -> ([u64; N], usize) {\n    let mut primes = [0u64; N];\n    let mut count = 0;\n    let mut candidate = 2;\n    \n    while count < N {\n        if is_prime(candidate) {\n            primes[count] = candidate;\n            count += 1;\n        }\n        candidate += 1;\n    }\n    \n    (primes, count)\n}\n\nconst PRIMES: ([u64; 100], usize) = generate_primes::<100>();\n\n// Const generic bounds and where clauses\nstruct Buffer<const N: usize>\nwhere\n    [u8; N]: Sized,\n{\n    data: [u8; N],\n}\n\nimpl<const N: usize> Buffer<N>\nwhere\n    [u8; N]: Sized,\n{\n    const fn new() -> Self {\n        Self { data: [0; N] }\n    }\n    \n    const fn from_array(arr: [u8; N]) -> Self {\n        Self { data: arr }\n    }\n}\n\n// Compile-time format string validation\nmacro_rules! const_format {\n    ($fmt:literal $(, $arg:expr)*) => {{\n        const FMT: &str = $fmt;\n        const _: () = {\n            let bytes = FMT.as_bytes();\n            let mut i = 0;\n            let mut placeholders = 0;\n            \n            while i < bytes.len() {\n                if bytes[i] == b'{' && i + 1 < bytes.len() && bytes[i + 1] == b'}' {\n                    placeholders += 1;\n                    i += 2;\n                } else {\n                    i += 1;\n                }\n            }\n            \n            let args = 0 $(+ { let _ = $arg; 1 })*;\n            assert!(placeholders == args, \"Format string placeholder count mismatch\");\n        };\n        \n        format!($fmt $(, $arg)*)\n    }};\n}\n\n// Usage demonstrations\nconst FACTORIAL_10: u64 = factorial(10);\nconst FIBONACCI_20: u64 = fibonacci(20);\nconst GCD_48_18: u64 = gcd(48, 18);\n\nconst IDENTITY_3X3: Matrix<3, 3> = Matrix::identity();\n\nconst fn complex_computation() -> u64 {\n    let a = factorial(5);\n    let b = fibonacci(10);\n    let c = gcd(a, b);\n    next_power_of_two(c)\n}\n\nconst COMPLEX_RESULT: u64 = complex_computation();\n\n// Static assertions\nconst _: () = assert!(FACTORIAL_10 == 3628800);\nconst _: () = assert!(is_prime(17));\nconst _: () = assert!(!is_prime(18));\nconst _: () = assert!(count_bits(0b1010101) == 4);\n\nfn main() {\n    // All computations happen at compile time\n    println!(\"10! = {}\", FACTORIAL_10);\n    println!(\"Fibonacci(20) = {}\", FIBONACCI_20);\n    println!(\"GCD(48, 18) = {}\", GCD_48_18);\n    \n    // Type-level computation\n    println!(\"Three::VALUE = {}\", Three::VALUE);\n    \n    // Static map lookup\n    match MAP.get(\"bar\") {\n        Some(val) => println!(\"MAP['bar'] = {}\", val),\n        None => println!(\"Key not found\"),\n    }\n    \n    // Lookup table usage\n    println!(\"LOOKUP_TABLE[42] = {}\", LOOKUP_TABLE[42]);\n    \n    // Prime table\n    println!(\"First 10 primes: {:?}\", &PRIMES.0[..10]);\n    \n    // Complex computation result\n    println!(\"Complex computation result: {}\", COMPLEX_RESULT);\n    \n    // Const generic validation\n    let config = Config::<true, 100>::new();\n    assert!(Config::<true, 100>::validate());\n    \n    // Format string validation at compile time\n    let formatted = const_format!(\"Hello, {}!\", \"world\");\n    println!(\"{}\", formatted);\n}",
    "key_concepts": [
      "const functions",
      "const generics",
      "compile-time computation",
      "const trait implementations",
      "type-level programming",
      "static assertions",
      "compile-time validation",
      "const evaluation",
      "zero-cost abstractions",
      "compile-time data structures"
    ]
  },
  {
    "prompt": "Create a compile-time expression evaluator in Rust that can evaluate mathematical expressions at compile time using const functions and type-level programming. Include support for basic operations, variables, and function calls.",
    "response": "#![feature(const_trait_impl)]\n#![feature(const_option_ext)]\n#![feature(const_slice_index)]\n\n// Token types for the expression parser\n#[derive(Debug, Clone, Copy, PartialEq, Eq)]\nenum Token {\n    Number(i64),\n    Plus,\n    Minus,\n    Multiply,\n    Divide,\n    Power,\n    LeftParen,\n    RightParen,\n    Variable(u8), // Store variable index as u8\n    Function(FunctionType),\n    Comma,\n    End,\n}\n\n#[derive(Debug, Clone, Copy, PartialEq, Eq)]\nenum FunctionType {\n    Abs,\n    Min,\n    Max,\n    Factorial,\n}\n\n// Const expression tokenizer\nconst fn tokenize<const N: usize>(expr: &str) -> ([Token; N], usize) {\n    let bytes = expr.as_bytes();\n    let mut tokens = [Token::End; N];\n    let mut token_count = 0;\n    let mut i = 0;\n    \n    while i < bytes.len() && token_count < N {\n        // Skip whitespace\n        while i < bytes.len() && bytes[i] == b' ' {\n            i += 1;\n        }\n        \n        if i >= bytes.len() {\n            break;\n        }\n        \n        match bytes[i] {\n            b'+' => {\n                tokens[token_count] = Token::Plus;\n                token_count += 1;\n                i += 1;\n            }\n            b'-' => {\n                tokens[token_count] = Token::Minus;\n                token_count += 1;\n                i += 1;\n            }\n            b'*' => {\n                tokens[token_count] = Token::Multiply;\n                token_count += 1;\n                i += 1;\n            }\n            b'/' => {\n                tokens[token_count] = Token::Divide;\n                token_count += 1;\n                i += 1;\n            }\n            b'^' => {\n                tokens[token_count] = Token::Power;\n                token_count += 1;\n                i += 1;\n            }\n            b'(' => {\n                tokens[token_count] = Token::LeftParen;\n                token_count += 1;\n                i += 1;\n            }\n            b')' => {\n                tokens[token_count] = Token::RightParen;\n                token_count += 1;\n                i += 1;\n            }\n            b',' => {\n                tokens[token_count] = Token::Comma;\n                token_count += 1;\n                i += 1;\n            }\n            b'0'..=b'9' => {\n                let mut num = 0i64;\n                while i < bytes.len() && bytes[i] >= b'0' && bytes[i] <= b'9' {\n                    num = num * 10 + (bytes[i] - b'0') as i64;\n                    i += 1;\n                }\n                tokens[token_count] = Token::Number(num);\n                token_count += 1;\n            }\n            b'a'..=b'z' | b'A'..=b'Z' => {\n                let start = i;\n                while i < bytes.len() && \n                      ((bytes[i] >= b'a' && bytes[i] <= b'z') ||\n                       (bytes[i] >= b'A' && bytes[i] <= b'Z')) {\n                    i += 1;\n                }\n                \n                // Check for function names\n                if i - start == 3 {\n                    if bytes[start] == b'a' && bytes[start+1] == b'b' && bytes[start+2] == b's' {\n                        tokens[token_count] = Token::Function(FunctionType::Abs);\n                        token_count += 1;\n                    } else if bytes[start] == b'm' && bytes[start+1] == b'i' && bytes[start+2] == b'n' {\n                        tokens[token_count] = Token::Function(FunctionType::Min);\n                        token_count += 1;\n                    } else if bytes[start] == b'm' && bytes[start+1] == b'a' && bytes[start+2] == b'x' {\n                        tokens[token_count] = Token::Function(FunctionType::Max);\n                        token_count += 1;\n                    } else {\n                        // Variable (use first char as index)\n                        tokens[token_count] = Token::Variable((bytes[start] - b'a') as u8);\n                        token_count += 1;\n                    }\n                } else if i - start == 9 {\n                    // Check for \"factorial\"\n                    tokens[token_count] = Token::Function(FunctionType::Factorial);\n                    token_count += 1;\n                } else {\n                    // Variable\n                    tokens[token_count] = Token::Variable((bytes[start] - b'a') as u8);\n                    token_count += 1;\n                }\n            }\n            _ => i += 1,\n        }\n    }\n    \n    (tokens, token_count)\n}\n\n// Expression parser and evaluator\nstruct ConstExprEvaluator<const N: usize> {\n    tokens: [Token; N],\n    pos: usize,\n    token_count: usize,\n    variables: [i64; 26], // Support up to 26 variables (a-z)\n}\n\nimpl<const N: usize> ConstExprEvaluator<N> {\n    const fn new(tokens: [Token; N], token_count: usize) -> Self {\n        Self {\n            tokens,\n            pos: 0,\n            token_count,\n            variables: [0; 26],\n        }\n    }\n    \n    const fn with_variables(mut self, vars: &[(&str, i64)]) -> Self {\n        let mut i = 0;\n        while i < vars.len() {\n            let var_name = vars[i].0.as_bytes();\n            if var_name.len() > 0 {\n                let index = (var_name[0] - b'a') as usize;\n                if index < 26 {\n                    self.variables[index] = vars[i].1;\n                }\n            }\n            i += 1;\n        }\n        self\n    }\n    \n    const fn current(&self) -> Token {\n        if self.pos < self.token_count {\n            self.tokens[self.pos]\n        } else {\n            Token::End\n        }\n    }\n    \n    const fn advance(&mut self) {\n        if self.pos < self.token_count {\n            self.pos += 1;\n        }\n    }\n    \n    const fn parse_primary(&mut self) -> i64 {\n        match self.current() {\n            Token::Number(n) => {\n                self.advance();\n                n\n            }\n            Token::Variable(idx) => {\n                self.advance();\n                self.variables[idx as usize]\n            }\n            Token::LeftParen => {\n                self.advance(); // consume '('\n                let result = self.parse_expression();\n                if matches!(self.current(), Token::RightParen) {\n                    self.advance(); // consume ')'\n                }\n                result\n            }\n            Token::Minus => {\n                self.advance();\n                -self.parse_primary()\n            }\n            Token::Function(func) => {\n                self.advance();\n                self.parse_function(func)\n            }\n            _ => 0,\n        }\n    }\n    \n    const fn parse_function(&mut self, func: FunctionType) -> i64 {\n        if !matches!(self.current(), Token::LeftParen) {\n            return 0;\n        }\n        self.advance(); // consume '('\n        \n        match func {\n            FunctionType::Abs => {\n                let arg = self.parse_expression();\n                if matches!(self.current(), Token::RightParen) {\n                    self.advance();\n                }\n                if arg < 0 { -arg } else { arg }\n            }\n            FunctionType::Min => {\n                let arg1 = self.parse_expression();\n                if !matches!(self.current(), Token::Comma) {\n                    return arg1;\n                }\n                self.advance(); // consume ','\n                let arg2 = self.parse_expression();\n                if matches!(self.current(), Token::RightParen) {\n                    self.advance();\n                }\n                if arg1 < arg2 { arg1 } else { arg2 }\n            }\n            FunctionType::Max => {\n                let arg1 = self.parse_expression();\n                if !matches!(self.current(), Token::Comma) {\n                    return arg1;\n                }\n                self.advance(); // consume ','\n                let arg2 = self.parse_expression();\n                if matches!(self.current(), Token::RightParen) {\n                    self.advance();\n                }\n                if arg1 > arg2 { arg1 } else { arg2 }\n            }\n            FunctionType::Factorial => {\n                let arg = self.parse_expression();\n                if matches!(self.current(), Token::RightParen) {\n                    self.advance();\n                }\n                const_factorial(arg)\n            }\n        }\n    }\n    \n    const fn parse_power(&mut self) -> i64 {\n        let mut left = self.parse_primary();\n        \n        while matches!(self.current(), Token::Power) {\n            self.advance();\n            let right = self.parse_primary();\n            left = const_pow(left, right);\n        }\n        \n        left\n    }\n    \n    const fn parse_term(&mut self) -> i64 {\n        let mut left = self.parse_power();\n        \n        loop {\n            match self.current() {\n                Token::Multiply => {\n                    self.advance();\n                    left = left * self.parse_power();\n                }\n                Token::Divide => {\n                    self.advance();\n                    let right = self.parse_power();\n                    if right != 0 {\n                        left = left / right;\n                    }\n                }\n                _ => break,\n            }\n        }\n        \n        left\n    }\n    \n    const fn parse_expression(&mut self) -> i64 {\n        let mut left = self.parse_term();\n        \n        loop {\n            match self.current() {\n                Token::Plus => {\n                    self.advance();\n                    left = left + self.parse_term();\n                }\n                Token::Minus => {\n                    self.advance();\n                    left = left - self.parse_term();\n                }\n                _ => break,\n            }\n        }\n        \n        left\n    }\n    \n    const fn evaluate(mut self) -> i64 {\n        self.parse_expression()\n    }\n}\n\n// Helper functions\nconst fn const_pow(base: i64, exp: i64) -> i64 {\n    if exp < 0 {\n        return 0; // Integer division\n    }\n    \n    let mut result = 1;\n    let mut i = 0;\n    while i < exp {\n        result *= base;\n        i += 1;\n    }\n    result\n}\n\nconst fn const_factorial(n: i64) -> i64 {\n    if n < 0 {\n        return 0;\n    }\n    if n <= 1 {\n        return 1;\n    }\n    \n    let mut result = 1;\n    let mut i = 2;\n    while i <= n {\n        result *= i;\n        i += 1;\n    }\n    result\n}\n\n// Main evaluation function\nconst fn const_eval<const N: usize>(expr: &str) -> i64 {\n    let (tokens, count) = tokenize::<N>(expr);\n    let evaluator = ConstExprEvaluator::new(tokens, count);\n    evaluator.evaluate()\n}\n\nconst fn const_eval_with_vars<const N: usize>(\n    expr: &str,\n    vars: &[(&str, i64)]\n) -> i64 {\n    let (tokens, count) = tokenize::<N>(expr);\n    let evaluator = ConstExprEvaluator::new(tokens, count)\n        .with_variables(vars);\n    evaluator.evaluate()\n}\n\n// Compile-time tests\nconst _: () = assert!(const_eval::<10>(\"2 + 3 * 4\") == 14);\nconst _: () = assert!(const_eval::<10>(\"(2 + 3) * 4\") == 20);\nconst _: () = assert!(const_eval::<10>(\"2 ^ 3\") == 8);\nconst _: () = assert!(const_eval::<10>(\"abs(-5)\") == 5);\nconst _: () = assert!(const_eval::<10>(\"min(10, 5)\") == 5);\nconst _: () = assert!(const_eval::<10>(\"max(10, 5)\") == 10);\nconst _: () = assert!(const_eval::<10>(\"factorial(5)\") == 120);\n\n// Examples with variables\nconst EXPR_WITH_VARS: i64 = const_eval_with_vars::<20>(\n    \"a * 2 + b ^ 2\",\n    &[(\"a\", 3), (\"b\", 4)]\n);\nconst _: () = assert!(EXPR_WITH_VARS == 22); // 3 * 2 + 4^2 = 6 + 16 = 22\n\n// Complex expression\nconst COMPLEX_EXPR: i64 = const_eval::<30>(\n    \"factorial(4) + max(10, 15) - abs(-8)\"\n);\nconst _: () = assert!(COMPLEX_EXPR == 31); // 24 + 15 - 8 = 31\n\n// Macro for easier usage\nmacro_rules! const_expr {\n    ($expr:literal) => {\n        const_eval::<100>($expr)\n    };\n    ($expr:literal, $($var:ident = $val:expr),*) => {{\n        const_eval_with_vars::<100>(\n            $expr,\n            &[$((stringify!($var), $val)),*]\n        )\n    }};\n}\n\nfn main() {\n    // All evaluations happen at compile time\n    const RESULT1: i64 = const_expr!(\"2 + 3 * 4\");\n    const RESULT2: i64 = const_expr!(\"(2 + 3) * 4\");\n    const RESULT3: i64 = const_expr!(\"2 ^ 3 + factorial(4)\");\n    const RESULT4: i64 = const_expr!(\"a * x + b\", a = 2, x = 5, b = 3);\n    \n    println!(\"2 + 3 * 4 = {}\", RESULT1);\n    println!(\"(2 + 3) * 4 = {}\", RESULT2);\n    println!(\"2 ^ 3 + factorial(4) = {}\", RESULT3);\n    println!(\"2 * 5 + 3 = {}\", RESULT4);\n    \n    // Complex nested expression\n    const NESTED: i64 = const_expr!(\n        \"max(factorial(3), min(10, 20)) + abs(-5)\"\n    );\n    println!(\"max(factorial(3), min(10, 20)) + abs(-5) = {}\", NESTED);\n}",
    "key_concepts": [
      "const expression evaluation",
      "compile-time parsing",
      "const tokenization",
      "recursive descent parser",
      "const function calls",
      "variable substitution",
      "mathematical operations",
      "type-level computation",
      "static assertions",
      "zero-runtime overhead"
    ]
  },
  {
    "prompt": "Build a compile-time type-safe SQL query builder in Rust using const functions and type-level programming. Include support for SELECT, INSERT, UPDATE, DELETE operations with type checking at compile time.",
    "response": "#![feature(const_trait_impl)]\n#![feature(generic_const_exprs)]\n#![feature(const_type_name)]\n\nuse std::marker::PhantomData;\n\n// Type-level states for query builder\nstruct SelectState;\nstruct FromState;\nstruct WhereState;\nstruct CompleteState;\n\n// Type-level markers for SQL operations\nstruct Select;\nstruct Insert;\nstruct Update;\nstruct Delete;\n\n// Column type markers\ntrait SqlType {\n    const SQL_TYPE: &'static str;\n}\n\nstruct Integer;\nstruct Text;\nstruct Real;\nstruct Boolean;\n\nimpl SqlType for Integer {\n    const SQL_TYPE: &'static str = \"INTEGER\";\n}\n\nimpl SqlType for Text {\n    const SQL_TYPE: &'static str = \"TEXT\";\n}\n\nimpl SqlType for Real {\n    const SQL_TYPE: &'static str = \"REAL\";\n}\n\nimpl SqlType for Boolean {\n    const SQL_TYPE: &'static str = \"BOOLEAN\";\n}\n\n// Column definition\nstruct Column<T: SqlType> {\n    name: &'static str,\n    _type: PhantomData<T>,\n}\n\nimpl<T: SqlType> Column<T> {\n    const fn new(name: &'static str) -> Self {\n        Self {\n            name,\n            _type: PhantomData,\n        }\n    }\n}\n\n// Table definition with compile-time schema\nstruct Table<const N: usize> {\n    name: &'static str,\n    columns: [&'static str; N],\n}\n\nimpl<const N: usize> Table<N> {\n    const fn new(name: &'static str, columns: [&'static str; N]) -> Self {\n        Self { name, columns }\n    }\n    \n    const fn has_column(&self, column: &str) -> bool {\n        let mut i = 0;\n        while i < N {\n            if const_str_eq(self.columns[i], column) {\n                return true;\n            }\n            i += 1;\n        }\n        false\n    }\n}\n\n// Const string comparison\nconst fn const_str_eq(a: &str, b: &str) -> bool {\n    let a_bytes = a.as_bytes();\n    let b_bytes = b.as_bytes();\n    \n    if a_bytes.len() != b_bytes.len() {\n        return false;\n    }\n    \n    let mut i = 0;\n    while i < a_bytes.len() {\n        if a_bytes[i] != b_bytes[i] {\n            return false;\n        }\n        i += 1;\n    }\n    true\n}\n\n// Query builder with phantom types for state management\nstruct QueryBuilder<Op, State, const N: usize> {\n    query: ConstString<1024>,\n    table: Table<N>,\n    _op: PhantomData<Op>,\n    _state: PhantomData<State>,\n}\n\n// Const string builder for compile-time query construction\nstruct ConstString<const N: usize> {\n    buffer: [u8; N],\n    len: usize,\n}\n\nimpl<const N: usize> ConstString<N> {\n    const fn new() -> Self {\n        Self {\n            buffer: [0; N],\n            len: 0,\n        }\n    }\n    \n    const fn append(mut self, s: &str) -> Self {\n        let bytes = s.as_bytes();\n        let mut i = 0;\n        \n        while i < bytes.len() && self.len < N {\n            self.buffer[self.len] = bytes[i];\n            self.len += 1;\n            i += 1;\n        }\n        \n        self\n    }\n    \n    const fn append_number(mut self, n: i64) -> Self {\n        if n == 0 {\n            if self.len < N {\n                self.buffer[self.len] = b'0';\n                self.len += 1;\n            }\n            return self;\n        }\n        \n        let mut num = n;\n        let mut digits = [0u8; 20];\n        let mut digit_count = 0;\n        let is_negative = n < 0;\n        \n        if is_negative {\n            num = -num;\n        }\n        \n        while num > 0 && digit_count < 20 {\n            digits[digit_count] = (num % 10) as u8 + b'0';\n            num /= 10;\n            digit_count += 1;\n        }\n        \n        if is_negative && self.len < N {\n            self.buffer[self.len] = b'-';\n            self.len += 1;\n        }\n        \n        let mut i = digit_count;\n        while i > 0 && self.len < N {\n            self.buffer[self.len] = digits[i - 1];\n            self.len += 1;\n            i -= 1;\n        }\n        \n        self\n    }\n    \n    const fn as_str(&self) -> &str {\n        unsafe {\n            std::str::from_utf8_unchecked(\n                std::slice::from_raw_parts(self.buffer.as_ptr(), self.len)\n            )\n        }\n    }\n}\n\n// SELECT query builder\nimpl<const N: usize> QueryBuilder<Select, SelectState, N> {\n    const fn select(table: Table<N>, columns: &[&'static str]) -> Self {\n        let mut query = ConstString::<1024>::new().append(\"SELECT \");\n        \n        let mut i = 0;\n        while i < columns.len() {\n            // Compile-time validation\n            if !table.has_column(columns[i]) {\n                panic!(\"Column does not exist in table\");\n            }\n            \n            if i > 0 {\n                query = query.append(\", \");\n            }\n            query = query.append(columns[i]);\n            i += 1;\n        }\n        \n        Self {\n            query,\n            table,\n            _op: PhantomData,\n            _state: PhantomData,\n        }\n    }\n    \n    const fn from(mut self) -> QueryBuilder<Select, FromState, N> {\n        self.query = self.query.append(\" FROM \").append(self.table.name);\n        \n        QueryBuilder {\n            query: self.query,\n            table: self.table,\n            _op: PhantomData,\n            _state: PhantomData,\n        }\n    }\n}\n\nimpl<const N: usize> QueryBuilder<Select, FromState, N> {\n    const fn where_clause(mut self, condition: &str) -> QueryBuilder<Select, WhereState, N> {\n        self.query = self.query.append(\" WHERE \").append(condition);\n        \n        QueryBuilder {\n            query: self.query,\n            table: self.table,\n            _op: PhantomData,\n            _state: PhantomData,\n        }\n    }\n    \n    const fn build(self) -> &'static str {\n        self.query.as_str()\n    }\n}\n\nimpl<const N: usize> QueryBuilder<Select, WhereState, N> {\n    const fn and(mut self, condition: &str) -> Self {\n        self.query = self.query.append(\" AND \").append(condition);\n        self\n    }\n    \n    const fn or(mut self, condition: &str) -> Self {\n        self.query = self.query.append(\" OR \").append(condition);\n        self\n    }\n    \n    const fn build(self) -> &'static str {\n        self.query.as_str()\n    }\n}\n\n// INSERT query builder\nimpl<const N: usize> QueryBuilder<Insert, SelectState, N> {\n    const fn insert_into(table: Table<N>) -> Self {\n        let query = ConstString::<1024>::new()\n            .append(\"INSERT INTO \")\n            .append(table.name);\n        \n        Self {\n            query,\n            table,\n            _op: PhantomData,\n            _state: PhantomData,\n        }\n    }\n    \n    const fn columns(mut self, columns: &[&'static str]) -> QueryBuilder<Insert, FromState, N> {\n        self.query = self.query.append(\" (\");\n        \n        let mut i = 0;\n        while i < columns.len() {\n            if !self.table.has_column(columns[i]) {\n                panic!(\"Column does not exist in table\");\n            }\n            \n            if i > 0 {\n                self.query = self.query.append(\", \");\n            }\n            self.query = self.query.append(columns[i]);\n            i += 1;\n        }\n        \n        self.query = self.query.append(\")\");\n        \n        QueryBuilder {\n            query: self.query,\n            table: self.table,\n            _op: PhantomData,\n            _state: PhantomData,\n        }\n    }\n}\n\nimpl<const N: usize> QueryBuilder<Insert, FromState, N> {\n    const fn values_str(mut self, values: &[&'static str]) -> QueryBuilder<Insert, CompleteState, N> {\n        self.query = self.query.append(\" VALUES (\");\n        \n        let mut i = 0;\n        while i < values.len() {\n            if i > 0 {\n                self.query = self.query.append(\", \");\n            }\n            self.query = self.query.append(\"'\").append(values[i]).append(\"'\");\n            i += 1;\n        }\n        \n        self.query = self.query.append(\")\");\n        \n        QueryBuilder {\n            query: self.query,\n            table: self.table,\n            _op: PhantomData,\n            _state: PhantomData,\n        }\n    }\n    \n    const fn values_int(mut self, values: &[i64]) -> QueryBuilder<Insert, CompleteState, N> {\n        self.query = self.query.append(\" VALUES (\");\n        \n        let mut i = 0;\n        while i < values.len() {\n            if i > 0 {\n                self.query = self.query.append(\", \");\n            }\n            self.query = self.query.append_number(values[i]);\n            i += 1;\n        }\n        \n        self.query = self.query.append(\")\");\n        \n        QueryBuilder {\n            query: self.query,\n            table: self.table,\n            _op: PhantomData,\n            _state: PhantomData,\n        }\n    }\n}\n\n// UPDATE query builder\nimpl<const N: usize> QueryBuilder<Update, SelectState, N> {\n    const fn update(table: Table<N>) -> Self {\n        let query = ConstString::<1024>::new()\n            .append(\"UPDATE \")\n            .append(table.name);\n        \n        Self {\n            query,\n            table,\n            _op: PhantomData,\n            _state: PhantomData,\n        }\n    }\n    \n    const fn set(mut self, column: &'static str, value: &'static str) -> QueryBuilder<Update, FromState, N> {\n        if !self.table.has_column(column) {\n            panic!(\"Column does not exist in table\");\n        }\n        \n        self.query = self.query\n            .append(\" SET \")\n            .append(column)\n            .append(\" = '\")\n            .append(value)\n            .append(\"'\");\n        \n        QueryBuilder {\n            query: self.query,\n            table: self.table,\n            _op: PhantomData,\n            _state: PhantomData,\n        }\n    }\n}\n\n// DELETE query builder\nimpl<const N: usize> QueryBuilder<Delete, SelectState, N> {\n    const fn delete_from(table: Table<N>) -> QueryBuilder<Delete, FromState, N> {\n        let query = ConstString::<1024>::new()\n            .append(\"DELETE FROM \")\n            .append(table.name);\n        \n        QueryBuilder {\n            query,\n            table,\n            _op: PhantomData,\n            _state: PhantomData,\n        }\n    }\n}\n\nimpl<const N: usize> QueryBuilder<Delete, FromState, N> {\n    const fn where_clause(mut self, condition: &str) -> QueryBuilder<Delete, WhereState, N> {\n        self.query = self.query.append(\" WHERE \").append(condition);\n        \n        QueryBuilder {\n            query: self.query,\n            table: self.table,\n            _op: PhantomData,\n            _state: PhantomData,\n        }\n    }\n    \n    const fn build(self) -> &'static str {\n        self.query.as_str()\n    }\n}\n\n// Table definitions\nconst USERS_TABLE: Table<4> = Table::new(\n    \"users\",\n    [\"id\", \"name\", \"email\", \"age\"]\n);\n\nconst POSTS_TABLE: Table<5> = Table::new(\n    \"posts\",\n    [\"id\", \"user_id\", \"title\", \"content\", \"created_at\"]\n);\n\n// Compile-time query generation\nconst SELECT_QUERY: &str = QueryBuilder::select(\n    USERS_TABLE,\n    &[\"id\", \"name\", \"email\"]\n)\n.from()\n.where_clause(\"age > 18\")\n.and(\"email LIKE '%@example.com'\")\n.build();\n\nconst INSERT_QUERY: &str = QueryBuilder::insert_into(USERS_TABLE)\n    .columns(&[\"name\", \"email\", \"age\"])\n    .values_str(&[\"John Doe\", \"john@example.com\", \"25\"])\n    .build();\n\nconst UPDATE_QUERY: &str = QueryBuilder::update(USERS_TABLE)\n    .set(\"email\", \"newemail@example.com\")\n    .where_clause(\"id = 1\")\n    .build();\n\nconst DELETE_QUERY: &str = QueryBuilder::delete_from(POSTS_TABLE)\n    .where_clause(\"created_at < '2023-01-01'\")\n    .build();\n\n// Compile-time validation examples\n// const INVALID_COLUMN: &str = QueryBuilder::select(\n//     USERS_TABLE,\n//     &[\"invalid_column\"] // This would cause a compile-time panic\n// ).from().build();\n\n// Type-safe query execution (runtime)\ntrait Executable {\n    fn execute(&self) -> Result<(), &'static str>;\n}\n\nstruct TypedQuery<T> {\n    sql: &'static str,\n    _phantom: PhantomData<T>,\n}\n\nimpl<T> TypedQuery<T> {\n    const fn new(sql: &'static str) -> Self {\n        Self {\n            sql,\n            _phantom: PhantomData,\n        }\n    }\n}\n\n// Macro for easier query building\nmacro_rules! sql_query {\n    (SELECT $($col:ident),+ FROM $table:ident WHERE $cond:expr) => {{\n        QueryBuilder::select(\n            $table,\n            &[$(stringify!($col)),+]\n        )\n        .from()\n        .where_clause($cond)\n        .build()\n    }};\n    \n    (INSERT INTO $table:ident ($($col:ident),+) VALUES ($($val:expr),+)) => {{\n        QueryBuilder::insert_into($table)\n            .columns(&[$(stringify!($col)),+])\n            .values_str(&[$($val),+])\n            .build()\n    }};\n}\n\nfn main() {\n    // All queries are generated at compile time\n    println!(\"SELECT Query: {}\", SELECT_QUERY);\n    println!(\"INSERT Query: {}\", INSERT_QUERY);\n    println!(\"UPDATE Query: {}\", UPDATE_QUERY);\n    println!(\"DELETE Query: {}\", DELETE_QUERY);\n    \n    // Using the macro\n    const MACRO_QUERY: &str = sql_query!(\n        SELECT id, name FROM USERS_TABLE WHERE \"active = true\"\n    );\n    println!(\"Macro Query: {}\", MACRO_QUERY);\n    \n    // Type-safe queries\n    const TYPED_SELECT: TypedQuery<(i32, String, String)> = TypedQuery::new(SELECT_QUERY);\n    println!(\"Typed Query SQL: {}\", TYPED_SELECT.sql);\n}",
    "key_concepts": [
      "compile-time SQL generation",
      "type-safe query builder",
      "const string manipulation",
      "phantom types",
      "type-level state machine",
      "compile-time validation",
      "const table schemas",
      "zero-cost SQL abstractions",
      "type-level programming",
      "const generic expressions"
    ]
  },
  {
    "prompt": "Implement a thread pool with work stealing in Rust using crossbeam channels and atomic operations. Include task scheduling, worker threads, load balancing, and graceful shutdown with backpressure handling.",
    "response": "use std::sync::{Arc, Mutex, Condvar, atomic::{AtomicBool, AtomicUsize, Ordering}};\nuse std::thread::{self, JoinHandle};\nuse std::time::{Duration, Instant};\nuse crossbeam::deque::{Injector, Stealer, Worker};\nuse crossbeam::channel::{self, Receiver, Sender};\nuse std::collections::VecDeque;\n\n// Task trait for work items\npub trait Task: Send + 'static {\n    fn execute(self: Box<Self>);\n    fn priority(&self) -> Priority {\n        Priority::Normal\n    }\n}\n\n#[derive(Debug, Clone, Copy, PartialEq, Eq, PartialOrd, Ord)]\npub enum Priority {\n    Low = 0,\n    Normal = 1,\n    High = 2,\n    Critical = 3,\n}\n\n// Simple function task wrapper\npub struct FnTask<F>\nwhere\n    F: FnOnce() + Send + 'static,\n{\n    func: Option<F>,\n    priority: Priority,\n}\n\nimpl<F> FnTask<F>\nwhere\n    F: FnOnce() + Send + 'static,\n{\n    pub fn new(func: F) -> Self {\n        Self {\n            func: Some(func),\n            priority: Priority::Normal,\n        }\n    }\n    \n    pub fn with_priority(func: F, priority: Priority) -> Self {\n        Self {\n            func: Some(func),\n            priority,\n        }\n    }\n}\n\nimpl<F> Task for FnTask<F>\nwhere\n    F: FnOnce() + Send + 'static,\n{\n    fn execute(mut self: Box<Self>) {\n        if let Some(func) = self.func.take() {\n            func();\n        }\n    }\n    \n    fn priority(&self) -> Priority {\n        self.priority\n    }\n}\n\n// Work-stealing thread pool\npub struct ThreadPool {\n    workers: Vec<WorkerThread>,\n    global_queue: Arc<Injector<Box<dyn Task>>>,\n    shutdown: Arc<AtomicBool>,\n    active_tasks: Arc<AtomicUsize>,\n    max_queue_size: usize,\n    backpressure_signal: Arc<(Mutex<bool>, Condvar)>,\n}\n\nstruct WorkerThread {\n    id: usize,\n    handle: Option<JoinHandle<()>>,\n    local_queue: Worker<Box<dyn Task>>,\n    stealer: Stealer<Box<dyn Task>>,\n}\n\nimpl ThreadPool {\n    pub fn new(num_threads: usize) -> Self {\n        Self::with_config(num_threads, 10000)\n    }\n    \n    pub fn with_config(num_threads: usize, max_queue_size: usize) -> Self {\n        let global_queue = Arc::new(Injector::new());\n        let shutdown = Arc::new(AtomicBool::new(false));\n        let active_tasks = Arc::new(AtomicUsize::new(0));\n        let backpressure_signal = Arc::new((Mutex::new(false), Condvar::new()));\n        \n        let mut workers = Vec::with_capacity(num_threads);\n        let mut stealers = Vec::with_capacity(num_threads);\n        \n        // Create workers and collect stealers\n        for id in 0..num_threads {\n            let local_queue = Worker::new_fifo();\n            let stealer = local_queue.stealer();\n            stealers.push(stealer.clone());\n            \n            workers.push(WorkerThread {\n                id,\n                handle: None,\n                local_queue,\n                stealer,\n            });\n        }\n        \n        // Start worker threads\n        for (i, worker) in workers.iter_mut().enumerate() {\n            let global_queue = Arc::clone(&global_queue);\n            let shutdown = Arc::clone(&shutdown);\n            let active_tasks = Arc::clone(&active_tasks);\n            let backpressure_signal = Arc::clone(&backpressure_signal);\n            let stealers = stealers.clone();\n            let worker_stealer = worker.stealer.clone();\n            \n            let handle = thread::Builder::new()\n                .name(format!(\"worker-{}\", i))\n                .spawn(move || {\n                    Self::worker_loop(\n                        i,\n                        worker_stealer,\n                        global_queue,\n                        stealers,\n                        shutdown,\n                        active_tasks,\n                        backpressure_signal,\n                    );\n                })\n                .expect(\"Failed to spawn worker thread\");\n            \n            worker.handle = Some(handle);\n        }\n        \n        Self {\n            workers,\n            global_queue,\n            shutdown,\n            active_tasks,\n            max_queue_size,\n            backpressure_signal,\n        }\n    }\n    \n    pub fn execute<T>(&self, task: T) -> Result<(), &'static str>\n    where\n        T: Task,\n    {\n        if self.shutdown.load(Ordering::Relaxed) {\n            return Err(\"Thread pool is shutting down\");\n        }\n        \n        // Check backpressure\n        if self.global_queue.len() > self.max_queue_size {\n            let (lock, cvar) = &*self.backpressure_signal;\n            let mut backpressure = lock.lock().unwrap();\n            *backpressure = true;\n            \n            // Wait for queue to drain or timeout\n            let timeout = Duration::from_millis(100);\n            let _ = cvar.wait_timeout(backpressure, timeout);\n            \n            if self.global_queue.len() > self.max_queue_size {\n                return Err(\"Queue is full - backpressure activated\");\n            }\n        }\n        \n        // Try to push to a local queue first (better cache locality)\n        let task = Box::new(task) as Box<dyn Task>;\n        \n        // Round-robin assignment to worker queues\n        let worker_id = self.active_tasks.load(Ordering::Relaxed) % self.workers.len();\n        \n        if let Err(task) = self.workers[worker_id].local_queue.push(task) {\n            // Local queue full, push to global queue\n            self.global_queue.push(task);\n        }\n        \n        self.active_tasks.fetch_add(1, Ordering::Relaxed);\n        Ok(())\n    }\n    \n    pub fn execute_with_priority<T>(&self, task: T) -> Result<(), &'static str>\n    where\n        T: Task,\n    {\n        // For high priority tasks, always use global queue for faster stealing\n        if task.priority() >= Priority::High {\n            if self.shutdown.load(Ordering::Relaxed) {\n                return Err(\"Thread pool is shutting down\");\n            }\n            \n            let task = Box::new(task) as Box<dyn Task>;\n            self.global_queue.push(task);\n            self.active_tasks.fetch_add(1, Ordering::Relaxed);\n            Ok(())\n        } else {\n            self.execute(task)\n        }\n    }\n    \n    fn worker_loop(\n        worker_id: usize,\n        local_queue: Stealer<Box<dyn Task>>,\n        global_queue: Arc<Injector<Box<dyn Task>>>,\n        stealers: Vec<Stealer<Box<dyn Task>>>,\n        shutdown: Arc<AtomicBool>,\n        active_tasks: Arc<AtomicUsize>,\n        backpressure_signal: Arc<(Mutex<bool>, Condvar)>,\n    ) {\n        let mut idle_count = 0;\n        let max_idle = 100;\n        \n        while !shutdown.load(Ordering::Relaxed) {\n            let task = Self::find_task(worker_id, &local_queue, &global_queue, &stealers);\n            \n            match task {\n                Some(task) => {\n                    idle_count = 0;\n                    \n                    // Execute the task\n                    let start = Instant::now();\n                    task.execute();\n                    let duration = start.elapsed();\n                    \n                    // Update metrics\n                    active_tasks.fetch_sub(1, Ordering::Relaxed);\n                    \n                    // Signal backpressure relief if queue is getting empty\n                    if global_queue.len() < 1000 {\n                        let (lock, cvar) = &*backpressure_signal;\n                        let mut backpressure = lock.lock().unwrap();\n                        if *backpressure {\n                            *backpressure = false;\n                            cvar.notify_all();\n                        }\n                    }\n                    \n                    // Log slow tasks\n                    if duration > Duration::from_millis(100) {\n                        eprintln!(\"Worker {}: Slow task completed in {:?}\", worker_id, duration);\n                    }\n                }\n                None => {\n                    idle_count += 1;\n                    \n                    if idle_count > max_idle {\n                        // Longer sleep for extended idle periods\n                        thread::sleep(Duration::from_millis(10));\n                        idle_count = 0;\n                    } else {\n                        // Short yield for brief idle periods\n                        thread::yield_now();\n                    }\n                }\n            }\n        }\n        \n        println!(\"Worker {} shutting down\", worker_id);\n    }\n    \n    fn find_task(\n        worker_id: usize,\n        local_queue: &Stealer<Box<dyn Task>>,\n        global_queue: &Injector<Box<dyn Task>>,\n        stealers: &[Stealer<Box<dyn Task>>],\n    ) -> Option<Box<dyn Task>> {\n        // 1. Try local queue first\n        if let crossbeam::deque::Steal::Success(task) = local_queue.steal() {\n            return Some(task);\n        }\n        \n        // 2. Try global queue\n        if let crossbeam::deque::Steal::Success(task) = global_queue.steal() {\n            return Some(task);\n        }\n        \n        // 3. Try stealing from other workers (work stealing)\n        for (i, stealer) in stealers.iter().enumerate() {\n            if i != worker_id {\n                if let crossbeam::deque::Steal::Success(task) = stealer.steal() {\n                    return Some(task);\n                }\n            }\n        }\n        \n        None\n    }\n    \n    pub fn active_tasks(&self) -> usize {\n        self.active_tasks.load(Ordering::Relaxed)\n    }\n    \n    pub fn queue_len(&self) -> usize {\n        self.global_queue.len()\n    }\n    \n    pub fn shutdown_graceful(self, timeout: Duration) -> Result<(), &'static str> {\n        println!(\"Initiating graceful shutdown...\");\n        \n        // Stop accepting new tasks\n        self.shutdown.store(true, Ordering::Relaxed);\n        \n        // Wait for active tasks to complete\n        let start = Instant::now();\n        while self.active_tasks.load(Ordering::Relaxed) > 0 && start.elapsed() < timeout {\n            thread::sleep(Duration::from_millis(10));\n        }\n        \n        // Join all worker threads\n        for mut worker in self.workers {\n            if let Some(handle) = worker.handle.take() {\n                let _ = handle.join();\n            }\n        }\n        \n        let remaining_tasks = self.active_tasks.load(Ordering::Relaxed);\n        if remaining_tasks > 0 {\n            Err(\"Some tasks did not complete within timeout\")\n        } else {\n            println!(\"Graceful shutdown completed\");\n            Ok(())\n        }\n    }\n}\n\n// Thread pool statistics\npub struct PoolStats {\n    pub active_tasks: usize,\n    pub queue_length: usize,\n    pub total_workers: usize,\n}\n\nimpl ThreadPool {\n    pub fn stats(&self) -> PoolStats {\n        PoolStats {\n            active_tasks: self.active_tasks(),\n            queue_length: self.queue_len(),\n            total_workers: self.workers.len(),\n        }\n    }\n}\n\n// Adaptive thread pool that adjusts worker count based on load\npub struct AdaptiveThreadPool {\n    core_pool: ThreadPool,\n    min_threads: usize,\n    max_threads: usize,\n    current_threads: AtomicUsize,\n    load_monitor: Arc<AtomicUsize>,\n}\n\nimpl AdaptiveThreadPool {\n    pub fn new(min_threads: usize, max_threads: usize) -> Self {\n        let core_pool = ThreadPool::new(min_threads);\n        \n        Self {\n            core_pool,\n            min_threads,\n            max_threads,\n            current_threads: AtomicUsize::new(min_threads),\n            load_monitor: Arc::new(AtomicUsize::new(0)),\n        }\n    }\n    \n    pub fn execute<T>(&self, task: T) -> Result<(), &'static str>\n    where\n        T: Task,\n    {\n        // Update load metrics\n        self.load_monitor.fetch_add(1, Ordering::Relaxed);\n        \n        // Auto-scale based on queue length\n        let queue_len = self.core_pool.queue_len();\n        let current_threads = self.current_threads.load(Ordering::Relaxed);\n        \n        if queue_len > current_threads * 10 && current_threads < self.max_threads {\n            // Scale up\n            println!(\"Scaling up: queue_len={}, current_threads={}\", queue_len, current_threads);\n            // In a real implementation, you'd add more worker threads here\n        } else if queue_len < current_threads * 2 && current_threads > self.min_threads {\n            // Scale down\n            println!(\"Scaling down: queue_len={}, current_threads={}\", queue_len, current_threads);\n            // In a real implementation, you'd remove worker threads here\n        }\n        \n        self.core_pool.execute(task)\n    }\n}\n\n// Example usage and testing\nfn main() -> Result<(), Box<dyn std::error::Error>> {\n    // Create thread pool\n    let pool = ThreadPool::new(4);\n    \n    println!(\"Starting thread pool with 4 workers\");\n    \n    // Submit various tasks\n    for i in 0..20 {\n        let task = FnTask::with_priority(\n            move || {\n                println!(\"Executing task {}\", i);\n                thread::sleep(Duration::from_millis(100 + (i % 3) * 50));\n                println!(\"Task {} completed\", i);\n            },\n            if i % 5 == 0 { Priority::High } else { Priority::Normal }\n        );\n        \n        pool.execute(task)?;\n    }\n    \n    // Submit a CPU-intensive task\n    pool.execute(FnTask::new(|| {\n        println!(\"Starting CPU-intensive task\");\n        let mut sum = 0u64;\n        for i in 0..10_000_000 {\n            sum = sum.wrapping_add(i);\n        }\n        println!(\"CPU-intensive task completed: sum = {}\", sum);\n    }))?;\n    \n    // Monitor pool statistics\n    for _ in 0..10 {\n        let stats = pool.stats();\n        println!(\n            \"Pool stats - Active: {}, Queue: {}, Workers: {}\",\n            stats.active_tasks, stats.queue_length, stats.total_workers\n        );\n        thread::sleep(Duration::from_millis(200));\n    }\n    \n    // Test backpressure by overwhelming the pool\n    println!(\"Testing backpressure...\");\n    for i in 0..1000 {\n        match pool.execute(FnTask::new(move || {\n            thread::sleep(Duration::from_millis(10));\n        })) {\n            Ok(()) => {},\n            Err(e) => {\n                println!(\"Backpressure triggered at task {}: {}\", i, e);\n                break;\n            }\n        }\n    }\n    \n    // Graceful shutdown\n    pool.shutdown_graceful(Duration::from_secs(5))?;\n    \n    Ok(())\n}",
    "key_concepts": [
      "work stealing",
      "thread pools",
      "crossbeam channels",
      "atomic operations",
      "backpressure handling",
      "load balancing",
      "graceful shutdown",
      "task scheduling",
      "concurrent data structures",
      "performance monitoring"
    ]
  },
  {
    "prompt": "Build a lock-free concurrent HashMap in Rust using atomic operations and hazard pointers for memory management. Include resize operations, thread-safe iteration, and compare with std::collections::HashMap performance.",
    "response": "use std::sync::atomic::{AtomicPtr, AtomicUsize, AtomicBool, Ordering};\nuse std::ptr::{self, NonNull};\nuse std::mem::{self, MaybeUninit};\nuse std::hash::{Hash, Hasher, BuildHasher, RandomState};\nuse std::marker::PhantomData;\nuse std::thread;\nuse std::time::{Duration, Instant};\nuse std::collections::HashMap as StdHashMap;\nuse crossbeam_epoch::{self as epoch, Atomic, Owned, Shared, Guard, Collector};\n\n// Hash table entry\nstruct Entry<K, V> {\n    key: K,\n    value: V,\n    hash: u64,\n    next: Atomic<Entry<K, V>>,\n}\n\nimpl<K, V> Entry<K, V> {\n    fn new(key: K, value: V, hash: u64) -> Self {\n        Self {\n            key,\n            value,\n            hash,\n            next: Atomic::null(),\n        }\n    }\n}\n\n// Lock-free hash table\npub struct LockFreeHashMap<K, V, S = RandomState> {\n    buckets: AtomicPtr<Atomic<Entry<K, V>>>,\n    bucket_count: AtomicUsize,\n    size: AtomicUsize,\n    hash_builder: S,\n    resize_in_progress: AtomicBool,\n    collector: Collector,\n}\n\nimpl<K, V> LockFreeHashMap<K, V, RandomState> {\n    pub fn new() -> Self {\n        Self::with_capacity_and_hasher(16, RandomState::new())\n    }\n    \n    pub fn with_capacity(capacity: usize) -> Self {\n        Self::with_capacity_and_hasher(capacity.next_power_of_two(), RandomState::new())\n    }\n}\n\nimpl<K, V, S> LockFreeHashMap<K, V, S>\nwhere\n    K: Hash + Eq,\n    S: BuildHasher,\n{\n    pub fn with_capacity_and_hasher(capacity: usize, hash_builder: S) -> Self {\n        let bucket_count = capacity.max(16).next_power_of_two();\n        let buckets = Self::allocate_buckets(bucket_count);\n        \n        Self {\n            buckets: AtomicPtr::new(buckets),\n            bucket_count: AtomicUsize::new(bucket_count),\n            size: AtomicUsize::new(0),\n            hash_builder,\n            resize_in_progress: AtomicBool::new(false),\n            collector: Collector::new(),\n        }\n    }\n    \n    fn allocate_buckets(count: usize) -> *mut Atomic<Entry<K, V>> {\n        let layout = std::alloc::Layout::array::<Atomic<Entry<K, V>>>(count).unwrap();\n        let ptr = unsafe { std::alloc::alloc(layout) as *mut Atomic<Entry<K, V>> };\n        \n        if ptr.is_null() {\n            std::alloc::handle_alloc_error(layout);\n        }\n        \n        // Initialize all buckets to null\n        for i in 0..count {\n            unsafe {\n                ptr.add(i).write(Atomic::null());\n            }\n        }\n        \n        ptr\n    }\n    \n    fn hash_key(&self, key: &K) -> u64 {\n        let mut hasher = self.hash_builder.build_hasher();\n        key.hash(&mut hasher);\n        hasher.finish()\n    }\n    \n    fn bucket_index(&self, hash: u64, bucket_count: usize) -> usize {\n        (hash as usize) & (bucket_count - 1)\n    }\n    \n    pub fn insert(&self, key: K, value: V) -> Option<V> {\n        let guard = &self.collector.register().pin();\n        let hash = self.hash_key(&key);\n        \n        loop {\n            let bucket_count = self.bucket_count.load(Ordering::Acquire);\n            let buckets = self.buckets.load(Ordering::Acquire);\n            \n            if buckets.is_null() {\n                continue; // Resize in progress\n            }\n            \n            let bucket_idx = self.bucket_index(hash, bucket_count);\n            let bucket = unsafe { &*buckets.add(bucket_idx) };\n            \n            // Try to insert or update\n            let mut current = bucket.load(Ordering::Acquire, guard);\n            \n            loop {\n                if current.is_null() {\n                    // Empty bucket, try to insert new entry\n                    let new_entry = Owned::new(Entry::new(key, value, hash));\n                    \n                    match bucket.compare_exchange_weak(\n                        current,\n                        new_entry,\n                        Ordering::Release,\n                        Ordering::Relaxed,\n                        guard,\n                    ) {\n                        Ok(_) => {\n                            self.size.fetch_add(1, Ordering::Relaxed);\n                            self.try_resize(guard);\n                            return None;\n                        }\n                        Err(e) => {\n                            current = e.current;\n                            continue;\n                        }\n                    }\n                } else {\n                    let entry = unsafe { current.deref() };\n                    \n                    if entry.hash == hash && entry.key == key {\n                        // Key found, this is an update operation\n                        // For simplicity, we'll create a new entry (in practice, you'd use CAS on value)\n                        let new_entry = Owned::new(Entry::new(key, value, hash));\n                        new_entry.next.store(entry.next.load(Ordering::Acquire, guard), Ordering::Relaxed);\n                        \n                        match bucket.compare_exchange_weak(\n                            current,\n                            new_entry,\n                            Ordering::Release,\n                            Ordering::Relaxed,\n                            guard,\n                        ) {\n                            Ok(_) => {\n                                unsafe { guard.defer_destroy(current) };\n                                // Return old value (simplified - would need to extract actual old value)\n                                return Some(entry.value);\n                            }\n                            Err(e) => {\n                                current = e.current;\n                                continue;\n                            }\n                        }\n                    } else {\n                        // Different key, check next in chain\n                        let next = entry.next.load(Ordering::Acquire, guard);\n                        if next.is_null() {\n                            // End of chain, insert new entry\n                            let new_entry = Owned::new(Entry::new(key, value, hash));\n                            \n                            match entry.next.compare_exchange_weak(\n                                next,\n                                new_entry,\n                                Ordering::Release,\n                                Ordering::Relaxed,\n                                guard,\n                            ) {\n                                Ok(_) => {\n                                    self.size.fetch_add(1, Ordering::Relaxed);\n                                    self.try_resize(guard);\n                                    return None;\n                                }\n                                Err(e) => {\n                                    current = e.current;\n                                    continue;\n                                }\n                            }\n                        } else {\n                            current = next;\n                        }\n                    }\n                }\n            }\n        }\n    }\n    \n    pub fn get<'g>(&'g self, key: &K, guard: &'g Guard) -> Option<&'g V> {\n        let hash = self.hash_key(key);\n        let bucket_count = self.bucket_count.load(Ordering::Acquire);\n        let buckets = self.buckets.load(Ordering::Acquire);\n        \n        if buckets.is_null() {\n            return None;\n        }\n        \n        let bucket_idx = self.bucket_index(hash, bucket_count);\n        let bucket = unsafe { &*buckets.add(bucket_idx) };\n        \n        let mut current = bucket.load(Ordering::Acquire, guard);\n        \n        while !current.is_null() {\n            let entry = unsafe { current.deref() };\n            \n            if entry.hash == hash && entry.key == *key {\n                return Some(&entry.value);\n            }\n            \n            current = entry.next.load(Ordering::Acquire, guard);\n        }\n        \n        None\n    }\n    \n    pub fn remove(&self, key: &K) -> Option<V> {\n        let guard = &self.collector.register().pin();\n        let hash = self.hash_key(key);\n        let bucket_count = self.bucket_count.load(Ordering::Acquire);\n        let buckets = self.buckets.load(Ordering::Acquire);\n        \n        if buckets.is_null() {\n            return None;\n        }\n        \n        let bucket_idx = self.bucket_index(hash, bucket_count);\n        let bucket = unsafe { &*buckets.add(bucket_idx) };\n        \n        loop {\n            let current = bucket.load(Ordering::Acquire, guard);\n            \n            if current.is_null() {\n                return None;\n            }\n            \n            let entry = unsafe { current.deref() };\n            \n            if entry.hash == hash && entry.key == *key {\n                // Found the entry to remove\n                let next = entry.next.load(Ordering::Acquire, guard);\n                \n                match bucket.compare_exchange_weak(\n                    current,\n                    next,\n                    Ordering::Release,\n                    Ordering::Relaxed,\n                    guard,\n                ) {\n                    Ok(_) => {\n                        self.size.fetch_sub(1, Ordering::Relaxed);\n                        unsafe { guard.defer_destroy(current) };\n                        return Some(entry.value);\n                    }\n                    Err(_) => continue,\n                }\n            } else {\n                // Check if next entry matches\n                let mut prev = current;\n                let mut current = entry.next.load(Ordering::Acquire, guard);\n                \n                while !current.is_null() {\n                    let entry = unsafe { current.deref() };\n                    \n                    if entry.hash == hash && entry.key == *key {\n                        let next = entry.next.load(Ordering::Acquire, guard);\n                        let prev_entry = unsafe { prev.deref() };\n                        \n                        match prev_entry.next.compare_exchange_weak(\n                            current,\n                            next,\n                            Ordering::Release,\n                            Ordering::Relaxed,\n                            guard,\n                        ) {\n                            Ok(_) => {\n                                self.size.fetch_sub(1, Ordering::Relaxed);\n                                unsafe { guard.defer_destroy(current) };\n                                return Some(entry.value);\n                            }\n                            Err(_) => break,\n                        }\n                    }\n                    \n                    prev = current;\n                    current = entry.next.load(Ordering::Acquire, guard);\n                }\n                \n                return None;\n            }\n        }\n    }\n    \n    fn try_resize(&self, guard: &Guard) {\n        let size = self.size.load(Ordering::Relaxed);\n        let bucket_count = self.bucket_count.load(Ordering::Relaxed);\n        \n        // Resize when load factor > 0.75\n        if size > bucket_count * 3 / 4 {\n            self.resize(bucket_count * 2, guard);\n        }\n    }\n    \n    fn resize(&self, new_bucket_count: usize, guard: &Guard) {\n        if !self.resize_in_progress.compare_exchange(\n            false,\n            true,\n            Ordering::Acquire,\n            Ordering::Relaxed,\n        ).is_ok() {\n            return; // Another thread is already resizing\n        }\n        \n        let old_buckets = self.buckets.load(Ordering::Acquire);\n        let old_bucket_count = self.bucket_count.load(Ordering::Acquire);\n        \n        if old_bucket_count >= new_bucket_count {\n            self.resize_in_progress.store(false, Ordering::Release);\n            return;\n        }\n        \n        let new_buckets = Self::allocate_buckets(new_bucket_count);\n        \n        // Migrate entries from old buckets to new buckets\n        for i in 0..old_bucket_count {\n            let old_bucket = unsafe { &*old_buckets.add(i) };\n            let mut current = old_bucket.load(Ordering::Acquire, guard);\n            \n            while !current.is_null() {\n                let entry = unsafe { current.deref() };\n                let next = entry.next.load(Ordering::Acquire, guard);\n                \n                // Calculate new bucket index\n                let new_bucket_idx = self.bucket_index(entry.hash, new_bucket_count);\n                let new_bucket = unsafe { &*new_buckets.add(new_bucket_idx) };\n                \n                // Move entry to new bucket (simplified)\n                let new_entry = Owned::new(Entry::new(entry.key, entry.value, entry.hash));\n                let old_head = new_bucket.load(Ordering::Acquire, guard);\n                new_entry.next.store(old_head, Ordering::Relaxed);\n                new_bucket.store(new_entry, Ordering::Release);\n                \n                current = next;\n            }\n        }\n        \n        // Atomically switch to new buckets\n        self.buckets.store(new_buckets, Ordering::Release);\n        self.bucket_count.store(new_bucket_count, Ordering::Release);\n        \n        // Schedule old buckets for deferred destruction\n        unsafe {\n            guard.defer(move || {\n                let layout = std::alloc::Layout::array::<Atomic<Entry<K, V>>>(old_bucket_count).unwrap();\n                std::alloc::dealloc(old_buckets as *mut u8, layout);\n            });\n        }\n        \n        self.resize_in_progress.store(false, Ordering::Release);\n        println!(\"Resized hash table from {} to {} buckets\", old_bucket_count, new_bucket_count);\n    }\n    \n    pub fn len(&self) -> usize {\n        self.size.load(Ordering::Relaxed)\n    }\n    \n    pub fn is_empty(&self) -> bool {\n        self.len() == 0\n    }\n    \n    // Thread-safe iteration (simplified)\n    pub fn iter<'g>(&'g self, guard: &'g Guard) -> LockFreeIterator<'g, K, V> {\n        LockFreeIterator {\n            map: self,\n            bucket_idx: 0,\n            current_entry: Shared::null(),\n            guard,\n        }\n    }\n}\n\n// Lock-free iterator\npub struct LockFreeIterator<'g, K, V> {\n    map: &'g LockFreeHashMap<K, V>,\n    bucket_idx: usize,\n    current_entry: Shared<'g, Entry<K, V>>,\n    guard: &'g Guard,\n}\n\nimpl<'g, K, V> Iterator for LockFreeIterator<'g, K, V> {\n    type Item = (&'g K, &'g V);\n    \n    fn next(&mut self) -> Option<Self::Item> {\n        loop {\n            if !self.current_entry.is_null() {\n                let entry = unsafe { self.current_entry.deref() };\n                self.current_entry = entry.next.load(Ordering::Acquire, self.guard);\n                return Some((&entry.key, &entry.value));\n            }\n            \n            let bucket_count = self.map.bucket_count.load(Ordering::Acquire);\n            if self.bucket_idx >= bucket_count {\n                return None;\n            }\n            \n            let buckets = self.map.buckets.load(Ordering::Acquire);\n            if buckets.is_null() {\n                return None;\n            }\n            \n            let bucket = unsafe { &*buckets.add(self.bucket_idx) };\n            self.current_entry = bucket.load(Ordering::Acquire, self.guard);\n            self.bucket_idx += 1;\n        }\n    }\n}\n\n// Performance comparison\nfn benchmark_comparison() {\n    const NUM_OPERATIONS: usize = 100_000;\n    const NUM_THREADS: usize = 4;\n    \n    println!(\"Benchmarking HashMap implementations...\");\n    \n    // Benchmark lock-free HashMap\n    let lock_free_map = std::sync::Arc::new(LockFreeHashMap::new());\n    let start = Instant::now();\n    \n    let handles: Vec<_> = (0..NUM_THREADS).map(|thread_id| {\n        let map = lock_free_map.clone();\n        thread::spawn(move || {\n            for i in 0..NUM_OPERATIONS / NUM_THREADS {\n                let key = thread_id * (NUM_OPERATIONS / NUM_THREADS) + i;\n                map.insert(key, key * 2);\n                \n                if i % 100 == 0 {\n                    let guard = &map.collector.register().pin();\n                    map.get(&key, guard);\n                }\n            }\n        })\n    }).collect();\n    \n    for handle in handles {\n        handle.join().unwrap();\n    }\n    \n    let lock_free_duration = start.elapsed();\n    println!(\"Lock-free HashMap: {:?} for {} operations\", lock_free_duration, NUM_OPERATIONS);\n    \n    // Benchmark std::HashMap with Mutex\n    let std_map = std::sync::Arc::new(std::sync::Mutex::new(StdHashMap::new()));\n    let start = Instant::now();\n    \n    let handles: Vec<_> = (0..NUM_THREADS).map(|thread_id| {\n        let map = std_map.clone();\n        thread::spawn(move || {\n            for i in 0..NUM_OPERATIONS / NUM_THREADS {\n                let key = thread_id * (NUM_OPERATIONS / NUM_THREADS) + i;\n                \n                {\n                    let mut guard = map.lock().unwrap();\n                    guard.insert(key, key * 2);\n                }\n                \n                if i % 100 == 0 {\n                    let guard = map.lock().unwrap();\n                    guard.get(&key);\n                }\n            }\n        })\n    }).collect();\n    \n    for handle in handles {\n        handle.join().unwrap();\n    }\n    \n    let std_duration = start.elapsed();\n    println!(\"Std HashMap + Mutex: {:?} for {} operations\", std_duration, NUM_OPERATIONS);\n    \n    let speedup = std_duration.as_nanos() as f64 / lock_free_duration.as_nanos() as f64;\n    println!(\"Lock-free speedup: {:.2}x\", speedup);\n}\n\nfn main() {\n    let map = LockFreeHashMap::new();\n    \n    // Basic operations\n    println!(\"Testing basic operations...\");\n    map.insert(\"key1\", \"value1\");\n    map.insert(\"key2\", \"value2\");\n    map.insert(\"key3\", \"value3\");\n    \n    let guard = &map.collector.register().pin();\n    \n    println!(\"key1: {:?}\", map.get(&\"key1\", guard));\n    println!(\"key2: {:?}\", map.get(&\"key2\", guard));\n    println!(\"Map size: {}\", map.len());\n    \n    // Test iteration\n    println!(\"Iterating over map:\");\n    for (key, value) in map.iter(guard) {\n        println!(\"  {} -> {}\", key, value);\n    }\n    \n    // Test removal\n    println!(\"Removed key2: {:?}\", map.remove(&\"key2\"));\n    println!(\"Map size after removal: {}\", map.len());\n    \n    // Test concurrent operations\n    println!(\"Testing concurrent operations...\");\n    let map = std::sync::Arc::new(LockFreeHashMap::new());\n    \n    let handles: Vec<_> = (0..4).map(|thread_id| {\n        let map = map.clone();\n        thread::spawn(move || {\n            for i in 0..1000 {\n                let key = format!(\"thread_{}_key_{}\", thread_id, i);\n                let value = format!(\"value_{}\", i);\n                map.insert(key, value);\n            }\n        })\n    }).collect();\n    \n    for handle in handles {\n        handle.join().unwrap();\n    }\n    \n    println!(\"Final map size: {}\", map.len());\n    \n    // Performance comparison\n    benchmark_comparison();\n}",
    "key_concepts": [
      "lock-free data structures",
      "atomic operations",
      "hazard pointers",
      "crossbeam epoch",
      "memory reclamation",
      "concurrent hash table",
      "compare-and-swap",
      "ABA problem prevention",
      "thread-safe iteration",
      "performance benchmarking"
    ]
  },
  {
    "prompt": "Create a producer-consumer system in Rust using multiple channel types (mpsc, crossbeam, flume) with different message patterns, backpressure handling, and priority queues. Include performance analysis and graceful shutdown.",
    "response": "use std::sync::{Arc, Mutex, Condvar};\nuse std::sync::atomic::{AtomicBool, AtomicUsize, Ordering};\nuse std::thread::{self, JoinHandle};\nuse std::time::{Duration, Instant};\nuse std::collections::{BinaryHeap, VecDeque};\nuse std::cmp::Reverse;\n\nuse tokio::sync::{mpsc as tokio_mpsc, oneshot};\nuse crossbeam::channel::{self as crossbeam_channel, Receiver, Sender};\nuse flume;\n\n// Message types for different communication patterns\n#[derive(Debug, Clone, PartialEq, Eq)]\npub struct Message {\n    pub id: usize,\n    pub priority: Priority,\n    pub payload: MessagePayload,\n    pub timestamp: std::time::Instant,\n}\n\n#[derive(Debug, Clone, PartialEq, Eq, PartialOrd, Ord)]\npub enum Priority {\n    Low = 1,\n    Normal = 2,\n    High = 3,\n    Critical = 4,\n}\n\n#[derive(Debug, Clone, PartialEq, Eq)]\npub enum MessagePayload {\n    Text(String),\n    Binary(Vec<u8>),\n    Control(ControlMessage),\n    Batch(Vec<String>),\n}\n\n#[derive(Debug, Clone, PartialEq, Eq)]\npub enum ControlMessage {\n    Start,\n    Stop,\n    Pause,\n    Resume,\n    Shutdown,\n}\n\n// Backpressure strategy\n#[derive(Debug, Clone)]\npub enum BackpressureStrategy {\n    Block,\n    Drop,\n    DropOldest,\n    Overflow(usize), // Maximum buffer size before applying strategy\n}\n\n// Channel type selection\n#[derive(Debug, Clone)]\npub enum ChannelType {\n    StdMpsc,\n    Crossbeam(usize), // buffer size\n    Flume(usize),     // buffer size\n    TokioMpsc(usize), // buffer size\n}\n\n// Producer configuration\n#[derive(Debug, Clone)]\npub struct ProducerConfig {\n    pub id: usize,\n    pub message_rate: Duration, // Delay between messages\n    pub batch_size: usize,\n    pub priority_distribution: [f32; 4], // Low, Normal, High, Critical\n    pub total_messages: Option<usize>,\n}\n\n// Consumer configuration\n#[derive(Debug, Clone)]\npub struct ConsumerConfig {\n    pub id: usize,\n    pub processing_time: Duration,\n    pub batch_processing: bool,\n    pub error_rate: f32, // Simulated error rate (0.0 - 1.0)\n}\n\n// System metrics\n#[derive(Debug, Default)]\npub struct SystemMetrics {\n    pub messages_produced: AtomicUsize,\n    pub messages_consumed: AtomicUsize,\n    pub messages_dropped: AtomicUsize,\n    pub processing_errors: AtomicUsize,\n    pub total_latency_ns: AtomicUsize,\n    pub max_queue_size: AtomicUsize,\n}\n\nimpl SystemMetrics {\n    pub fn throughput_per_second(&self, duration: Duration) -> f64 {\n        let consumed = self.messages_consumed.load(Ordering::Relaxed) as f64;\n        consumed / duration.as_secs_f64()\n    }\n    \n    pub fn average_latency_ms(&self) -> f64 {\n        let total_latency = self.total_latency_ns.load(Ordering::Relaxed);\n        let message_count = self.messages_consumed.load(Ordering::Relaxed);\n        \n        if message_count > 0 {\n            (total_latency / message_count) as f64 / 1_000_000.0\n        } else {\n            0.0\n        }\n    }\n    \n    pub fn error_rate(&self) -> f64 {\n        let errors = self.processing_errors.load(Ordering::Relaxed) as f64;\n        let total = self.messages_consumed.load(Ordering::Relaxed) as f64;\n        \n        if total > 0.0 {\n            errors / total\n        } else {\n            0.0\n        }\n    }\n}\n\n// Priority queue wrapper for different channel types\npub struct PriorityChannelSender<T> {\n    sender: Box<dyn PrioritySender<T> + Send>,\n    backpressure: BackpressureStrategy,\n    queue_size: Arc<AtomicUsize>,\n    max_size: usize,\n}\n\npub trait PrioritySender<T>: Send {\n    fn send(&self, item: T) -> Result<(), T>;\n    fn try_send(&self, item: T) -> Result<(), T>;\n}\n\n// Std mpsc priority sender\nstruct StdMpscSender<T> {\n    sender: std::sync::mpsc::Sender<T>,\n}\n\nimpl<T> PrioritySender<T> for StdMpscSender<T> {\n    fn send(&self, item: T) -> Result<(), T> {\n        self.sender.send(item).map_err(|e| e.0)\n    }\n    \n    fn try_send(&self, item: T) -> Result<(), T> {\n        self.sender.send(item).map_err(|e| e.0)\n    }\n}\n\n// Crossbeam priority sender\nstruct CrossbeamSender<T> {\n    sender: crossbeam_channel::Sender<T>,\n}\n\nimpl<T> PrioritySender<T> for CrossbeamSender<T> {\n    fn send(&self, item: T) -> Result<(), T> {\n        self.sender.send(item).map_err(|e| e.0)\n    }\n    \n    fn try_send(&self, item: T) -> Result<(), T> {\n        self.sender.try_send(item).map_err(|e| match e {\n            crossbeam_channel::TrySendError::Full(item) => item,\n            crossbeam_channel::TrySendError::Disconnected(item) => item,\n        })\n    }\n}\n\n// Flume priority sender\nstruct FlumeSender<T> {\n    sender: flume::Sender<T>,\n}\n\nimpl<T> PrioritySender<T> for FlumeSender<T> {\n    fn send(&self, item: T) -> Result<(), T> {\n        self.sender.send(item).map_err(|e| e.0)\n    }\n    \n    fn try_send(&self, item: T) -> Result<(), T> {\n        self.sender.try_send(item).map_err(|e| match e {\n            flume::TrySendError::Full(item) => item,\n            flume::TrySendError::Disconnected(item) => item,\n        })\n    }\n}\n\nimpl<T> PriorityChannelSender<T>\nwhere\n    T: Ord + Clone,\n{\n    pub fn send_with_backpressure(&self, item: T) -> Result<(), &'static str> {\n        let current_size = self.queue_size.load(Ordering::Relaxed);\n        \n        match &self.backpressure {\n            BackpressureStrategy::Block => {\n                self.sender.send(item).map_err(|_| \"Channel closed\")\n            }\n            BackpressureStrategy::Drop => {\n                if current_size >= self.max_size {\n                    Err(\"Queue full - message dropped\")\n                } else {\n                    self.sender.try_send(item).map_err(|_| \"Send failed\")\n                }\n            }\n            BackpressureStrategy::DropOldest => {\n                // This would require a custom queue implementation\n                self.sender.send(item).map_err(|_| \"Channel closed\")\n            }\n            BackpressureStrategy::Overflow(max_overflow) => {\n                if current_size >= self.max_size + max_overflow {\n                    Err(\"Queue overflow\")\n                } else {\n                    self.sender.send(item).map_err(|_| \"Channel closed\")\n                }\n            }\n        }\n    }\n}\n\n// Producer implementation\npub struct Producer {\n    config: ProducerConfig,\n    sender: Arc<dyn PrioritySender<Message> + Send + Sync>,\n    metrics: Arc<SystemMetrics>,\n    shutdown: Arc<AtomicBool>,\n}\n\nimpl Producer {\n    pub fn new(\n        config: ProducerConfig,\n        sender: Arc<dyn PrioritySender<Message> + Send + Sync>,\n        metrics: Arc<SystemMetrics>,\n        shutdown: Arc<AtomicBool>,\n    ) -> Self {\n        Self {\n            config,\n            sender,\n            metrics,\n            shutdown,\n        }\n    }\n    \n    pub fn start(self) -> JoinHandle<()> {\n        thread::Builder::new()\n            .name(format!(\"producer-{}\", self.config.id))\n            .spawn(move || self.run())\n            .expect(\"Failed to spawn producer thread\")\n    }\n    \n    fn run(self) {\n        let mut message_id = 0;\n        let mut messages_sent = 0;\n        \n        println!(\"Producer {} starting\", self.config.id);\n        \n        while !self.shutdown.load(Ordering::Relaxed) {\n            if let Some(total) = self.config.total_messages {\n                if messages_sent >= total {\n                    break;\n                }\n            }\n            \n            // Generate message batch\n            let batch_size = if self.config.batch_size > 1 {\n                self.config.batch_size\n            } else {\n                1\n            };\n            \n            for _ in 0..batch_size {\n                let priority = self.select_priority();\n                let payload = self.generate_payload(priority);\n                \n                let message = Message {\n                    id: message_id,\n                    priority,\n                    payload,\n                    timestamp: Instant::now(),\n                };\n                \n                match self.sender.send(message) {\n                    Ok(()) => {\n                        self.metrics.messages_produced.fetch_add(1, Ordering::Relaxed);\n                        message_id += 1;\n                        messages_sent += 1;\n                    }\n                    Err(_) => {\n                        self.metrics.messages_dropped.fetch_add(1, Ordering::Relaxed);\n                        println!(\"Producer {}: Failed to send message {}\", self.config.id, message_id);\n                        break;\n                    }\n                }\n            }\n            \n            if !self.config.message_rate.is_zero() {\n                thread::sleep(self.config.message_rate);\n            }\n        }\n        \n        println!(\"Producer {} finished, sent {} messages\", self.config.id, messages_sent);\n    }\n    \n    fn select_priority(&self) -> Priority {\n        let rand_val: f32 = rand::random();\n        let mut cumulative = 0.0;\n        \n        for (i, &prob) in self.config.priority_distribution.iter().enumerate() {\n            cumulative += prob;\n            if rand_val <= cumulative {\n                return match i {\n                    0 => Priority::Low,\n                    1 => Priority::Normal,\n                    2 => Priority::High,\n                    3 => Priority::Critical,\n                    _ => Priority::Normal,\n                };\n            }\n        }\n        \n        Priority::Normal\n    }\n    \n    fn generate_payload(&self, priority: Priority) -> MessagePayload {\n        match priority {\n            Priority::Critical => MessagePayload::Control(ControlMessage::Start),\n            Priority::High => MessagePayload::Text(format!(\"High priority message from producer {}\", self.config.id)),\n            Priority::Normal => MessagePayload::Text(format!(\"Normal message from producer {}\", self.config.id)),\n            Priority::Low => MessagePayload::Binary(vec![0u8; 1024]), // Larger payload for low priority\n        }\n    }\n}\n\n// Consumer implementation\npub struct Consumer {\n    config: ConsumerConfig,\n    receiver: Box<dyn PriorityReceiver + Send>,\n    metrics: Arc<SystemMetrics>,\n    shutdown: Arc<AtomicBool>,\n}\n\npub trait PriorityReceiver: Send {\n    fn recv(&self) -> Result<Message, &'static str>;\n    fn try_recv(&self) -> Result<Message, &'static str>;\n}\n\nstruct StdMpscReceiver {\n    receiver: std::sync::mpsc::Receiver<Message>,\n}\n\nimpl PriorityReceiver for StdMpscReceiver {\n    fn recv(&self) -> Result<Message, &'static str> {\n        self.receiver.recv().map_err(|_| \"Channel closed\")\n    }\n    \n    fn try_recv(&self) -> Result<Message, &'static str> {\n        match self.receiver.try_recv() {\n            Ok(msg) => Ok(msg),\n            Err(std::sync::mpsc::TryRecvError::Empty) => Err(\"No message available\"),\n            Err(std::sync::mpsc::TryRecvError::Disconnected) => Err(\"Channel closed\"),\n        }\n    }\n}\n\nimpl Consumer {\n    pub fn new(\n        config: ConsumerConfig,\n        receiver: Box<dyn PriorityReceiver + Send>,\n        metrics: Arc<SystemMetrics>,\n        shutdown: Arc<AtomicBool>,\n    ) -> Self {\n        Self {\n            config,\n            receiver,\n            metrics,\n            shutdown,\n        }\n    }\n    \n    pub fn start(self) -> JoinHandle<()> {\n        thread::Builder::new()\n            .name(format!(\"consumer-{}\", self.config.id))\n            .spawn(move || self.run())\n            .expect(\"Failed to spawn consumer thread\")\n    }\n    \n    fn run(self) {\n        let mut messages_processed = 0;\n        println!(\"Consumer {} starting\", self.config.id);\n        \n        while !self.shutdown.load(Ordering::Relaxed) {\n            match self.receiver.recv() {\n                Ok(message) => {\n                    let processing_start = Instant::now();\n                    \n                    // Calculate latency\n                    let latency = processing_start.duration_since(message.timestamp);\n                    self.metrics.total_latency_ns.fetch_add(\n                        latency.as_nanos() as usize,\n                        Ordering::Relaxed,\n                    );\n                    \n                    // Process message\n                    if let Err(e) = self.process_message(&message) {\n                        self.metrics.processing_errors.fetch_add(1, Ordering::Relaxed);\n                        println!(\"Consumer {}: Processing error - {}\", self.config.id, e);\n                    }\n                    \n                    self.metrics.messages_consumed.fetch_add(1, Ordering::Relaxed);\n                    messages_processed += 1;\n                    \n                    // Simulate processing time\n                    if !self.config.processing_time.is_zero() {\n                        thread::sleep(self.config.processing_time);\n                    }\n                }\n                Err(_) => {\n                    // Channel closed or no message available\n                    if self.shutdown.load(Ordering::Relaxed) {\n                        break;\n                    }\n                    thread::sleep(Duration::from_millis(1));\n                }\n            }\n        }\n        \n        println!(\"Consumer {} finished, processed {} messages\", self.config.id, messages_processed);\n    }\n    \n    fn process_message(&self, message: &Message) -> Result<(), &'static str> {\n        // Simulate random errors\n        if rand::random::<f32>() < self.config.error_rate {\n            return Err(\"Simulated processing error\");\n        }\n        \n        match &message.payload {\n            MessagePayload::Control(ControlMessage::Shutdown) => {\n                println!(\"Consumer {}: Received shutdown signal\", self.config.id);\n                self.shutdown.store(true, Ordering::Relaxed);\n            }\n            MessagePayload::Text(text) => {\n                if message.priority == Priority::Critical {\n                    println!(\"Consumer {}: CRITICAL - {}\", self.config.id, text);\n                }\n            }\n            MessagePayload::Binary(data) => {\n                // Process binary data\n                let checksum: u32 = data.iter().map(|&b| b as u32).sum();\n                if self.config.id == 0 { // Only log from first consumer to reduce noise\n                    println!(\"Consumer {}: Processed binary data, checksum: {}\", self.config.id, checksum);\n                }\n            }\n            MessagePayload::Batch(items) => {\n                println!(\"Consumer {}: Processing batch of {} items\", self.config.id, items.len());\n            }\n        }\n        \n        Ok(())\n    }\n}\n\n// System orchestrator\npub struct ProducerConsumerSystem {\n    producers: Vec<JoinHandle<()>>,\n    consumers: Vec<JoinHandle<()>>,\n    metrics: Arc<SystemMetrics>,\n    shutdown: Arc<AtomicBool>,\n}\n\nimpl ProducerConsumerSystem {\n    pub fn new() -> Self {\n        Self {\n            producers: Vec::new(),\n            consumers: Vec::new(),\n            metrics: Arc::new(SystemMetrics::default()),\n            shutdown: Arc::new(AtomicBool::new(false)),\n        }\n    }\n    \n    pub fn add_std_mpsc_channel(\n        &mut self,\n        producer_configs: Vec<ProducerConfig>,\n        consumer_configs: Vec<ConsumerConfig>,\n    ) {\n        let (tx, rx) = std::sync::mpsc::channel();\n        let sender = Arc::new(StdMpscSender { sender: tx }) as Arc<dyn PrioritySender<Message> + Send + Sync>;\n        let receiver = Box::new(StdMpscReceiver { receiver: rx }) as Box<dyn PriorityReceiver + Send>;\n        \n        // Start producers\n        for config in producer_configs {\n            let producer = Producer::new(\n                config,\n                sender.clone(),\n                self.metrics.clone(),\n                self.shutdown.clone(),\n            );\n            self.producers.push(producer.start());\n        }\n        \n        // Start consumers (only one for std::mpsc since it's single-consumer)\n        if let Some(config) = consumer_configs.into_iter().next() {\n            let consumer = Consumer::new(\n                config,\n                receiver,\n                self.metrics.clone(),\n                self.shutdown.clone(),\n            );\n            self.consumers.push(consumer.start());\n        }\n    }\n    \n    pub fn run_benchmark(&self, duration: Duration) {\n        println!(\"Running benchmark for {:?}...\", duration);\n        let start = Instant::now();\n        \n        // Monitor metrics\n        while start.elapsed() < duration && !self.shutdown.load(Ordering::Relaxed) {\n            thread::sleep(Duration::from_secs(1));\n            \n            let elapsed = start.elapsed();\n            let throughput = self.metrics.throughput_per_second(elapsed);\n            let avg_latency = self.metrics.average_latency_ms();\n            let error_rate = self.metrics.error_rate();\n            \n            println!(\n                \"Metrics - Throughput: {:.0} msg/s, Avg Latency: {:.2} ms, Error Rate: {:.2}%\",\n                throughput,\n                avg_latency,\n                error_rate * 100.0\n            );\n        }\n    }\n    \n    pub fn shutdown_graceful(self, timeout: Duration) {\n        println!(\"Initiating graceful shutdown...\");\n        self.shutdown.store(true, Ordering::Relaxed);\n        \n        let start = Instant::now();\n        \n        // Wait for producers to finish\n        for (i, handle) in self.producers.into_iter().enumerate() {\n            if start.elapsed() < timeout {\n                if let Err(_) = handle.join() {\n                    println!(\"Producer {} failed to join\", i);\n                }\n            }\n        }\n        \n        // Wait for consumers to finish\n        for (i, handle) in self.consumers.into_iter().enumerate() {\n            if start.elapsed() < timeout {\n                if let Err(_) = handle.join() {\n                    println!(\"Consumer {} failed to join\", i);\n                }\n            }\n        }\n        \n        // Print final metrics\n        println!(\"Final Metrics:\");\n        println!(\"  Messages Produced: {}\", self.metrics.messages_produced.load(Ordering::Relaxed));\n        println!(\"  Messages Consumed: {}\", self.metrics.messages_consumed.load(Ordering::Relaxed));\n        println!(\"  Messages Dropped: {}\", self.metrics.messages_dropped.load(Ordering::Relaxed));\n        println!(\"  Processing Errors: {}\", self.metrics.processing_errors.load(Ordering::Relaxed));\n        println!(\"  Average Latency: {:.2} ms\", self.metrics.average_latency_ms());\n        println!(\"  Error Rate: {:.2}%\", self.metrics.error_rate() * 100.0);\n    }\n}\n\nfn main() -> Result<(), Box<dyn std::error::Error>> {\n    println!(\"Starting Producer-Consumer System Benchmark\");\n    \n    let mut system = ProducerConsumerSystem::new();\n    \n    // Configuration for std::mpsc test\n    let producer_configs = vec![\n        ProducerConfig {\n            id: 0,\n            message_rate: Duration::from_millis(10),\n            batch_size: 1,\n            priority_distribution: [0.1, 0.6, 0.25, 0.05], // Low, Normal, High, Critical\n            total_messages: Some(1000),\n        },\n        ProducerConfig {\n            id: 1,\n            message_rate: Duration::from_millis(15),\n            batch_size: 5,\n            priority_distribution: [0.2, 0.5, 0.2, 0.1],\n            total_messages: Some(800),\n        },\n    ];\n    \n    let consumer_configs = vec![\n        ConsumerConfig {\n            id: 0,\n            processing_time: Duration::from_millis(5),\n            batch_processing: false,\n            error_rate: 0.02, // 2% error rate\n        },\n    ];\n    \n    system.add_std_mpsc_channel(producer_configs, consumer_configs);\n    \n    // Run benchmark\n    system.run_benchmark(Duration::from_secs(10));\n    \n    // Graceful shutdown\n    system.shutdown_graceful(Duration::from_secs(5));\n    \n    println!(\"Benchmark completed\");\n    Ok(())\n}",
    "key_concepts": [
      "producer-consumer pattern",
      "multiple channel types",
      "backpressure handling",
      "priority queues",
      "graceful shutdown",
      "performance analysis",
      "message routing",
      "error handling",
      "throughput monitoring",
      "latency measurement"
    ]
  },
  {
    "prompt": "Implement a distributed actor system in Rust using Actix with supervision trees, message routing, fault tolerance, and cluster communication. Include actor lifecycle management and distributed state synchronization.",
    "response": "use actix::prelude::*;\nuse actix::{Actor, Context, Handler, Recipient, Supervised, Supervisor};\nuse serde::{Deserialize, Serialize};\nuse std::collections::{HashMap, HashSet};\nuse std::time::{Duration, Instant};\nuse uuid::Uuid;\nuse tokio::time::interval;\nuse std::sync::Arc;\nuse tokio::sync::RwLock;\n\n// Message types for actor communication\n#[derive(Debug, Clone, Serialize, Deserialize, Message)]\n#[rtype(result = \"Result<(), ActorError>\")]\npub enum ActorMessage {\n    Initialize { config: ActorConfig },\n    Process { data: String, correlation_id: Uuid },\n    Heartbeat,\n    Shutdown,\n    StateSync { state: ActorState },\n    ClusterJoin { node_id: String, address: String },\n    ClusterLeave { node_id: String },\n    RouteMessage { target: String, message: Box<ActorMessage> },\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize, Message)]\n#[rtype(result = \"SupervisorResponse\")]\npub enum SupervisorMessage {\n    CreateChild { actor_type: ActorType, config: ActorConfig },\n    RestartChild { actor_id: String },\n    StopChild { actor_id: String },\n    GetChildrenStatus,\n    EscalateFailure { actor_id: String, error: ActorError },\n}\n\n#[derive(Debug, Clone)]\npub enum SupervisorResponse {\n    ChildCreated { actor_id: String },\n    ChildRestarted { actor_id: String },\n    ChildStopped { actor_id: String },\n    ChildrenStatus { children: Vec<ChildStatus> },\n    FailureEscalated,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub enum ActorType {\n    Worker,\n    Router,\n    StateManager,\n    ClusterNode,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ActorConfig {\n    pub actor_id: String,\n    pub restart_policy: RestartPolicy,\n    pub max_retries: u32,\n    pub timeout: Duration,\n    pub batch_size: Option<usize>,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub enum RestartPolicy {\n    Never,\n    Always,\n    OnFailure,\n    OnAbnormalExit,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ActorState {\n    pub actor_id: String,\n    pub status: ActorStatus,\n    pub processed_count: u64,\n    pub error_count: u64,\n    pub last_heartbeat: Option<Instant>,\n    pub custom_data: HashMap<String, String>,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub enum ActorStatus {\n    Initializing,\n    Running,\n    Paused,\n    Stopping,\n    Stopped,\n    Failed,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct ChildStatus {\n    pub actor_id: String,\n    pub actor_type: ActorType,\n    pub status: ActorStatus,\n    pub restart_count: u32,\n    pub uptime: Duration,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub enum ActorError {\n    ProcessingFailed(String),\n    TimeoutError,\n    InitializationFailed(String),\n    CommunicationError(String),\n    StateCorrupted,\n    ResourceExhausted,\n}\n\n// Worker Actor - handles business logic\npub struct WorkerActor {\n    config: ActorConfig,\n    state: ActorState,\n    supervisor: Option<Recipient<SupervisorMessage>>,\n    message_buffer: Vec<ActorMessage>,\n    start_time: Instant,\n}\n\nimpl WorkerActor {\n    pub fn new(config: ActorConfig) -> Self {\n        let state = ActorState {\n            actor_id: config.actor_id.clone(),\n            status: ActorStatus::Initializing,\n            processed_count: 0,\n            error_count: 0,\n            last_heartbeat: None,\n            custom_data: HashMap::new(),\n        };\n        \n        Self {\n            config,\n            state,\n            supervisor: None,\n            message_buffer: Vec::new(),\n            start_time: Instant::now(),\n        }\n    }\n    \n    fn process_business_logic(&mut self, data: &str) -> Result<String, ActorError> {\n        // Simulate processing\n        if data.contains(\"error\") {\n            return Err(ActorError::ProcessingFailed(\"Invalid data\".to_string()));\n        }\n        \n        if data.contains(\"timeout\") {\n            std::thread::sleep(self.config.timeout + Duration::from_millis(100));\n            return Err(ActorError::TimeoutError);\n        }\n        \n        // Simulate actual work\n        let result = format!(\"Processed: {} by {}\", data, self.config.actor_id);\n        self.state.processed_count += 1;\n        Ok(result)\n    }\n    \n    fn send_heartbeat(&self, ctx: &mut Context<Self>) {\n        if let Some(supervisor) = &self.supervisor {\n            // In a real implementation, this would be a heartbeat message\n            println!(\"Worker {} sending heartbeat\", self.config.actor_id);\n        }\n    }\n    \n    fn handle_failure(&mut self, error: ActorError, ctx: &mut Context<Self>) {\n        self.state.error_count += 1;\n        self.state.status = ActorStatus::Failed;\n        \n        println!(\"Worker {} failed: {:?}\", self.config.actor_id, error);\n        \n        // Escalate to supervisor based on restart policy\n        if let Some(supervisor) = &self.supervisor {\n            let escalation = SupervisorMessage::EscalateFailure {\n                actor_id: self.config.actor_id.clone(),\n                error,\n            };\n            supervisor.do_send(escalation);\n        }\n        \n        match self.config.restart_policy {\n            RestartPolicy::Never => ctx.stop(),\n            RestartPolicy::Always => {\n                self.restart(ctx);\n            }\n            RestartPolicy::OnFailure => {\n                if self.state.error_count <= self.config.max_retries as u64 {\n                    self.restart(ctx);\n                } else {\n                    ctx.stop();\n                }\n            }\n            RestartPolicy::OnAbnormalExit => {\n                // Would check exit reason in real implementation\n                self.restart(ctx);\n            }\n        }\n    }\n    \n    fn restart(&mut self, ctx: &mut Context<Self>) {\n        println!(\"Restarting worker {}\", self.config.actor_id);\n        self.state.status = ActorStatus::Initializing;\n        self.message_buffer.clear();\n        \n        // Reinitialize actor state\n        ctx.run_later(Duration::from_millis(100), |actor, ctx| {\n            actor.state.status = ActorStatus::Running;\n            println!(\"Worker {} restarted successfully\", actor.config.actor_id);\n        });\n    }\n}\n\nimpl Actor for WorkerActor {\n    type Context = Context<Self>;\n    \n    fn started(&mut self, ctx: &mut Self::Context) {\n        println!(\"Worker {} started\", self.config.actor_id);\n        self.state.status = ActorStatus::Running;\n        \n        // Setup heartbeat interval\n        let interval = Duration::from_secs(30);\n        ctx.run_interval(interval, |actor, ctx| {\n            actor.send_heartbeat(ctx);\n            actor.state.last_heartbeat = Some(Instant::now());\n        });\n    }\n    \n    fn stopped(&mut self, _ctx: &mut Self::Context) {\n        println!(\"Worker {} stopped\", self.config.actor_id);\n        self.state.status = ActorStatus::Stopped;\n    }\n}\n\nimpl Supervised for WorkerActor {\n    fn restarting(&mut self, _ctx: &mut Context<WorkerActor>) {\n        println!(\"Worker {} is being restarted by supervisor\", self.config.actor_id);\n        self.restart(_ctx);\n    }\n}\n\nimpl Handler<ActorMessage> for WorkerActor {\n    type Result = Result<(), ActorError>;\n    \n    fn handle(&mut self, msg: ActorMessage, ctx: &mut Context<Self>) -> Self::Result {\n        match msg {\n            ActorMessage::Initialize { config } => {\n                self.config = config;\n                self.state.status = ActorStatus::Running;\n                Ok(())\n            }\n            ActorMessage::Process { data, correlation_id } => {\n                match self.process_business_logic(&data) {\n                    Ok(result) => {\n                        println!(\"Worker {}: {} (correlation: {})\", \n                                self.config.actor_id, result, correlation_id);\n                        Ok(())\n                    }\n                    Err(error) => {\n                        self.handle_failure(error.clone(), ctx);\n                        Err(error)\n                    }\n                }\n            }\n            ActorMessage::Heartbeat => {\n                self.state.last_heartbeat = Some(Instant::now());\n                Ok(())\n            }\n            ActorMessage::Shutdown => {\n                self.state.status = ActorStatus::Stopping;\n                ctx.stop();\n                Ok(())\n            }\n            _ => Err(ActorError::ProcessingFailed(\"Unsupported message\".to_string())),\n        }\n    }\n}\n\n// Supervisor Actor - manages child actors\npub struct SupervisorActor {\n    children: HashMap<String, ChildInfo>,\n    supervisor_config: SupervisorConfig,\n    router: Option<Addr<RouterActor>>,\n}\n\n#[derive(Debug, Clone)]\nstruct ChildInfo {\n    addr: Addr<WorkerActor>,\n    config: ActorConfig,\n    actor_type: ActorType,\n    restart_count: u32,\n    start_time: Instant,\n}\n\n#[derive(Debug, Clone)]\npub struct SupervisorConfig {\n    pub max_children: usize,\n    pub restart_intensity: u32, // Max restarts per time period\n    pub restart_period: Duration,\n    pub escalation_policy: EscalationPolicy,\n}\n\n#[derive(Debug, Clone)]\npub enum EscalationPolicy {\n    RestartChild,\n    RestartAllChildren,\n    RestartSupervisor,\n    Shutdown,\n}\n\nimpl SupervisorActor {\n    pub fn new(supervisor_config: SupervisorConfig) -> Self {\n        Self {\n            children: HashMap::new(),\n            supervisor_config,\n            router: None,\n        }\n    }\n    \n    fn create_child(&mut self, actor_type: ActorType, config: ActorConfig) -> Result<String, ActorError> {\n        if self.children.len() >= self.supervisor_config.max_children {\n            return Err(ActorError::ResourceExhausted);\n        }\n        \n        let actor_id = config.actor_id.clone();\n        \n        let addr = match actor_type {\n            ActorType::Worker => {\n                let worker = WorkerActor::new(config.clone());\n                Supervisor::start(|_| worker)\n            }\n            _ => return Err(ActorError::InitializationFailed(\"Unsupported actor type\".to_string())),\n        };\n        \n        let child_info = ChildInfo {\n            addr,\n            config,\n            actor_type,\n            restart_count: 0,\n            start_time: Instant::now(),\n        };\n        \n        self.children.insert(actor_id.clone(), child_info);\n        println!(\"Supervisor created child: {}\", actor_id);\n        \n        Ok(actor_id)\n    }\n    \n    fn restart_child(&mut self, actor_id: &str) -> Result<(), ActorError> {\n        if let Some(child_info) = self.children.get_mut(actor_id) {\n            child_info.restart_count += 1;\n            child_info.start_time = Instant::now();\n            \n            // Check restart intensity\n            if child_info.restart_count > self.supervisor_config.restart_intensity {\n                return self.escalate_failure(actor_id);\n            }\n            \n            // Send restart message to child\n            child_info.addr.do_send(ActorMessage::Initialize { \n                config: child_info.config.clone() \n            });\n            \n            println!(\"Supervisor restarted child: {} (restart count: {})\", \n                    actor_id, child_info.restart_count);\n            Ok(())\n        } else {\n            Err(ActorError::ProcessingFailed(\"Child not found\".to_string()))\n        }\n    }\n    \n    fn escalate_failure(&mut self, actor_id: &str) -> Result<(), ActorError> {\n        println!(\"Escalating failure for child: {}\", actor_id);\n        \n        match self.supervisor_config.escalation_policy {\n            EscalationPolicy::RestartChild => {\n                // Already tried, so remove child\n                self.children.remove(actor_id);\n                Ok(())\n            }\n            EscalationPolicy::RestartAllChildren => {\n                for (id, child) in &self.children {\n                    child.addr.do_send(ActorMessage::Initialize { \n                        config: child.config.clone() \n                    });\n                }\n                Ok(())\n            }\n            EscalationPolicy::RestartSupervisor => {\n                // Signal parent supervisor to restart this supervisor\n                Err(ActorError::StateCorrupted)\n            }\n            EscalationPolicy::Shutdown => {\n                // Shutdown all children and supervisor\n                for child in self.children.values() {\n                    child.addr.do_send(ActorMessage::Shutdown);\n                }\n                self.children.clear();\n                Err(ActorError::StateCorrupted)\n            }\n        }\n    }\n}\n\nimpl Actor for SupervisorActor {\n    type Context = Context<Self>;\n    \n    fn started(&mut self, ctx: &mut Self::Context) {\n        println!(\"Supervisor started\");\n        \n        // Monitor children health\n        ctx.run_interval(Duration::from_secs(10), |actor, _ctx| {\n            for (id, child) in &actor.children {\n                child.addr.do_send(ActorMessage::Heartbeat);\n            }\n        });\n    }\n}\n\nimpl Handler<SupervisorMessage> for SupervisorActor {\n    type Result = SupervisorResponse;\n    \n    fn handle(&mut self, msg: SupervisorMessage, ctx: &mut Context<Self>) -> Self::Result {\n        match msg {\n            SupervisorMessage::CreateChild { actor_type, config } => {\n                match self.create_child(actor_type, config) {\n                    Ok(actor_id) => SupervisorResponse::ChildCreated { actor_id },\n                    Err(_) => SupervisorResponse::FailureEscalated,\n                }\n            }\n            SupervisorMessage::RestartChild { actor_id } => {\n                match self.restart_child(&actor_id) {\n                    Ok(_) => SupervisorResponse::ChildRestarted { actor_id },\n                    Err(_) => SupervisorResponse::FailureEscalated,\n                }\n            }\n            SupervisorMessage::StopChild { actor_id } => {\n                if let Some(child) = self.children.remove(&actor_id) {\n                    child.addr.do_send(ActorMessage::Shutdown);\n                    SupervisorResponse::ChildStopped { actor_id }\n                } else {\n                    SupervisorResponse::FailureEscalated\n                }\n            }\n            SupervisorMessage::GetChildrenStatus => {\n                let children: Vec<ChildStatus> = self.children.iter().map(|(id, child)| {\n                    ChildStatus {\n                        actor_id: id.clone(),\n                        actor_type: child.actor_type.clone(),\n                        status: ActorStatus::Running, // Simplified\n                        restart_count: child.restart_count,\n                        uptime: child.start_time.elapsed(),\n                    }\n                }).collect();\n                \n                SupervisorResponse::ChildrenStatus { children }\n            }\n            SupervisorMessage::EscalateFailure { actor_id, error } => {\n                println!(\"Received failure escalation from {}: {:?}\", actor_id, error);\n                let _ = self.escalate_failure(&actor_id);\n                SupervisorResponse::FailureEscalated\n            }\n        }\n    }\n}\n\n// Router Actor - handles message routing and load balancing\npub struct RouterActor {\n    workers: Vec<Addr<WorkerActor>>,\n    routing_strategy: RoutingStrategy,\n    current_index: usize,\n    message_count: u64,\n}\n\n#[derive(Debug, Clone)]\npub enum RoutingStrategy {\n    RoundRobin,\n    LeastConnections,\n    Random,\n    Broadcast,\n}\n\nimpl RouterActor {\n    pub fn new(routing_strategy: RoutingStrategy) -> Self {\n        Self {\n            workers: Vec::new(),\n            routing_strategy,\n            current_index: 0,\n            message_count: 0,\n        }\n    }\n    \n    pub fn add_worker(&mut self, worker: Addr<WorkerActor>) {\n        self.workers.push(worker);\n    }\n    \n    fn route_message(&mut self, message: ActorMessage) -> Result<(), ActorError> {\n        if self.workers.is_empty() {\n            return Err(ActorError::ProcessingFailed(\"No workers available\".to_string()));\n        }\n        \n        match self.routing_strategy {\n            RoutingStrategy::RoundRobin => {\n                let worker = &self.workers[self.current_index];\n                worker.do_send(message);\n                self.current_index = (self.current_index + 1) % self.workers.len();\n            }\n            RoutingStrategy::Random => {\n                let index = (rand::random::<usize>()) % self.workers.len();\n                self.workers[index].do_send(message);\n            }\n            RoutingStrategy::Broadcast => {\n                for worker in &self.workers {\n                    worker.do_send(message.clone());\n                }\n            }\n            RoutingStrategy::LeastConnections => {\n                // Simplified - would need to track connections per worker\n                let worker = &self.workers[0];\n                worker.do_send(message);\n            }\n        }\n        \n        self.message_count += 1;\n        Ok(())\n    }\n}\n\nimpl Actor for RouterActor {\n    type Context = Context<Self>;\n    \n    fn started(&mut self, _ctx: &mut Self::Context) {\n        println!(\"Router started with strategy: {:?}\", self.routing_strategy);\n    }\n}\n\nimpl Handler<ActorMessage> for RouterActor {\n    type Result = Result<(), ActorError>;\n    \n    fn handle(&mut self, msg: ActorMessage, _ctx: &mut Context<Self>) -> Self::Result {\n        match msg {\n            ActorMessage::RouteMessage { target: _, message } => {\n                self.route_message(*message)\n            }\n            _ => self.route_message(msg),\n        }\n    }\n}\n\n// Cluster Node Actor - handles distributed communication\npub struct ClusterNodeActor {\n    node_id: String,\n    cluster_members: HashSet<String>,\n    state_manager: Option<Addr<StateManagerActor>>,\n    local_supervisor: Addr<SupervisorActor>,\n}\n\nimpl ClusterNodeActor {\n    pub fn new(node_id: String, local_supervisor: Addr<SupervisorActor>) -> Self {\n        Self {\n            node_id,\n            cluster_members: HashSet::new(),\n            state_manager: None,\n            local_supervisor,\n        }\n    }\n    \n    fn handle_cluster_join(&mut self, node_id: String, _address: String) {\n        self.cluster_members.insert(node_id.clone());\n        println!(\"Node {} joined cluster. Members: {:?}\", node_id, self.cluster_members);\n        \n        // Sync state with new node\n        if let Some(state_manager) = &self.state_manager {\n            // In real implementation, would sync state\n            println!(\"Syncing state with new node: {}\", node_id);\n        }\n    }\n    \n    fn handle_cluster_leave(&mut self, node_id: String) {\n        self.cluster_members.remove(&node_id);\n        println!(\"Node {} left cluster. Members: {:?}\", node_id, self.cluster_members);\n    }\n}\n\nimpl Actor for ClusterNodeActor {\n    type Context = Context<Self>;\n    \n    fn started(&mut self, _ctx: &mut Self::Context) {\n        println!(\"Cluster node {} started\", self.node_id);\n    }\n}\n\nimpl Handler<ActorMessage> for ClusterNodeActor {\n    type Result = Result<(), ActorError>;\n    \n    fn handle(&mut self, msg: ActorMessage, _ctx: &mut Context<Self>) -> Self::Result {\n        match msg {\n            ActorMessage::ClusterJoin { node_id, address } => {\n                self.handle_cluster_join(node_id, address);\n                Ok(())\n            }\n            ActorMessage::ClusterLeave { node_id } => {\n                self.handle_cluster_leave(node_id);\n                Ok(())\n            }\n            ActorMessage::StateSync { state } => {\n                println!(\"Received state sync: {:?}\", state);\n                Ok(())\n            }\n            _ => Err(ActorError::ProcessingFailed(\"Unsupported cluster message\".to_string())),\n        }\n    }\n}\n\n// State Manager Actor - handles distributed state synchronization\npub struct StateManagerActor {\n    local_state: Arc<RwLock<HashMap<String, ActorState>>>,\n    cluster_node: Addr<ClusterNodeActor>,\n    sync_interval: Duration,\n}\n\nimpl StateManagerActor {\n    pub fn new(cluster_node: Addr<ClusterNodeActor>) -> Self {\n        Self {\n            local_state: Arc::new(RwLock::new(HashMap::new())),\n            cluster_node,\n            sync_interval: Duration::from_secs(10),\n        }\n    }\n    \n    async fn sync_state(&self) {\n        let state = self.local_state.read().await;\n        for (actor_id, actor_state) in state.iter() {\n            let sync_msg = ActorMessage::StateSync { \n                state: actor_state.clone() \n            };\n            self.cluster_node.do_send(sync_msg);\n        }\n    }\n}\n\nimpl Actor for StateManagerActor {\n    type Context = Context<Self>;\n    \n    fn started(&mut self, ctx: &mut Self::Context) {\n        println!(\"State manager started\");\n        \n        // Periodic state synchronization\n        ctx.run_interval(self.sync_interval, |actor, _ctx| {\n            let actor_clone = actor.clone();\n            actix::spawn(async move {\n                actor_clone.sync_state().await;\n            });\n        });\n    }\n}\n\nimpl Clone for StateManagerActor {\n    fn clone(&self) -> Self {\n        Self {\n            local_state: self.local_state.clone(),\n            cluster_node: self.cluster_node.clone(),\n            sync_interval: self.sync_interval,\n        }\n    }\n}\n\nimpl Handler<ActorMessage> for StateManagerActor {\n    type Result = Result<(), ActorError>;\n    \n    fn handle(&mut self, msg: ActorMessage, _ctx: &mut Context<Self>) -> Self::Result {\n        match msg {\n            ActorMessage::StateSync { state } => {\n                let local_state = self.local_state.clone();\n                let actor_id = state.actor_id.clone();\n                \n                actix::spawn(async move {\n                    let mut state_map = local_state.write().await;\n                    state_map.insert(actor_id, state);\n                });\n                \n                Ok(())\n            }\n            _ => Err(ActorError::ProcessingFailed(\"Unsupported state message\".to_string())),\n        }\n    }\n}\n\n#[actix::main]\nasync fn main() -> Result<(), Box<dyn std::error::Error>> {\n    println!(\"Starting distributed actor system...\");\n    \n    // Create supervisor configuration\n    let supervisor_config = SupervisorConfig {\n        max_children: 10,\n        restart_intensity: 3,\n        restart_period: Duration::from_secs(60),\n        escalation_policy: EscalationPolicy::RestartChild,\n    };\n    \n    // Start supervisor\n    let supervisor = SupervisorActor::new(supervisor_config).start();\n    \n    // Start cluster node\n    let cluster_node = ClusterNodeActor::new(\"node1\".to_string(), supervisor.clone()).start();\n    \n    // Start state manager\n    let state_manager = StateManagerActor::new(cluster_node.clone()).start();\n    \n    // Create workers through supervisor\n    for i in 0..3 {\n        let config = ActorConfig {\n            actor_id: format!(\"worker-{}\", i),\n            restart_policy: RestartPolicy::OnFailure,\n            max_retries: 3,\n            timeout: Duration::from_secs(5),\n            batch_size: None,\n        };\n        \n        let create_msg = SupervisorMessage::CreateChild {\n            actor_type: ActorType::Worker,\n            config,\n        };\n        \n        if let Ok(response) = supervisor.send(create_msg).await {\n            println!(\"Created worker: {:?}\", response);\n        }\n    }\n    \n    // Test message processing\n    tokio::time::sleep(Duration::from_secs(2)).await;\n    \n    // Send test messages\n    for i in 0..10 {\n        let message = ActorMessage::Process {\n            data: format!(\"test data {}\", i),\n            correlation_id: Uuid::new_v4(),\n        };\n        \n        // Route through supervisor (simplified)\n        println!(\"Sending test message {}\", i);\n    }\n    \n    // Test cluster operations\n    cluster_node.do_send(ActorMessage::ClusterJoin {\n        node_id: \"node2\".to_string(),\n        address: \"127.0.0.1:8081\".to_string(),\n    });\n    \n    // Test failure scenarios\n    tokio::time::sleep(Duration::from_secs(1)).await;\n    \n    let error_message = ActorMessage::Process {\n        data: \"error data\".to_string(),\n        correlation_id: Uuid::new_v4(),\n    };\n    \n    println!(\"Sending error message to test fault tolerance\");\n    \n    // Keep system running\n    tokio::time::sleep(Duration::from_secs(30)).await;\n    \n    println!(\"Shutting down actor system...\");\n    Ok(())\n}",
    "key_concepts": [
      "actor model",
      "supervision trees",
      "fault tolerance",
      "message routing",
      "distributed systems",
      "cluster communication",
      "state synchronization",
      "actor lifecycle",
      "error escalation",
      "system resilience"
    ]
  },
  {
    "prompt": "Build a high-performance parallel iterator system in Rust using Rayon with custom parallel algorithms, work stealing, dynamic load balancing, and NUMA-aware scheduling. Include benchmarks against sequential algorithms.",
    "response": "use rayon::prelude::*;\nuse rayon::{ThreadPool, ThreadPoolBuilder, Configuration};\nuse std::sync::{Arc, Mutex, atomic::{AtomicUsize, AtomicBool, Ordering}};\nuse std::time::{Duration, Instant};\nuse std::thread;\nuse std::collections::HashMap;\nuse num_cpus;\nuse rand::{thread_rng, Rng};\n\n// NUMA-aware thread pool configuration\npub struct NumaConfig {\n    pub numa_nodes: usize,\n    pub cores_per_node: usize,\n    pub enable_affinity: bool,\n    pub work_stealing_ratio: f64,\n}\n\nimpl Default for NumaConfig {\n    fn default() -> Self {\n        Self {\n            numa_nodes: 1,\n            cores_per_node: num_cpus::get(),\n            enable_affinity: false,\n            work_stealing_ratio: 0.1,\n        }\n    }\n}\n\n// Custom parallel iterator with work stealing\npub struct ParallelRange<T> {\n    start: T,\n    end: T,\n    chunk_size: Option<usize>,\n    numa_config: NumaConfig,\n}\n\nimpl<T> ParallelRange<T>\nwhere\n    T: Copy + PartialOrd + std::ops::Add<Output = T> + std::ops::Sub<Output = T> + From<usize> + Into<usize>,\n{\n    pub fn new(start: T, end: T) -> Self {\n        Self {\n            start,\n            end,\n            chunk_size: None,\n            numa_config: NumaConfig::default(),\n        }\n    }\n    \n    pub fn with_chunk_size(mut self, chunk_size: usize) -> Self {\n        self.chunk_size = Some(chunk_size);\n        self\n    }\n    \n    pub fn with_numa_config(mut self, numa_config: NumaConfig) -> Self {\n        self.numa_config = numa_config;\n        self\n    }\n    \n    pub fn parallel_map<F, R>(&self, f: F) -> Vec<R>\n    where\n        F: Fn(T) -> R + Send + Sync,\n        R: Send,\n    {\n        let total_size: usize = (self.end.into()) - (self.start.into());\n        let chunk_size = self.chunk_size.unwrap_or_else(|| {\n            (total_size / (num_cpus::get() * 4)).max(1)\n        });\n        \n        (self.start.into()..self.end.into())\n            .step_by(1)\n            .collect::<Vec<_>>()\n            .par_chunks(chunk_size)\n            .flat_map(|chunk| {\n                chunk.par_iter().map(|&i| f(T::from(i)))\n            })\n            .collect()\n    }\n    \n    pub fn parallel_reduce<F, R, I>(&self, identity: I, f: F) -> R\n    where\n        F: Fn(R, T) -> R + Send + Sync,\n        I: Fn() -> R + Send + Sync,\n        R: Send + Clone,\n    {\n        (self.start.into()..self.end.into())\n            .into_par_iter()\n            .map(|i| T::from(i))\n            .fold(identity, f)\n            .reduce(identity, |a, b| {\n                // Custom reduction logic - simplified\n                a // In practice, you'd combine a and b\n            })\n    }\n}\n\n// Dynamic load balancing work stealer\npub struct WorkStealingScheduler {\n    thread_queues: Vec<Arc<Mutex<VecDeque<Box<dyn FnOnce() + Send>>>>>,\n    steal_attempts: Arc<AtomicUsize>,\n    numa_topology: NumaTopology,\n}\n\nuse std::collections::VecDeque;\n\n#[derive(Debug, Clone)]\npub struct NumaTopology {\n    pub nodes: Vec<NumaNode>,\n    pub total_cores: usize,\n}\n\n#[derive(Debug, Clone)]\npub struct NumaNode {\n    pub id: usize,\n    pub cores: Vec<usize>,\n    pub memory_gb: usize,\n}\n\nimpl WorkStealingScheduler {\n    pub fn new(numa_config: &NumaConfig) -> Self {\n        let numa_topology = Self::detect_numa_topology(numa_config);\n        let thread_count = numa_topology.total_cores;\n        \n        let thread_queues = (0..thread_count)\n            .map(|_| Arc::new(Mutex::new(VecDeque::new())))\n            .collect();\n        \n        Self {\n            thread_queues,\n            steal_attempts: Arc::new(AtomicUsize::new(0)),\n            numa_topology,\n        }\n    }\n    \n    fn detect_numa_topology(config: &NumaConfig) -> NumaTopology {\n        // Simplified NUMA detection\n        let mut nodes = Vec::new();\n        let cores_per_node = config.cores_per_node;\n        \n        for node_id in 0..config.numa_nodes {\n            let cores = (node_id * cores_per_node..(node_id + 1) * cores_per_node).collect();\n            nodes.push(NumaNode {\n                id: node_id,\n                cores,\n                memory_gb: 16, // Simplified\n            });\n        }\n        \n        NumaTopology {\n            nodes,\n            total_cores: config.numa_nodes * cores_per_node,\n        }\n    }\n    \n    pub fn schedule_work<F>(&self, work: F, preferred_node: Option<usize>) -> Result<(), &'static str>\n    where\n        F: FnOnce() + Send + 'static,\n    {\n        let work_item = Box::new(work);\n        \n        // Try to schedule on preferred NUMA node first\n        if let Some(node_id) = preferred_node {\n            if let Some(node) = self.numa_topology.nodes.get(node_id) {\n                for &core_id in &node.cores {\n                    if let Some(queue) = self.thread_queues.get(core_id) {\n                        if let Ok(mut q) = queue.try_lock() {\n                            q.push_back(work_item);\n                            return Ok(());\n                        }\n                    }\n                }\n            }\n        }\n        \n        // Fallback to any available queue\n        for queue in &self.thread_queues {\n            if let Ok(mut q) = queue.try_lock() {\n                q.push_back(work_item);\n                return Ok(());\n            }\n        }\n        \n        Err(\"All queues are busy\")\n    }\n    \n    pub fn try_steal_work(&self, thread_id: usize) -> Option<Box<dyn FnOnce() + Send>> {\n        self.steal_attempts.fetch_add(1, Ordering::Relaxed);\n        \n        // Try to steal from other queues in same NUMA node first\n        let current_node = self.get_numa_node_for_thread(thread_id);\n        \n        if let Some(node) = current_node {\n            for &core_id in &node.cores {\n                if core_id != thread_id {\n                    if let Some(queue) = self.thread_queues.get(core_id) {\n                        if let Ok(mut q) = queue.try_lock() {\n                            if let Some(work) = q.pop_front() {\n                                return Some(work);\n                            }\n                        }\n                    }\n                }\n            }\n        }\n        \n        // Steal from other NUMA nodes as last resort\n        for (i, queue) in self.thread_queues.iter().enumerate() {\n            if i != thread_id {\n                if let Ok(mut q) = queue.try_lock() {\n                    if let Some(work) = q.pop_front() {\n                        return Some(work);\n                    }\n                }\n            }\n        }\n        \n        None\n    }\n    \n    fn get_numa_node_for_thread(&self, thread_id: usize) -> Option<&NumaNode> {\n        self.numa_topology.nodes.iter()\n            .find(|node| node.cores.contains(&thread_id))\n    }\n    \n    pub fn stats(&self) -> SchedulerStats {\n        let total_tasks: usize = self.thread_queues.iter()\n            .map(|q| q.lock().unwrap().len())\n            .sum();\n        \n        SchedulerStats {\n            total_queued_tasks: total_tasks,\n            steal_attempts: self.steal_attempts.load(Ordering::Relaxed),\n            active_threads: self.numa_topology.total_cores,\n        }\n    }\n}\n\n#[derive(Debug)]\npub struct SchedulerStats {\n    pub total_queued_tasks: usize,\n    pub steal_attempts: usize,\n    pub active_threads: usize,\n}\n\n// High-performance parallel algorithms\npub struct ParallelAlgorithms;\n\nimpl ParallelAlgorithms {\n    // Parallel matrix multiplication with NUMA optimization\n    pub fn parallel_matrix_multiply(\n        a: &[Vec<f64>],\n        b: &[Vec<f64>],\n        numa_config: &NumaConfig,\n    ) -> Vec<Vec<f64>> {\n        let rows_a = a.len();\n        let cols_a = a[0].len();\n        let cols_b = b[0].len();\n        \n        assert_eq!(cols_a, b.len(), \"Matrix dimensions don't match\");\n        \n        let mut result = vec![vec![0.0; cols_b]; rows_a];\n        \n        // Use NUMA-aware chunking\n        let chunk_size = (rows_a / numa_config.numa_nodes).max(1);\n        \n        result.par_chunks_mut(chunk_size)\n            .enumerate()\n            .for_each(|(chunk_idx, chunk)| {\n                let start_row = chunk_idx * chunk_size;\n                \n                for (row_idx, row) in chunk.iter_mut().enumerate() {\n                    let global_row = start_row + row_idx;\n                    if global_row < rows_a {\n                        for col in 0..cols_b {\n                            let mut sum = 0.0;\n                            for k in 0..cols_a {\n                                sum += a[global_row][k] * b[k][col];\n                            }\n                            row[col] = sum;\n                        }\n                    }\n                }\n            });\n        \n        result\n    }\n    \n    // Parallel merge sort with work stealing\n    pub fn parallel_merge_sort<T>(data: &mut [T], thread_pool: &ThreadPool)\n    where\n        T: Send + Sync + Ord + Clone,\n    {\n        if data.len() <= 1 {\n            return;\n        }\n        \n        thread_pool.install(|| {\n            Self::parallel_merge_sort_impl(data);\n        });\n    }\n    \n    fn parallel_merge_sort_impl<T>(data: &mut [T])\n    where\n        T: Send + Sync + Ord + Clone,\n    {\n        let len = data.len();\n        if len <= 1000 {\n            // Use sequential sort for small arrays\n            data.sort();\n            return;\n        }\n        \n        let mid = len / 2;\n        let (left, right) = data.split_at_mut(mid);\n        \n        rayon::join(\n            || Self::parallel_merge_sort_impl(left),\n            || Self::parallel_merge_sort_impl(right),\n        );\n        \n        // Merge sorted halves\n        let mut temp = Vec::with_capacity(len);\n        let mut i = 0;\n        let mut j = 0;\n        \n        while i < left.len() && j < right.len() {\n            if left[i] <= right[j] {\n                temp.push(left[i].clone());\n                i += 1;\n            } else {\n                temp.push(right[j].clone());\n                j += 1;\n            }\n        }\n        \n        temp.extend_from_slice(&left[i..]);\n        temp.extend_from_slice(&right[j..]);\n        \n        data.clone_from_slice(&temp);\n    }\n    \n    // Parallel reduction with custom operator\n    pub fn parallel_reduce<T, F>(data: &[T], identity: T, op: F) -> T\n    where\n        T: Send + Sync + Clone,\n        F: Fn(T, T) -> T + Send + Sync,\n    {\n        data.par_iter()\n            .cloned()\n            .fold(|| identity.clone(), &op)\n            .reduce(|| identity.clone(), &op)\n    }\n    \n    // Parallel scan (prefix sum) with work-efficient algorithm\n    pub fn parallel_scan<T, F>(data: &[T], identity: T, op: F) -> Vec<T>\n    where\n        T: Send + Sync + Clone,\n        F: Fn(&T, &T) -> T + Send + Sync,\n    {\n        if data.is_empty() {\n            return Vec::new();\n        }\n        \n        let len = data.len();\n        let mut result = vec![identity.clone(); len];\n        \n        // Up-sweep (reduction) phase\n        let mut step = 1;\n        while step < len {\n            (0..len).into_par_iter()\n                .step_by(step * 2)\n                .for_each(|i| {\n                    let right = (i + step * 2 - 1).min(len - 1);\n                    let left = i + step - 1;\n                    if right < len && left < len {\n                        result[right] = op(&result[left], &result[right]);\n                    }\n                });\n            step *= 2;\n        }\n        \n        // Down-sweep phase\n        result[len - 1] = identity.clone();\n        step = len / 2;\n        \n        while step > 0 {\n            (0..len).into_par_iter()\n                .step_by(step * 2)\n                .for_each(|i| {\n                    let right = (i + step * 2 - 1).min(len - 1);\n                    let left = i + step - 1;\n                    if right < len && left < len {\n                        let temp = result[left].clone();\n                        result[left] = result[right].clone();\n                        result[right] = op(&result[right], &temp);\n                    }\n                });\n            step /= 2;\n        }\n        \n        result\n    }\n}\n\n// Benchmark framework\npub struct ParallelBenchmark {\n    name: String,\n    thread_pool: ThreadPool,\n    numa_config: NumaConfig,\n}\n\nimpl ParallelBenchmark {\n    pub fn new(name: String, numa_config: NumaConfig) -> Self {\n        let thread_pool = ThreadPoolBuilder::new()\n            .num_threads(numa_config.numa_nodes * numa_config.cores_per_node)\n            .build()\n            .expect(\"Failed to create thread pool\");\n        \n        Self {\n            name,\n            thread_pool,\n            numa_config,\n        }\n    }\n    \n    pub fn bench_matrix_multiply(&self, size: usize) -> BenchmarkResult {\n        println!(\"Benchmarking matrix multiplication ({}x{})\", size, size);\n        \n        // Generate test matrices\n        let matrix_a = self.generate_matrix(size, size);\n        let matrix_b = self.generate_matrix(size, size);\n        \n        // Sequential benchmark\n        let sequential_start = Instant::now();\n        let _sequential_result = self.sequential_matrix_multiply(&matrix_a, &matrix_b);\n        let sequential_time = sequential_start.elapsed();\n        \n        // Parallel benchmark\n        let parallel_start = Instant::now();\n        let _parallel_result = ParallelAlgorithms::parallel_matrix_multiply(\n            &matrix_a,\n            &matrix_b,\n            &self.numa_config,\n        );\n        let parallel_time = parallel_start.elapsed();\n        \n        BenchmarkResult {\n            algorithm: \"Matrix Multiplication\".to_string(),\n            sequential_time,\n            parallel_time,\n            speedup: sequential_time.as_nanos() as f64 / parallel_time.as_nanos() as f64,\n            efficiency: (sequential_time.as_nanos() as f64 / parallel_time.as_nanos() as f64) \n                        / (self.numa_config.numa_nodes * self.numa_config.cores_per_node) as f64,\n            data_size: size * size,\n        }\n    }\n    \n    pub fn bench_sort(&self, size: usize) -> BenchmarkResult {\n        println!(\"Benchmarking sort (size: {})\", size);\n        \n        // Generate test data\n        let mut sequential_data = self.generate_random_data(size);\n        let mut parallel_data = sequential_data.clone();\n        \n        // Sequential benchmark\n        let sequential_start = Instant::now();\n        sequential_data.sort();\n        let sequential_time = sequential_start.elapsed();\n        \n        // Parallel benchmark\n        let parallel_start = Instant::now();\n        ParallelAlgorithms::parallel_merge_sort(&mut parallel_data, &self.thread_pool);\n        let parallel_time = parallel_start.elapsed();\n        \n        BenchmarkResult {\n            algorithm: \"Merge Sort\".to_string(),\n            sequential_time,\n            parallel_time,\n            speedup: sequential_time.as_nanos() as f64 / parallel_time.as_nanos() as f64,\n            efficiency: (sequential_time.as_nanos() as f64 / parallel_time.as_nanos() as f64) \n                        / (self.numa_config.numa_nodes * self.numa_config.cores_per_node) as f64,\n            data_size: size,\n        }\n    }\n    \n    pub fn bench_reduction(&self, size: usize) -> BenchmarkResult {\n        println!(\"Benchmarking reduction (size: {})\", size);\n        \n        let data = self.generate_random_data(size);\n        \n        // Sequential benchmark\n        let sequential_start = Instant::now();\n        let _sequential_sum: i32 = data.iter().sum();\n        let sequential_time = sequential_start.elapsed();\n        \n        // Parallel benchmark\n        let parallel_start = Instant::now();\n        let _parallel_sum = ParallelAlgorithms::parallel_reduce(&data, 0, |a, b| a + b);\n        let parallel_time = parallel_start.elapsed();\n        \n        BenchmarkResult {\n            algorithm: \"Reduction\".to_string(),\n            sequential_time,\n            parallel_time,\n            speedup: sequential_time.as_nanos() as f64 / parallel_time.as_nanos() as f64,\n            efficiency: (sequential_time.as_nanos() as f64 / parallel_time.as_nanos() as f64) \n                        / (self.numa_config.numa_nodes * self.numa_config.cores_per_node) as f64,\n            data_size: size,\n        }\n    }\n    \n    fn generate_matrix(&self, rows: usize, cols: usize) -> Vec<Vec<f64>> {\n        let mut rng = thread_rng();\n        (0..rows)\n            .map(|_| (0..cols).map(|_| rng.gen_range(0.0..10.0)).collect())\n            .collect()\n    }\n    \n    fn generate_random_data(&self, size: usize) -> Vec<i32> {\n        let mut rng = thread_rng();\n        (0..size).map(|_| rng.gen_range(0..1000)).collect()\n    }\n    \n    fn sequential_matrix_multiply(&self, a: &[Vec<f64>], b: &[Vec<f64>]) -> Vec<Vec<f64>> {\n        let rows_a = a.len();\n        let cols_a = a[0].len();\n        let cols_b = b[0].len();\n        \n        let mut result = vec![vec![0.0; cols_b]; rows_a];\n        \n        for i in 0..rows_a {\n            for j in 0..cols_b {\n                let mut sum = 0.0;\n                for k in 0..cols_a {\n                    sum += a[i][k] * b[k][j];\n                }\n                result[i][j] = sum;\n            }\n        }\n        \n        result\n    }\n}\n\n#[derive(Debug)]\npub struct BenchmarkResult {\n    pub algorithm: String,\n    pub sequential_time: Duration,\n    pub parallel_time: Duration,\n    pub speedup: f64,\n    pub efficiency: f64,\n    pub data_size: usize,\n}\n\nimpl BenchmarkResult {\n    pub fn print_results(&self) {\n        println!(\"\n=== {} Benchmark Results ===\", self.algorithm);\n        println!(\"Data size: {}\", self.data_size);\n        println!(\"Sequential time: {:?}\", self.sequential_time);\n        println!(\"Parallel time: {:?}\", self.parallel_time);\n        println!(\"Speedup: {:.2}x\", self.speedup);\n        println!(\"Efficiency: {:.2}%\", self.efficiency * 100.0);\n        println!(\"Parallel efficiency: {:.2}%\", \n                (self.speedup / num_cpus::get() as f64) * 100.0);\n    }\n}\n\nfn main() -> Result<(), Box<dyn std::error::Error>> {\n    println!(\"High-Performance Parallel Iterator Benchmarks\");\n    println!(\"CPU cores: {}\", num_cpus::get());\n    \n    let numa_config = NumaConfig {\n        numa_nodes: 1,\n        cores_per_node: num_cpus::get(),\n        enable_affinity: true,\n        work_stealing_ratio: 0.1,\n    };\n    \n    let benchmark = ParallelBenchmark::new(\"Rayon Parallel\".to_string(), numa_config);\n    \n    // Test work stealing scheduler\n    let scheduler = WorkStealingScheduler::new(&benchmark.numa_config);\n    \n    // Schedule some test work\n    for i in 0..10 {\n        let work = move || {\n            println!(\"Executing work item {}\", i);\n            thread::sleep(Duration::from_millis(100));\n        };\n        scheduler.schedule_work(work, Some(i % benchmark.numa_config.numa_nodes))?;\n    }\n    \n    println!(\"Scheduler stats: {:?}\", scheduler.stats());\n    \n    // Run benchmarks\n    let matrix_result = benchmark.bench_matrix_multiply(500);\n    matrix_result.print_results();\n    \n    let sort_result = benchmark.bench_sort(1_000_000);\n    sort_result.print_results();\n    \n    let reduction_result = benchmark.bench_reduction(10_000_000);\n    reduction_result.print_results();\n    \n    // Test custom parallel range\n    println!(\"\n=== Custom Parallel Range Test ===\");\n    let range = ParallelRange::new(0usize, 1000)\n        .with_chunk_size(100)\n        .with_numa_config(benchmark.numa_config.clone());\n    \n    let start = Instant::now();\n    let squares: Vec<usize> = range.parallel_map(|x| x * x);\n    let parallel_range_time = start.elapsed();\n    \n    println!(\"Parallel range processing time: {:?}\", parallel_range_time);\n    println!(\"First 10 squares: {:?}\", &squares[0..10]);\n    \n    // Compare with sequential version\n    let start = Instant::now();\n    let sequential_squares: Vec<usize> = (0..1000).map(|x| x * x).collect();\n    let sequential_range_time = start.elapsed();\n    \n    println!(\"Sequential range processing time: {:?}\", sequential_range_time);\n    println!(\"Range speedup: {:.2}x\", \n            sequential_range_time.as_nanos() as f64 / parallel_range_time.as_nanos() as f64);\n    \n    // Verify correctness\n    assert_eq!(squares, sequential_squares);\n    println!(\"Correctness verified!\");\n    \n    Ok(())\n}",
    "key_concepts": [
      "parallel iterators",
      "Rayon framework",
      "work stealing",
      "NUMA awareness",
      "dynamic load balancing",
      "parallel algorithms",
      "performance benchmarking",
      "custom parallel patterns",
      "thread pool optimization",
      "parallel efficiency analysis"
    ]
  },
  {
    "prompt": "Create a comprehensive testing framework in Rust with property-based testing using proptest, integration tests, mocking with mockall, and custom test harnesses. Include test data factories and parameterized tests.",
    "response": "use proptest::prelude::*;\nuse mockall::{predicate::*, *};\nuse criterion::{black_box, criterion_group, criterion_main, Criterion};\nuse std::collections::HashMap;\nuse serde::{Deserialize, Serialize};\nuse uuid::Uuid;\nuse std::sync::{Arc, Mutex};\nuse std::time::{Duration, SystemTime};\n\n// Domain models for testing\n#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]\npub struct User {\n    pub id: Uuid,\n    pub username: String,\n    pub email: String,\n    pub age: u8,\n    pub created_at: SystemTime,\n}\n\n#[derive(Debug, Clone, PartialEq)]\npub struct Order {\n    pub id: Uuid,\n    pub user_id: Uuid,\n    pub items: Vec<OrderItem>,\n    pub total: f64,\n    pub status: OrderStatus,\n}\n\n#[derive(Debug, Clone, PartialEq)]\npub struct OrderItem {\n    pub product_id: Uuid,\n    pub quantity: u32,\n    pub price: f64,\n}\n\n#[derive(Debug, Clone, PartialEq)]\npub enum OrderStatus {\n    Pending,\n    Processing,\n    Shipped,\n    Delivered,\n    Cancelled,\n}\n\n// Repository traits for mocking\n#[automock]\npub trait UserRepository: Send + Sync {\n    fn create(&self, user: User) -> Result<User, RepositoryError>;\n    fn find_by_id(&self, id: Uuid) -> Result<Option<User>, RepositoryError>;\n    fn find_by_email(&self, email: &str) -> Result<Option<User>, RepositoryError>;\n    fn update(&self, user: User) -> Result<User, RepositoryError>;\n    fn delete(&self, id: Uuid) -> Result<(), RepositoryError>;\n    fn count(&self) -> Result<usize, RepositoryError>;\n}\n\n#[automock]\npub trait OrderRepository: Send + Sync {\n    fn create(&self, order: Order) -> Result<Order, RepositoryError>;\n    fn find_by_id(&self, id: Uuid) -> Result<Option<Order>, RepositoryError>;\n    fn find_by_user(&self, user_id: Uuid) -> Result<Vec<Order>, RepositoryError>;\n    fn update_status(&self, id: Uuid, status: OrderStatus) -> Result<(), RepositoryError>;\n}\n\n#[derive(Debug, Clone, thiserror::Error)]\npub enum RepositoryError {\n    #[error(\"Not found\")]\n    NotFound,\n    #[error(\"Database error: {0}\")]\n    Database(String),\n    #[error(\"Validation error: {0}\")]\n    Validation(String),\n}\n\n// Service layer for business logic\npub struct UserService {\n    user_repo: Arc<dyn UserRepository>,\n    email_service: Arc<dyn EmailService>,\n}\n\n#[automock]\npub trait EmailService: Send + Sync {\n    fn send_welcome_email(&self, user: &User) -> Result<(), EmailError>;\n    fn send_notification(&self, email: &str, subject: &str, body: &str) -> Result<(), EmailError>;\n}\n\n#[derive(Debug, Clone, thiserror::Error)]\npub enum EmailError {\n    #[error(\"Invalid email format\")]\n    InvalidFormat,\n    #[error(\"Service unavailable\")]\n    ServiceUnavailable,\n}\n\nimpl UserService {\n    pub fn new(user_repo: Arc<dyn UserRepository>, email_service: Arc<dyn EmailService>) -> Self {\n        Self { user_repo, email_service }\n    }\n    \n    pub fn register_user(&self, username: String, email: String, age: u8) -> Result<User, ServiceError> {\n        // Validation\n        if username.len() < 3 {\n            return Err(ServiceError::InvalidInput(\"Username too short\".to_string()));\n        }\n        \n        if age < 13 {\n            return Err(ServiceError::InvalidInput(\"User must be at least 13 years old\".to_string()));\n        }\n        \n        if !email.contains('@') {\n            return Err(ServiceError::InvalidInput(\"Invalid email format\".to_string()));\n        }\n        \n        // Check if email already exists\n        if let Ok(Some(_)) = self.user_repo.find_by_email(&email) {\n            return Err(ServiceError::AlreadyExists(\"Email already registered\".to_string()));\n        }\n        \n        let user = User {\n            id: Uuid::new_v4(),\n            username,\n            email: email.clone(),\n            age,\n            created_at: SystemTime::now(),\n        };\n        \n        let created_user = self.user_repo.create(user)\n            .map_err(|e| ServiceError::Repository(e))?;\n        \n        // Send welcome email\n        if let Err(e) = self.email_service.send_welcome_email(&created_user) {\n            eprintln!(\"Failed to send welcome email: {}\", e);\n        }\n        \n        Ok(created_user)\n    }\n    \n    pub fn get_user_stats(&self) -> Result<UserStats, ServiceError> {\n        let total_users = self.user_repo.count()\n            .map_err(|e| ServiceError::Repository(e))?;\n        \n        Ok(UserStats {\n            total_users,\n            active_users: total_users, // Simplified\n        })\n    }\n}\n\n#[derive(Debug, Clone)]\npub struct UserStats {\n    pub total_users: usize,\n    pub active_users: usize,\n}\n\n#[derive(Debug, Clone, thiserror::Error)]\npub enum ServiceError {\n    #[error(\"Invalid input: {0}\")]\n    InvalidInput(String),\n    #[error(\"Resource already exists: {0}\")]\n    AlreadyExists(String),\n    #[error(\"Repository error: {0}\")]\n    Repository(RepositoryError),\n}\n\n// Test data factories\npub struct TestDataFactory;\n\nimpl TestDataFactory {\n    pub fn user() -> UserBuilder {\n        UserBuilder::default()\n    }\n    \n    pub fn order() -> OrderBuilder {\n        OrderBuilder::default()\n    }\n    \n    pub fn valid_users(count: usize) -> Vec<User> {\n        (0..count).map(|i| {\n            User {\n                id: Uuid::new_v4(),\n                username: format!(\"user{}\", i),\n                email: format!(\"user{}@example.com\", i),\n                age: 20 + (i as u8 % 50),\n                created_at: SystemTime::now(),\n            }\n        }).collect()\n    }\n}\n\n#[derive(Default)]\npub struct UserBuilder {\n    id: Option<Uuid>,\n    username: Option<String>,\n    email: Option<String>,\n    age: Option<u8>,\n    created_at: Option<SystemTime>,\n}\n\nimpl UserBuilder {\n    pub fn id(mut self, id: Uuid) -> Self {\n        self.id = Some(id);\n        self\n    }\n    \n    pub fn username<S: Into<String>>(mut self, username: S) -> Self {\n        self.username = Some(username.into());\n        self\n    }\n    \n    pub fn email<S: Into<String>>(mut self, email: S) -> Self {\n        self.email = Some(email.into());\n        self\n    }\n    \n    pub fn age(mut self, age: u8) -> Self {\n        self.age = Some(age);\n        self\n    }\n    \n    pub fn build(self) -> User {\n        User {\n            id: self.id.unwrap_or_else(Uuid::new_v4),\n            username: self.username.unwrap_or_else(|| \"testuser\".to_string()),\n            email: self.email.unwrap_or_else(|| \"test@example.com\".to_string()),\n            age: self.age.unwrap_or(25),\n            created_at: self.created_at.unwrap_or_else(SystemTime::now),\n        }\n    }\n}\n\n#[derive(Default)]\npub struct OrderBuilder {\n    id: Option<Uuid>,\n    user_id: Option<Uuid>,\n    items: Vec<OrderItem>,\n    status: Option<OrderStatus>,\n}\n\nimpl OrderBuilder {\n    pub fn user_id(mut self, user_id: Uuid) -> Self {\n        self.user_id = Some(user_id);\n        self\n    }\n    \n    pub fn add_item(mut self, product_id: Uuid, quantity: u32, price: f64) -> Self {\n        self.items.push(OrderItem { product_id, quantity, price });\n        self\n    }\n    \n    pub fn status(mut self, status: OrderStatus) -> Self {\n        self.status = Some(status);\n        self\n    }\n    \n    pub fn build(self) -> Order {\n        let total = self.items.iter()\n            .map(|item| item.quantity as f64 * item.price)\n            .sum();\n        \n        Order {\n            id: self.id.unwrap_or_else(Uuid::new_v4),\n            user_id: self.user_id.unwrap_or_else(Uuid::new_v4),\n            items: self.items,\n            total,\n            status: self.status.unwrap_or(OrderStatus::Pending),\n        }\n    }\n}\n\n// Property-based test strategies\nprop_compose! {\n    fn arb_user()(\n        username in \"[a-zA-Z][a-zA-Z0-9_]{2,20}\",\n        email in \"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\",\n        age in 13u8..120u8\n    ) -> (String, String, u8) {\n        (username, email, age)\n    }\n}\n\nprop_compose! {\n    fn arb_order_item()(\n        quantity in 1u32..100u32,\n        price in 0.01f64..1000.0f64\n    ) -> (u32, f64) {\n        (quantity, price)\n    }\n}\n\n// Custom test framework\npub struct TestSuite {\n    name: String,\n    tests: Vec<Box<dyn Fn() -> TestResult + Send + Sync>>,\n    setup: Option<Box<dyn Fn() + Send + Sync>>,\n    teardown: Option<Box<dyn Fn() + Send + Sync>>,\n}\n\n#[derive(Debug)]\npub enum TestResult {\n    Pass,\n    Fail(String),\n    Skip(String),\n}\n\nimpl TestSuite {\n    pub fn new(name: &str) -> Self {\n        Self {\n            name: name.to_string(),\n            tests: Vec::new(),\n            setup: None,\n            teardown: None,\n        }\n    }\n    \n    pub fn setup<F>(mut self, f: F) -> Self\n    where\n        F: Fn() + Send + Sync + 'static,\n    {\n        self.setup = Some(Box::new(f));\n        self\n    }\n    \n    pub fn teardown<F>(mut self, f: F) -> Self\n    where\n        F: Fn() + Send + Sync + 'static,\n    {\n        self.teardown = Some(Box::new(f));\n        self\n    }\n    \n    pub fn add_test<F>(mut self, test: F) -> Self\n    where\n        F: Fn() -> TestResult + Send + Sync + 'static,\n    {\n        self.tests.push(Box::new(test));\n        self\n    }\n    \n    pub fn run(self) -> TestSuiteResult {\n        println!(\"Running test suite: {}\", self.name);\n        \n        if let Some(setup) = &self.setup {\n            setup();\n        }\n        \n        let mut passed = 0;\n        let mut failed = 0;\n        let mut skipped = 0;\n        let mut failures = Vec::new();\n        \n        for (i, test) in self.tests.iter().enumerate() {\n            match test() {\n                TestResult::Pass => {\n                    println!(\"  Test {}: PASS\", i + 1);\n                    passed += 1;\n                }\n                TestResult::Fail(msg) => {\n                    println!(\"  Test {}: FAIL - {}\", i + 1, msg);\n                    failed += 1;\n                    failures.push(format!(\"Test {}: {}\", i + 1, msg));\n                }\n                TestResult::Skip(msg) => {\n                    println!(\"  Test {}: SKIP - {}\", i + 1, msg);\n                    skipped += 1;\n                }\n            }\n        }\n        \n        if let Some(teardown) = &self.teardown {\n            teardown();\n        }\n        \n        TestSuiteResult {\n            suite_name: self.name,\n            passed,\n            failed,\n            skipped,\n            failures,\n        }\n    }\n}\n\n#[derive(Debug)]\npub struct TestSuiteResult {\n    pub suite_name: String,\n    pub passed: usize,\n    pub failed: usize,\n    pub skipped: usize,\n    pub failures: Vec<String>,\n}\n\nimpl TestSuiteResult {\n    pub fn is_success(&self) -> bool {\n        self.failed == 0\n    }\n    \n    pub fn print_summary(&self) {\n        println!(\"\n=== {} Test Results ===\", self.suite_name);\n        println!(\"Passed: {}\", self.passed);\n        println!(\"Failed: {}\", self.failed);\n        println!(\"Skipped: {}\", self.skipped);\n        \n        if !self.failures.is_empty() {\n            println!(\"\nFailures:\");\n            for failure in &self.failures {\n                println!(\"  - {}\", failure);\n            }\n        }\n    }\n}\n\n// Parameterized test macro\nmacro_rules! parameterized_test {\n    ($test_name:ident, $params:expr, $test_fn:expr) => {\n        #[test]\n        fn $test_name() {\n            for (i, param) in $params.iter().enumerate() {\n                let result = std::panic::catch_unwind(|| $test_fn(param));\n                match result {\n                    Ok(_) => println!(\"Parameter {}: PASS\", i),\n                    Err(_) => panic!(\"Parameter {} failed\", i),\n                }\n            }\n        }\n    };\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    \n    // Unit tests with mocking\n    #[test]\n    fn test_user_registration_success() {\n        let mut mock_user_repo = MockUserRepository::new();\n        let mut mock_email_service = MockEmailService::new();\n        \n        let expected_user = TestDataFactory::user()\n            .username(\"testuser\")\n            .email(\"test@example.com\")\n            .age(25)\n            .build();\n        \n        // Setup expectations\n        mock_user_repo\n            .expect_find_by_email()\n            .with(eq(\"test@example.com\"))\n            .times(1)\n            .returning(|_| Ok(None));\n        \n        mock_user_repo\n            .expect_create()\n            .times(1)\n            .returning(move |user| Ok(user));\n        \n        mock_email_service\n            .expect_send_welcome_email()\n            .times(1)\n            .returning(|_| Ok(()));\n        \n        let service = UserService::new(\n            Arc::new(mock_user_repo),\n            Arc::new(mock_email_service),\n        );\n        \n        let result = service.register_user(\n            \"testuser\".to_string(),\n            \"test@example.com\".to_string(),\n            25,\n        );\n        \n        assert!(result.is_ok());\n        let user = result.unwrap();\n        assert_eq!(user.username, \"testuser\");\n        assert_eq!(user.email, \"test@example.com\");\n        assert_eq!(user.age, 25);\n    }\n    \n    #[test]\n    fn test_user_registration_duplicate_email() {\n        let mut mock_user_repo = MockUserRepository::new();\n        let mock_email_service = MockEmailService::new();\n        \n        let existing_user = TestDataFactory::user()\n            .email(\"test@example.com\")\n            .build();\n        \n        mock_user_repo\n            .expect_find_by_email()\n            .with(eq(\"test@example.com\"))\n            .times(1)\n            .returning(move |_| Ok(Some(existing_user.clone())));\n        \n        let service = UserService::new(\n            Arc::new(mock_user_repo),\n            Arc::new(mock_email_service),\n        );\n        \n        let result = service.register_user(\n            \"testuser\".to_string(),\n            \"test@example.com\".to_string(),\n            25,\n        );\n        \n        assert!(result.is_err());\n        if let Err(ServiceError::AlreadyExists(msg)) = result {\n            assert_eq!(msg, \"Email already registered\");\n        } else {\n            panic!(\"Expected AlreadyExists error\");\n        }\n    }\n    \n    // Property-based tests\n    proptest! {\n        #[test]\n        fn test_user_registration_properties(\n            (username, email, age) in arb_user()\n        ) {\n            let mut mock_user_repo = MockUserRepository::new();\n            let mock_email_service = MockEmailService::new();\n            \n            mock_user_repo\n                .expect_find_by_email()\n                .returning(|_| Ok(None));\n            \n            mock_user_repo\n                .expect_create()\n                .returning(|user| Ok(user));\n            \n            let service = UserService::new(\n                Arc::new(mock_user_repo),\n                Arc::new(mock_email_service),\n            );\n            \n            let result = service.register_user(username.clone(), email.clone(), age);\n            \n            prop_assert!(result.is_ok());\n            let user = result.unwrap();\n            prop_assert_eq!(user.username, username);\n            prop_assert_eq!(user.email, email);\n            prop_assert_eq!(user.age, age);\n        }\n        \n        #[test]\n        fn test_order_total_calculation(\n            items in prop::collection::vec(arb_order_item(), 1..10)\n        ) {\n            let mut order_builder = TestDataFactory::order();\n            let mut expected_total = 0.0;\n            \n            for (quantity, price) in items {\n                order_builder = order_builder.add_item(Uuid::new_v4(), quantity, price);\n                expected_total += quantity as f64 * price;\n            }\n            \n            let order = order_builder.build();\n            prop_assert!((order.total - expected_total).abs() < 0.01);\n        }\n    }\n    \n    // Parameterized tests\n    parameterized_test!(\n        test_invalid_usernames,\n        vec![\"\", \"ab\", \"a\", \"user@name\"],\n        |username: &str| {\n            let mut mock_user_repo = MockUserRepository::new();\n            let mock_email_service = MockEmailService::new();\n            \n            let service = UserService::new(\n                Arc::new(mock_user_repo),\n                Arc::new(mock_email_service),\n            );\n            \n            let result = service.register_user(\n                username.to_string(),\n                \"test@example.com\".to_string(),\n                25,\n            );\n            \n            assert!(result.is_err());\n        }\n    );\n    \n    // Custom test suite example\n    #[test]\n    fn test_custom_suite() {\n        let suite = TestSuite::new(\"User Service Tests\")\n            .setup(|| println!(\"Setting up test environment\"))\n            .add_test(|| {\n                // Test 1: Valid user creation\n                TestResult::Pass\n            })\n            .add_test(|| {\n                // Test 2: Invalid email format\n                TestResult::Fail(\"Invalid email format\".to_string())\n            })\n            .add_test(|| {\n                // Test 3: Skipped test\n                TestResult::Skip(\"Feature not implemented\".to_string())\n            })\n            .teardown(|| println!(\"Cleaning up test environment\"));\n        \n        let result = suite.run();\n        result.print_summary();\n        \n        assert_eq!(result.passed, 1);\n        assert_eq!(result.failed, 1);\n        assert_eq!(result.skipped, 1);\n    }\n}\n\n// Integration tests\n#[cfg(test)]\nmod integration_tests {\n    use super::*;\n    use std::collections::HashMap;\n    use std::sync::{Arc, Mutex};\n    \n    // In-memory repository implementation for integration testing\n    pub struct InMemoryUserRepository {\n        users: Arc<Mutex<HashMap<Uuid, User>>>,\n        email_index: Arc<Mutex<HashMap<String, Uuid>>>,\n    }\n    \n    impl InMemoryUserRepository {\n        pub fn new() -> Self {\n            Self {\n                users: Arc::new(Mutex::new(HashMap::new())),\n                email_index: Arc::new(Mutex::new(HashMap::new())),\n            }\n        }\n    }\n    \n    impl UserRepository for InMemoryUserRepository {\n        fn create(&self, user: User) -> Result<User, RepositoryError> {\n            let mut users = self.users.lock().unwrap();\n            let mut email_index = self.email_index.lock().unwrap();\n            \n            if email_index.contains_key(&user.email) {\n                return Err(RepositoryError::Validation(\"Email already exists\".to_string()));\n            }\n            \n            users.insert(user.id, user.clone());\n            email_index.insert(user.email.clone(), user.id);\n            \n            Ok(user)\n        }\n        \n        fn find_by_id(&self, id: Uuid) -> Result<Option<User>, RepositoryError> {\n            let users = self.users.lock().unwrap();\n            Ok(users.get(&id).cloned())\n        }\n        \n        fn find_by_email(&self, email: &str) -> Result<Option<User>, RepositoryError> {\n            let email_index = self.email_index.lock().unwrap();\n            let users = self.users.lock().unwrap();\n            \n            if let Some(&user_id) = email_index.get(email) {\n                Ok(users.get(&user_id).cloned())\n            } else {\n                Ok(None)\n            }\n        }\n        \n        fn update(&self, user: User) -> Result<User, RepositoryError> {\n            let mut users = self.users.lock().unwrap();\n            users.insert(user.id, user.clone());\n            Ok(user)\n        }\n        \n        fn delete(&self, id: Uuid) -> Result<(), RepositoryError> {\n            let mut users = self.users.lock().unwrap();\n            let mut email_index = self.email_index.lock().unwrap();\n            \n            if let Some(user) = users.remove(&id) {\n                email_index.remove(&user.email);\n                Ok(())\n            } else {\n                Err(RepositoryError::NotFound)\n            }\n        }\n        \n        fn count(&self) -> Result<usize, RepositoryError> {\n            let users = self.users.lock().unwrap();\n            Ok(users.len())\n        }\n    }\n    \n    struct MockEmailService;\n    \n    impl EmailService for MockEmailService {\n        fn send_welcome_email(&self, _user: &User) -> Result<(), EmailError> {\n            Ok(())\n        }\n        \n        fn send_notification(&self, _email: &str, _subject: &str, _body: &str) -> Result<(), EmailError> {\n            Ok(())\n        }\n    }\n    \n    #[test]\n    fn test_complete_user_workflow() {\n        let user_repo = Arc::new(InMemoryUserRepository::new());\n        let email_service = Arc::new(MockEmailService);\n        let service = UserService::new(user_repo.clone(), email_service);\n        \n        // Register multiple users\n        let users = vec![\n            (\"alice\", \"alice@example.com\", 25),\n            (\"bob\", \"bob@example.com\", 30),\n            (\"charlie\", \"charlie@example.com\", 35),\n        ];\n        \n        for (username, email, age) in users {\n            let result = service.register_user(\n                username.to_string(),\n                email.to_string(),\n                age,\n            );\n            assert!(result.is_ok());\n        }\n        \n        // Check user count\n        let stats = service.get_user_stats().unwrap();\n        assert_eq!(stats.total_users, 3);\n        \n        // Find user by email\n        let alice = user_repo.find_by_email(\"alice@example.com\").unwrap();\n        assert!(alice.is_some());\n        assert_eq!(alice.unwrap().username, \"alice\");\n        \n        // Try to register duplicate email\n        let duplicate_result = service.register_user(\n            \"alice2\".to_string(),\n            \"alice@example.com\".to_string(),\n            28,\n        );\n        assert!(duplicate_result.is_err());\n    }\n}\n\nfn main() {\n    println!(\"Running comprehensive test examples...\");\n    \n    // This would normally be run with `cargo test`\n    println!(\"Tests should be run with: cargo test\");\n    println!(\"Property tests: cargo test --features proptest\");\n    println!(\"Integration tests: cargo test --test integration_tests\");\n}",
    "key_concepts": [
      "property-based testing",
      "mocking with mockall",
      "test data factories",
      "parameterized tests",
      "integration testing",
      "custom test frameworks",
      "test builders",
      "proptest strategies",
      "unit testing patterns",
      "test isolation"
    ]
  },
  {
    "prompt": "Build a performance benchmarking suite in Rust using Criterion with statistical analysis, flamegraph integration, memory profiling, and automated regression detection. Include micro-benchmarks and end-to-end performance tests.",
    "response": "use criterion::{\n    criterion_group, criterion_main, BenchmarkId, Criterion, Throughput, \n    PlotConfiguration, AxisScale, BatchSize, black_box, measurement::WallTime\n};\nuse criterion_perf_events::Perf;\nuse pprof::criterion::{Output, PProfProfiler};\nuse std::time::{Duration, Instant};\nuse std::collections::{HashMap, BTreeMap, VecDeque};\nuse std::sync::{Arc, Mutex};\nuse rayon::prelude::*;\nuse serde::{Deserialize, Serialize};\nuse rand::{thread_rng, Rng, distributions::Alphanumeric};\n\n// Memory tracking utility\n#[derive(Debug, Clone)]\npub struct MemoryStats {\n    pub allocated: usize,\n    pub deallocated: usize,\n    pub peak_usage: usize,\n    pub current_usage: usize,\n}\n\npub struct MemoryTracker {\n    stats: Arc<Mutex<MemoryStats>>,\n}\n\nimpl MemoryTracker {\n    pub fn new() -> Self {\n        Self {\n            stats: Arc::new(Mutex::new(MemoryStats {\n                allocated: 0,\n                deallocated: 0,\n                peak_usage: 0,\n                current_usage: 0,\n            })),\n        }\n    }\n    \n    pub fn track_allocation(&self, size: usize) {\n        let mut stats = self.stats.lock().unwrap();\n        stats.allocated += size;\n        stats.current_usage += size;\n        if stats.current_usage > stats.peak_usage {\n            stats.peak_usage = stats.current_usage;\n        }\n    }\n    \n    pub fn track_deallocation(&self, size: usize) {\n        let mut stats = self.stats.lock().unwrap();\n        stats.deallocated += size;\n        stats.current_usage = stats.current_usage.saturating_sub(size);\n    }\n    \n    pub fn get_stats(&self) -> MemoryStats {\n        self.stats.lock().unwrap().clone()\n    }\n    \n    pub fn reset(&self) {\n        let mut stats = self.stats.lock().unwrap();\n        *stats = MemoryStats {\n            allocated: 0,\n            deallocated: 0,\n            peak_usage: 0,\n            current_usage: 0,\n        };\n    }\n}\n\n// Data structures for benchmarking\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct BenchmarkData {\n    pub id: u64,\n    pub name: String,\n    pub value: f64,\n    pub tags: Vec<String>,\n    pub metadata: HashMap<String, String>,\n}\n\nimpl BenchmarkData {\n    pub fn new(id: u64) -> Self {\n        let mut rng = thread_rng();\n        Self {\n            id,\n            name: (0..20).map(|_| rng.sample(Alphanumeric) as char).collect(),\n            value: rng.gen_range(0.0..1000.0),\n            tags: (0..5).map(|i| format!(\"tag{}\", i)).collect(),\n            metadata: (0..10).map(|i| (\n                format!(\"key{}\", i),\n                format!(\"value{}\", i)\n            )).collect(),\n        }\n    }\n}\n\n// Algorithm implementations for benchmarking\npub struct SortingAlgorithms;\n\nimpl SortingAlgorithms {\n    pub fn quicksort<T: Ord + Clone>(arr: &mut [T]) {\n        if arr.len() <= 1 {\n            return;\n        }\n        \n        let pivot_index = Self::partition(arr);\n        let (left, right) = arr.split_at_mut(pivot_index);\n        \n        Self::quicksort(left);\n        Self::quicksort(&mut right[1..]);\n    }\n    \n    fn partition<T: Ord + Clone>(arr: &mut [T]) -> usize {\n        let len = arr.len();\n        let pivot_index = len / 2;\n        arr.swap(pivot_index, len - 1);\n        \n        let mut i = 0;\n        for j in 0..len - 1 {\n            if arr[j] <= arr[len - 1] {\n                arr.swap(i, j);\n                i += 1;\n            }\n        }\n        arr.swap(i, len - 1);\n        i\n    }\n    \n    pub fn mergesort<T: Ord + Clone>(arr: &mut [T]) {\n        let len = arr.len();\n        if len <= 1 {\n            return;\n        }\n        \n        let mid = len / 2;\n        Self::mergesort(&mut arr[0..mid]);\n        Self::mergesort(&mut arr[mid..]);\n        \n        let mut temp = arr.to_vec();\n        Self::merge(&arr[0..mid], &arr[mid..], &mut temp);\n        arr.clone_from_slice(&temp);\n    }\n    \n    fn merge<T: Ord + Clone>(left: &[T], right: &[T], result: &mut [T]) {\n        let mut i = 0;\n        let mut j = 0;\n        let mut k = 0;\n        \n        while i < left.len() && j < right.len() {\n            if left[i] <= right[j] {\n                result[k] = left[i].clone();\n                i += 1;\n            } else {\n                result[k] = right[j].clone();\n                j += 1;\n            }\n            k += 1;\n        }\n        \n        while i < left.len() {\n            result[k] = left[i].clone();\n            i += 1;\n            k += 1;\n        }\n        \n        while j < right.len() {\n            result[k] = right[j].clone();\n            j += 1;\n            k += 1;\n        }\n    }\n    \n    pub fn parallel_sort<T: Ord + Clone + Send>(arr: &mut [T]) {\n        arr.par_sort();\n    }\n}\n\n// Hash map implementations for comparison\npub struct HashMapBenchmarks;\n\nimpl HashMapBenchmarks {\n    pub fn std_hashmap_insert(data: &[BenchmarkData]) -> HashMap<u64, BenchmarkData> {\n        let mut map = HashMap::with_capacity(data.len());\n        for item in data {\n            map.insert(item.id, item.clone());\n        }\n        map\n    }\n    \n    pub fn btreemap_insert(data: &[BenchmarkData]) -> BTreeMap<u64, BenchmarkData> {\n        let mut map = BTreeMap::new();\n        for item in data {\n            map.insert(item.id, item.clone());\n        }\n        map\n    }\n    \n    pub fn lookup_performance(map: &HashMap<u64, BenchmarkData>, keys: &[u64]) -> usize {\n        keys.iter()\n            .filter_map(|&key| map.get(&key))\n            .count()\n    }\n}\n\n// I/O benchmarks\npub struct IOBenchmarks;\n\nimpl IOBenchmarks {\n    pub fn write_json_data(data: &[BenchmarkData]) -> Result<Vec<u8>, Box<dyn std::error::Error>> {\n        Ok(serde_json::to_vec(data)?)\n    }\n    \n    pub fn read_json_data(bytes: &[u8]) -> Result<Vec<BenchmarkData>, Box<dyn std::error::Error>> {\n        Ok(serde_json::from_slice(bytes)?)\n    }\n    \n    pub fn write_binary_data(data: &[BenchmarkData]) -> Result<Vec<u8>, Box<dyn std::error::Error>> {\n        Ok(bincode::serialize(data)?)\n    }\n    \n    pub fn read_binary_data(bytes: &[u8]) -> Result<Vec<BenchmarkData>, Box<dyn std::error::Error>> {\n        Ok(bincode::deserialize(bytes)?)\n    }\n}\n\n// Regression detection\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct BenchmarkResult {\n    pub name: String,\n    pub duration_ns: u64,\n    pub throughput: Option<f64>,\n    pub memory_usage: Option<MemoryStats>,\n    pub timestamp: std::time::SystemTime,\n}\n\npub struct RegressionDetector {\n    historical_results: HashMap<String, Vec<BenchmarkResult>>,\n    threshold_percentage: f64,\n}\n\nimpl RegressionDetector {\n    pub fn new(threshold_percentage: f64) -> Self {\n        Self {\n            historical_results: HashMap::new(),\n            threshold_percentage,\n        }\n    }\n    \n    pub fn add_result(&mut self, result: BenchmarkResult) {\n        self.historical_results\n            .entry(result.name.clone())\n            .or_insert_with(Vec::new)\n            .push(result);\n    }\n    \n    pub fn detect_regression(&self, new_result: &BenchmarkResult) -> Option<RegressionReport> {\n        if let Some(historical) = self.historical_results.get(&new_result.name) {\n            if historical.len() < 5 {\n                return None; // Need more data points\n            }\n            \n            let recent_results: Vec<_> = historical.iter()\n                .rev()\n                .take(10)\n                .collect();\n            \n            let avg_duration = recent_results.iter()\n                .map(|r| r.duration_ns as f64)\n                .sum::<f64>() / recent_results.len() as f64;\n            \n            let new_duration = new_result.duration_ns as f64;\n            let percentage_change = ((new_duration - avg_duration) / avg_duration) * 100.0;\n            \n            if percentage_change > self.threshold_percentage {\n                return Some(RegressionReport {\n                    benchmark_name: new_result.name.clone(),\n                    current_duration: new_result.duration_ns,\n                    baseline_duration: avg_duration as u64,\n                    percentage_regression: percentage_change,\n                    confidence: self.calculate_confidence(&recent_results, new_duration),\n                });\n            }\n        }\n        \n        None\n    }\n    \n    fn calculate_confidence(&self, historical: &[&BenchmarkResult], new_value: f64) -> f64 {\n        let values: Vec<f64> = historical.iter()\n            .map(|r| r.duration_ns as f64)\n            .collect();\n        \n        let mean = values.iter().sum::<f64>() / values.len() as f64;\n        let variance = values.iter()\n            .map(|v| (v - mean).powi(2))\n            .sum::<f64>() / values.len() as f64;\n        let std_dev = variance.sqrt();\n        \n        let z_score = (new_value - mean) / std_dev;\n        z_score.abs() / 3.0 // Simplified confidence calculation\n    }\n}\n\n#[derive(Debug)]\npub struct RegressionReport {\n    pub benchmark_name: String,\n    pub current_duration: u64,\n    pub baseline_duration: u64,\n    pub percentage_regression: f64,\n    pub confidence: f64,\n}\n\n// Benchmark functions\nfn bench_sorting_algorithms(c: &mut Criterion) {\n    let mut group = c.benchmark_group(\"sorting_algorithms\");\n    group.plot_config(PlotConfiguration::default().summary_scale(AxisScale::Logarithmic));\n    \n    for size in [100, 1000, 10000, 100000].iter() {\n        let data: Vec<i32> = (0..*size).map(|_| thread_rng().gen()).collect();\n        \n        group.throughput(Throughput::Elements(*size as u64));\n        \n        group.bench_with_input(\n            BenchmarkId::new(\"quicksort\", size),\n            size,\n            |b, &size| {\n                b.iter_batched(\n                    || data.clone(),\n                    |mut data| SortingAlgorithms::quicksort(&mut data),\n                    BatchSize::SmallInput,\n                );\n            },\n        );\n        \n        group.bench_with_input(\n            BenchmarkId::new(\"mergesort\", size),\n            size,\n            |b, &size| {\n                b.iter_batched(\n                    || data.clone(),\n                    |mut data| SortingAlgorithms::mergesort(&mut data),\n                    BatchSize::SmallInput,\n                );\n            },\n        );\n        \n        group.bench_with_input(\n            BenchmarkId::new(\"std_sort\", size),\n            size,\n            |b, &size| {\n                b.iter_batched(\n                    || data.clone(),\n                    |mut data| data.sort(),\n                    BatchSize::SmallInput,\n                );\n            },\n        );\n        \n        group.bench_with_input(\n            BenchmarkId::new(\"parallel_sort\", size),\n            size,\n            |b, &size| {\n                b.iter_batched(\n                    || data.clone(),\n                    |mut data| SortingAlgorithms::parallel_sort(&mut data),\n                    BatchSize::SmallInput,\n                );\n            },\n        );\n    }\n    \n    group.finish();\n}\n\nfn bench_data_structures(c: &mut Criterion) {\n    let mut group = c.benchmark_group(\"data_structures\");\n    \n    for size in [1000, 10000, 100000].iter() {\n        let data: Vec<BenchmarkData> = (0..*size)\n            .map(|i| BenchmarkData::new(i as u64))\n            .collect();\n        \n        group.throughput(Throughput::Elements(*size as u64));\n        \n        group.bench_with_input(\n            BenchmarkId::new(\"hashmap_insert\", size),\n            &data,\n            |b, data| {\n                b.iter(|| HashMapBenchmarks::std_hashmap_insert(black_box(data)))\n            },\n        );\n        \n        group.bench_with_input(\n            BenchmarkId::new(\"btreemap_insert\", size),\n            &data,\n            |b, data| {\n                b.iter(|| HashMapBenchmarks::btreemap_insert(black_box(data)))\n            },\n        );\n        \n        // Lookup benchmarks\n        let hashmap = HashMapBenchmarks::std_hashmap_insert(&data);\n        let lookup_keys: Vec<u64> = (0..*size).step_by(10).map(|i| i as u64).collect();\n        \n        group.bench_with_input(\n            BenchmarkId::new(\"hashmap_lookup\", size),\n            &lookup_keys,\n            |b, keys| {\n                b.iter(|| HashMapBenchmarks::lookup_performance(black_box(&hashmap), black_box(keys)))\n            },\n        );\n    }\n    \n    group.finish();\n}\n\nfn bench_serialization(c: &mut Criterion) {\n    let mut group = c.benchmark_group(\"serialization\");\n    \n    for size in [100, 1000, 10000].iter() {\n        let data: Vec<BenchmarkData> = (0..*size)\n            .map(|i| BenchmarkData::new(i as u64))\n            .collect();\n        \n        group.throughput(Throughput::Elements(*size as u64));\n        \n        group.bench_with_input(\n            BenchmarkId::new(\"json_serialize\", size),\n            &data,\n            |b, data| {\n                b.iter(|| IOBenchmarks::write_json_data(black_box(data)).unwrap())\n            },\n        );\n        \n        group.bench_with_input(\n            BenchmarkId::new(\"binary_serialize\", size),\n            &data,\n            |b, data| {\n                b.iter(|| IOBenchmarks::write_binary_data(black_box(data)).unwrap())\n            },\n        );\n        \n        let json_bytes = IOBenchmarks::write_json_data(&data).unwrap();\n        let binary_bytes = IOBenchmarks::write_binary_data(&data).unwrap();\n        \n        group.bench_with_input(\n            BenchmarkId::new(\"json_deserialize\", size),\n            &json_bytes,\n            |b, bytes| {\n                b.iter(|| IOBenchmarks::read_json_data(black_box(bytes)).unwrap())\n            },\n        );\n        \n        group.bench_with_input(\n            BenchmarkId::new(\"binary_deserialize\", size),\n            &binary_bytes,\n            |b, bytes| {\n                b.iter(|| IOBenchmarks::read_binary_data(black_box(bytes)).unwrap())\n            },\n        );\n    }\n    \n    group.finish();\n}\n\nfn bench_memory_allocation(c: &mut Criterion) {\n    let mut group = c.benchmark_group(\"memory_allocation\");\n    let memory_tracker = MemoryTracker::new();\n    \n    for size in [1000, 10000, 100000].iter() {\n        group.bench_with_input(\n            BenchmarkId::new(\"vector_allocation\", size),\n            size,\n            |b, &size| {\n                b.iter_custom(|iters| {\n                    memory_tracker.reset();\n                    let start = Instant::now();\n                    \n                    for _ in 0..iters {\n                        let vec: Vec<i32> = Vec::with_capacity(size);\n                        memory_tracker.track_allocation(size * std::mem::size_of::<i32>());\n                        black_box(vec);\n                    }\n                    \n                    start.elapsed()\n                });\n            },\n        );\n        \n        group.bench_with_input(\n            BenchmarkId::new(\"hashmap_allocation\", size),\n            size,\n            |b, &size| {\n                b.iter_custom(|iters| {\n                    memory_tracker.reset();\n                    let start = Instant::now();\n                    \n                    for _ in 0..iters {\n                        let map: HashMap<i32, i32> = HashMap::with_capacity(size);\n                        memory_tracker.track_allocation(size * (std::mem::size_of::<i32>() * 2 + 8));\n                        black_box(map);\n                    }\n                    \n                    start.elapsed()\n                });\n            },\n        );\n    }\n    \n    group.finish();\n}\n\nfn bench_parallel_algorithms(c: &mut Criterion) {\n    let mut group = c.benchmark_group(\"parallel_algorithms\");\n    \n    for size in [10000, 100000, 1000000].iter() {\n        let data: Vec<i32> = (0..*size).map(|_| thread_rng().gen()).collect();\n        \n        group.throughput(Throughput::Elements(*size as u64));\n        \n        group.bench_with_input(\n            BenchmarkId::new(\"sequential_sum\", size),\n            &data,\n            |b, data| {\n                b.iter(|| {\n                    black_box(data.iter().sum::<i32>())\n                })\n            },\n        );\n        \n        group.bench_with_input(\n            BenchmarkId::new(\"parallel_sum\", size),\n            &data,\n            |b, data| {\n                b.iter(|| {\n                    black_box(data.par_iter().sum::<i32>())\n                })\n            },\n        );\n        \n        group.bench_with_input(\n            BenchmarkId::new(\"sequential_filter_map\", size),\n            &data,\n            |b, data| {\n                b.iter(|| {\n                    black_box(\n                        data.iter()\n                            .filter(|&&x| x % 2 == 0)\n                            .map(|&x| x * 2)\n                            .collect::<Vec<_>>()\n                    )\n                })\n            },\n        );\n        \n        group.bench_with_input(\n            BenchmarkId::new(\"parallel_filter_map\", size),\n            &data,\n            |b, data| {\n                b.iter(|| {\n                    black_box(\n                        data.par_iter()\n                            .filter(|&&x| x % 2 == 0)\n                            .map(|&x| x * 2)\n                            .collect::<Vec<_>>()\n                    )\n                })\n            },\n        );\n    }\n    \n    group.finish();\n}\n\n// End-to-end benchmark\nfn bench_end_to_end_workflow(c: &mut Criterion) {\n    let mut group = c.benchmark_group(\"end_to_end\");\n    \n    group.bench_function(\"complete_data_pipeline\", |b| {\n        b.iter(|| {\n            // Generate data\n            let data: Vec<BenchmarkData> = (0..1000)\n                .map(|i| BenchmarkData::new(i as u64))\n                .collect();\n            \n            // Process data\n            let mut sorted_data = data.clone();\n            sorted_data.sort_by_key(|d| d.id);\n            \n            // Create index\n            let index: HashMap<u64, BenchmarkData> = HashMapBenchmarks::std_hashmap_insert(&data);\n            \n            // Serialize\n            let serialized = IOBenchmarks::write_json_data(&sorted_data).unwrap();\n            \n            // Deserialize\n            let deserialized: Vec<BenchmarkData> = IOBenchmarks::read_json_data(&serialized).unwrap();\n            \n            black_box((index, deserialized))\n        })\n    });\n    \n    group.finish();\n}\n\n// Custom measurement for memory profiling\nfn bench_with_memory_profiling(c: &mut Criterion) {\n    let memory_tracker = MemoryTracker::new();\n    \n    c.bench_function(\"memory_intensive_operation\", |b| {\n        b.iter_custom(|iters| {\n            memory_tracker.reset();\n            let start = Instant::now();\n            \n            for _ in 0..iters {\n                let mut data = Vec::with_capacity(10000);\n                memory_tracker.track_allocation(10000 * std::mem::size_of::<i32>());\n                \n                for i in 0..10000 {\n                    data.push(i);\n                }\n                \n                let _processed: Vec<i32> = data.iter().map(|&x| x * 2).collect();\n                memory_tracker.track_allocation(10000 * std::mem::size_of::<i32>());\n                \n                black_box(data);\n            }\n            \n            let duration = start.elapsed();\n            let stats = memory_tracker.get_stats();\n            println!(\"Memory stats: {:?}\", stats);\n            \n            duration\n        });\n    });\n}\n\n// Criterion configuration with profiling\nfn configure_criterion() -> Criterion {\n    Criterion::default()\n        .warm_up_time(Duration::from_secs(1))\n        .measurement_time(Duration::from_secs(5))\n        .sample_size(100)\n        .with_profiler(PProfProfiler::new(100, Output::Flamegraph(None)))\n        .plotting_backend(criterion::PlottingBackend::Plotters)\n}\n\n// Custom benchmark harness\nfn custom_benchmark_harness() {\n    println!(\"Running custom benchmark harness...\");\n    \n    let mut regression_detector = RegressionDetector::new(10.0); // 10% threshold\n    \n    // Simulate some historical results\n    for i in 0..20 {\n        let result = BenchmarkResult {\n            name: \"test_benchmark\".to_string(),\n            duration_ns: 1000000 + (i * 10000), // Gradually increasing\n            throughput: Some(1000.0),\n            memory_usage: None,\n            timestamp: std::time::SystemTime::now(),\n        };\n        regression_detector.add_result(result);\n    }\n    \n    // Test with a regression\n    let new_result = BenchmarkResult {\n        name: \"test_benchmark\".to_string(),\n        duration_ns: 1500000, // 50% slower\n        throughput: Some(667.0),\n        memory_usage: None,\n        timestamp: std::time::SystemTime::now(),\n    };\n    \n    if let Some(regression) = regression_detector.detect_regression(&new_result) {\n        println!(\"REGRESSION DETECTED!\");\n        println!(\"Benchmark: {}\", regression.benchmark_name);\n        println!(\"Current: {}ns\", regression.current_duration);\n        println!(\"Baseline: {}ns\", regression.baseline_duration);\n        println!(\"Regression: {:.2}%\", regression.percentage_regression);\n        println!(\"Confidence: {:.2}\", regression.confidence);\n    }\n}\n\ncriterion_group! {\n    name = benches;\n    config = configure_criterion();\n    targets = \n        bench_sorting_algorithms,\n        bench_data_structures,\n        bench_serialization,\n        bench_memory_allocation,\n        bench_parallel_algorithms,\n        bench_end_to_end_workflow,\n        bench_with_memory_profiling\n}\n\ncriterion_main!(benches);\n\n#[cfg(test)]\nmod benchmark_tests {\n    use super::*;\n    \n    #[test]\n    fn test_regression_detector() {\n        let mut detector = RegressionDetector::new(20.0);\n        \n        // Add baseline results\n        for i in 0..10 {\n            let result = BenchmarkResult {\n                name: \"test\".to_string(),\n                duration_ns: 1000000,\n                throughput: None,\n                memory_usage: None,\n                timestamp: std::time::SystemTime::now(),\n            };\n            detector.add_result(result);\n        }\n        \n        // Test no regression\n        let normal_result = BenchmarkResult {\n            name: \"test\".to_string(),\n            duration_ns: 1100000, // 10% slower\n            throughput: None,\n            memory_usage: None,\n            timestamp: std::time::SystemTime::now(),\n        };\n        \n        assert!(detector.detect_regression(&normal_result).is_none());\n        \n        // Test regression\n        let regression_result = BenchmarkResult {\n            name: \"test\".to_string(),\n            duration_ns: 1300000, // 30% slower\n            throughput: None,\n            memory_usage: None,\n            timestamp: std::time::SystemTime::now(),\n        };\n        \n        assert!(detector.detect_regression(&regression_result).is_some());\n    }\n    \n    #[test]\n    fn test_memory_tracker() {\n        let tracker = MemoryTracker::new();\n        \n        tracker.track_allocation(1000);\n        tracker.track_allocation(500);\n        \n        let stats = tracker.get_stats();\n        assert_eq!(stats.allocated, 1500);\n        assert_eq!(stats.current_usage, 1500);\n        assert_eq!(stats.peak_usage, 1500);\n        \n        tracker.track_deallocation(500);\n        let stats = tracker.get_stats();\n        assert_eq!(stats.current_usage, 1000);\n        assert_eq!(stats.deallocated, 500);\n    }\n}\n\nfn main() {\n    custom_benchmark_harness();\n    \n    println!(\"To run benchmarks:\");\n    println!(\"cargo bench\");\n    println!(\"cargo bench --bench benchmark_name\");\n    println!(\"cargo bench -- --output-format html\");\n    println!(\"cargo bench -- --profile-time 10\");\n}",
    "key_concepts": [
      "criterion benchmarking",
      "statistical analysis",
      "flamegraph profiling",
      "memory profiling",
      "regression detection",
      "micro-benchmarks",
      "throughput analysis",
      "performance monitoring",
      "benchmark automation",
      "profiling integration"
    ]
  },
  {
    "prompt": "Implement fuzz testing in Rust using cargo-fuzz and libfuzzer with custom fuzzing targets, crash reproduction, and coverage analysis. Include structured fuzzing and mutation strategies for complex data types.",
    "response": "#![no_main]\nuse libfuzzer_sys::fuzz_target;\nuse arbitrary::{Arbitrary, Unstructured};\nuse serde::{Deserialize, Serialize};\nuse std::collections::{HashMap, BTreeMap};\nuse std::convert::TryFrom;\n\n// Domain types for fuzzing\n#[derive(Debug, Clone, PartialEq, Arbitrary, Serialize, Deserialize)]\npub struct ParsedData {\n    pub version: u8,\n    pub flags: DataFlags,\n    pub payload: DataPayload,\n    pub checksum: u32,\n}\n\n#[derive(Debug, Clone, PartialEq, Arbitrary, Serialize, Deserialize)]\npub struct DataFlags {\n    pub compressed: bool,\n    pub encrypted: bool,\n    pub signed: bool,\n    pub priority: Priority,\n}\n\n#[derive(Debug, Clone, PartialEq, Arbitrary, Serialize, Deserialize)]\npub enum Priority {\n    Low,\n    Normal,\n    High,\n    Critical,\n}\n\n#[derive(Debug, Clone, PartialEq, Arbitrary, Serialize, Deserialize)]\npub enum DataPayload {\n    Text(String),\n    Binary(Vec<u8>),\n    Structured(StructuredData),\n    Compound(Vec<DataPayload>),\n}\n\n#[derive(Debug, Clone, PartialEq, Arbitrary, Serialize, Deserialize)]\npub struct StructuredData {\n    pub fields: HashMap<String, FieldValue>,\n    pub metadata: BTreeMap<String, String>,\n}\n\n#[derive(Debug, Clone, PartialEq, Arbitrary, Serialize, Deserialize)]\npub enum FieldValue {\n    Integer(i64),\n    Float(f64),\n    Text(String),\n    Boolean(bool),\n    Array(Vec<FieldValue>),\n    Nested(Box<StructuredData>),\n}\n\n// Parser implementation to fuzz\npub struct DataParser {\n    strict_mode: bool,\n    max_depth: usize,\n    max_size: usize,\n}\n\nimpl DataParser {\n    pub fn new() -> Self {\n        Self {\n            strict_mode: false,\n            max_depth: 10,\n            max_size: 1024 * 1024, // 1MB\n        }\n    }\n    \n    pub fn with_strict_mode(mut self) -> Self {\n        self.strict_mode = true;\n        self\n    }\n    \n    pub fn with_limits(mut self, max_depth: usize, max_size: usize) -> Self {\n        self.max_depth = max_depth;\n        self.max_size = max_size;\n        self\n    }\n    \n    pub fn parse(&self, data: &[u8]) -> Result<ParsedData, ParseError> {\n        if data.len() < 8 {\n            return Err(ParseError::InvalidFormat(\"Too short\".into()));\n        }\n        \n        if data.len() > self.max_size {\n            return Err(ParseError::SizeLimit);\n        }\n        \n        let version = data[0];\n        if self.strict_mode && version > 3 {\n            return Err(ParseError::UnsupportedVersion(version));\n        }\n        \n        let flags_byte = data[1];\n        let flags = DataFlags {\n            compressed: (flags_byte & 0x01) != 0,\n            encrypted: (flags_byte & 0x02) != 0,\n            signed: (flags_byte & 0x04) != 0,\n            priority: match (flags_byte >> 3) & 0x03 {\n                0 => Priority::Low,\n                1 => Priority::Normal,\n                2 => Priority::High,\n                3 => Priority::Critical,\n                _ => unreachable!(),\n            },\n        };\n        \n        let payload_len = u32::from_le_bytes([data[2], data[3], data[4], data[5]]) as usize;\n        if payload_len > data.len() - 8 {\n            return Err(ParseError::InvalidFormat(\"Payload length mismatch\".into()));\n        }\n        \n        let checksum = u32::from_le_bytes([data[data.len()-4], data[data.len()-3], data[data.len()-2], data[data.len()-1]]);\n        \n        let payload_data = &data[6..6+payload_len];\n        let payload = self.parse_payload(payload_data, 0)?;\n        \n        // Verify checksum\n        let calculated_checksum = self.calculate_checksum(&data[0..data.len()-4]);\n        if self.strict_mode && calculated_checksum != checksum {\n            return Err(ParseError::ChecksumMismatch);\n        }\n        \n        Ok(ParsedData {\n            version,\n            flags,\n            payload,\n            checksum,\n        })\n    }\n    \n    fn parse_payload(&self, data: &[u8], depth: usize) -> Result<DataPayload, ParseError> {\n        if depth > self.max_depth {\n            return Err(ParseError::DepthLimit);\n        }\n        \n        if data.is_empty() {\n            return Ok(DataPayload::Text(String::new()));\n        }\n        \n        match data[0] {\n            0x00 => {\n                // Text payload\n                let text = std::str::from_utf8(&data[1..])\n                    .map_err(|_| ParseError::InvalidFormat(\"Invalid UTF-8\".into()))?;\n                Ok(DataPayload::Text(text.to_string()))\n            }\n            0x01 => {\n                // Binary payload\n                Ok(DataPayload::Binary(data[1..].to_vec()))\n            }\n            0x02 => {\n                // Structured payload\n                if data.len() < 5 {\n                    return Err(ParseError::InvalidFormat(\"Structured data too short\".into()));\n                }\n                \n                let field_count = u32::from_le_bytes([data[1], data[2], data[3], data[4]]) as usize;\n                if field_count > 1000 {\n                    return Err(ParseError::InvalidFormat(\"Too many fields\".into()));\n                }\n                \n                let mut fields = HashMap::new();\n                let mut metadata = BTreeMap::new();\n                let mut offset = 5;\n                \n                for _ in 0..field_count {\n                    if offset >= data.len() {\n                        break;\n                    }\n                    \n                    let (key, value, new_offset) = self.parse_field(&data[offset..], offset, depth + 1)?;\n                    fields.insert(key, value);\n                    offset = new_offset;\n                }\n                \n                Ok(DataPayload::Structured(StructuredData { fields, metadata }))\n            }\n            0x03 => {\n                // Compound payload\n                if data.len() < 3 {\n                    return Err(ParseError::InvalidFormat(\"Compound data too short\".into()));\n                }\n                \n                let item_count = u16::from_le_bytes([data[1], data[2]]) as usize;\n                if item_count > 100 {\n                    return Err(ParseError::InvalidFormat(\"Too many compound items\".into()));\n                }\n                \n                let mut items = Vec::new();\n                let mut offset = 3;\n                \n                for _ in 0..item_count {\n                    if offset >= data.len() {\n                        break;\n                    }\n                    \n                    let item_len = data.get(offset).copied().unwrap_or(0) as usize;\n                    offset += 1;\n                    \n                    if offset + item_len > data.len() {\n                        break;\n                    }\n                    \n                    let item = self.parse_payload(&data[offset..offset + item_len], depth + 1)?;\n                    items.push(item);\n                    offset += item_len;\n                }\n                \n                Ok(DataPayload::Compound(items))\n            }\n            _ => Err(ParseError::InvalidFormat(\"Unknown payload type\".into())),\n        }\n    }\n    \n    fn parse_field(&self, data: &[u8], base_offset: usize, depth: usize) -> Result<(String, FieldValue, usize), ParseError> {\n        if data.len() < 2 {\n            return Err(ParseError::InvalidFormat(\"Field data too short\".into()));\n        }\n        \n        let key_len = data[0] as usize;\n        let value_type = data[1];\n        let mut offset = 2;\n        \n        if offset + key_len > data.len() {\n            return Err(ParseError::InvalidFormat(\"Key length overflow\".into()));\n        }\n        \n        let key = std::str::from_utf8(&data[offset..offset + key_len])\n            .map_err(|_| ParseError::InvalidFormat(\"Invalid key UTF-8\".into()))?\n            .to_string();\n        offset += key_len;\n        \n        let value = match value_type {\n            0x10 => {\n                // Integer\n                if offset + 8 > data.len() {\n                    return Err(ParseError::InvalidFormat(\"Integer field too short\".into()));\n                }\n                let int_val = i64::from_le_bytes([\n                    data[offset], data[offset+1], data[offset+2], data[offset+3],\n                    data[offset+4], data[offset+5], data[offset+6], data[offset+7]\n                ]);\n                offset += 8;\n                FieldValue::Integer(int_val)\n            }\n            0x11 => {\n                // Float\n                if offset + 8 > data.len() {\n                    return Err(ParseError::InvalidFormat(\"Float field too short\".into()));\n                }\n                let float_val = f64::from_le_bytes([\n                    data[offset], data[offset+1], data[offset+2], data[offset+3],\n                    data[offset+4], data[offset+5], data[offset+6], data[offset+7]\n                ]);\n                offset += 8;\n                FieldValue::Float(float_val)\n            }\n            0x12 => {\n                // Text\n                if offset >= data.len() {\n                    return Err(ParseError::InvalidFormat(\"Text field missing length\".into()));\n                }\n                let text_len = data[offset] as usize;\n                offset += 1;\n                \n                if offset + text_len > data.len() {\n                    return Err(ParseError::InvalidFormat(\"Text field length overflow\".into()));\n                }\n                \n                let text = std::str::from_utf8(&data[offset..offset + text_len])\n                    .map_err(|_| ParseError::InvalidFormat(\"Invalid text UTF-8\".into()))?\n                    .to_string();\n                offset += text_len;\n                FieldValue::Text(text)\n            }\n            0x13 => {\n                // Boolean\n                if offset >= data.len() {\n                    return Err(ParseError::InvalidFormat(\"Boolean field missing\".into()));\n                }\n                let bool_val = data[offset] != 0;\n                offset += 1;\n                FieldValue::Boolean(bool_val)\n            }\n            _ => return Err(ParseError::InvalidFormat(\"Unknown field type\".into())),\n        };\n        \n        Ok((key, value, base_offset + offset))\n    }\n    \n    fn calculate_checksum(&self, data: &[u8]) -> u32 {\n        data.iter().fold(0u32, |acc, &byte| {\n            acc.wrapping_mul(31).wrapping_add(byte as u32)\n        })\n    }\n}\n\n#[derive(Debug, Clone, thiserror::Error)]\npub enum ParseError {\n    #[error(\"Invalid format: {0}\")]\n    InvalidFormat(String),\n    #[error(\"Unsupported version: {0}\")]\n    UnsupportedVersion(u8),\n    #[error(\"Size limit exceeded\")]\n    SizeLimit,\n    #[error(\"Depth limit exceeded\")]\n    DepthLimit,\n    #[error(\"Checksum mismatch\")]\n    ChecksumMismatch,\n}\n\n// Serializer for generating test data\npub struct DataSerializer;\n\nimpl DataSerializer {\n    pub fn serialize(data: &ParsedData) -> Vec<u8> {\n        let mut result = Vec::new();\n        \n        // Version\n        result.push(data.version);\n        \n        // Flags\n        let mut flags_byte = 0u8;\n        if data.flags.compressed { flags_byte |= 0x01; }\n        if data.flags.encrypted { flags_byte |= 0x02; }\n        if data.flags.signed { flags_byte |= 0x04; }\n        \n        flags_byte |= (match data.flags.priority {\n            Priority::Low => 0,\n            Priority::Normal => 1,\n            Priority::High => 2,\n            Priority::Critical => 3,\n        }) << 3;\n        \n        result.push(flags_byte);\n        \n        // Serialize payload\n        let payload_bytes = Self::serialize_payload(&data.payload);\n        \n        // Payload length\n        result.extend_from_slice(&(payload_bytes.len() as u32).to_le_bytes());\n        \n        // Payload\n        result.extend_from_slice(&payload_bytes);\n        \n        // Checksum\n        let checksum = data.checksum;\n        result.extend_from_slice(&checksum.to_le_bytes());\n        \n        result\n    }\n    \n    fn serialize_payload(payload: &DataPayload) -> Vec<u8> {\n        let mut result = Vec::new();\n        \n        match payload {\n            DataPayload::Text(text) => {\n                result.push(0x00);\n                result.extend_from_slice(text.as_bytes());\n            }\n            DataPayload::Binary(data) => {\n                result.push(0x01);\n                result.extend_from_slice(data);\n            }\n            DataPayload::Structured(structured) => {\n                result.push(0x02);\n                result.extend_from_slice(&(structured.fields.len() as u32).to_le_bytes());\n                \n                for (key, value) in &structured.fields {\n                    result.push(key.len() as u8);\n                    \n                    match value {\n                        FieldValue::Integer(i) => {\n                            result.push(0x10);\n                            result.extend_from_slice(key.as_bytes());\n                            result.extend_from_slice(&i.to_le_bytes());\n                        }\n                        FieldValue::Float(f) => {\n                            result.push(0x11);\n                            result.extend_from_slice(key.as_bytes());\n                            result.extend_from_slice(&f.to_le_bytes());\n                        }\n                        FieldValue::Text(text) => {\n                            result.push(0x12);\n                            result.extend_from_slice(key.as_bytes());\n                            result.push(text.len() as u8);\n                            result.extend_from_slice(text.as_bytes());\n                        }\n                        FieldValue::Boolean(b) => {\n                            result.push(0x13);\n                            result.extend_from_slice(key.as_bytes());\n                            result.push(if *b { 1 } else { 0 });\n                        }\n                        _ => {} // Simplified for fuzzing\n                    }\n                }\n            }\n            DataPayload::Compound(items) => {\n                result.push(0x03);\n                result.extend_from_slice(&(items.len() as u16).to_le_bytes());\n                \n                for item in items {\n                    let item_bytes = Self::serialize_payload(item);\n                    result.push(item_bytes.len() as u8);\n                    result.extend_from_slice(&item_bytes);\n                }\n            }\n        }\n        \n        result\n    }\n}\n\n// Fuzzing targets\n\n// Basic parser fuzzing\nfuzz_target!(|data: &[u8]| {\n    let parser = DataParser::new();\n    let _ = parser.parse(data);\n});\n\n// Structured fuzzing with Arbitrary\nfuzz_target!(|data: ParsedData| {\n    let serialized = DataSerializer::serialize(&data);\n    let parser = DataParser::new();\n    \n    if let Ok(parsed) = parser.parse(&serialized) {\n        // Verify round-trip consistency\n        assert_eq!(parsed.version, data.version);\n        assert_eq!(parsed.flags, data.flags);\n        // Note: payload comparison might fail due to serialization limits\n    }\n});\n\n// Coverage-guided fuzzing for specific scenarios\nfuzz_target!(|input: (u8, bool, Vec<u8>)| {\n    let (version, strict_mode, data) = input;\n    \n    let mut parser = DataParser::new();\n    if strict_mode {\n        parser = parser.with_strict_mode();\n    }\n    \n    // Test with different version numbers\n    let mut test_data = vec![version, 0x00, 0x04, 0x00, 0x00, 0x00];\n    test_data.extend_from_slice(&data);\n    test_data.extend_from_slice(&[0x00, 0x00, 0x00, 0x00]); // checksum\n    \n    let _ = parser.parse(&test_data);\n});\n\n// Differential fuzzing - compare strict vs non-strict modes\nfuzz_target!(|data: &[u8]| {\n    let strict_parser = DataParser::new().with_strict_mode();\n    let lenient_parser = DataParser::new();\n    \n    let strict_result = strict_parser.parse(data);\n    let lenient_result = lenient_parser.parse(data);\n    \n    // If strict parsing succeeds, lenient should also succeed\n    if strict_result.is_ok() {\n        assert!(lenient_result.is_ok());\n    }\n});\n\n// Performance fuzzing - detect algorithmic complexity issues\nfuzz_target!(|input: (usize, Vec<u8>)| {\n    let (depth, data) = input;\n    let max_depth = (depth % 20) + 1; // Limit depth to prevent timeout\n    \n    let parser = DataParser::new().with_limits(max_depth, 1024 * 1024);\n    let start = std::time::Instant::now();\n    \n    let _ = parser.parse(&data);\n    \n    let duration = start.elapsed();\n    // Assert that parsing doesn't take too long (detect potential DoS)\n    assert!(duration.as_millis() < 1000, \"Parsing took too long: {:?}\", duration);\n});\n\n// State-based fuzzing for compound payloads\nfuzz_target!(|operations: Vec<FuzzOperation>| {\n    let mut builder = CompoundDataBuilder::new();\n    \n    for op in operations {\n        match op {\n            FuzzOperation::AddText(text) => {\n                builder.add_text_payload(text);\n            }\n            FuzzOperation::AddBinary(data) => {\n                builder.add_binary_payload(data);\n            }\n            FuzzOperation::AddNested(depth) => {\n                if depth % 5 == 0 { // Limit nesting\n                    builder.add_nested_payload();\n                }\n            }\n            FuzzOperation::Serialize => {\n                if let Some(data) = builder.build() {\n                    let serialized = DataSerializer::serialize(&data);\n                    let parser = DataParser::new();\n                    let _ = parser.parse(&serialized);\n                }\n            }\n        }\n    }\n});\n\n#[derive(Debug, Clone, Arbitrary)]\nenum FuzzOperation {\n    AddText(String),\n    AddBinary(Vec<u8>),\n    AddNested(u8),\n    Serialize,\n}\n\nstruct CompoundDataBuilder {\n    items: Vec<DataPayload>,\n}\n\nimpl CompoundDataBuilder {\n    fn new() -> Self {\n        Self { items: Vec::new() }\n    }\n    \n    fn add_text_payload(&mut self, text: String) {\n        self.items.push(DataPayload::Text(text));\n    }\n    \n    fn add_binary_payload(&mut self, data: Vec<u8>) {\n        if data.len() < 1000 { // Prevent memory exhaustion\n            self.items.push(DataPayload::Binary(data));\n        }\n    }\n    \n    fn add_nested_payload(&mut self) {\n        let mut fields = HashMap::new();\n        fields.insert(\"nested\".to_string(), FieldValue::Boolean(true));\n        \n        self.items.push(DataPayload::Structured(StructuredData {\n            fields,\n            metadata: BTreeMap::new(),\n        }));\n    }\n    \n    fn build(self) -> Option<ParsedData> {\n        if self.items.is_empty() {\n            return None;\n        }\n        \n        Some(ParsedData {\n            version: 1,\n            flags: DataFlags {\n                compressed: false,\n                encrypted: false,\n                signed: false,\n                priority: Priority::Normal,\n            },\n            payload: DataPayload::Compound(self.items),\n            checksum: 0, // Will be calculated during serialization\n        })\n    }\n}\n\n// Regression fuzzing - test against known crashes\nfuzz_target!(|data: &[u8]| {\n    // Test specific known problematic patterns\n    let patterns = [\n        // Empty data\n        &[] as &[u8],\n        // Minimal valid data\n        &[1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n        // Maximum valid version\n        &[3, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n        // Large payload length\n        &[1, 0, 255, 255, 255, 255, 0, 0, 0, 0],\n    ];\n    \n    let parser = DataParser::new();\n    \n    // Test input data\n    let _ = parser.parse(data);\n    \n    // Test known patterns with input as suffix\n    for pattern in &patterns {\n        let mut combined = pattern.to_vec();\n        combined.extend_from_slice(data);\n        let _ = parser.parse(&combined);\n    }\n});\n\n// Custom mutator for structured input\npub fn custom_mutate(data: &mut [u8], max_size: usize) -> usize {\n    if data.is_empty() {\n        return 0;\n    }\n    \n    let mut rng = fastrand::Rng::new();\n    \n    match rng.u8(0..4) {\n        0 => {\n            // Flip version byte\n            if !data.is_empty() {\n                data[0] = rng.u8(0..10);\n            }\n        }\n        1 => {\n            // Modify flags\n            if data.len() > 1 {\n                data[1] = rng.u8(0..255);\n            }\n        }\n        2 => {\n            // Corrupt payload length\n            if data.len() >= 6 {\n                let corrupt_len = rng.u32(0..0xFFFFFFFF);\n                data[2..6].copy_from_slice(&corrupt_len.to_le_bytes());\n            }\n        }\n        3 => {\n            // Random byte flip\n            let idx = rng.usize(0..data.len());\n            data[idx] = rng.u8(0..255);\n        }\n        _ => {}\n    }\n    \n    data.len().min(max_size)\n}\n\n// Crash reproduction utilities\npub fn minimize_crash(crash_input: &[u8]) -> Vec<u8> {\n    let parser = DataParser::new();\n    \n    // Try to minimize the input while preserving the crash\n    let mut minimal = crash_input.to_vec();\n    \n    // Remove bytes from the end\n    while minimal.len() > 1 {\n        let mut test = minimal.clone();\n        test.pop();\n        \n        if parser.parse(&test).is_err() {\n            minimal = test;\n        } else {\n            break;\n        }\n    }\n    \n    // Try zeroing bytes\n    for i in 0..minimal.len() {\n        let original = minimal[i];\n        minimal[i] = 0;\n        \n        if parser.parse(&minimal).is_ok() {\n            minimal[i] = original; // Restore if it doesn't crash\n        }\n    }\n    \n    minimal\n}\n\n#[cfg(test)]\nmod fuzz_tests {\n    use super::*;\n    \n    #[test]\n    fn test_crash_reproduction() {\n        // Example crash case\n        let crash_input = vec![1, 255, 255, 255, 255, 255, 0, 0, 0, 0];\n        let minimized = minimize_crash(&crash_input);\n        \n        let parser = DataParser::new();\n        assert!(parser.parse(&crash_input).is_err());\n        assert!(parser.parse(&minimized).is_err());\n        assert!(minimized.len() <= crash_input.len());\n    }\n    \n    #[test]\n    fn test_round_trip_fuzzing() {\n        use arbitrary::{Arbitrary, Unstructured};\n        \n        let test_data = vec![0u8; 1000];\n        let mut unstructured = Unstructured::new(&test_data);\n        \n        if let Ok(parsed_data) = ParsedData::arbitrary(&mut unstructured) {\n            let serialized = DataSerializer::serialize(&parsed_data);\n            let parser = DataParser::new();\n            \n            // Should not crash\n            let _ = parser.parse(&serialized);\n        }\n    }\n    \n    #[test]\n    fn test_differential_fuzzing() {\n        let test_cases = vec![\n            vec![1, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n            vec![2, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n            vec![3, 255, 10, 0, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 0, 0, 0, 0],\n        ];\n        \n        for test_case in test_cases {\n            let strict_parser = DataParser::new().with_strict_mode();\n            let lenient_parser = DataParser::new();\n            \n            let strict_result = strict_parser.parse(&test_case);\n            let lenient_result = lenient_parser.parse(&test_case);\n            \n            // If strict succeeds, lenient should also succeed\n            if strict_result.is_ok() {\n                assert!(lenient_result.is_ok());\n            }\n        }\n    }\n}\n\n// Coverage analysis helper\npub fn analyze_coverage(corpus_dir: &str) -> std::io::Result<CoverageReport> {\n    use std::fs;\n    use std::path::Path;\n    \n    let corpus_path = Path::new(corpus_dir);\n    let mut total_inputs = 0;\n    let mut successful_parses = 0;\n    let mut error_types = HashMap::new();\n    \n    for entry in fs::read_dir(corpus_path)? {\n        let entry = entry?;\n        let data = fs::read(entry.path())?;\n        total_inputs += 1;\n        \n        let parser = DataParser::new();\n        match parser.parse(&data) {\n            Ok(_) => successful_parses += 1,\n            Err(e) => {\n                let error_type = std::mem::discriminant(&e);\n                *error_types.entry(format!(\"{:?}\", error_type)).or_insert(0) += 1;\n            }\n        }\n    }\n    \n    Ok(CoverageReport {\n        total_inputs,\n        successful_parses,\n        error_types,\n        coverage_percentage: (successful_parses as f64 / total_inputs as f64) * 100.0,\n    })\n}\n\n#[derive(Debug)]\npub struct CoverageReport {\n    pub total_inputs: usize,\n    pub successful_parses: usize,\n    pub error_types: HashMap<String, usize>,\n    pub coverage_percentage: f64,\n}\n\nfn main() {\n    println!(\"Fuzz testing setup for Rust\");\n    println!(\"Run with: cargo fuzz run <target>\");\n    println!(\"Available targets:\");\n    println!(\"  - parser_basic\");\n    println!(\"  - parser_structured\");\n    println!(\"  - parser_differential\");\n    println!(\"  - parser_performance\");\n    println!(\"  - parser_stateful\");\n    println!(\"  - parser_regression\");\n}",
    "key_concepts": [
      "fuzz testing",
      "cargo-fuzz",
      "libfuzzer",
      "arbitrary trait",
      "structured fuzzing",
      "mutation strategies",
      "crash reproduction",
      "coverage analysis",
      "differential fuzzing",
      "state-based fuzzing"
    ]
  },
  {
    "prompt": "Create integration tests for microservices in Rust using Docker containers, test databases, service discovery, and distributed tracing. Include contract testing, chaos engineering, and end-to-end workflow validation.",
    "response": "use std::collections::HashMap;\nuse std::time::Duration;\nuse tokio::time::timeout;\nuse testcontainers::{clients::Cli, Container, Docker, Image, WaitFor};\nuse reqwest::Client;\nuse serde::{Deserialize, Serialize};\nuse uuid::Uuid;\nuse tracing::{info, warn, error, instrument};\nuse tracing_subscriber;\nuse opentelemetry::trace::{Tracer, SpanKind};\nuse opentelemetry_jaeger;\n\n// Service definitions\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct User {\n    pub id: Uuid,\n    pub username: String,\n    pub email: String,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct Order {\n    pub id: Uuid,\n    pub user_id: Uuid,\n    pub items: Vec<OrderItem>,\n    pub total: f64,\n    pub status: OrderStatus,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct OrderItem {\n    pub product_id: Uuid,\n    pub quantity: u32,\n    pub price: f64,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub enum OrderStatus {\n    Created,\n    Paid,\n    Shipped,\n    Delivered,\n    Cancelled,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct Payment {\n    pub id: Uuid,\n    pub order_id: Uuid,\n    pub amount: f64,\n    pub status: PaymentStatus,\n    pub gateway: String,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub enum PaymentStatus {\n    Pending,\n    Authorized,\n    Captured,\n    Failed,\n    Refunded,\n}\n\n// Docker container configurations\n#[derive(Default)]\npub struct PostgresImage {\n    tag: String,\n}\n\nimpl PostgresImage {\n    pub fn new(tag: &str) -> Self {\n        Self { tag: tag.to_string() }\n    }\n}\n\nimpl Image for PostgresImage {\n    type Args = Vec<String>;\n    \n    fn name(&self) -> String {\n        \"postgres\".to_string()\n    }\n    \n    fn tag(&self) -> String {\n        if self.tag.is_empty() {\n            \"13\".to_string()\n        } else {\n            self.tag.clone()\n        }\n    }\n    \n    fn ready_conditions(&self) -> Vec<WaitFor> {\n        vec![WaitFor::message_on_stderr(\"database system is ready to accept connections\")]\n    }\n    \n    fn env_vars(&self) -> Box<dyn Iterator<Item = (&String, &String)> + '_> {\n        let mut vars = HashMap::new();\n        vars.insert(\"POSTGRES_DB\".to_string(), \"testdb\".to_string());\n        vars.insert(\"POSTGRES_USER\".to_string(), \"testuser\".to_string());\n        vars.insert(\"POSTGRES_PASSWORD\".to_string(), \"testpass\".to_string());\n        \n        Box::new(vars.iter())\n    }\n}\n\n#[derive(Default)]\npub struct RedisImage;\n\nimpl Image for RedisImage {\n    type Args = Vec<String>;\n    \n    fn name(&self) -> String {\n        \"redis\".to_string()\n    }\n    \n    fn tag(&self) -> String {\n        \"6-alpine\".to_string()\n    }\n    \n    fn ready_conditions(&self) -> Vec<WaitFor> {\n        vec![WaitFor::message_on_stdout(\"Ready to accept connections\")]\n    }\n}\n\n#[derive(Default)]\npub struct JaegerImage;\n\nimpl Image for JaegerImage {\n    type Args = Vec<String>;\n    \n    fn name(&self) -> String {\n        \"jaegertracing/all-in-one\".to_string()\n    }\n    \n    fn tag(&self) -> String {\n        \"latest\".to_string()\n    }\n    \n    fn ready_conditions(&self) -> Vec<WaitFor> {\n        vec![WaitFor::message_on_stdout(\"Query server started\")]\n    }\n    \n    fn env_vars(&self) -> Box<dyn Iterator<Item = (&String, &String)> + '_> {\n        let mut vars = HashMap::new();\n        vars.insert(\"COLLECTOR_ZIPKIN_HTTP_PORT\".to_string(), \"9411\".to_string());\n        \n        Box::new(vars.iter())\n    }\n}\n\n// Service client wrappers\npub struct UserServiceClient {\n    client: Client,\n    base_url: String,\n}\n\nimpl UserServiceClient {\n    pub fn new(base_url: String) -> Self {\n        Self {\n            client: Client::new(),\n            base_url,\n        }\n    }\n    \n    #[instrument(skip(self))]\n    pub async fn create_user(&self, username: &str, email: &str) -> Result<User, Box<dyn std::error::Error>> {\n        let user = serde_json::json!({\n            \"username\": username,\n            \"email\": email\n        });\n        \n        let response = self.client\n            .post(&format!(\"{}/users\", self.base_url))\n            .json(&user)\n            .send()\n            .await?;\n        \n        if response.status().is_success() {\n            let user: User = response.json().await?;\n            info!(\"Created user: {:?}\", user);\n            Ok(user)\n        } else {\n            let error = response.text().await?;\n            Err(format!(\"Failed to create user: {}\", error).into())\n        }\n    }\n    \n    #[instrument(skip(self))]\n    pub async fn get_user(&self, user_id: Uuid) -> Result<Option<User>, Box<dyn std::error::Error>> {\n        let response = self.client\n            .get(&format!(\"{}/users/{}\", self.base_url, user_id))\n            .send()\n            .await?;\n        \n        match response.status().as_u16() {\n            200 => {\n                let user: User = response.json().await?;\n                Ok(Some(user))\n            }\n            404 => Ok(None),\n            _ => {\n                let error = response.text().await?;\n                Err(format!(\"Failed to get user: {}\", error).into())\n            }\n        }\n    }\n}\n\npub struct OrderServiceClient {\n    client: Client,\n    base_url: String,\n}\n\nimpl OrderServiceClient {\n    pub fn new(base_url: String) -> Self {\n        Self {\n            client: Client::new(),\n            base_url,\n        }\n    }\n    \n    #[instrument(skip(self))]\n    pub async fn create_order(&self, user_id: Uuid, items: Vec<OrderItem>) -> Result<Order, Box<dyn std::error::Error>> {\n        let order_request = serde_json::json!({\n            \"user_id\": user_id,\n            \"items\": items\n        });\n        \n        let response = self.client\n            .post(&format!(\"{}/orders\", self.base_url))\n            .json(&order_request)\n            .send()\n            .await?;\n        \n        if response.status().is_success() {\n            let order: Order = response.json().await?;\n            info!(\"Created order: {:?}\", order);\n            Ok(order)\n        } else {\n            let error = response.text().await?;\n            Err(format!(\"Failed to create order: {}\", error).into())\n        }\n    }\n    \n    #[instrument(skip(self))]\n    pub async fn get_order(&self, order_id: Uuid) -> Result<Option<Order>, Box<dyn std::error::Error>> {\n        let response = self.client\n            .get(&format!(\"{}/orders/{}\", self.base_url, order_id))\n            .send()\n            .await?;\n        \n        match response.status().as_u16() {\n            200 => {\n                let order: Order = response.json().await?;\n                Ok(Some(order))\n            }\n            404 => Ok(None),\n            _ => {\n                let error = response.text().await?;\n                Err(format!(\"Failed to get order: {}\", error).into())\n            }\n        }\n    }\n    \n    #[instrument(skip(self))]\n    pub async fn update_order_status(&self, order_id: Uuid, status: OrderStatus) -> Result<(), Box<dyn std::error::Error>> {\n        let update_request = serde_json::json!({\n            \"status\": status\n        });\n        \n        let response = self.client\n            .put(&format!(\"{}/orders/{}/status\", self.base_url, order_id))\n            .json(&update_request)\n            .send()\n            .await?;\n        \n        if response.status().is_success() {\n            info!(\"Updated order {} status to {:?}\", order_id, status);\n            Ok(())\n        } else {\n            let error = response.text().await?;\n            Err(format!(\"Failed to update order status: {}\", error).into())\n        }\n    }\n}\n\npub struct PaymentServiceClient {\n    client: Client,\n    base_url: String,\n}\n\nimpl PaymentServiceClient {\n    pub fn new(base_url: String) -> Self {\n        Self {\n            client: Client::new(),\n            base_url,\n        }\n    }\n    \n    #[instrument(skip(self))]\n    pub async fn process_payment(&self, order_id: Uuid, amount: f64) -> Result<Payment, Box<dyn std::error::Error>> {\n        let payment_request = serde_json::json!({\n            \"order_id\": order_id,\n            \"amount\": amount,\n            \"gateway\": \"stripe\"\n        });\n        \n        let response = self.client\n            .post(&format!(\"{}/payments\", self.base_url))\n            .json(&payment_request)\n            .send()\n            .await?;\n        \n        if response.status().is_success() {\n            let payment: Payment = response.json().await?;\n            info!(\"Processed payment: {:?}\", payment);\n            Ok(payment)\n        } else {\n            let error = response.text().await?;\n            Err(format!(\"Failed to process payment: {}\", error).into())\n        }\n    }\n}\n\n// Test environment setup\npub struct TestEnvironment {\n    docker: Cli,\n    postgres_container: Option<Container<'static, PostgresImage>>,\n    redis_container: Option<Container<'static, RedisImage>>,\n    jaeger_container: Option<Container<'static, JaegerImage>>,\n    user_service: UserServiceClient,\n    order_service: OrderServiceClient,\n    payment_service: PaymentServiceClient,\n}\n\nimpl TestEnvironment {\n    pub async fn new() -> Result<Self, Box<dyn std::error::Error>> {\n        // Initialize tracing\n        let tracer = opentelemetry_jaeger::new_pipeline()\n            .with_service_name(\"integration-test\")\n            .install_simple()?;\n        \n        tracing_subscriber::fmt()\n            .with_env_filter(\"debug\")\n            .init();\n        \n        let docker = Cli::default();\n        \n        // Start containers\n        info!(\"Starting test containers...\");\n        \n        let postgres_container = docker.run(PostgresImage::new(\"13\"));\n        let postgres_port = postgres_container.get_host_port_ipv4(5432);\n        \n        let redis_container = docker.run(RedisImage);\n        let redis_port = redis_container.get_host_port_ipv4(6379);\n        \n        let jaeger_container = docker.run(JaegerImage);\n        let jaeger_port = jaeger_container.get_host_port_ipv4(14268);\n        \n        info!(\"Containers started - Postgres: {}, Redis: {}, Jaeger: {}\", \n              postgres_port, redis_port, jaeger_port);\n        \n        // Wait for services to be ready\n        tokio::time::sleep(Duration::from_secs(5)).await;\n        \n        // Initialize service clients (assuming services are running)\n        let user_service = UserServiceClient::new(\"http://localhost:8001\".to_string());\n        let order_service = OrderServiceClient::new(\"http://localhost:8002\".to_string());\n        let payment_service = PaymentServiceClient::new(\"http://localhost:8003\".to_string());\n        \n        Ok(Self {\n            docker,\n            postgres_container: Some(postgres_container),\n            redis_container: Some(redis_container),\n            jaeger_container: Some(jaeger_container),\n            user_service,\n            order_service,\n            payment_service,\n        })\n    }\n    \n    pub fn postgres_url(&self) -> String {\n        if let Some(container) = &self.postgres_container {\n            let port = container.get_host_port_ipv4(5432);\n            format!(\"postgres://testuser:testpass@localhost:{}/testdb\", port)\n        } else {\n            \"postgres://testuser:testpass@localhost:5432/testdb\".to_string()\n        }\n    }\n    \n    pub fn redis_url(&self) -> String {\n        if let Some(container) = &self.redis_container {\n            let port = container.get_host_port_ipv4(6379);\n            format!(\"redis://localhost:{}\", port)\n        } else {\n            \"redis://localhost:6379\".to_string()\n        }\n    }\n}\n\n// Contract testing\npub struct ServiceContract {\n    pub name: String,\n    pub version: String,\n    pub endpoints: Vec<EndpointContract>,\n}\n\npub struct EndpointContract {\n    pub path: String,\n    pub method: String,\n    pub request_schema: serde_json::Value,\n    pub response_schema: serde_json::Value,\n    pub status_code: u16,\n}\n\nimpl ServiceContract {\n    pub async fn verify_user_service_contract(&self, client: &UserServiceClient) -> Result<Vec<ContractViolation>, Box<dyn std::error::Error>> {\n        let mut violations = Vec::new();\n        \n        // Test user creation endpoint\n        let test_user = client.create_user(\"testuser\", \"test@example.com\").await?;\n        \n        // Verify response structure\n        if test_user.username.is_empty() {\n            violations.push(ContractViolation {\n                endpoint: \"/users\".to_string(),\n                field: \"username\".to_string(),\n                expected: \"non-empty string\".to_string(),\n                actual: \"empty string\".to_string(),\n            });\n        }\n        \n        // Test user retrieval endpoint\n        if let Some(retrieved_user) = client.get_user(test_user.id).await? {\n            if retrieved_user.id != test_user.id {\n                violations.push(ContractViolation {\n                    endpoint: format!(\"/users/{}\", test_user.id),\n                    field: \"id\".to_string(),\n                    expected: test_user.id.to_string(),\n                    actual: retrieved_user.id.to_string(),\n                });\n            }\n        } else {\n            violations.push(ContractViolation {\n                endpoint: format!(\"/users/{}\", test_user.id),\n                field: \"response\".to_string(),\n                expected: \"user object\".to_string(),\n                actual: \"null\".to_string(),\n            });\n        }\n        \n        Ok(violations)\n    }\n}\n\n#[derive(Debug)]\npub struct ContractViolation {\n    pub endpoint: String,\n    pub field: String,\n    pub expected: String,\n    pub actual: String,\n}\n\n// Chaos engineering\npub struct ChaosEngineer {\n    client: Client,\n}\n\nimpl ChaosEngineer {\n    pub fn new() -> Self {\n        Self {\n            client: Client::new(),\n        }\n    }\n    \n    #[instrument(skip(self))]\n    pub async fn introduce_network_delay(&self, service_name: &str, delay_ms: u64) -> Result<(), Box<dyn std::error::Error>> {\n        info!(\"Introducing {}ms network delay to {}\", delay_ms, service_name);\n        \n        // Simulate network delay using toxiproxy or similar\n        // This would integrate with actual chaos engineering tools\n        tokio::time::sleep(Duration::from_millis(delay_ms)).await;\n        \n        Ok(())\n    }\n    \n    #[instrument(skip(self))]\n    pub async fn introduce_service_failure(&self, service_name: &str, failure_rate: f64) -> Result<(), Box<dyn std::error::Error>> {\n        info!(\"Introducing {}% failure rate to {}\", failure_rate * 100.0, service_name);\n        \n        // Simulate service failures\n        if rand::random::<f64>() < failure_rate {\n            return Err(\"Simulated service failure\".into());\n        }\n        \n        Ok(())\n    }\n    \n    #[instrument(skip(self))]\n    pub async fn introduce_database_partition(&self, duration: Duration) -> Result<(), Box<dyn std::error::Error>> {\n        info!(\"Introducing database partition for {:?}\", duration);\n        \n        // Simulate database partition\n        tokio::time::sleep(duration).await;\n        \n        Ok(())\n    }\n}\n\n// Load testing\npub struct LoadTester {\n    client: Client,\n    concurrent_users: usize,\n    test_duration: Duration,\n}\n\nimpl LoadTester {\n    pub fn new(concurrent_users: usize, test_duration: Duration) -> Self {\n        Self {\n            client: Client::new(),\n            concurrent_users,\n            test_duration,\n        }\n    }\n    \n    #[instrument(skip(self, env))]\n    pub async fn run_load_test(&self, env: &TestEnvironment) -> Result<LoadTestResults, Box<dyn std::error::Error>> {\n        info!(\"Starting load test with {} users for {:?}\", self.concurrent_users, self.test_duration);\n        \n        let start_time = std::time::Instant::now();\n        let mut handles = Vec::new();\n        \n        for user_id in 0..self.concurrent_users {\n            let user_service = UserServiceClient::new(\"http://localhost:8001\".to_string());\n            let order_service = OrderServiceClient::new(\"http://localhost:8002\".to_string());\n            let payment_service = PaymentServiceClient::new(\"http://localhost:8003\".to_string());\n            \n            let handle = tokio::spawn(async move {\n                let mut results = UserTestResults::default();\n                let end_time = start_time + self.test_duration;\n                \n                while std::time::Instant::now() < end_time {\n                    let start = std::time::Instant::now();\n                    \n                    // Create user\n                    match user_service.create_user(\n                        &format!(\"loadtest_user_{}\", user_id),\n                        &format!(\"loadtest_{}@example.com\", user_id)\n                    ).await {\n                        Ok(user) => {\n                            results.successful_requests += 1;\n                            results.total_response_time += start.elapsed();\n                            \n                            // Create order\n                            let items = vec![OrderItem {\n                                product_id: Uuid::new_v4(),\n                                quantity: 1,\n                                price: 10.0,\n                            }];\n                            \n                            if let Ok(order) = order_service.create_order(user.id, items).await {\n                                // Process payment\n                                if let Ok(_) = payment_service.process_payment(order.id, order.total).await {\n                                    results.end_to_end_success += 1;\n                                }\n                            }\n                        }\n                        Err(_) => {\n                            results.failed_requests += 1;\n                        }\n                    }\n                    \n                    // Small delay between requests\n                    tokio::time::sleep(Duration::from_millis(100)).await;\n                }\n                \n                results\n            });\n            \n            handles.push(handle);\n        }\n        \n        // Wait for all users to complete\n        let mut total_results = LoadTestResults::default();\n        for handle in handles {\n            let user_results = handle.await?;\n            total_results.successful_requests += user_results.successful_requests;\n            total_results.failed_requests += user_results.failed_requests;\n            total_results.total_response_time += user_results.total_response_time;\n            total_results.end_to_end_success += user_results.end_to_end_success;\n        }\n        \n        total_results.duration = start_time.elapsed();\n        \n        Ok(total_results)\n    }\n}\n\n#[derive(Debug, Default)]\npub struct UserTestResults {\n    pub successful_requests: usize,\n    pub failed_requests: usize,\n    pub total_response_time: Duration,\n    pub end_to_end_success: usize,\n}\n\n#[derive(Debug, Default)]\npub struct LoadTestResults {\n    pub successful_requests: usize,\n    pub failed_requests: usize,\n    pub total_response_time: Duration,\n    pub end_to_end_success: usize,\n    pub duration: Duration,\n}\n\nimpl LoadTestResults {\n    pub fn requests_per_second(&self) -> f64 {\n        (self.successful_requests + self.failed_requests) as f64 / self.duration.as_secs_f64()\n    }\n    \n    pub fn average_response_time_ms(&self) -> f64 {\n        if self.successful_requests > 0 {\n            self.total_response_time.as_millis() as f64 / self.successful_requests as f64\n        } else {\n            0.0\n        }\n    }\n    \n    pub fn success_rate(&self) -> f64 {\n        let total = self.successful_requests + self.failed_requests;\n        if total > 0 {\n            self.successful_requests as f64 / total as f64\n        } else {\n            0.0\n        }\n    }\n}\n\n// Integration test cases\n#[cfg(test)]\nmod integration_tests {\n    use super::*;\n    \n    #[tokio::test]\n    async fn test_end_to_end_order_workflow() -> Result<(), Box<dyn std::error::Error>> {\n        let env = TestEnvironment::new().await?;\n        \n        // Create user\n        let user = env.user_service.create_user(\"john_doe\", \"john@example.com\").await?;\n        assert!(!user.username.is_empty());\n        assert_eq!(user.email, \"john@example.com\");\n        \n        // Create order\n        let items = vec![\n            OrderItem {\n                product_id: Uuid::new_v4(),\n                quantity: 2,\n                price: 25.99,\n            },\n            OrderItem {\n                product_id: Uuid::new_v4(),\n                quantity: 1,\n                price: 15.50,\n            },\n        ];\n        \n        let order = env.order_service.create_order(user.id, items).await?;\n        assert_eq!(order.user_id, user.id);\n        assert_eq!(order.total, 67.48); // 2 * 25.99 + 1 * 15.50\n        \n        // Process payment\n        let payment = env.payment_service.process_payment(order.id, order.total).await?;\n        assert_eq!(payment.order_id, order.id);\n        assert_eq!(payment.amount, order.total);\n        \n        // Update order status\n        env.order_service.update_order_status(order.id, OrderStatus::Paid).await?;\n        \n        // Verify order status\n        let updated_order = env.order_service.get_order(order.id).await?;\n        assert!(updated_order.is_some());\n        assert!(matches!(updated_order.unwrap().status, OrderStatus::Paid));\n        \n        Ok(())\n    }\n    \n    #[tokio::test]\n    async fn test_service_contract_compliance() -> Result<(), Box<dyn std::error::Error>> {\n        let env = TestEnvironment::new().await?;\n        \n        let contract = ServiceContract {\n            name: \"user-service\".to_string(),\n            version: \"1.0.0\".to_string(),\n            endpoints: vec![],\n        };\n        \n        let violations = contract.verify_user_service_contract(&env.user_service).await?;\n        \n        if !violations.is_empty() {\n            for violation in &violations {\n                warn!(\"Contract violation: {:?}\", violation);\n            }\n        }\n        \n        assert!(violations.is_empty(), \"Contract violations found: {:?}\", violations);\n        \n        Ok(())\n    }\n    \n    #[tokio::test]\n    async fn test_resilience_under_chaos() -> Result<(), Box<dyn std::error::Error>> {\n        let env = TestEnvironment::new().await?;\n        let chaos = ChaosEngineer::new();\n        \n        // Test with network delays\n        chaos.introduce_network_delay(\"user-service\", 500).await?;\n        \n        let start = std::time::Instant::now();\n        let user = timeout(\n            Duration::from_secs(2),\n            env.user_service.create_user(\"chaos_user\", \"chaos@example.com\")\n        ).await??;\n        \n        let duration = start.elapsed();\n        assert!(duration >= Duration::from_millis(500), \"Network delay not applied\");\n        assert!(!user.username.is_empty());\n        \n        // Test with service failures\n        let mut success_count = 0;\n        let mut failure_count = 0;\n        \n        for _ in 0..10 {\n            if let Err(_) = chaos.introduce_service_failure(\"payment-service\", 0.3).await {\n                failure_count += 1;\n            } else {\n                success_count += 1;\n            }\n        }\n        \n        // Should have some failures but not all\n        assert!(failure_count > 0);\n        assert!(success_count > 0);\n        \n        Ok(())\n    }\n    \n    #[tokio::test]\n    async fn test_performance_under_load() -> Result<(), Box<dyn std::error::Error>> {\n        let env = TestEnvironment::new().await?;\n        \n        let load_tester = LoadTester::new(10, Duration::from_secs(30));\n        let results = load_tester.run_load_test(&env).await?;\n        \n        info!(\"Load test results: {:?}\", results);\n        \n        // Assert performance requirements\n        assert!(results.requests_per_second() > 5.0, \"Throughput too low\");\n        assert!(results.average_response_time_ms() < 1000.0, \"Response time too high\");\n        assert!(results.success_rate() > 0.95, \"Success rate too low\");\n        \n        Ok(())\n    }\n    \n    #[tokio::test]\n    async fn test_data_consistency_across_services() -> Result<(), Box<dyn std::error::Error>> {\n        let env = TestEnvironment::new().await?;\n        \n        // Create user and order\n        let user = env.user_service.create_user(\"consistency_user\", \"consistency@example.com\").await?;\n        \n        let items = vec![OrderItem {\n            product_id: Uuid::new_v4(),\n            quantity: 1,\n            price: 100.0,\n        }];\n        \n        let order = env.order_service.create_order(user.id, items).await?;\n        \n        // Verify user exists in user service\n        let retrieved_user = env.user_service.get_user(user.id).await?;\n        assert!(retrieved_user.is_some());\n        assert_eq!(retrieved_user.unwrap().id, user.id);\n        \n        // Verify order references valid user\n        let retrieved_order = env.order_service.get_order(order.id).await?;\n        assert!(retrieved_order.is_some());\n        assert_eq!(retrieved_order.unwrap().user_id, user.id);\n        \n        Ok(())\n    }\n    \n    #[tokio::test]\n    async fn test_transaction_rollback_on_failure() -> Result<(), Box<dyn std::error::Error>> {\n        let env = TestEnvironment::new().await?;\n        \n        // Create user\n        let user = env.user_service.create_user(\"rollback_user\", \"rollback@example.com\").await?;\n        \n        // Create order\n        let items = vec![OrderItem {\n            product_id: Uuid::new_v4(),\n            quantity: 1,\n            price: 50.0,\n        }];\n        \n        let order = env.order_service.create_order(user.id, items).await?;\n        \n        // Simulate payment failure\n        let payment_result = env.payment_service.process_payment(order.id, -1.0).await; // Invalid amount\n        assert!(payment_result.is_err());\n        \n        // Verify order status wasn't updated\n        let order_after_failure = env.order_service.get_order(order.id).await?;\n        assert!(order_after_failure.is_some());\n        assert!(matches!(order_after_failure.unwrap().status, OrderStatus::Created));\n        \n        Ok(())\n    }\n}\n\nfn main() {\n    println!(\"Integration test suite for microservices\");\n    println!(\"Run with: cargo test --test integration_tests\");\n    println!(\"Features tested:\");\n    println!(\"  - End-to-end workflows\");\n    println!(\"  - Service contracts\");\n    println!(\"  - Chaos engineering\");\n    println!(\"  - Performance under load\");\n    println!(\"  - Data consistency\");\n    println!(\"  - Transaction rollbacks\");\n}",
    "key_concepts": [
      "integration testing",
      "Docker containers",
      "testcontainers",
      "service discovery",
      "distributed tracing",
      "contract testing",
      "chaos engineering",
      "end-to-end workflows",
      "microservices testing",
      "load testing"
    ]
  },
  {
    "prompt": "Implement custom test frameworks and assertion libraries in Rust with snapshot testing, parameterized tests, test fixtures, parallel execution, and detailed reporting. Include test discovery and custom matchers.",
    "response": "use std::collections::{HashMap, BTreeMap};\nuse std::sync::{Arc, Mutex, RwLock};\nuse std::path::{Path, PathBuf};\nuse std::fs;\nuse std::time::{Duration, Instant};\nuse std::thread;\nuse std::panic::{self, AssertUnwindSafe};\nuse rayon::prelude::*;\nuse serde::{Serialize, Deserialize};\nuse serde_json;\nuse sha2::{Sha256, Digest};\n\n// Core test framework types\n#[derive(Debug, Clone)]\npub struct TestCase {\n    pub name: String,\n    pub test_fn: Arc<dyn Fn() -> TestResult + Send + Sync>,\n    pub tags: Vec<String>,\n    pub timeout: Option<Duration>,\n    pub should_panic: bool,\n    pub ignore: bool,\n}\n\n#[derive(Debug, Clone, PartialEq)]\npub enum TestResult {\n    Pass,\n    Fail(String),\n    Ignored(String),\n    Panic(String),\n    Timeout,\n}\n\nimpl TestResult {\n    pub fn is_success(&self) -> bool {\n        matches!(self, TestResult::Pass)\n    }\n    \n    pub fn is_failure(&self) -> bool {\n        matches!(self, TestResult::Fail(_) | TestResult::Panic(_) | TestResult::Timeout)\n    }\n}\n\n// Test execution context\n#[derive(Debug)]\npub struct TestContext {\n    pub name: String,\n    pub start_time: Instant,\n    pub fixtures: HashMap<String, Box<dyn std::any::Any + Send + Sync>>,\n    pub cleanup_fns: Vec<Box<dyn FnOnce() + Send>>,\n}\n\nimpl TestContext {\n    pub fn new(name: String) -> Self {\n        Self {\n            name,\n            start_time: Instant::now(),\n            fixtures: HashMap::new(),\n            cleanup_fns: Vec::new(),\n        }\n    }\n    \n    pub fn add_fixture<T: Send + Sync + 'static>(&mut self, key: String, value: T) {\n        self.fixtures.insert(key, Box::new(value));\n    }\n    \n    pub fn get_fixture<T: Send + Sync + 'static>(&self, key: &str) -> Option<&T> {\n        self.fixtures.get(key)?.downcast_ref::<T>()\n    }\n    \n    pub fn add_cleanup<F: FnOnce() + Send + 'static>(&mut self, cleanup: F) {\n        self.cleanup_fns.push(Box::new(cleanup));\n    }\n}\n\nimpl Drop for TestContext {\n    fn drop(&mut self) {\n        // Execute cleanup functions in reverse order\n        while let Some(cleanup) = self.cleanup_fns.pop() {\n            cleanup();\n        }\n    }\n}\n\n// Custom assertion framework\npub struct Assertion<T> {\n    actual: T,\n    description: String,\n}\n\nimpl<T> Assertion<T> {\n    pub fn new(actual: T) -> Self {\n        Self {\n            actual,\n            description: \"assertion\".to_string(),\n        }\n    }\n    \n    pub fn with_description(mut self, description: String) -> Self {\n        self.description = description;\n        self\n    }\n}\n\nimpl<T: PartialEq + std::fmt::Debug> Assertion<T> {\n    pub fn equals(self, expected: T) -> Result<(), String> {\n        if self.actual == expected {\n            Ok(())\n        } else {\n            Err(format!(\n                \"{}: expected {:?}, got {:?}\",\n                self.description, expected, self.actual\n            ))\n        }\n    }\n    \n    pub fn not_equals(self, unexpected: T) -> Result<(), String> {\n        if self.actual != unexpected {\n            Ok(())\n        } else {\n            Err(format!(\n                \"{}: expected not to equal {:?}\",\n                self.description, unexpected\n            ))\n        }\n    }\n}\n\nimpl<T: PartialOrd + std::fmt::Debug> Assertion<T> {\n    pub fn greater_than(self, other: T) -> Result<(), String> {\n        if self.actual > other {\n            Ok(())\n        } else {\n            Err(format!(\n                \"{}: expected {:?} > {:?}\",\n                self.description, self.actual, other\n            ))\n        }\n    }\n    \n    pub fn less_than(self, other: T) -> Result<(), String> {\n        if self.actual < other {\n            Ok(())\n        } else {\n            Err(format!(\n                \"{}: expected {:?} < {:?}\",\n                self.description, self.actual, other\n            ))\n        }\n    }\n}\n\nimpl<T> Assertion<Option<T>> {\n    pub fn is_some(self) -> Result<Assertion<T>, String> {\n        match self.actual {\n            Some(value) => Ok(Assertion::new(value).with_description(self.description)),\n            None => Err(format!(\"{}: expected Some, got None\", self.description)),\n        }\n    }\n    \n    pub fn is_none(self) -> Result<(), String> {\n        match self.actual {\n            None => Ok(()),\n            Some(_) => Err(format!(\"{}: expected None, got Some\", self.description)),\n        }\n    }\n}\n\nimpl<T, E: std::fmt::Debug> Assertion<Result<T, E>> {\n    pub fn is_ok(self) -> Result<Assertion<T>, String> {\n        match self.actual {\n            Ok(value) => Ok(Assertion::new(value).with_description(self.description)),\n            Err(e) => Err(format!(\"{}: expected Ok, got Err({:?})\", self.description, e)),\n        }\n    }\n    \n    pub fn is_err(self) -> Result<Assertion<E>, String> {\n        match self.actual {\n            Err(e) => Ok(Assertion::new(e).with_description(self.description)),\n            Ok(_) => Err(format!(\"{}: expected Err, got Ok\", self.description)),\n        }\n    }\n}\n\nimpl Assertion<String> {\n    pub fn contains(self, substring: &str) -> Result<(), String> {\n        if self.actual.contains(substring) {\n            Ok(())\n        } else {\n            Err(format!(\n                \"{}: expected '{}' to contain '{}'\",\n                self.description, self.actual, substring\n            ))\n        }\n    }\n    \n    pub fn starts_with(self, prefix: &str) -> Result<(), String> {\n        if self.actual.starts_with(prefix) {\n            Ok(())\n        } else {\n            Err(format!(\n                \"{}: expected '{}' to start with '{}'\",\n                self.description, self.actual, prefix\n            ))\n        }\n    }\n    \n    pub fn matches_regex(self, pattern: &str) -> Result<(), String> {\n        let regex = regex::Regex::new(pattern)\n            .map_err(|e| format!(\"Invalid regex pattern '{}': {}\", pattern, e))?;\n        \n        if regex.is_match(&self.actual) {\n            Ok(())\n        } else {\n            Err(format!(\n                \"{}: expected '{}' to match pattern '{}'\",\n                self.description, self.actual, pattern\n            ))\n        }\n    }\n}\n\nimpl<T> Assertion<Vec<T>> {\n    pub fn has_length(self, expected_len: usize) -> Result<(), String> {\n        if self.actual.len() == expected_len {\n            Ok(())\n        } else {\n            Err(format!(\n                \"{}: expected length {}, got {}\",\n                self.description, expected_len, self.actual.len()\n            ))\n        }\n    }\n    \n    pub fn is_empty(self) -> Result<(), String> {\n        if self.actual.is_empty() {\n            Ok(())\n        } else {\n            Err(format!(\n                \"{}: expected empty collection, got {} items\",\n                self.description, self.actual.len()\n            ))\n        }\n    }\n}\n\nimpl<T: PartialEq + std::fmt::Debug> Assertion<Vec<T>> {\n    pub fn contains_item(self, item: &T) -> Result<(), String> {\n        if self.actual.contains(item) {\n            Ok(())\n        } else {\n            Err(format!(\n                \"{}: collection does not contain {:?}\",\n                self.description, item\n            ))\n        }\n    }\n}\n\n// Convenience macros for assertions\nmacro_rules! assert_that {\n    ($actual:expr) => {\n        Assertion::new($actual)\n    };\n    ($actual:expr, $description:expr) => {\n        Assertion::new($actual).with_description($description.to_string())\n    };\n}\n\n// Snapshot testing\n#[derive(Debug, Serialize, Deserialize)]\npub struct Snapshot {\n    pub name: String,\n    pub content: String,\n    pub hash: String,\n    pub created_at: String,\n}\n\nimpl Snapshot {\n    pub fn new(name: String, content: String) -> Self {\n        let hash = format!(\"{:x}\", Sha256::digest(content.as_bytes()));\n        let created_at = chrono::Utc::now().to_rfc3339();\n        \n        Self {\n            name,\n            content,\n            hash,\n            created_at,\n        }\n    }\n}\n\npub struct SnapshotTester {\n    snapshots_dir: PathBuf,\n    update_snapshots: bool,\n}\n\nimpl SnapshotTester {\n    pub fn new<P: AsRef<Path>>(snapshots_dir: P) -> Self {\n        Self {\n            snapshots_dir: snapshots_dir.as_ref().to_path_buf(),\n            update_snapshots: std::env::var(\"UPDATE_SNAPSHOTS\").is_ok(),\n        }\n    }\n    \n    pub fn assert_snapshot(&self, name: &str, content: &str) -> Result<(), String> {\n        let snapshot_path = self.snapshots_dir.join(format!(\"{}.snap\", name));\n        \n        if snapshot_path.exists() && !self.update_snapshots {\n            let existing_content = fs::read_to_string(&snapshot_path)\n                .map_err(|e| format!(\"Failed to read snapshot: {}\", e))?;\n            \n            let existing_snapshot: Snapshot = serde_json::from_str(&existing_content)\n                .map_err(|e| format!(\"Failed to parse snapshot: {}\", e))?;\n            \n            if existing_snapshot.content != content {\n                return Err(format!(\n                    \"Snapshot mismatch for '{}':\nExpected:\n{}\nActual:\n{}\",\n                    name, existing_snapshot.content, content\n                ));\n            }\n        } else {\n            // Create or update snapshot\n            let snapshot = Snapshot::new(name.to_string(), content.to_string());\n            let snapshot_json = serde_json::to_string_pretty(&snapshot)\n                .map_err(|e| format!(\"Failed to serialize snapshot: {}\", e))?;\n            \n            fs::create_dir_all(&self.snapshots_dir)\n                .map_err(|e| format!(\"Failed to create snapshots directory: {}\", e))?;\n            \n            fs::write(&snapshot_path, snapshot_json)\n                .map_err(|e| format!(\"Failed to write snapshot: {}\", e))?;\n            \n            if self.update_snapshots {\n                println!(\"Updated snapshot: {}\", name);\n            } else {\n                println!(\"Created snapshot: {}\", name);\n            }\n        }\n        \n        Ok(())\n    }\n}\n\n// Parameterized testing\npub struct ParameterizedTest<T> {\n    name: String,\n    parameters: Vec<(String, T)>,\n    test_fn: Arc<dyn Fn(&T) -> Result<(), String> + Send + Sync>,\n}\n\nimpl<T> ParameterizedTest<T>\nwhere\n    T: Send + Sync + 'static,\n{\n    pub fn new<F>(name: String, test_fn: F) -> Self\n    where\n        F: Fn(&T) -> Result<(), String> + Send + Sync + 'static,\n    {\n        Self {\n            name,\n            parameters: Vec::new(),\n            test_fn: Arc::new(test_fn),\n        }\n    }\n    \n    pub fn with_parameter(mut self, name: String, value: T) -> Self {\n        self.parameters.push((name, value));\n        self\n    }\n    \n    pub fn with_parameters(mut self, parameters: Vec<(String, T)>) -> Self {\n        self.parameters.extend(parameters);\n        self\n    }\n    \n    pub fn run_all(&self) -> Vec<(String, TestResult)> {\n        self.parameters\n            .iter()\n            .map(|(param_name, param_value)| {\n                let test_name = format!(\"{}[{}]\", self.name, param_name);\n                let result = match std::panic::catch_unwind(AssertUnwindSafe(|| {\n                    (self.test_fn)(param_value)\n                })) {\n                    Ok(Ok(())) => TestResult::Pass,\n                    Ok(Err(msg)) => TestResult::Fail(msg),\n                    Err(_) => TestResult::Panic(\"Test panicked\".to_string()),\n                };\n                (test_name, result)\n            })\n            .collect()\n    }\n}\n\n// Test fixtures\npub trait TestFixture: Send + Sync {\n    fn setup(&self) -> Result<(), String>;\n    fn teardown(&self) -> Result<(), String>;\n}\n\npub struct DatabaseFixture {\n    pub connection_string: String,\n    pub migrations_path: Option<PathBuf>,\n}\n\nimpl TestFixture for DatabaseFixture {\n    fn setup(&self) -> Result<(), String> {\n        println!(\"Setting up database with connection: {}\", self.connection_string);\n        \n        if let Some(migrations_path) = &self.migrations_path {\n            println!(\"Running migrations from: {:?}\", migrations_path);\n            // Run database migrations\n        }\n        \n        Ok(())\n    }\n    \n    fn teardown(&self) -> Result<(), String> {\n        println!(\"Cleaning up database\");\n        // Clean up test data\n        Ok(())\n    }\n}\n\npub struct TempDirectoryFixture {\n    pub base_path: PathBuf,\n    created_dirs: RwLock<Vec<PathBuf>>,\n}\n\nimpl TempDirectoryFixture {\n    pub fn new() -> Self {\n        Self {\n            base_path: std::env::temp_dir().join(\"test_framework\"),\n            created_dirs: RwLock::new(Vec::new()),\n        }\n    }\n    \n    pub fn create_temp_dir(&self, name: &str) -> Result<PathBuf, String> {\n        let dir_path = self.base_path.join(name);\n        fs::create_dir_all(&dir_path)\n            .map_err(|e| format!(\"Failed to create temp directory: {}\", e))?;\n        \n        self.created_dirs.write().unwrap().push(dir_path.clone());\n        Ok(dir_path)\n    }\n}\n\nimpl TestFixture for TempDirectoryFixture {\n    fn setup(&self) -> Result<(), String> {\n        fs::create_dir_all(&self.base_path)\n            .map_err(|e| format!(\"Failed to create base temp directory: {}\", e))?;\n        Ok(())\n    }\n    \n    fn teardown(&self) -> Result<(), String> {\n        let dirs = self.created_dirs.read().unwrap();\n        for dir in dirs.iter() {\n            if dir.exists() {\n                fs::remove_dir_all(dir)\n                    .map_err(|e| format!(\"Failed to remove temp directory: {}\", e))?;\n            }\n        }\n        Ok(())\n    }\n}\n\n// Test discovery\npub struct TestDiscovery;\n\nimpl TestDiscovery {\n    pub fn discover_tests(search_paths: &[PathBuf]) -> Vec<TestCase> {\n        let mut tests = Vec::new();\n        \n        for path in search_paths {\n            if path.is_dir() {\n                tests.extend(Self::discover_tests_in_directory(path));\n            }\n        }\n        \n        tests\n    }\n    \n    fn discover_tests_in_directory(dir: &Path) -> Vec<TestCase> {\n        let mut tests = Vec::new();\n        \n        if let Ok(entries) = fs::read_dir(dir) {\n            for entry in entries.flatten() {\n                let path = entry.path();\n                \n                if path.is_dir() {\n                    tests.extend(Self::discover_tests_in_directory(&path));\n                } else if path.extension().map_or(false, |ext| ext == \"rs\") {\n                    tests.extend(Self::parse_test_file(&path));\n                }\n            }\n        }\n        \n        tests\n    }\n    \n    fn parse_test_file(file_path: &Path) -> Vec<TestCase> {\n        // Simplified test discovery - in practice, this would parse Rust AST\n        // or use proc macros to discover test functions\n        let mut tests = Vec::new();\n        \n        if let Ok(content) = fs::read_to_string(file_path) {\n            for (line_num, line) in content.lines().enumerate() {\n                if line.trim().starts_with(\"#[test]\") {\n                    // Extract test function name from next line\n                    if let Some(next_line) = content.lines().nth(line_num + 1) {\n                        if let Some(fn_name) = Self::extract_function_name(next_line) {\n                            tests.push(TestCase {\n                                name: fn_name,\n                                test_fn: Arc::new(|| TestResult::Pass), // Placeholder\n                                tags: vec![\"discovered\".to_string()],\n                                timeout: None,\n                                should_panic: line.contains(\"should_panic\"),\n                                ignore: line.contains(\"ignore\"),\n                            });\n                        }\n                    }\n                }\n            }\n        }\n        \n        tests\n    }\n    \n    fn extract_function_name(line: &str) -> Option<String> {\n        let trimmed = line.trim();\n        if trimmed.starts_with(\"fn \") {\n            let parts: Vec<&str> = trimmed.split_whitespace().collect();\n            if parts.len() >= 2 {\n                let fn_name = parts[1].split('(').next()?;\n                return Some(fn_name.to_string());\n            }\n        }\n        None\n    }\n}\n\n// Test runner with parallel execution\npub struct TestRunner {\n    parallel: bool,\n    thread_count: Option<usize>,\n    fixtures: Vec<Box<dyn TestFixture>>,\n    filter: Option<String>,\n}\n\nimpl TestRunner {\n    pub fn new() -> Self {\n        Self {\n            parallel: true,\n            thread_count: None,\n            fixtures: Vec::new(),\n            filter: None,\n        }\n    }\n    \n    pub fn with_parallel_execution(mut self, parallel: bool) -> Self {\n        self.parallel = parallel;\n        self\n    }\n    \n    pub fn with_thread_count(mut self, count: usize) -> Self {\n        self.thread_count = Some(count);\n        self\n    }\n    \n    pub fn add_fixture<F: TestFixture + 'static>(mut self, fixture: F) -> Self {\n        self.fixtures.push(Box::new(fixture));\n        self\n    }\n    \n    pub fn with_filter(mut self, filter: String) -> Self {\n        self.filter = Some(filter);\n        self\n    }\n    \n    pub fn run_tests(&self, tests: Vec<TestCase>) -> TestRunResults {\n        // Setup fixtures\n        for fixture in &self.fixtures {\n            if let Err(e) = fixture.setup() {\n                return TestRunResults {\n                    total: 0,\n                    passed: 0,\n                    failed: 1,\n                    ignored: 0,\n                    duration: Duration::from_secs(0),\n                    test_results: vec![(\"fixture_setup\".to_string(), TestResult::Fail(e))],\n                };\n            }\n        }\n        \n        // Filter tests\n        let filtered_tests: Vec<_> = tests\n            .into_iter()\n            .filter(|test| {\n                if let Some(filter) = &self.filter {\n                    test.name.contains(filter)\n                } else {\n                    true\n                }\n            })\n            .collect();\n        \n        let start_time = Instant::now();\n        \n        let test_results = if self.parallel {\n            self.run_tests_parallel(filtered_tests)\n        } else {\n            self.run_tests_sequential(filtered_tests)\n        };\n        \n        let duration = start_time.elapsed();\n        \n        // Teardown fixtures\n        for fixture in &self.fixtures {\n            let _ = fixture.teardown();\n        }\n        \n        let total = test_results.len();\n        let passed = test_results.iter().filter(|(_, r)| r.is_success()).count();\n        let failed = test_results.iter().filter(|(_, r)| r.is_failure()).count();\n        let ignored = test_results.iter().filter(|(_, r)| matches!(r, TestResult::Ignored(_))).count();\n        \n        TestRunResults {\n            total,\n            passed,\n            failed,\n            ignored,\n            duration,\n            test_results,\n        }\n    }\n    \n    fn run_tests_parallel(&self, tests: Vec<TestCase>) -> Vec<(String, TestResult)> {\n        let thread_count = self.thread_count.unwrap_or_else(|| {\n            std::thread::available_parallelism().map(|n| n.get()).unwrap_or(1)\n        });\n        \n        tests\n            .into_par_iter()\n            .with_min_len(1)\n            .map(|test| {\n                let result = self.execute_test(test.clone());\n                (test.name, result)\n            })\n            .collect()\n    }\n    \n    fn run_tests_sequential(&self, tests: Vec<TestCase>) -> Vec<(String, TestResult)> {\n        tests\n            .into_iter()\n            .map(|test| {\n                let result = self.execute_test(test.clone());\n                (test.name, result)\n            })\n            .collect()\n    }\n    \n    fn execute_test(&self, test: TestCase) -> TestResult {\n        if test.ignore {\n            return TestResult::Ignored(\"Test marked as ignored\".to_string());\n        }\n        \n        let start_time = Instant::now();\n        \n        let result = if let Some(timeout) = test.timeout {\n            // Run with timeout\n            let (tx, rx) = std::sync::mpsc::channel();\n            let test_fn = test.test_fn.clone();\n            \n            thread::spawn(move || {\n                let result = std::panic::catch_unwind(AssertUnwindSafe(|| test_fn()));\n                let _ = tx.send(result);\n            });\n            \n            match rx.recv_timeout(timeout) {\n                Ok(Ok(result)) => result,\n                Ok(Err(_)) => TestResult::Panic(\"Test panicked\".to_string()),\n                Err(_) => TestResult::Timeout,\n            }\n        } else {\n            // Run without timeout\n            match std::panic::catch_unwind(AssertUnwindSafe(|| (test.test_fn)())) {\n                Ok(result) => result,\n                Err(_) => TestResult::Panic(\"Test panicked\".to_string()),\n            }\n        };\n        \n        // Handle should_panic expectation\n        if test.should_panic {\n            match result {\n                TestResult::Panic(_) => TestResult::Pass,\n                TestResult::Pass => TestResult::Fail(\"Expected test to panic\".to_string()),\n                other => other,\n            }\n        } else {\n            result\n        }\n    }\n}\n\n#[derive(Debug)]\npub struct TestRunResults {\n    pub total: usize,\n    pub passed: usize,\n    pub failed: usize,\n    pub ignored: usize,\n    pub duration: Duration,\n    pub test_results: Vec<(String, TestResult)>,\n}\n\nimpl TestRunResults {\n    pub fn print_summary(&self) {\n        println!(\"\nTest Results:\");\n        println!(\"=============\");\n        \n        for (name, result) in &self.test_results {\n            match result {\n                TestResult::Pass => println!(\"\u2713 {}\", name),\n                TestResult::Fail(msg) => println!(\"\u2717 {} - {}\", name, msg),\n                TestResult::Panic(msg) => println!(\"\ud83d\udca5 {} - {}\", name, msg),\n                TestResult::Timeout => println!(\"\u23f0 {} - timeout\", name),\n                TestResult::Ignored(msg) => println!(\"\u2298 {} - {}\", name, msg),\n            }\n        }\n        \n        println!(\"\nSummary:\");\n        println!(\"  Total: {}\", self.total);\n        println!(\"  Passed: {}\", self.passed);\n        println!(\"  Failed: {}\", self.failed);\n        println!(\"  Ignored: {}\", self.ignored);\n        println!(\"  Duration: {:?}\", self.duration);\n        \n        if self.failed > 0 {\n            println!(\"\n\u274c Some tests failed\");\n        } else {\n            println!(\"\n\u2705 All tests passed\");\n        }\n    }\n}\n\n// Example usage and tests\n#[cfg(test)]\nmod framework_tests {\n    use super::*;\n    \n    #[test]\n    fn test_assertion_framework() {\n        // Test basic assertions\n        assert_that!(5).equals(5).unwrap();\n        assert_that!(10).greater_than(5).unwrap();\n        assert_that!(vec![1, 2, 3]).has_length(3).unwrap();\n        \n        // Test string assertions\n        assert_that!(\"hello world\".to_string())\n            .contains(\"world\")\n            .unwrap();\n        \n        // Test optional assertions\n        assert_that!(Some(42)).is_some().unwrap().equals(42).unwrap();\n        assert_that!(None::<i32>).is_none().unwrap();\n        \n        // Test result assertions\n        let result: Result<i32, &str> = Ok(42);\n        assert_that!(result).is_ok().unwrap().equals(42).unwrap();\n    }\n    \n    #[test]\n    fn test_parameterized_testing() {\n        let test = ParameterizedTest::new(\n            \"math_operations\".to_string(),\n            |&(a, b, expected): &(i32, i32, i32)| {\n                let result = a + b;\n                if result == expected {\n                    Ok(())\n                } else {\n                    Err(format!(\"Expected {}, got {}\", expected, result))\n                }\n            },\n        )\n        .with_parameter(\"2_plus_3\".to_string(), (2, 3, 5))\n        .with_parameter(\"10_plus_20\".to_string(), (10, 20, 30))\n        .with_parameter(\"negative_numbers\".to_string(), (-5, -3, -8));\n        \n        let results = test.run_all();\n        \n        for (name, result) in results {\n            assert!(result.is_success(), \"Test {} failed: {:?}\", name, result);\n        }\n    }\n    \n    #[test]\n    fn test_snapshot_testing() {\n        let snapshot_dir = std::env::temp_dir().join(\"test_snapshots\");\n        let tester = SnapshotTester::new(&snapshot_dir);\n        \n        let test_data = r#\"{\n    \"name\": \"John Doe\",\n    \"age\": 30,\n    \"city\": \"New York\"\n}\"#;\n        \n        // This will create a snapshot on first run, compare on subsequent runs\n        tester.assert_snapshot(\"user_data\", test_data).unwrap();\n    }\n    \n    #[test]\n    fn test_custom_test_runner() {\n        let tests = vec![\n            TestCase {\n                name: \"passing_test\".to_string(),\n                test_fn: Arc::new(|| TestResult::Pass),\n                tags: vec![],\n                timeout: None,\n                should_panic: false,\n                ignore: false,\n            },\n            TestCase {\n                name: \"failing_test\".to_string(),\n                test_fn: Arc::new(|| TestResult::Fail(\"Intentional failure\".to_string())),\n                tags: vec![],\n                timeout: None,\n                should_panic: false,\n                ignore: false,\n            },\n            TestCase {\n                name: \"ignored_test\".to_string(),\n                test_fn: Arc::new(|| TestResult::Pass),\n                tags: vec![],\n                timeout: None,\n                should_panic: false,\n                ignore: true,\n            },\n        ];\n        \n        let runner = TestRunner::new()\n            .with_parallel_execution(false)\n            .add_fixture(TempDirectoryFixture::new());\n        \n        let results = runner.run_tests(tests);\n        \n        assert_eq!(results.total, 3);\n        assert_eq!(results.passed, 1);\n        assert_eq!(results.failed, 1);\n        assert_eq!(results.ignored, 1);\n    }\n}\n\nfn main() {\n    println!(\"Custom test framework for Rust\");\n    println!(\"Features:\");\n    println!(\"  - Custom assertion library\");\n    println!(\"  - Snapshot testing\");\n    println!(\"  - Parameterized tests\");\n    println!(\"  - Test fixtures\");\n    println!(\"  - Parallel execution\");\n    println!(\"  - Test discovery\");\n    println!(\"  - Detailed reporting\");\n    \n    // Example test run\n    let tests = vec![\n        TestCase {\n            name: \"example_test\".to_string(),\n            test_fn: Arc::new(|| {\n                assert_that!(2 + 2).equals(4)?;\n                assert_that!(\"hello\".to_string()).starts_with(\"he\")?;\n                Ok(())\n            }),\n            tags: vec![\"example\".to_string()],\n            timeout: Some(Duration::from_secs(1)),\n            should_panic: false,\n            ignore: false,\n        },\n    ];\n    \n    let runner = TestRunner::new();\n    let results = runner.run_tests(tests);\n    results.print_summary();\n}",
    "key_concepts": [
      "custom test frameworks",
      "assertion libraries",
      "snapshot testing",
      "parameterized tests",
      "test fixtures",
      "parallel execution",
      "test discovery",
      "custom matchers",
      "test reporting",
      "test context management"
    ]
  },
  {
    "prompt": "Create a WebAssembly module in Rust using wasm-bindgen with JavaScript interop, DOM manipulation, and Web APIs integration. Include TypeScript definitions, memory management, and performance optimization.",
    "response": "use wasm_bindgen::prelude::*;\nuse wasm_bindgen::JsCast;\nuse web_sys::*;\nuse js_sys::*;\nuse std::collections::HashMap;\nuse std::rc::Rc;\nuse std::cell::RefCell;\n\n// External JavaScript functions\n#[wasm_bindgen]\nextern \"C\" {\n    #[wasm_bindgen(js_namespace = console)]\n    fn log(s: &str);\n    \n    #[wasm_bindgen(js_namespace = console, js_name = log)]\n    fn log_u32(a: u32);\n    \n    #[wasm_bindgen(js_namespace = Date, js_name = now)]\n    fn date_now() -> f64;\n    \n    #[wasm_bindgen(js_namespace = performance, js_name = now)]\n    fn performance_now() -> f64;\n}\n\n// Macro for console logging\nmacro_rules! console_log {\n    ($($t:tt)*) => (log(&format_args!($($t)*).to_string()))\n}\n\n// Core data structures\n#[wasm_bindgen]\n#[derive(Debug, Clone)]\npub struct Point {\n    x: f64,\n    y: f64,\n}\n\n#[wasm_bindgen]\nimpl Point {\n    #[wasm_bindgen(constructor)]\n    pub fn new(x: f64, y: f64) -> Point {\n        Point { x, y }\n    }\n    \n    #[wasm_bindgen(getter)]\n    pub fn x(&self) -> f64 {\n        self.x\n    }\n    \n    #[wasm_bindgen(setter)]\n    pub fn set_x(&mut self, x: f64) {\n        self.x = x;\n    }\n    \n    #[wasm_bindgen(getter)]\n    pub fn y(&self) -> f64 {\n        self.y\n    }\n    \n    #[wasm_bindgen(setter)]\n    pub fn set_y(&mut self, y: f64) {\n        self.y = y;\n    }\n    \n    pub fn distance_to(&self, other: &Point) -> f64 {\n        let dx = self.x - other.x;\n        let dy = self.y - other.y;\n        (dx * dx + dy * dy).sqrt()\n    }\n    \n    pub fn translate(&mut self, dx: f64, dy: f64) {\n        self.x += dx;\n        self.y += dy;\n    }\n}\n\n// Canvas drawing utilities\n#[wasm_bindgen]\npub struct CanvasRenderer {\n    canvas: HtmlCanvasElement,\n    context: CanvasRenderingContext2d,\n    width: u32,\n    height: u32,\n}\n\n#[wasm_bindgen]\nimpl CanvasRenderer {\n    #[wasm_bindgen(constructor)]\n    pub fn new(canvas_id: &str) -> Result<CanvasRenderer, JsValue> {\n        let document = window().unwrap().document().unwrap();\n        let canvas = document\n            .get_element_by_id(canvas_id)\n            .unwrap()\n            .dyn_into::<HtmlCanvasElement>()?;\n        \n        let context = canvas\n            .get_context(\"2d\")?\n            .unwrap()\n            .dyn_into::<CanvasRenderingContext2d>()?;\n        \n        let width = canvas.width();\n        let height = canvas.height();\n        \n        Ok(CanvasRenderer {\n            canvas,\n            context,\n            width,\n            height,\n        })\n    }\n    \n    pub fn clear(&self) {\n        self.context.clear_rect(0.0, 0.0, self.width as f64, self.height as f64);\n    }\n    \n    pub fn draw_circle(&self, x: f64, y: f64, radius: f64, color: &str) {\n        self.context.begin_path();\n        self.context.set_fill_style(&JsValue::from_str(color));\n        self.context.arc(x, y, radius, 0.0, 2.0 * std::f64::consts::PI).unwrap();\n        self.context.fill();\n    }\n    \n    pub fn draw_line(&self, start: &Point, end: &Point, color: &str, width: f64) {\n        self.context.begin_path();\n        self.context.set_stroke_style(&JsValue::from_str(color));\n        self.context.set_line_width(width);\n        self.context.move_to(start.x, start.y);\n        self.context.line_to(end.x, end.y);\n        self.context.stroke();\n    }\n    \n    pub fn draw_text(&self, text: &str, x: f64, y: f64, font: &str, color: &str) {\n        self.context.set_font(font);\n        self.context.set_fill_style(&JsValue::from_str(color));\n        self.context.fill_text(text, x, y).unwrap();\n    }\n    \n    pub fn get_image_data(&self) -> Result<ImageData, JsValue> {\n        self.context.get_image_data(0.0, 0.0, self.width as f64, self.height as f64)\n    }\n    \n    pub fn put_image_data(&self, image_data: &ImageData) -> Result<(), JsValue> {\n        self.context.put_image_data(image_data, 0.0, 0.0)\n    }\n}\n\n// Image processing utilities\n#[wasm_bindgen]\npub struct ImageProcessor {\n    width: u32,\n    height: u32,\n    data: Vec<u8>,\n}\n\n#[wasm_bindgen]\nimpl ImageProcessor {\n    #[wasm_bindgen(constructor)]\n    pub fn new(width: u32, height: u32) -> ImageProcessor {\n        let size = (width * height * 4) as usize; // RGBA\n        let data = vec![0; size];\n        \n        ImageProcessor {\n            width,\n            height,\n            data,\n        }\n    }\n    \n    pub fn from_image_data(image_data: &ImageData) -> ImageProcessor {\n        let width = image_data.width();\n        let height = image_data.height();\n        let data = image_data.data().to_vec();\n        \n        ImageProcessor {\n            width,\n            height,\n            data,\n        }\n    }\n    \n    pub fn to_image_data(&self) -> Result<ImageData, JsValue> {\n        ImageData::new_with_u8_clamped_array_and_sh(\n            wasm_bindgen::Clamped(&self.data),\n            self.width,\n            self.height,\n        )\n    }\n    \n    pub fn apply_grayscale(&mut self) {\n        for chunk in self.data.chunks_mut(4) {\n            let r = chunk[0] as f32;\n            let g = chunk[1] as f32;\n            let b = chunk[2] as f32;\n            \n            let gray = (0.299 * r + 0.587 * g + 0.114 * b) as u8;\n            \n            chunk[0] = gray;\n            chunk[1] = gray;\n            chunk[2] = gray;\n            // Alpha channel remains unchanged\n        }\n    }\n    \n    pub fn apply_sepia(&mut self) {\n        for chunk in self.data.chunks_mut(4) {\n            let r = chunk[0] as f32;\n            let g = chunk[1] as f32;\n            let b = chunk[2] as f32;\n            \n            let new_r = ((r * 0.393) + (g * 0.769) + (b * 0.189)).min(255.0) as u8;\n            let new_g = ((r * 0.349) + (g * 0.686) + (b * 0.168)).min(255.0) as u8;\n            let new_b = ((r * 0.272) + (g * 0.534) + (b * 0.131)).min(255.0) as u8;\n            \n            chunk[0] = new_r;\n            chunk[1] = new_g;\n            chunk[2] = new_b;\n        }\n    }\n    \n    pub fn apply_blur(&mut self, radius: u32) {\n        if radius == 0 {\n            return;\n        }\n        \n        let mut new_data = self.data.clone();\n        let kernel_size = (radius * 2 + 1) as i32;\n        let kernel_weight = 1.0 / (kernel_size * kernel_size) as f32;\n        \n        for y in 0..self.height as i32 {\n            for x in 0..self.width as i32 {\n                let mut r_sum = 0.0;\n                let mut g_sum = 0.0;\n                let mut b_sum = 0.0;\n                let mut a_sum = 0.0;\n                \n                for ky in -(radius as i32)..=(radius as i32) {\n                    for kx in -(radius as i32)..=(radius as i32) {\n                        let px = (x + kx).max(0).min(self.width as i32 - 1);\n                        let py = (y + ky).max(0).min(self.height as i32 - 1);\n                        \n                        let idx = ((py * self.width as i32 + px) * 4) as usize;\n                        \n                        r_sum += self.data[idx] as f32 * kernel_weight;\n                        g_sum += self.data[idx + 1] as f32 * kernel_weight;\n                        b_sum += self.data[idx + 2] as f32 * kernel_weight;\n                        a_sum += self.data[idx + 3] as f32 * kernel_weight;\n                    }\n                }\n                \n                let idx = ((y * self.width as i32 + x) * 4) as usize;\n                new_data[idx] = r_sum as u8;\n                new_data[idx + 1] = g_sum as u8;\n                new_data[idx + 2] = b_sum as u8;\n                new_data[idx + 3] = a_sum as u8;\n            }\n        }\n        \n        self.data = new_data;\n    }\n    \n    pub fn get_pixel(&self, x: u32, y: u32) -> Vec<u8> {\n        if x >= self.width || y >= self.height {\n            return vec![0, 0, 0, 0];\n        }\n        \n        let idx = ((y * self.width + x) * 4) as usize;\n        vec![\n            self.data[idx],\n            self.data[idx + 1],\n            self.data[idx + 2],\n            self.data[idx + 3],\n        ]\n    }\n    \n    pub fn set_pixel(&mut self, x: u32, y: u32, rgba: &[u8]) {\n        if x >= self.width || y >= self.height || rgba.len() < 4 {\n            return;\n        }\n        \n        let idx = ((y * self.width + x) * 4) as usize;\n        self.data[idx] = rgba[0];\n        self.data[idx + 1] = rgba[1];\n        self.data[idx + 2] = rgba[2];\n        self.data[idx + 3] = rgba[3];\n    }\n}\n\n// DOM manipulation utilities\n#[wasm_bindgen]\npub struct DomHelper;\n\n#[wasm_bindgen]\nimpl DomHelper {\n    pub fn create_element(tag: &str) -> Result<Element, JsValue> {\n        let document = window().unwrap().document().unwrap();\n        document.create_element(tag)\n    }\n    \n    pub fn get_element_by_id(id: &str) -> Option<Element> {\n        let document = window().unwrap().document().unwrap();\n        document.get_element_by_id(id)\n    }\n    \n    pub fn add_event_listener(\n        element: &Element,\n        event_type: &str,\n        callback: &Closure<dyn FnMut(Event)>,\n    ) -> Result<(), JsValue> {\n        element.add_event_listener_with_callback(event_type, callback.as_ref().unchecked_ref())\n    }\n    \n    pub fn set_inner_html(element: &Element, html: &str) {\n        element.set_inner_html(html);\n    }\n    \n    pub fn get_inner_html(element: &Element) -> String {\n        element.inner_html()\n    }\n    \n    pub fn add_class(element: &Element, class_name: &str) -> Result<(), JsValue> {\n        element.class_list().add_1(class_name)\n    }\n    \n    pub fn remove_class(element: &Element, class_name: &str) -> Result<(), JsValue> {\n        element.class_list().remove_1(class_name)\n    }\n    \n    pub fn set_attribute(element: &Element, name: &str, value: &str) -> Result<(), JsValue> {\n        element.set_attribute(name, value)\n    }\n    \n    pub fn get_attribute(element: &Element, name: &str) -> Option<String> {\n        element.get_attribute(name)\n    }\n}\n\n// Performance monitoring\n#[wasm_bindgen]\npub struct PerformanceMonitor {\n    start_time: f64,\n    measurements: HashMap<String, f64>,\n}\n\n#[wasm_bindgen]\nimpl PerformanceMonitor {\n    #[wasm_bindgen(constructor)]\n    pub fn new() -> PerformanceMonitor {\n        PerformanceMonitor {\n            start_time: performance_now(),\n            measurements: HashMap::new(),\n        }\n    }\n    \n    pub fn start_measurement(&mut self, name: &str) {\n        self.measurements.insert(name.to_string(), performance_now());\n    }\n    \n    pub fn end_measurement(&mut self, name: &str) -> f64 {\n        if let Some(start_time) = self.measurements.get(name) {\n            let duration = performance_now() - start_time;\n            console_log!(\"Measurement '{}': {:.3}ms\", name, duration);\n            duration\n        } else {\n            console_log!(\"Measurement '{}' not found\", name);\n            0.0\n        }\n    }\n    \n    pub fn get_elapsed_time(&self) -> f64 {\n        performance_now() - self.start_time\n    }\n}\n\n// Memory-efficient data structures\n#[wasm_bindgen]\npub struct MemoryPool {\n    pool: Vec<Vec<u8>>,\n    chunk_size: usize,\n    available: Vec<usize>,\n}\n\n#[wasm_bindgen]\nimpl MemoryPool {\n    #[wasm_bindgen(constructor)]\n    pub fn new(chunk_size: usize, initial_chunks: usize) -> MemoryPool {\n        let mut pool = Vec::with_capacity(initial_chunks);\n        let mut available = Vec::with_capacity(initial_chunks);\n        \n        for i in 0..initial_chunks {\n            pool.push(vec![0; chunk_size]);\n            available.push(i);\n        }\n        \n        MemoryPool {\n            pool,\n            chunk_size,\n            available,\n        }\n    }\n    \n    pub fn allocate(&mut self) -> Option<usize> {\n        self.available.pop()\n    }\n    \n    pub fn deallocate(&mut self, index: usize) {\n        if index < self.pool.len() {\n            // Clear the memory chunk\n            self.pool[index].fill(0);\n            self.available.push(index);\n        }\n    }\n    \n    pub fn get_chunk(&self, index: usize) -> Option<&[u8]> {\n        self.pool.get(index).map(|v| v.as_slice())\n    }\n    \n    pub fn get_chunk_mut(&mut self, index: usize) -> Option<&mut [u8]> {\n        self.pool.get_mut(index).map(|v| v.as_mut_slice())\n    }\n    \n    pub fn available_chunks(&self) -> usize {\n        self.available.len()\n    }\n    \n    pub fn total_chunks(&self) -> usize {\n        self.pool.len()\n    }\n}\n\n// Web API integrations\n#[wasm_bindgen]\npub struct WebApiHelper;\n\n#[wasm_bindgen]\nimpl WebApiHelper {\n    pub async fn fetch_text(url: &str) -> Result<String, JsValue> {\n        let window = web_sys::window().unwrap();\n        let resp_value = JsFuture::from(window.fetch_with_str(url)).await?;\n        let resp: Response = resp_value.dyn_into()?;\n        let text = JsFuture::from(resp.text()?).await?;\n        Ok(text.as_string().unwrap())\n    }\n    \n    pub async fn fetch_json(url: &str) -> Result<JsValue, JsValue> {\n        let window = web_sys::window().unwrap();\n        let resp_value = JsFuture::from(window.fetch_with_str(url)).await?;\n        let resp: Response = resp_value.dyn_into()?;\n        let json = JsFuture::from(resp.json()?).await?;\n        Ok(json)\n    }\n    \n    pub fn local_storage_set(key: &str, value: &str) -> Result<(), JsValue> {\n        let storage = window().unwrap().local_storage()?.unwrap();\n        storage.set_item(key, value)\n    }\n    \n    pub fn local_storage_get(key: &str) -> Result<Option<String>, JsValue> {\n        let storage = window().unwrap().local_storage()?.unwrap();\n        storage.get_item(key)\n    }\n    \n    pub fn session_storage_set(key: &str, value: &str) -> Result<(), JsValue> {\n        let storage = window().unwrap().session_storage()?.unwrap();\n        storage.set_item(key, value)\n    }\n    \n    pub fn session_storage_get(key: &str) -> Result<Option<String>, JsValue> {\n        let storage = window().unwrap().session_storage()?.unwrap();\n        storage.get_item(key)\n    }\n    \n    pub fn get_user_agent() -> String {\n        window().unwrap().navigator().user_agent().unwrap()\n    }\n    \n    pub fn get_viewport_dimensions() -> (u32, u32) {\n        let window = window().unwrap();\n        let width = window.inner_width().unwrap().as_f64().unwrap() as u32;\n        let height = window.inner_height().unwrap().as_f64().unwrap() as u32;\n        (width, height)\n    }\n}\n\n// Game loop and animation\n#[wasm_bindgen]\npub struct AnimationLoop {\n    callback: Option<Closure<dyn FnMut(f64)>>,\n    request_id: Option<i32>,\n    last_frame_time: f64,\n    frame_count: u32,\n    fps: f64,\n}\n\n#[wasm_bindgen]\nimpl AnimationLoop {\n    #[wasm_bindgen(constructor)]\n    pub fn new() -> AnimationLoop {\n        AnimationLoop {\n            callback: None,\n            request_id: None,\n            last_frame_time: 0.0,\n            frame_count: 0,\n            fps: 0.0,\n        }\n    }\n    \n    pub fn start(&mut self, callback: js_sys::Function) {\n        let callback = Closure::wrap(Box::new(move |timestamp: f64| {\n            callback.call1(&JsValue::NULL, &JsValue::from_f64(timestamp)).unwrap();\n        }) as Box<dyn FnMut(f64)>);\n        \n        let window = window().unwrap();\n        let request_id = window\n            .request_animation_frame(callback.as_ref().unchecked_ref())\n            .unwrap();\n        \n        self.callback = Some(callback);\n        self.request_id = Some(request_id);\n    }\n    \n    pub fn stop(&mut self) {\n        if let Some(request_id) = self.request_id.take() {\n            window().unwrap().cancel_animation_frame(request_id).unwrap();\n        }\n        self.callback = None;\n    }\n    \n    pub fn update_fps(&mut self, timestamp: f64) {\n        self.frame_count += 1;\n        \n        if self.last_frame_time == 0.0 {\n            self.last_frame_time = timestamp;\n        }\n        \n        let delta = timestamp - self.last_frame_time;\n        if delta >= 1000.0 {\n            self.fps = (self.frame_count as f64 * 1000.0) / delta;\n            self.frame_count = 0;\n            self.last_frame_time = timestamp;\n        }\n    }\n    \n    pub fn get_fps(&self) -> f64 {\n        self.fps\n    }\n}\n\n// Math utilities optimized for WASM\n#[wasm_bindgen]\npub struct MathUtils;\n\n#[wasm_bindgen]\nimpl MathUtils {\n    pub fn fast_sqrt(x: f64) -> f64 {\n        x.sqrt()\n    }\n    \n    pub fn fast_sin(x: f64) -> f64 {\n        x.sin()\n    }\n    \n    pub fn fast_cos(x: f64) -> f64 {\n        x.cos()\n    }\n    \n    pub fn lerp(a: f64, b: f64, t: f64) -> f64 {\n        a + (b - a) * t\n    }\n    \n    pub fn clamp(value: f64, min: f64, max: f64) -> f64 {\n        value.max(min).min(max)\n    }\n    \n    pub fn map_range(value: f64, in_min: f64, in_max: f64, out_min: f64, out_max: f64) -> f64 {\n        (value - in_min) * (out_max - out_min) / (in_max - in_min) + out_min\n    }\n    \n    pub fn distance_2d(x1: f64, y1: f64, x2: f64, y2: f64) -> f64 {\n        let dx = x2 - x1;\n        let dy = y2 - y1;\n        (dx * dx + dy * dy).sqrt()\n    }\n    \n    pub fn angle_between_points(x1: f64, y1: f64, x2: f64, y2: f64) -> f64 {\n        (y2 - y1).atan2(x2 - x1)\n    }\n}\n\n// Utility functions\nfn window() -> web_sys::Window {\n    web_sys::window().expect(\"no global `window` exists\")\n}\n\n// Module initialization\n#[wasm_bindgen(start)]\npub fn main() {\n    console_error_panic_hook::set_once();\n    console_log!(\"WASM module initialized successfully\");\n}\n\n// Export utility functions for JavaScript\n#[wasm_bindgen]\npub fn greet(name: &str) -> String {\n    format!(\"Hello, {}! Greetings from Rust and WebAssembly!\", name)\n}\n\n#[wasm_bindgen]\npub fn add(a: i32, b: i32) -> i32 {\n    a + b\n}\n\n#[wasm_bindgen]\npub fn fibonacci(n: u32) -> u32 {\n    match n {\n        0 => 0,\n        1 => 1,\n        _ => fibonacci(n - 1) + fibonacci(n - 2),\n    }\n}\n\n#[wasm_bindgen]\npub fn fibonacci_iterative(n: u32) -> u32 {\n    if n <= 1 {\n        return n;\n    }\n    \n    let mut a = 0;\n    let mut b = 1;\n    \n    for _ in 2..=n {\n        let temp = a + b;\n        a = b;\n        b = temp;\n    }\n    \n    b\n}\n\n// Memory management helpers\n#[wasm_bindgen]\npub fn get_memory_usage() -> u32 {\n    (wasm_bindgen::memory().buffer().byte_length() / 1024) as u32\n}\n\n#[wasm_bindgen]\npub fn force_gc() {\n    // In browsers that support it, this might trigger garbage collection\n    // This is mainly for testing memory management\n}",
    "key_concepts": [
      "WebAssembly",
      "wasm-bindgen",
      "JavaScript interop",
      "DOM manipulation",
      "Web APIs",
      "Canvas rendering",
      "Image processing",
      "memory management",
      "performance optimization",
      "TypeScript integration"
    ]
  },
  {
    "prompt": "Build a browser-based game engine in Rust compiled to WebAssembly with entity-component-system architecture, 2D graphics, input handling, audio, and physics simulation. Include asset loading and scene management.",
    "response": "use wasm_bindgen::prelude::*;\nuse wasm_bindgen::JsCast;\nuse web_sys::*;\nuse js_sys::*;\nuse std::collections::{HashMap, HashSet};\nuse std::rc::Rc;\nuse std::cell::RefCell;\nuse std::f64::consts::PI;\n\n// External JavaScript bindings\n#[wasm_bindgen]\nextern \"C\" {\n    #[wasm_bindgen(js_namespace = console)]\n    fn log(s: &str);\n    \n    #[wasm_bindgen(js_namespace = Date, js_name = now)]\n    fn date_now() -> f64;\n}\n\nmacro_rules! console_log {\n    ($($t:tt)*) => (log(&format_args!($($t)*).to_string()))\n}\n\n// Core ECS types\npub type EntityId = u32;\npub type ComponentTypeId = std::any::TypeId;\n\n// Component trait\npub trait Component: 'static {\n    fn type_id() -> ComponentTypeId {\n        std::any::TypeId::of::<Self>()\n    }\n}\n\n// Transform component\n#[derive(Debug, Clone)]\npub struct Transform {\n    pub position: Vec2,\n    pub rotation: f64,\n    pub scale: Vec2,\n}\n\nimpl Component for Transform {}\n\nimpl Default for Transform {\n    fn default() -> Self {\n        Self {\n            position: Vec2::ZERO,\n            rotation: 0.0,\n            scale: Vec2::ONE,\n        }\n    }\n}\n\n// Sprite component\n#[derive(Debug, Clone)]\npub struct Sprite {\n    pub texture_id: Option<String>,\n    pub color: Color,\n    pub size: Vec2,\n    pub anchor: Vec2,\n    pub visible: bool,\n}\n\nimpl Component for Sprite {}\n\nimpl Default for Sprite {\n    fn default() -> Self {\n        Self {\n            texture_id: None,\n            color: Color::WHITE,\n            size: Vec2::new(32.0, 32.0),\n            anchor: Vec2::new(0.5, 0.5),\n            visible: true,\n        }\n    }\n}\n\n// Physics components\n#[derive(Debug, Clone)]\npub struct RigidBody {\n    pub velocity: Vec2,\n    pub acceleration: Vec2,\n    pub mass: f64,\n    pub drag: f64,\n    pub is_kinematic: bool,\n    pub gravity_scale: f64,\n}\n\nimpl Component for RigidBody {}\n\nimpl Default for RigidBody {\n    fn default() -> Self {\n        Self {\n            velocity: Vec2::ZERO,\n            acceleration: Vec2::ZERO,\n            mass: 1.0,\n            drag: 0.98,\n            is_kinematic: false,\n            gravity_scale: 1.0,\n        }\n    }\n}\n\n#[derive(Debug, Clone)]\npub struct Collider {\n    pub shape: ColliderShape,\n    pub is_trigger: bool,\n    pub collision_layer: u32,\n    pub collision_mask: u32,\n}\n\nimpl Component for Collider {}\n\n#[derive(Debug, Clone)]\npub enum ColliderShape {\n    Rectangle { width: f64, height: f64 },\n    Circle { radius: f64 },\n}\n\n// Audio component\n#[derive(Debug, Clone)]\npub struct AudioSource {\n    pub clip_id: Option<String>,\n    pub volume: f64,\n    pub pitch: f64,\n    pub looping: bool,\n    pub is_playing: bool,\n}\n\nimpl Component for AudioSource {}\n\nimpl Default for AudioSource {\n    fn default() -> Self {\n        Self {\n            clip_id: None,\n            volume: 1.0,\n            pitch: 1.0,\n            looping: false,\n            is_playing: false,\n        }\n    }\n}\n\n// Math types\n#[wasm_bindgen]\n#[derive(Debug, Clone, Copy, PartialEq)]\npub struct Vec2 {\n    pub x: f64,\n    pub y: f64,\n}\n\n#[wasm_bindgen]\nimpl Vec2 {\n    #[wasm_bindgen(constructor)]\n    pub fn new(x: f64, y: f64) -> Vec2 {\n        Vec2 { x, y }\n    }\n    \n    #[wasm_bindgen(getter)]\n    pub fn x(&self) -> f64 { self.x }\n    \n    #[wasm_bindgen(setter)]\n    pub fn set_x(&mut self, x: f64) { self.x = x; }\n    \n    #[wasm_bindgen(getter)]\n    pub fn y(&self) -> f64 { self.y }\n    \n    #[wasm_bindgen(setter)]\n    pub fn set_y(&mut self, y: f64) { self.y = y; }\n    \n    pub fn magnitude(&self) -> f64 {\n        (self.x * self.x + self.y * self.y).sqrt()\n    }\n    \n    pub fn normalized(&self) -> Vec2 {\n        let mag = self.magnitude();\n        if mag > 0.0 {\n            Vec2::new(self.x / mag, self.y / mag)\n        } else {\n            Vec2::ZERO\n        }\n    }\n    \n    pub fn distance_to(&self, other: &Vec2) -> f64 {\n        let dx = self.x - other.x;\n        let dy = self.y - other.y;\n        (dx * dx + dy * dy).sqrt()\n    }\n    \n    pub fn dot(&self, other: &Vec2) -> f64 {\n        self.x * other.x + self.y * other.y\n    }\n    \n    pub fn lerp(&self, other: &Vec2, t: f64) -> Vec2 {\n        Vec2::new(\n            self.x + (other.x - self.x) * t,\n            self.y + (other.y - self.y) * t,\n        )\n    }\n}\n\nimpl Vec2 {\n    pub const ZERO: Vec2 = Vec2 { x: 0.0, y: 0.0 };\n    pub const ONE: Vec2 = Vec2 { x: 1.0, y: 1.0 };\n    pub const UP: Vec2 = Vec2 { x: 0.0, y: -1.0 };\n    pub const DOWN: Vec2 = Vec2 { x: 0.0, y: 1.0 };\n    pub const LEFT: Vec2 = Vec2 { x: -1.0, y: 0.0 };\n    pub const RIGHT: Vec2 = Vec2 { x: 1.0, y: 0.0 };\n    \n    pub fn add(&self, other: &Vec2) -> Vec2 {\n        Vec2::new(self.x + other.x, self.y + other.y)\n    }\n    \n    pub fn sub(&self, other: &Vec2) -> Vec2 {\n        Vec2::new(self.x - other.x, self.y - other.y)\n    }\n    \n    pub fn mul(&self, scalar: f64) -> Vec2 {\n        Vec2::new(self.x * scalar, self.y * scalar)\n    }\n    \n    pub fn rotate(&self, angle: f64) -> Vec2 {\n        let cos_a = angle.cos();\n        let sin_a = angle.sin();\n        Vec2::new(\n            self.x * cos_a - self.y * sin_a,\n            self.x * sin_a + self.y * cos_a,\n        )\n    }\n}\n\n#[wasm_bindgen]\n#[derive(Debug, Clone, Copy, PartialEq)]\npub struct Color {\n    pub r: f64,\n    pub g: f64,\n    pub b: f64,\n    pub a: f64,\n}\n\n#[wasm_bindgen]\nimpl Color {\n    #[wasm_bindgen(constructor)]\n    pub fn new(r: f64, g: f64, b: f64, a: f64) -> Color {\n        Color { r, g, b, a }\n    }\n    \n    pub fn to_css_string(&self) -> String {\n        format!(\n            \"rgba({}, {}, {}, {})\",\n            (self.r * 255.0) as u8,\n            (self.g * 255.0) as u8,\n            (self.b * 255.0) as u8,\n            self.a\n        )\n    }\n}\n\nimpl Color {\n    pub const WHITE: Color = Color { r: 1.0, g: 1.0, b: 1.0, a: 1.0 };\n    pub const BLACK: Color = Color { r: 0.0, g: 0.0, b: 0.0, a: 1.0 };\n    pub const RED: Color = Color { r: 1.0, g: 0.0, b: 0.0, a: 1.0 };\n    pub const GREEN: Color = Color { r: 0.0, g: 1.0, b: 0.0, a: 1.0 };\n    pub const BLUE: Color = Color { r: 0.0, g: 0.0, b: 1.0, a: 1.0 };\n    pub const TRANSPARENT: Color = Color { r: 0.0, g: 0.0, b: 0.0, a: 0.0 };\n}\n\n// ECS World\npub struct World {\n    entities: Vec<Option<EntityData>>,\n    next_entity_id: EntityId,\n    free_entities: Vec<EntityId>,\n    component_storage: HashMap<ComponentTypeId, Box<dyn ComponentStorage>>,\n}\n\nstruct EntityData {\n    id: EntityId,\n    components: HashSet<ComponentTypeId>,\n}\n\ntrait ComponentStorage {\n    fn remove(&mut self, entity: EntityId);\n    fn has(&self, entity: EntityId) -> bool;\n}\n\nstruct TypedComponentStorage<T: Component> {\n    components: HashMap<EntityId, T>,\n}\n\nimpl<T: Component> ComponentStorage for TypedComponentStorage<T> {\n    fn remove(&mut self, entity: EntityId) {\n        self.components.remove(&entity);\n    }\n    \n    fn has(&self, entity: EntityId) -> bool {\n        self.components.contains_key(&entity)\n    }\n}\n\nimpl World {\n    pub fn new() -> Self {\n        Self {\n            entities: Vec::new(),\n            next_entity_id: 0,\n            free_entities: Vec::new(),\n            component_storage: HashMap::new(),\n        }\n    }\n    \n    pub fn create_entity(&mut self) -> EntityId {\n        let id = if let Some(id) = self.free_entities.pop() {\n            id\n        } else {\n            let id = self.next_entity_id;\n            self.next_entity_id += 1;\n            id\n        };\n        \n        if id as usize >= self.entities.len() {\n            self.entities.resize(id as usize + 1, None);\n        }\n        \n        self.entities[id as usize] = Some(EntityData {\n            id,\n            components: HashSet::new(),\n        });\n        \n        id\n    }\n    \n    pub fn destroy_entity(&mut self, entity: EntityId) {\n        if let Some(entity_data) = self.entities.get_mut(entity as usize).and_then(|e| e.take()) {\n            // Remove all components\n            for component_type in &entity_data.components {\n                if let Some(storage) = self.component_storage.get_mut(component_type) {\n                    storage.remove(entity);\n                }\n            }\n            \n            self.free_entities.push(entity);\n        }\n    }\n    \n    pub fn add_component<T: Component>(&mut self, entity: EntityId, component: T) {\n        let type_id = T::type_id();\n        \n        // Ensure storage exists\n        if !self.component_storage.contains_key(&type_id) {\n            self.component_storage.insert(\n                type_id,\n                Box::new(TypedComponentStorage::<T> {\n                    components: HashMap::new(),\n                }),\n            );\n        }\n        \n        // Add component\n        if let Some(storage) = self.component_storage.get_mut(&type_id) {\n            let typed_storage = storage.as_mut() as *mut dyn ComponentStorage\n                as *mut TypedComponentStorage<T>;\n            unsafe {\n                (*typed_storage).components.insert(entity, component);\n            }\n        }\n        \n        // Update entity\n        if let Some(Some(entity_data)) = self.entities.get_mut(entity as usize) {\n            entity_data.components.insert(type_id);\n        }\n    }\n    \n    pub fn get_component<T: Component>(&self, entity: EntityId) -> Option<&T> {\n        let type_id = T::type_id();\n        \n        if let Some(storage) = self.component_storage.get(&type_id) {\n            let typed_storage = storage.as_ref() as *const dyn ComponentStorage\n                as *const TypedComponentStorage<T>;\n            unsafe {\n                (*typed_storage).components.get(&entity)\n            }\n        } else {\n            None\n        }\n    }\n    \n    pub fn get_component_mut<T: Component>(&mut self, entity: EntityId) -> Option<&mut T> {\n        let type_id = T::type_id();\n        \n        if let Some(storage) = self.component_storage.get_mut(&type_id) {\n            let typed_storage = storage.as_mut() as *mut dyn ComponentStorage\n                as *mut TypedComponentStorage<T>;\n            unsafe {\n                (*typed_storage).components.get_mut(&entity)\n            }\n        } else {\n            None\n        }\n    }\n    \n    pub fn has_component<T: Component>(&self, entity: EntityId) -> bool {\n        let type_id = T::type_id();\n        \n        if let Some(storage) = self.component_storage.get(&type_id) {\n            storage.has(entity)\n        } else {\n            false\n        }\n    }\n    \n    pub fn query<T: Component>(&self) -> Vec<(EntityId, &T)> {\n        let type_id = T::type_id();\n        let mut results = Vec::new();\n        \n        if let Some(storage) = self.component_storage.get(&type_id) {\n            let typed_storage = storage.as_ref() as *const dyn ComponentStorage\n                as *const TypedComponentStorage<T>;\n            unsafe {\n                for (&entity, component) in &(*typed_storage).components {\n                    results.push((entity, component));\n                }\n            }\n        }\n        \n        results\n    }\n}\n\n// Input handling\n#[wasm_bindgen]\npub struct InputManager {\n    keys_pressed: HashSet<String>,\n    keys_just_pressed: HashSet<String>,\n    keys_just_released: HashSet<String>,\n    mouse_position: Vec2,\n    mouse_buttons: HashSet<u16>,\n    mouse_just_pressed: HashSet<u16>,\n    mouse_just_released: HashSet<u16>,\n}\n\n#[wasm_bindgen]\nimpl InputManager {\n    #[wasm_bindgen(constructor)]\n    pub fn new() -> InputManager {\n        InputManager {\n            keys_pressed: HashSet::new(),\n            keys_just_pressed: HashSet::new(),\n            keys_just_released: HashSet::new(),\n            mouse_position: Vec2::ZERO,\n            mouse_buttons: HashSet::new(),\n            mouse_just_pressed: HashSet::new(),\n            mouse_just_released: HashSet::new(),\n        }\n    }\n    \n    pub fn key_down(&mut self, key: &str) {\n        if !self.keys_pressed.contains(key) {\n            self.keys_just_pressed.insert(key.to_string());\n        }\n        self.keys_pressed.insert(key.to_string());\n    }\n    \n    pub fn key_up(&mut self, key: &str) {\n        if self.keys_pressed.contains(key) {\n            self.keys_just_released.insert(key.to_string());\n        }\n        self.keys_pressed.remove(key);\n    }\n    \n    pub fn mouse_down(&mut self, button: u16) {\n        if !self.mouse_buttons.contains(&button) {\n            self.mouse_just_pressed.insert(button);\n        }\n        self.mouse_buttons.insert(button);\n    }\n    \n    pub fn mouse_up(&mut self, button: u16) {\n        if self.mouse_buttons.contains(&button) {\n            self.mouse_just_released.insert(button);\n        }\n        self.mouse_buttons.remove(&button);\n    }\n    \n    pub fn mouse_move(&mut self, x: f64, y: f64) {\n        self.mouse_position = Vec2::new(x, y);\n    }\n    \n    pub fn is_key_pressed(&self, key: &str) -> bool {\n        self.keys_pressed.contains(key)\n    }\n    \n    pub fn is_key_just_pressed(&self, key: &str) -> bool {\n        self.keys_just_pressed.contains(key)\n    }\n    \n    pub fn is_key_just_released(&self, key: &str) -> bool {\n        self.keys_just_released.contains(key)\n    }\n    \n    pub fn is_mouse_button_pressed(&self, button: u16) -> bool {\n        self.mouse_buttons.contains(&button)\n    }\n    \n    pub fn is_mouse_button_just_pressed(&self, button: u16) -> bool {\n        self.mouse_just_pressed.contains(&button)\n    }\n    \n    pub fn get_mouse_position(&self) -> Vec2 {\n        self.mouse_position\n    }\n    \n    pub fn update(&mut self) {\n        self.keys_just_pressed.clear();\n        self.keys_just_released.clear();\n        self.mouse_just_pressed.clear();\n        self.mouse_just_released.clear();\n    }\n}\n\n// Asset management\n#[wasm_bindgen]\npub struct AssetManager {\n    textures: HashMap<String, HtmlImageElement>,\n    audio_clips: HashMap<String, HtmlAudioElement>,\n    loading_count: u32,\n}\n\n#[wasm_bindgen]\nimpl AssetManager {\n    #[wasm_bindgen(constructor)]\n    pub fn new() -> AssetManager {\n        AssetManager {\n            textures: HashMap::new(),\n            audio_clips: HashMap::new(),\n            loading_count: 0,\n        }\n    }\n    \n    pub async fn load_texture(&mut self, id: &str, url: &str) -> Result<(), JsValue> {\n        let img = HtmlImageElement::new()?;\n        \n        let promise = js_sys::Promise::new(&mut |resolve, reject| {\n            let img_clone = img.clone();\n            let resolve_clone = resolve.clone();\n            let reject_clone = reject.clone();\n            \n            let onload = Closure::wrap(Box::new(move || {\n                resolve_clone.call0(&JsValue::NULL).unwrap();\n            }) as Box<dyn FnMut()>);\n            \n            let onerror = Closure::wrap(Box::new(move || {\n                reject_clone.call1(&JsValue::NULL, &JsValue::from_str(\"Failed to load image\")).unwrap();\n            }) as Box<dyn FnMut()>);\n            \n            img_clone.set_onload(Some(onload.as_ref().unchecked_ref()));\n            img_clone.set_onerror(Some(onerror.as_ref().unchecked_ref()));\n            \n            onload.forget();\n            onerror.forget();\n        });\n        \n        img.set_src(url);\n        \n        wasm_bindgen_futures::JsFuture::from(promise).await?;\n        \n        self.textures.insert(id.to_string(), img);\n        \n        Ok(())\n    }\n    \n    pub async fn load_audio(&mut self, id: &str, url: &str) -> Result<(), JsValue> {\n        let audio = HtmlAudioElement::new_with_src(url)?;\n        \n        let promise = js_sys::Promise::new(&mut |resolve, reject| {\n            let audio_clone = audio.clone();\n            let resolve_clone = resolve.clone();\n            let reject_clone = reject.clone();\n            \n            let onload = Closure::wrap(Box::new(move || {\n                resolve_clone.call0(&JsValue::NULL).unwrap();\n            }) as Box<dyn FnMut()>);\n            \n            let onerror = Closure::wrap(Box::new(move || {\n                reject_clone.call1(&JsValue::NULL, &JsValue::from_str(\"Failed to load audio\")).unwrap();\n            }) as Box<dyn FnMut()>);\n            \n            audio_clone.set_oncanplaythrough(Some(onload.as_ref().unchecked_ref()));\n            audio_clone.set_onerror(Some(onerror.as_ref().unchecked_ref()));\n            \n            onload.forget();\n            onerror.forget();\n        });\n        \n        wasm_bindgen_futures::JsFuture::from(promise).await?;\n        \n        self.audio_clips.insert(id.to_string(), audio);\n        \n        Ok(())\n    }\n    \n    pub fn get_texture(&self, id: &str) -> Option<&HtmlImageElement> {\n        self.textures.get(id)\n    }\n    \n    pub fn get_audio(&self, id: &str) -> Option<&HtmlAudioElement> {\n        self.audio_clips.get(id)\n    }\n    \n    pub fn is_loading(&self) -> bool {\n        self.loading_count > 0\n    }\n}\n\n// Renderer\n#[wasm_bindgen]\npub struct Renderer {\n    canvas: HtmlCanvasElement,\n    context: CanvasRenderingContext2d,\n    camera_position: Vec2,\n    camera_zoom: f64,\n}\n\n#[wasm_bindgen]\nimpl Renderer {\n    #[wasm_bindgen(constructor)]\n    pub fn new(canvas_id: &str) -> Result<Renderer, JsValue> {\n        let document = web_sys::window().unwrap().document().unwrap();\n        let canvas = document\n            .get_element_by_id(canvas_id)\n            .unwrap()\n            .dyn_into::<HtmlCanvasElement>()?;\n        \n        let context = canvas\n            .get_context(\"2d\")?\n            .unwrap()\n            .dyn_into::<CanvasRenderingContext2d>()?;\n        \n        Ok(Renderer {\n            canvas,\n            context,\n            camera_position: Vec2::ZERO,\n            camera_zoom: 1.0,\n        })\n    }\n    \n    pub fn clear(&self, color: &Color) {\n        self.context.set_fill_style(&JsValue::from_str(&color.to_css_string()));\n        self.context.fill_rect(0.0, 0.0, self.canvas.width() as f64, self.canvas.height() as f64);\n    }\n    \n    pub fn set_camera(&mut self, position: Vec2, zoom: f64) {\n        self.camera_position = position;\n        self.camera_zoom = zoom;\n    }\n    \n    pub fn world_to_screen(&self, world_pos: Vec2) -> Vec2 {\n        let camera_offset = world_pos.sub(&self.camera_position);\n        let screen_pos = camera_offset.mul(self.camera_zoom);\n        screen_pos.add(&Vec2::new(\n            self.canvas.width() as f64 / 2.0,\n            self.canvas.height() as f64 / 2.0,\n        ))\n    }\n    \n    pub fn screen_to_world(&self, screen_pos: Vec2) -> Vec2 {\n        let centered = screen_pos.sub(&Vec2::new(\n            self.canvas.width() as f64 / 2.0,\n            self.canvas.height() as f64 / 2.0,\n        ));\n        let world_offset = centered.mul(1.0 / self.camera_zoom);\n        world_offset.add(&self.camera_position)\n    }\n    \n    pub fn draw_sprite(\n        &self,\n        transform: &Transform,\n        sprite: &Sprite,\n        texture: Option<&HtmlImageElement>,\n    ) {\n        if !sprite.visible {\n            return;\n        }\n        \n        let screen_pos = self.world_to_screen(transform.position);\n        let scaled_size = sprite.size.mul(self.camera_zoom * transform.scale.x);\n        \n        self.context.save();\n        \n        // Apply transformations\n        self.context.translate(screen_pos.x, screen_pos.y).unwrap();\n        self.context.rotate(transform.rotation).unwrap();\n        \n        // Set color/alpha\n        self.context.set_global_alpha(sprite.color.a);\n        \n        let draw_x = -scaled_size.x * sprite.anchor.x;\n        let draw_y = -scaled_size.y * sprite.anchor.y;\n        \n        if let Some(img) = texture {\n            self.context\n                .draw_image_with_html_image_element_and_dw_and_dh(\n                    img,\n                    draw_x,\n                    draw_y,\n                    scaled_size.x,\n                    scaled_size.y,\n                )\n                .unwrap();\n        } else {\n            // Draw colored rectangle if no texture\n            self.context.set_fill_style(&JsValue::from_str(&sprite.color.to_css_string()));\n            self.context.fill_rect(draw_x, draw_y, scaled_size.x, scaled_size.y);\n        }\n        \n        self.context.restore();\n    }\n    \n    pub fn draw_circle(&self, position: Vec2, radius: f64, color: &Color) {\n        let screen_pos = self.world_to_screen(position);\n        let scaled_radius = radius * self.camera_zoom;\n        \n        self.context.begin_path();\n        self.context.set_fill_style(&JsValue::from_str(&color.to_css_string()));\n        self.context.arc(screen_pos.x, screen_pos.y, scaled_radius, 0.0, 2.0 * PI).unwrap();\n        self.context.fill();\n    }\n    \n    pub fn draw_line(&self, start: Vec2, end: Vec2, color: &Color, width: f64) {\n        let screen_start = self.world_to_screen(start);\n        let screen_end = self.world_to_screen(end);\n        \n        self.context.begin_path();\n        self.context.set_stroke_style(&JsValue::from_str(&color.to_css_string()));\n        self.context.set_line_width(width * self.camera_zoom);\n        self.context.move_to(screen_start.x, screen_start.y);\n        self.context.line_to(screen_end.x, screen_end.y);\n        self.context.stroke();\n    }\n}\n\n// Physics system\npub struct PhysicsSystem {\n    gravity: Vec2,\n    collision_pairs: Vec<(EntityId, EntityId)>,\n}\n\nimpl PhysicsSystem {\n    pub fn new() -> Self {\n        Self {\n            gravity: Vec2::new(0.0, 980.0), // 980 pixels/s^2 downward\n            collision_pairs: Vec::new(),\n        }\n    }\n    \n    pub fn update(&mut self, world: &mut World, delta_time: f64) {\n        self.collision_pairs.clear();\n        \n        // Apply physics to all rigid bodies\n        let entities_with_physics: Vec<EntityId> = world\n            .query::<RigidBody>()\n            .into_iter()\n            .map(|(entity, _)| entity)\n            .collect();\n        \n        for entity in entities_with_physics {\n            self.update_physics(world, entity, delta_time);\n        }\n        \n        // Check collisions\n        self.check_collisions(world);\n        \n        // Resolve collisions\n        for (entity_a, entity_b) in &self.collision_pairs {\n            self.resolve_collision(world, *entity_a, *entity_b);\n        }\n    }\n    \n    fn update_physics(&self, world: &mut World, entity: EntityId, delta_time: f64) {\n        if let (Some(rigid_body), Some(transform)) = (\n            world.get_component_mut::<RigidBody>(entity),\n            world.get_component_mut::<Transform>(entity),\n        ) {\n            if !rigid_body.is_kinematic {\n                // Apply gravity\n                let gravity_force = self.gravity.mul(rigid_body.gravity_scale);\n                rigid_body.acceleration = rigid_body.acceleration.add(&gravity_force);\n                \n                // Update velocity\n                let accel_delta = rigid_body.acceleration.mul(delta_time);\n                rigid_body.velocity = rigid_body.velocity.add(&accel_delta);\n                \n                // Apply drag\n                rigid_body.velocity = rigid_body.velocity.mul(rigid_body.drag);\n                \n                // Update position\n                let velocity_delta = rigid_body.velocity.mul(delta_time);\n                transform.position = transform.position.add(&velocity_delta);\n                \n                // Reset acceleration\n                rigid_body.acceleration = Vec2::ZERO;\n            }\n        }\n    }\n    \n    fn check_collisions(&mut self, world: &World) {\n        let entities_with_colliders: Vec<EntityId> = world\n            .query::<Collider>()\n            .into_iter()\n            .map(|(entity, _)| entity)\n            .collect();\n        \n        for i in 0..entities_with_colliders.len() {\n            for j in (i + 1)..entities_with_colliders.len() {\n                let entity_a = entities_with_colliders[i];\n                let entity_b = entities_with_colliders[j];\n                \n                if self.are_colliding(world, entity_a, entity_b) {\n                    self.collision_pairs.push((entity_a, entity_b));\n                }\n            }\n        }\n    }\n    \n    fn are_colliding(&self, world: &World, entity_a: EntityId, entity_b: EntityId) -> bool {\n        let (collider_a, transform_a) = match (\n            world.get_component::<Collider>(entity_a),\n            world.get_component::<Transform>(entity_a),\n        ) {\n            (Some(c), Some(t)) => (c, t),\n            _ => return false,\n        };\n        \n        let (collider_b, transform_b) = match (\n            world.get_component::<Collider>(entity_b),\n            world.get_component::<Transform>(entity_b),\n        ) {\n            (Some(c), Some(t)) => (c, t),\n            _ => return false,\n        };\n        \n        // Check collision layers\n        if (collider_a.collision_layer & collider_b.collision_mask) == 0 &&\n           (collider_b.collision_layer & collider_a.collision_mask) == 0 {\n            return false;\n        }\n        \n        // Simple AABB collision detection\n        match (&collider_a.shape, &collider_b.shape) {\n            (\n                ColliderShape::Rectangle { width: w1, height: h1 },\n                ColliderShape::Rectangle { width: w2, height: h2 },\n            ) => {\n                let pos_a = transform_a.position;\n                let pos_b = transform_b.position;\n                \n                let half_w1 = w1 / 2.0;\n                let half_h1 = h1 / 2.0;\n                let half_w2 = w2 / 2.0;\n                let half_h2 = h2 / 2.0;\n                \n                (pos_a.x - half_w1 < pos_b.x + half_w2) &&\n                (pos_a.x + half_w1 > pos_b.x - half_w2) &&\n                (pos_a.y - half_h1 < pos_b.y + half_h2) &&\n                (pos_a.y + half_h1 > pos_b.y - half_h2)\n            }\n            (\n                ColliderShape::Circle { radius: r1 },\n                ColliderShape::Circle { radius: r2 },\n            ) => {\n                let distance = transform_a.position.distance_to(&transform_b.position);\n                distance < (r1 + r2)\n            }\n            _ => false, // Mixed shapes not implemented\n        }\n    }\n    \n    fn resolve_collision(&self, world: &mut World, entity_a: EntityId, entity_b: EntityId) {\n        // Simple collision response - separate objects\n        if let (Some(transform_a), Some(transform_b)) = (\n            world.get_component::<Transform>(entity_a),\n            world.get_component::<Transform>(entity_b),\n        ) {\n            let direction = transform_a.position.sub(&transform_b.position).normalized();\n            let separation = direction.mul(2.0); // Small separation distance\n            \n            if let Some(transform_a_mut) = world.get_component_mut::<Transform>(entity_a) {\n                transform_a_mut.position = transform_a_mut.position.add(&separation);\n            }\n            \n            if let Some(transform_b_mut) = world.get_component_mut::<Transform>(entity_b) {\n                transform_b_mut.position = transform_b_mut.position.sub(&separation);\n            }\n        }\n    }\n}\n\n// Game engine\n#[wasm_bindgen]\npub struct GameEngine {\n    world: Rc<RefCell<World>>,\n    renderer: Rc<RefCell<Renderer>>,\n    input: Rc<RefCell<InputManager>>,\n    assets: Rc<RefCell<AssetManager>>,\n    physics: Rc<RefCell<PhysicsSystem>>,\n    last_frame_time: f64,\n    is_running: bool,\n}\n\n#[wasm_bindgen]\nimpl GameEngine {\n    #[wasm_bindgen(constructor)]\n    pub fn new(canvas_id: &str) -> Result<GameEngine, JsValue> {\n        console_error_panic_hook::set_once();\n        \n        let renderer = Renderer::new(canvas_id)?;\n        \n        Ok(GameEngine {\n            world: Rc::new(RefCell::new(World::new())),\n            renderer: Rc::new(RefCell::new(renderer)),\n            input: Rc::new(RefCell::new(InputManager::new())),\n            assets: Rc::new(RefCell::new(AssetManager::new())),\n            physics: Rc::new(RefCell::new(PhysicsSystem::new())),\n            last_frame_time: 0.0,\n            is_running: false,\n        })\n    }\n    \n    pub fn start(&mut self) {\n        self.is_running = true;\n        self.last_frame_time = date_now();\n        console_log!(\"Game engine started\");\n    }\n    \n    pub fn stop(&mut self) {\n        self.is_running = false;\n        console_log!(\"Game engine stopped\");\n    }\n    \n    pub fn update(&mut self, current_time: f64) {\n        if !self.is_running {\n            return;\n        }\n        \n        let delta_time = (current_time - self.last_frame_time) / 1000.0; // Convert to seconds\n        self.last_frame_time = current_time;\n        \n        // Update physics\n        self.physics.borrow_mut().update(&mut self.world.borrow_mut(), delta_time);\n        \n        // Update input\n        self.input.borrow_mut().update();\n        \n        // Render\n        self.render();\n    }\n    \n    pub fn render(&self) {\n        let mut renderer = self.renderer.borrow_mut();\n        let world = self.world.borrow();\n        let assets = self.assets.borrow();\n        \n        // Clear screen\n        renderer.clear(&Color::new(0.2, 0.3, 0.4, 1.0));\n        \n        // Render all sprites\n        let sprites_to_render: Vec<(EntityId, Transform, Sprite)> = world\n            .query::<Transform>()\n            .into_iter()\n            .filter_map(|(entity, transform)| {\n                world.get_component::<Sprite>(entity).map(|sprite| {\n                    (entity, transform.clone(), sprite.clone())\n                })\n            })\n            .collect();\n        \n        for (_, transform, sprite) in sprites_to_render {\n            let texture = sprite.texture_id\n                .as_ref()\n                .and_then(|id| assets.get_texture(id));\n            \n            renderer.draw_sprite(&transform, &sprite, texture);\n        }\n    }\n    \n    pub fn create_entity(&self) -> EntityId {\n        self.world.borrow_mut().create_entity()\n    }\n    \n    pub fn add_transform(&self, entity: EntityId, x: f64, y: f64, rotation: f64) {\n        let transform = Transform {\n            position: Vec2::new(x, y),\n            rotation,\n            scale: Vec2::ONE,\n        };\n        self.world.borrow_mut().add_component(entity, transform);\n    }\n    \n    pub fn add_sprite(&self, entity: EntityId, texture_id: Option<String>, width: f64, height: f64) {\n        let sprite = Sprite {\n            texture_id,\n            color: Color::WHITE,\n            size: Vec2::new(width, height),\n            anchor: Vec2::new(0.5, 0.5),\n            visible: true,\n        };\n        self.world.borrow_mut().add_component(entity, sprite);\n    }\n    \n    pub fn add_rigid_body(&self, entity: EntityId) {\n        let rigid_body = RigidBody::default();\n        self.world.borrow_mut().add_component(entity, rigid_body);\n    }\n    \n    pub fn add_box_collider(&self, entity: EntityId, width: f64, height: f64) {\n        let collider = Collider {\n            shape: ColliderShape::Rectangle { width, height },\n            is_trigger: false,\n            collision_layer: 1,\n            collision_mask: 1,\n        };\n        self.world.borrow_mut().add_component(entity, collider);\n    }\n    \n    pub fn set_camera(&self, x: f64, y: f64, zoom: f64) {\n        self.renderer.borrow_mut().set_camera(Vec2::new(x, y), zoom);\n    }\n    \n    pub fn on_key_down(&self, key: &str) {\n        self.input.borrow_mut().key_down(key);\n    }\n    \n    pub fn on_key_up(&self, key: &str) {\n        self.input.borrow_mut().key_up(key);\n    }\n    \n    pub fn on_mouse_down(&self, button: u16) {\n        self.input.borrow_mut().mouse_down(button);\n    }\n    \n    pub fn on_mouse_up(&self, button: u16) {\n        self.input.borrow_mut().mouse_up(button);\n    }\n    \n    pub fn on_mouse_move(&self, x: f64, y: f64) {\n        self.input.borrow_mut().mouse_move(x, y);\n    }\n}\n\n// Initialize the module\n#[wasm_bindgen(start)]\npub fn main() {\n    console_error_panic_hook::set_once();\n    console_log!(\"Game engine WASM module loaded\");\n}",
    "key_concepts": [
      "game engine architecture",
      "entity-component-system",
      "2D graphics rendering",
      "input handling",
      "physics simulation",
      "asset management",
      "scene management",
      "WebAssembly optimization",
      "browser APIs",
      "real-time systems"
    ]
  },
  {
    "prompt": "Create a WebAssembly-based data visualization library in Rust with D3.js-like functionality, SVG generation, interactive charts, animations, and real-time data streaming. Include TypeScript bindings and performance benchmarks.",
    "response": "use wasm_bindgen::prelude::*;\nuse wasm_bindgen::JsCast;\nuse web_sys::*;\nuse js_sys::*;\nuse std::collections::HashMap;\nuse std::rc::Rc;\nuse std::cell::RefCell;\nuse serde::{Serialize, Deserialize};\n\n// External JavaScript bindings\n#[wasm_bindgen]\nextern \"C\" {\n    #[wasm_bindgen(js_namespace = console)]\n    fn log(s: &str);\n    \n    #[wasm_bindgen(js_namespace = console, js_name = time)]\n    fn console_time(label: &str);\n    \n    #[wasm_bindgen(js_namespace = console, js_name = timeEnd)]\n    fn console_time_end(label: &str);\n    \n    #[wasm_bindgen(js_namespace = performance, js_name = now)]\n    fn performance_now() -> f64;\n    \n    #[wasm_bindgen(js_namespace = Date, js_name = now)]\n    fn date_now() -> f64;\n}\n\nmacro_rules! console_log {\n    ($($t:tt)*) => (log(&format_args!($($t)*).to_string()))\n}\n\n// Core data types\n#[wasm_bindgen]\n#[derive(Debug, Clone, Copy, Serialize, Deserialize)]\npub struct DataPoint {\n    pub x: f64,\n    pub y: f64,\n    pub value: f64,\n    pub timestamp: f64,\n}\n\n#[wasm_bindgen]\nimpl DataPoint {\n    #[wasm_bindgen(constructor)]\n    pub fn new(x: f64, y: f64, value: f64, timestamp: f64) -> DataPoint {\n        DataPoint { x, y, value, timestamp }\n    }\n    \n    #[wasm_bindgen(getter)]\n    pub fn x(&self) -> f64 { self.x }\n    \n    #[wasm_bindgen(getter)]\n    pub fn y(&self) -> f64 { self.y }\n    \n    #[wasm_bindgen(getter)]\n    pub fn value(&self) -> f64 { self.value }\n    \n    #[wasm_bindgen(getter)]\n    pub fn timestamp(&self) -> f64 { self.timestamp }\n}\n\n#[wasm_bindgen]\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct TimeSeries {\n    data: Vec<DataPoint>,\n    name: String,\n    color: String,\n}\n\n#[wasm_bindgen]\nimpl TimeSeries {\n    #[wasm_bindgen(constructor)]\n    pub fn new(name: String, color: String) -> TimeSeries {\n        TimeSeries {\n            data: Vec::new(),\n            name,\n            color,\n        }\n    }\n    \n    pub fn add_point(&mut self, point: DataPoint) {\n        self.data.push(point);\n        \n        // Keep data sorted by timestamp\n        self.data.sort_by(|a, b| a.timestamp.partial_cmp(&b.timestamp).unwrap());\n        \n        // Limit data points for performance\n        if self.data.len() > 10000 {\n            self.data.drain(0..1000);\n        }\n    }\n    \n    pub fn get_data(&self) -> Vec<DataPoint> {\n        self.data.clone()\n    }\n    \n    pub fn get_range(&self, start_time: f64, end_time: f64) -> Vec<DataPoint> {\n        self.data\n            .iter()\n            .filter(|p| p.timestamp >= start_time && p.timestamp <= end_time)\n            .cloned()\n            .collect()\n    }\n    \n    pub fn get_statistics(&self) -> DataStatistics {\n        if self.data.is_empty() {\n            return DataStatistics::default();\n        }\n        \n        let values: Vec<f64> = self.data.iter().map(|p| p.value).collect();\n        let min = values.iter().fold(f64::INFINITY, |a, &b| a.min(b));\n        let max = values.iter().fold(f64::NEG_INFINITY, |a, &b| a.max(b));\n        let sum: f64 = values.iter().sum();\n        let mean = sum / values.len() as f64;\n        \n        let variance = values.iter()\n            .map(|&v| (v - mean).powi(2))\n            .sum::<f64>() / values.len() as f64;\n        let std_dev = variance.sqrt();\n        \n        DataStatistics {\n            count: values.len(),\n            min,\n            max,\n            mean,\n            std_dev,\n            sum,\n        }\n    }\n    \n    #[wasm_bindgen(getter)]\n    pub fn name(&self) -> String { self.name.clone() }\n    \n    #[wasm_bindgen(getter)]\n    pub fn color(&self) -> String { self.color.clone() }\n    \n    pub fn length(&self) -> usize { self.data.len() }\n}\n\n#[wasm_bindgen]\n#[derive(Debug, Clone, Default, Serialize, Deserialize)]\npub struct DataStatistics {\n    pub count: usize,\n    pub min: f64,\n    pub max: f64,\n    pub mean: f64,\n    pub std_dev: f64,\n    pub sum: f64,\n}\n\n// Scale functions for mapping data to screen coordinates\n#[wasm_bindgen]\npub struct LinearScale {\n    domain_min: f64,\n    domain_max: f64,\n    range_min: f64,\n    range_max: f64,\n}\n\n#[wasm_bindgen]\nimpl LinearScale {\n    #[wasm_bindgen(constructor)]\n    pub fn new(domain_min: f64, domain_max: f64, range_min: f64, range_max: f64) -> LinearScale {\n        LinearScale {\n            domain_min,\n            domain_max,\n            range_min,\n            range_max,\n        }\n    }\n    \n    pub fn scale(&self, value: f64) -> f64 {\n        let domain_span = self.domain_max - self.domain_min;\n        let range_span = self.range_max - self.range_min;\n        \n        if domain_span == 0.0 {\n            return self.range_min;\n        }\n        \n        let normalized = (value - self.domain_min) / domain_span;\n        self.range_min + normalized * range_span\n    }\n    \n    pub fn invert(&self, value: f64) -> f64 {\n        let range_span = self.range_max - self.range_min;\n        let domain_span = self.domain_max - self.domain_min;\n        \n        if range_span == 0.0 {\n            return self.domain_min;\n        }\n        \n        let normalized = (value - self.range_min) / range_span;\n        self.domain_min + normalized * domain_span\n    }\n    \n    pub fn update_domain(&mut self, min: f64, max: f64) {\n        self.domain_min = min;\n        self.domain_max = max;\n    }\n    \n    pub fn update_range(&mut self, min: f64, max: f64) {\n        self.range_min = min;\n        self.range_max = max;\n    }\n    \n    pub fn get_ticks(&self, count: usize) -> Vec<f64> {\n        if count == 0 {\n            return Vec::new();\n        }\n        \n        let step = (self.domain_max - self.domain_min) / (count - 1) as f64;\n        (0..count)\n            .map(|i| self.domain_min + step * i as f64)\n            .collect()\n    }\n}\n\n// SVG builder for creating visualizations\n#[wasm_bindgen]\npub struct SvgBuilder {\n    svg_element: SvgElement,\n    width: f64,\n    height: f64,\n    margin: Margin,\n    animations: Vec<Animation>,\n}\n\n#[wasm_bindgen]\n#[derive(Debug, Clone)]\npub struct Margin {\n    pub top: f64,\n    pub right: f64,\n    pub bottom: f64,\n    pub left: f64,\n}\n\n#[wasm_bindgen]\nimpl Margin {\n    #[wasm_bindgen(constructor)]\n    pub fn new(top: f64, right: f64, bottom: f64, left: f64) -> Margin {\n        Margin { top, right, bottom, left }\n    }\n}\n\n#[derive(Debug, Clone)]\nstruct Animation {\n    element_id: String,\n    property: String,\n    from_value: String,\n    to_value: String,\n    duration: f64,\n    delay: f64,\n    easing: String,\n}\n\n#[wasm_bindgen]\nimpl SvgBuilder {\n    #[wasm_bindgen(constructor)]\n    pub fn new(container_id: &str, width: f64, height: f64) -> Result<SvgBuilder, JsValue> {\n        let document = window().unwrap().document().unwrap();\n        let container = document\n            .get_element_by_id(container_id)\n            .ok_or_else(|| JsValue::from_str(\"Container element not found\"))?;\n        \n        // Create SVG element\n        let svg = document\n            .create_element_ns(Some(\"http://www.w3.org/2000/svg\"), \"svg\")?\n            .dyn_into::<SvgElement>()?;\n        \n        svg.set_attribute(\"width\", &width.to_string())?;\n        svg.set_attribute(\"height\", &height.to_string())?;\n        svg.set_attribute(\"viewBox\", &format!(\"0 0 {} {}\", width, height))?;\n        \n        container.append_child(&svg)?;\n        \n        Ok(SvgBuilder {\n            svg_element: svg,\n            width,\n            height,\n            margin: Margin::new(20.0, 20.0, 40.0, 60.0),\n            animations: Vec::new(),\n        })\n    }\n    \n    pub fn set_margin(&mut self, margin: Margin) {\n        self.margin = margin;\n    }\n    \n    pub fn get_chart_width(&self) -> f64 {\n        self.width - self.margin.left - self.margin.right\n    }\n    \n    pub fn get_chart_height(&self) -> f64 {\n        self.height - self.margin.top - self.margin.bottom\n    }\n    \n    pub fn clear(&self) -> Result<(), JsValue> {\n        self.svg_element.set_inner_html(\"\");\n        Ok(())\n    }\n    \n    pub fn add_line(&self, x1: f64, y1: f64, x2: f64, y2: f64, stroke: &str, stroke_width: f64) -> Result<String, JsValue> {\n        let document = window().unwrap().document().unwrap();\n        let line = document\n            .create_element_ns(Some(\"http://www.w3.org/2000/svg\"), \"line\")?;\n        \n        let id = format!(\"line_{}\", date_now() as u64);\n        line.set_attribute(\"id\", &id)?;\n        line.set_attribute(\"x1\", &x1.to_string())?;\n        line.set_attribute(\"y1\", &y1.to_string())?;\n        line.set_attribute(\"x2\", &x2.to_string())?;\n        line.set_attribute(\"y2\", &y2.to_string())?;\n        line.set_attribute(\"stroke\", stroke)?;\n        line.set_attribute(\"stroke-width\", &stroke_width.to_string())?;\n        \n        self.svg_element.append_child(&line)?;\n        Ok(id)\n    }\n    \n    pub fn add_circle(&self, cx: f64, cy: f64, r: f64, fill: &str, stroke: &str) -> Result<String, JsValue> {\n        let document = window().unwrap().document().unwrap();\n        let circle = document\n            .create_element_ns(Some(\"http://www.w3.org/2000/svg\"), \"circle\")?;\n        \n        let id = format!(\"circle_{}\", date_now() as u64);\n        circle.set_attribute(\"id\", &id)?;\n        circle.set_attribute(\"cx\", &cx.to_string())?;\n        circle.set_attribute(\"cy\", &cy.to_string())?;\n        circle.set_attribute(\"r\", &r.to_string())?;\n        circle.set_attribute(\"fill\", fill)?;\n        circle.set_attribute(\"stroke\", stroke)?;\n        \n        self.svg_element.append_child(&circle)?;\n        Ok(id)\n    }\n    \n    pub fn add_rectangle(&self, x: f64, y: f64, width: f64, height: f64, fill: &str, stroke: &str) -> Result<String, JsValue> {\n        let document = window().unwrap().document().unwrap();\n        let rect = document\n            .create_element_ns(Some(\"http://www.w3.org/2000/svg\"), \"rect\")?;\n        \n        let id = format!(\"rect_{}\", date_now() as u64);\n        rect.set_attribute(\"id\", &id)?;\n        rect.set_attribute(\"x\", &x.to_string())?;\n        rect.set_attribute(\"y\", &y.to_string())?;\n        rect.set_attribute(\"width\", &width.to_string())?;\n        rect.set_attribute(\"height\", &height.to_string())?;\n        rect.set_attribute(\"fill\", fill)?;\n        rect.set_attribute(\"stroke\", stroke)?;\n        \n        self.svg_element.append_child(&rect)?;\n        Ok(id)\n    }\n    \n    pub fn add_path(&self, d: &str, fill: &str, stroke: &str, stroke_width: f64) -> Result<String, JsValue> {\n        let document = window().unwrap().document().unwrap();\n        let path = document\n            .create_element_ns(Some(\"http://www.w3.org/2000/svg\"), \"path\")?;\n        \n        let id = format!(\"path_{}\", date_now() as u64);\n        path.set_attribute(\"id\", &id)?;\n        path.set_attribute(\"d\", d)?;\n        path.set_attribute(\"fill\", fill)?;\n        path.set_attribute(\"stroke\", stroke)?;\n        path.set_attribute(\"stroke-width\", &stroke_width.to_string())?;\n        \n        self.svg_element.append_child(&path)?;\n        Ok(id)\n    }\n    \n    pub fn add_text(&self, x: f64, y: f64, text: &str, font_size: f64, fill: &str) -> Result<String, JsValue> {\n        let document = window().unwrap().document().unwrap();\n        let text_element = document\n            .create_element_ns(Some(\"http://www.w3.org/2000/svg\"), \"text\")?;\n        \n        let id = format!(\"text_{}\", date_now() as u64);\n        text_element.set_attribute(\"id\", &id)?;\n        text_element.set_attribute(\"x\", &x.to_string())?;\n        text_element.set_attribute(\"y\", &y.to_string())?;\n        text_element.set_attribute(\"font-size\", &font_size.to_string())?;\n        text_element.set_attribute(\"fill\", fill)?;\n        text_element.set_text_content(Some(text));\n        \n        self.svg_element.append_child(&text_element)?;\n        Ok(id)\n    }\n    \n    pub fn add_group(&self, transform: &str) -> Result<String, JsValue> {\n        let document = window().unwrap().document().unwrap();\n        let group = document\n            .create_element_ns(Some(\"http://www.w3.org/2000/svg\"), \"g\")?;\n        \n        let id = format!(\"group_{}\", date_now() as u64);\n        group.set_attribute(\"id\", &id)?;\n        group.set_attribute(\"transform\", transform)?;\n        \n        self.svg_element.append_child(&group)?;\n        Ok(id)\n    }\n    \n    pub fn animate_element(&self, element_id: &str, property: &str, from_value: &str, to_value: &str, duration: f64) -> Result<(), JsValue> {\n        let document = window().unwrap().document().unwrap();\n        let element = document\n            .get_element_by_id(element_id)\n            .ok_or_else(|| JsValue::from_str(\"Element not found\"))?;\n        \n        let animate = document\n            .create_element_ns(Some(\"http://www.w3.org/2000/svg\"), \"animate\")?;\n        \n        animate.set_attribute(\"attributeName\", property)?;\n        animate.set_attribute(\"from\", from_value)?;\n        animate.set_attribute(\"to\", to_value)?;\n        animate.set_attribute(\"dur\", &format!(\"{}s\", duration))?;\n        animate.set_attribute(\"fill\", \"freeze\")?;\n        \n        element.append_child(&animate)?;\n        \n        Ok(())\n    }\n}\n\n// Chart types\n#[wasm_bindgen]\npub struct LineChart {\n    svg: SvgBuilder,\n    x_scale: LinearScale,\n    y_scale: LinearScale,\n    series: Vec<TimeSeries>,\n    show_dots: bool,\n    show_grid: bool,\n    interactive: bool,\n}\n\n#[wasm_bindgen]\nimpl LineChart {\n    #[wasm_bindgen(constructor)]\n    pub fn new(container_id: &str, width: f64, height: f64) -> Result<LineChart, JsValue> {\n        let svg = SvgBuilder::new(container_id, width, height)?;\n        \n        Ok(LineChart {\n            svg,\n            x_scale: LinearScale::new(0.0, 100.0, 0.0, width - 80.0),\n            y_scale: LinearScale::new(0.0, 100.0, height - 60.0, 20.0),\n            series: Vec::new(),\n            show_dots: true,\n            show_grid: true,\n            interactive: false,\n        })\n    }\n    \n    pub fn add_series(&mut self, series: TimeSeries) {\n        self.series.push(series);\n        self.update_scales();\n    }\n    \n    pub fn set_options(&mut self, show_dots: bool, show_grid: bool, interactive: bool) {\n        self.show_dots = show_dots;\n        self.show_grid = show_grid;\n        self.interactive = interactive;\n    }\n    \n    fn update_scales(&mut self) {\n        if self.series.is_empty() {\n            return;\n        }\n        \n        let mut x_min = f64::INFINITY;\n        let mut x_max = f64::NEG_INFINITY;\n        let mut y_min = f64::INFINITY;\n        let mut y_max = f64::NEG_INFINITY;\n        \n        for series in &self.series {\n            for point in &series.data {\n                x_min = x_min.min(point.x);\n                x_max = x_max.max(point.x);\n                y_min = y_min.min(point.y);\n                y_max = y_max.max(point.y);\n            }\n        }\n        \n        // Add some padding\n        let x_padding = (x_max - x_min) * 0.05;\n        let y_padding = (y_max - y_min) * 0.05;\n        \n        self.x_scale.update_domain(x_min - x_padding, x_max + x_padding);\n        self.y_scale.update_domain(y_min - y_padding, y_max + y_padding);\n        \n        let chart_width = self.svg.get_chart_width();\n        let chart_height = self.svg.get_chart_height();\n        \n        self.x_scale.update_range(self.svg.margin.left, self.svg.margin.left + chart_width);\n        self.y_scale.update_range(self.svg.margin.top + chart_height, self.svg.margin.top);\n    }\n    \n    pub fn render(&self) -> Result<(), JsValue> {\n        self.svg.clear()?;\n        \n        if self.show_grid {\n            self.draw_grid()?;\n        }\n        \n        self.draw_axes()?;\n        \n        for series in &self.series {\n            self.draw_line_series(series)?;\n        }\n        \n        Ok(())\n    }\n    \n    fn draw_grid(&self) -> Result<(), JsValue> {\n        let x_ticks = self.x_scale.get_ticks(10);\n        let y_ticks = self.y_scale.get_ticks(8);\n        \n        // Vertical grid lines\n        for tick in &x_ticks {\n            let x = self.x_scale.scale(*tick);\n            self.svg.add_line(\n                x,\n                self.svg.margin.top,\n                x,\n                self.svg.margin.top + self.svg.get_chart_height(),\n                \"#e0e0e0\",\n                1.0,\n            )?;\n        }\n        \n        // Horizontal grid lines\n        for tick in &y_ticks {\n            let y = self.y_scale.scale(*tick);\n            self.svg.add_line(\n                self.svg.margin.left,\n                y,\n                self.svg.margin.left + self.svg.get_chart_width(),\n                y,\n                \"#e0e0e0\",\n                1.0,\n            )?;\n        }\n        \n        Ok(())\n    }\n    \n    fn draw_axes(&self) -> Result<(), JsValue> {\n        // X-axis\n        let x_axis_y = self.svg.margin.top + self.svg.get_chart_height();\n        self.svg.add_line(\n            self.svg.margin.left,\n            x_axis_y,\n            self.svg.margin.left + self.svg.get_chart_width(),\n            x_axis_y,\n            \"#333\",\n            2.0,\n        )?;\n        \n        // Y-axis\n        self.svg.add_line(\n            self.svg.margin.left,\n            self.svg.margin.top,\n            self.svg.margin.left,\n            self.svg.margin.top + self.svg.get_chart_height(),\n            \"#333\",\n            2.0,\n        )?;\n        \n        // X-axis labels\n        let x_ticks = self.x_scale.get_ticks(8);\n        for tick in &x_ticks {\n            let x = self.x_scale.scale(*tick);\n            self.svg.add_text(\n                x,\n                x_axis_y + 20.0,\n                &format!(\"{:.1}\", tick),\n                12.0,\n                \"#666\",\n            )?;\n        }\n        \n        // Y-axis labels\n        let y_ticks = self.y_scale.get_ticks(6);\n        for tick in &y_ticks {\n            let y = self.y_scale.scale(*tick);\n            self.svg.add_text(\n                self.svg.margin.left - 10.0,\n                y + 4.0,\n                &format!(\"{:.1}\", tick),\n                12.0,\n                \"#666\",\n            )?;\n        }\n        \n        Ok(())\n    }\n    \n    fn draw_line_series(&self, series: &TimeSeries) -> Result<(), JsValue> {\n        if series.data.is_empty() {\n            return Ok(());\n        }\n        \n        // Create path for line\n        let mut path_data = String::new();\n        \n        for (i, point) in series.data.iter().enumerate() {\n            let x = self.x_scale.scale(point.x);\n            let y = self.y_scale.scale(point.y);\n            \n            if i == 0 {\n                path_data.push_str(&format!(\"M {} {}\", x, y));\n            } else {\n                path_data.push_str(&format!(\" L {} {}\", x, y));\n            }\n        }\n        \n        // Draw line\n        self.svg.add_path(&path_data, \"none\", &series.color, 2.0)?;\n        \n        // Draw dots if enabled\n        if self.show_dots {\n            for point in &series.data {\n                let x = self.x_scale.scale(point.x);\n                let y = self.y_scale.scale(point.y);\n                \n                self.svg.add_circle(x, y, 3.0, &series.color, \"#fff\")?;\n            }\n        }\n        \n        Ok(())\n    }\n    \n    pub fn animate_in(&self) -> Result<(), JsValue> {\n        // Animate the chart appearance\n        // This would involve animating path lengths, circle radii, etc.\n        Ok(())\n    }\n    \n    pub fn update_real_time(&mut self, series_name: &str, point: DataPoint) -> Result<(), JsValue> {\n        // Find the series and add the new point\n        for series in &mut self.series {\n            if series.name == series_name {\n                series.add_point(point);\n                break;\n            }\n        }\n        \n        self.update_scales();\n        self.render()?;\n        \n        Ok(())\n    }\n}\n\n#[wasm_bindgen]\npub struct BarChart {\n    svg: SvgBuilder,\n    x_scale: LinearScale,\n    y_scale: LinearScale,\n    data: Vec<(String, f64)>,\n    bar_color: String,\n    show_values: bool,\n}\n\n#[wasm_bindgen]\nimpl BarChart {\n    #[wasm_bindgen(constructor)]\n    pub fn new(container_id: &str, width: f64, height: f64) -> Result<BarChart, JsValue> {\n        let svg = SvgBuilder::new(container_id, width, height)?;\n        \n        Ok(BarChart {\n            svg,\n            x_scale: LinearScale::new(0.0, 1.0, 0.0, width - 80.0),\n            y_scale: LinearScale::new(0.0, 100.0, height - 60.0, 20.0),\n            data: Vec::new(),\n            bar_color: \"#4285f4\".to_string(),\n            show_values: true,\n        })\n    }\n    \n    pub fn set_data(&mut self, labels: Vec<String>, values: Vec<f64>) {\n        self.data.clear();\n        for (label, value) in labels.into_iter().zip(values.into_iter()) {\n            self.data.push((label, value));\n        }\n        self.update_scales();\n    }\n    \n    pub fn set_color(&mut self, color: String) {\n        self.bar_color = color;\n    }\n    \n    fn update_scales(&mut self) {\n        if self.data.is_empty() {\n            return;\n        }\n        \n        let max_value = self.data.iter()\n            .map(|(_, value)| *value)\n            .fold(f64::NEG_INFINITY, f64::max);\n        \n        let min_value = self.data.iter()\n            .map(|(_, value)| *value)\n            .fold(f64::INFINITY, f64::min)\n            .min(0.0);\n        \n        self.y_scale.update_domain(min_value, max_value * 1.1);\n        \n        let chart_width = self.svg.get_chart_width();\n        let chart_height = self.svg.get_chart_height();\n        \n        self.x_scale.update_range(self.svg.margin.left, self.svg.margin.left + chart_width);\n        self.y_scale.update_range(self.svg.margin.top + chart_height, self.svg.margin.top);\n    }\n    \n    pub fn render(&self) -> Result<(), JsValue> {\n        self.svg.clear()?;\n        \n        if self.data.is_empty() {\n            return Ok(());\n        }\n        \n        let bar_width = self.svg.get_chart_width() / self.data.len() as f64 * 0.8;\n        let bar_spacing = self.svg.get_chart_width() / self.data.len() as f64;\n        let zero_y = self.y_scale.scale(0.0);\n        \n        for (i, (label, value)) in self.data.iter().enumerate() {\n            let x = self.svg.margin.left + i as f64 * bar_spacing + bar_spacing * 0.1;\n            let y = self.y_scale.scale(*value);\n            let height = (zero_y - y).abs();\n            \n            // Draw bar\n            self.svg.add_rectangle(\n                x,\n                y.min(zero_y),\n                bar_width,\n                height,\n                &self.bar_color,\n                \"none\",\n            )?;\n            \n            // Draw label\n            self.svg.add_text(\n                x + bar_width / 2.0,\n                zero_y + 20.0,\n                label,\n                10.0,\n                \"#666\",\n            )?;\n            \n            // Draw value if enabled\n            if self.show_values {\n                self.svg.add_text(\n                    x + bar_width / 2.0,\n                    y - 5.0,\n                    &format!(\"{:.1}\", value),\n                    10.0,\n                    \"#333\",\n                )?;\n            }\n        }\n        \n        // Draw axes\n        self.draw_axes()?;\n        \n        Ok(())\n    }\n    \n    fn draw_axes(&self) -> Result<(), JsValue> {\n        let x_axis_y = self.y_scale.scale(0.0);\n        \n        // X-axis\n        self.svg.add_line(\n            self.svg.margin.left,\n            x_axis_y,\n            self.svg.margin.left + self.svg.get_chart_width(),\n            x_axis_y,\n            \"#333\",\n            2.0,\n        )?;\n        \n        // Y-axis\n        self.svg.add_line(\n            self.svg.margin.left,\n            self.svg.margin.top,\n            self.svg.margin.left,\n            self.svg.margin.top + self.svg.get_chart_height(),\n            \"#333\",\n            2.0,\n        )?;\n        \n        // Y-axis labels\n        let y_ticks = self.y_scale.get_ticks(6);\n        for tick in &y_ticks {\n            let y = self.y_scale.scale(*tick);\n            self.svg.add_text(\n                self.svg.margin.left - 10.0,\n                y + 4.0,\n                &format!(\"{:.0}\", tick),\n                10.0,\n                \"#666\",\n            )?;\n        }\n        \n        Ok(())\n    }\n}\n\n// Real-time data streaming\n#[wasm_bindgen]\npub struct DataStreamer {\n    charts: HashMap<String, Rc<RefCell<LineChart>>>,\n    buffer_size: usize,\n    update_interval: f64,\n    last_update: f64,\n}\n\n#[wasm_bindgen]\nimpl DataStreamer {\n    #[wasm_bindgen(constructor)]\n    pub fn new(buffer_size: usize, update_interval_ms: f64) -> DataStreamer {\n        DataStreamer {\n            charts: HashMap::new(),\n            buffer_size,\n            update_interval: update_interval_ms,\n            last_update: 0.0,\n        }\n    }\n    \n    pub fn add_chart(&mut self, chart_id: String, chart: LineChart) {\n        self.charts.insert(chart_id, Rc::new(RefCell::new(chart)));\n    }\n    \n    pub fn stream_data(&mut self, chart_id: &str, series_name: &str, value: f64) -> Result<(), JsValue> {\n        let current_time = date_now();\n        \n        if current_time - self.last_update < self.update_interval {\n            return Ok(()); // Rate limiting\n        }\n        \n        if let Some(chart) = self.charts.get(chart_id) {\n            let point = DataPoint::new(current_time, value, value, current_time);\n            chart.borrow_mut().update_real_time(series_name, point)?;\n            self.last_update = current_time;\n        }\n        \n        Ok(())\n    }\n}\n\n// Performance benchmarking\n#[wasm_bindgen]\npub struct PerformanceBenchmark {\n    measurements: HashMap<String, Vec<f64>>,\n}\n\n#[wasm_bindgen]\nimpl PerformanceBenchmark {\n    #[wasm_bindgen(constructor)]\n    pub fn new() -> PerformanceBenchmark {\n        PerformanceBenchmark {\n            measurements: HashMap::new(),\n        }\n    }\n    \n    pub fn start_measurement(&self, name: &str) {\n        console_time(name);\n    }\n    \n    pub fn end_measurement(&self, name: &str) {\n        console_time_end(name);\n    }\n    \n    pub fn measure_function<F>(&mut self, name: &str, iterations: u32, mut func: F) -> f64\n    where\n        F: FnMut(),\n    {\n        let start = performance_now();\n        \n        for _ in 0..iterations {\n            func();\n        }\n        \n        let duration = performance_now() - start;\n        let avg_duration = duration / iterations as f64;\n        \n        self.measurements\n            .entry(name.to_string())\n            .or_insert_with(Vec::new)\n            .push(avg_duration);\n        \n        console_log!(\"Benchmark {}: {:.3}ms avg over {} iterations\", name, avg_duration, iterations);\n        \n        avg_duration\n    }\n    \n    pub fn get_statistics(&self, name: &str) -> Option<DataStatistics> {\n        self.measurements.get(name).map(|measurements| {\n            let count = measurements.len();\n            let min = measurements.iter().fold(f64::INFINITY, |a, &b| a.min(b));\n            let max = measurements.iter().fold(f64::NEG_INFINITY, |a, &b| a.max(b));\n            let sum: f64 = measurements.iter().sum();\n            let mean = sum / count as f64;\n            \n            let variance = measurements.iter()\n                .map(|&v| (v - mean).powi(2))\n                .sum::<f64>() / count as f64;\n            let std_dev = variance.sqrt();\n            \n            DataStatistics {\n                count,\n                min,\n                max,\n                mean,\n                std_dev,\n                sum,\n            }\n        })\n    }\n    \n    pub fn compare_implementations(&mut self, name1: &str, name2: &str) -> String {\n        if let (Some(stats1), Some(stats2)) = (self.get_statistics(name1), self.get_statistics(name2)) {\n            let speedup = stats2.mean / stats1.mean;\n            format!(\n                \"{} vs {}: {:.2}x speedup ({}ms vs {}ms)\",\n                name1, name2, speedup, stats1.mean, stats2.mean\n            )\n        } else {\n            \"Insufficient data for comparison\".to_string()\n        }\n    }\n}\n\n// Utility functions\nfn window() -> web_sys::Window {\n    web_sys::window().expect(\"no global `window` exists\")\n}\n\n// Module initialization\n#[wasm_bindgen(start)]\npub fn main() {\n    console_error_panic_hook::set_once();\n    console_log!(\"Data visualization WASM module loaded\");\n}\n\n// Export helper functions\n#[wasm_bindgen]\npub fn create_sample_data(count: usize) -> Vec<DataPoint> {\n    (0..count)\n        .map(|i| {\n            let x = i as f64;\n            let y = (x * 0.1).sin() * 50.0 + 50.0 + (fastrand::f64() - 0.5) * 10.0;\n            DataPoint::new(x, y, y, date_now() + i as f64 * 1000.0)\n        })\n        .collect()\n}\n\n#[wasm_bindgen]\npub fn interpolate_color(color1: &str, color2: &str, t: f64) -> String {\n    // Simple color interpolation (assumes hex colors)\n    format!(\"rgb({}, {}, {})\", \n            (255.0 * t) as u8,\n            (128.0 * (1.0 - t)) as u8,\n            (200.0 * t) as u8)\n}",
    "key_concepts": [
      "data visualization",
      "SVG generation",
      "D3.js-like functionality",
      "interactive charts",
      "real-time streaming",
      "animation system",
      "performance benchmarking",
      "TypeScript bindings",
      "scale functions",
      "chart components"
    ]
  },
  {
    "prompt": "Build a WebAssembly-based image processing and computer vision library in Rust with filters, edge detection, object recognition, and real-time camera processing. Include SIMD optimizations and WebGL integration for GPU acceleration.",
    "response": "use wasm_bindgen::prelude::*;\nuse wasm_bindgen::JsCast;\nuse web_sys::*;\nuse js_sys::*;\nuse std::arch::wasm32::*;\nuse std::collections::HashMap;\n\n// External JavaScript bindings\n#[wasm_bindgen]\nextern \"C\" {\n    #[wasm_bindgen(js_namespace = console)]\n    fn log(s: &str);\n    \n    #[wasm_bindgen(js_namespace = performance, js_name = now)]\n    fn performance_now() -> f64;\n    \n    #[wasm_bindgen(js_name = requestAnimationFrame)]\n    fn request_animation_frame(callback: &Closure<dyn FnMut(f64)>);\n}\n\nmacro_rules! console_log {\n    ($($t:tt)*) => (log(&format_args!($($t)*).to_string()))\n}\n\n// Core image types\n#[wasm_bindgen]\n#[derive(Debug, Clone)]\npub struct Image {\n    width: u32,\n    height: u32,\n    channels: u32,\n    data: Vec<u8>,\n}\n\n#[wasm_bindgen]\nimpl Image {\n    #[wasm_bindgen(constructor)]\n    pub fn new(width: u32, height: u32, channels: u32) -> Image {\n        let size = (width * height * channels) as usize;\n        Image {\n            width,\n            height,\n            channels,\n            data: vec![0; size],\n        }\n    }\n    \n    pub fn from_image_data(image_data: &ImageData) -> Image {\n        let width = image_data.width();\n        let height = image_data.height();\n        let data = image_data.data().to_vec();\n        \n        Image {\n            width,\n            height,\n            channels: 4, // RGBA\n            data,\n        }\n    }\n    \n    pub fn to_image_data(&self) -> Result<ImageData, JsValue> {\n        if self.channels != 4 {\n            return Err(JsValue::from_str(\"Only RGBA images can be converted to ImageData\"));\n        }\n        \n        ImageData::new_with_u8_clamped_array_and_sh(\n            wasm_bindgen::Clamped(&self.data),\n            self.width,\n            self.height,\n        )\n    }\n    \n    #[wasm_bindgen(getter)]\n    pub fn width(&self) -> u32 { self.width }\n    \n    #[wasm_bindgen(getter)]\n    pub fn height(&self) -> u32 { self.height }\n    \n    #[wasm_bindgen(getter)]\n    pub fn channels(&self) -> u32 { self.channels }\n    \n    pub fn get_pixel(&self, x: u32, y: u32) -> Vec<u8> {\n        if x >= self.width || y >= self.height {\n            return vec![0; self.channels as usize];\n        }\n        \n        let idx = ((y * self.width + x) * self.channels) as usize;\n        let end_idx = idx + self.channels as usize;\n        \n        if end_idx <= self.data.len() {\n            self.data[idx..end_idx].to_vec()\n        } else {\n            vec![0; self.channels as usize]\n        }\n    }\n    \n    pub fn set_pixel(&mut self, x: u32, y: u32, pixel: &[u8]) {\n        if x >= self.width || y >= self.height || pixel.len() != self.channels as usize {\n            return;\n        }\n        \n        let idx = ((y * self.width + x) * self.channels) as usize;\n        let end_idx = idx + self.channels as usize;\n        \n        if end_idx <= self.data.len() {\n            self.data[idx..end_idx].copy_from_slice(pixel);\n        }\n    }\n    \n    pub fn clone_image(&self) -> Image {\n        Image {\n            width: self.width,\n            height: self.height,\n            channels: self.channels,\n            data: self.data.clone(),\n        }\n    }\n    \n    pub fn get_data_ptr(&self) -> *const u8 {\n        self.data.as_ptr()\n    }\n    \n    pub fn get_data_length(&self) -> usize {\n        self.data.len()\n    }\n}\n\n// SIMD-optimized image filters\n#[wasm_bindgen]\npub struct ImageProcessor {\n    use_simd: bool,\n}\n\n#[wasm_bindgen]\nimpl ImageProcessor {\n    #[wasm_bindgen(constructor)]\n    pub fn new() -> ImageProcessor {\n        ImageProcessor {\n            use_simd: true,\n        }\n    }\n    \n    pub fn set_simd_enabled(&mut self, enabled: bool) {\n        self.use_simd = enabled;\n    }\n    \n    // Grayscale conversion with SIMD optimization\n    pub fn to_grayscale(&self, image: &Image) -> Image {\n        if self.use_simd && image.channels == 4 {\n            self.to_grayscale_simd(image)\n        } else {\n            self.to_grayscale_scalar(image)\n        }\n    }\n    \n    fn to_grayscale_simd(&self, image: &Image) -> Image {\n        let mut result = Image::new(image.width, image.height, 1);\n        \n        // SIMD constants for RGB to grayscale conversion\n        let r_weight = f32x4_splat(0.299);\n        let g_weight = f32x4_splat(0.587);\n        let b_weight = f32x4_splat(0.114);\n        \n        let chunks = image.data.chunks_exact(16); // Process 4 pixels at a time\n        let remainder = chunks.remainder();\n        \n        for (i, chunk) in chunks.enumerate() {\n            if chunk.len() >= 16 {\n                // Load 4 RGBA pixels\n                let pixels = v128_load(chunk.as_ptr() as *const v128);\n                \n                // Extract R, G, B, A channels\n                let rgba = u8x16_shuffle::<0, 4, 8, 12, 1, 5, 9, 13, 2, 6, 10, 14, 3, 7, 11, 15>(pixels, pixels);\n                \n                // Convert to float\n                let r = f32x4_convert_i32x4(i32x4_extend_low_i16x8(i16x8_extend_low_i8x16(rgba)));\n                let g = f32x4_convert_i32x4(i32x4_extend_low_i16x8(i16x8_extend_high_i8x16(rgba)));\n                let b = f32x4_convert_i32x4(i32x4_extend_high_i16x8(i16x8_extend_low_i8x16(rgba)));\n                \n                // Calculate grayscale\n                let gray = f32x4_add(f32x4_add(\n                    f32x4_mul(r, r_weight),\n                    f32x4_mul(g, g_weight)\n                ), f32x4_mul(b, b_weight));\n                \n                // Convert back to u8\n                let gray_i32 = i32x4_trunc_sat_f32x4(gray);\n                let gray_i16 = i16x8_narrow_i32x4(gray_i32, gray_i32);\n                let gray_u8 = u8x16_narrow_i16x8(gray_i16, gray_i16);\n                \n                // Store grayscale values\n                let base_idx = i * 4;\n                if base_idx + 4 <= result.data.len() {\n                    result.data[base_idx] = u8x16_extract_lane::<0>(gray_u8);\n                    result.data[base_idx + 1] = u8x16_extract_lane::<1>(gray_u8);\n                    result.data[base_idx + 2] = u8x16_extract_lane::<2>(gray_u8);\n                    result.data[base_idx + 3] = u8x16_extract_lane::<3>(gray_u8);\n                }\n            }\n        }\n        \n        // Process remaining pixels\n        let processed_pixels = chunks.len() * 4;\n        for i in 0..remainder.len() / 4 {\n            let pixel_idx = processed_pixels + i;\n            let data_idx = (processed_pixels + i) * 4;\n            \n            if data_idx + 3 < image.data.len() && pixel_idx < result.data.len() {\n                let r = image.data[data_idx] as f32;\n                let g = image.data[data_idx + 1] as f32;\n                let b = image.data[data_idx + 2] as f32;\n                \n                let gray = (r * 0.299 + g * 0.587 + b * 0.114) as u8;\n                result.data[pixel_idx] = gray;\n            }\n        }\n        \n        result\n    }\n    \n    fn to_grayscale_scalar(&self, image: &Image) -> Image {\n        let mut result = Image::new(image.width, image.height, 1);\n        \n        for y in 0..image.height {\n            for x in 0..image.width {\n                let pixel = image.get_pixel(x, y);\n                \n                let gray = if image.channels >= 3 {\n                    (pixel[0] as f32 * 0.299 + pixel[1] as f32 * 0.587 + pixel[2] as f32 * 0.114) as u8\n                } else {\n                    pixel[0]\n                };\n                \n                result.set_pixel(x, y, &[gray]);\n            }\n        }\n        \n        result\n    }\n    \n    // Gaussian blur with separable kernel\n    pub fn gaussian_blur(&self, image: &Image, sigma: f32) -> Image {\n        let kernel_size = ((sigma * 6.0) as usize).max(3) | 1; // Ensure odd size\n        let kernel = self.create_gaussian_kernel(kernel_size, sigma);\n        \n        // Horizontal pass\n        let temp = self.convolve_horizontal(image, &kernel);\n        \n        // Vertical pass\n        self.convolve_vertical(&temp, &kernel)\n    }\n    \n    fn create_gaussian_kernel(&self, size: usize, sigma: f32) -> Vec<f32> {\n        let mut kernel = vec![0.0; size];\n        let center = size / 2;\n        let two_sigma_sq = 2.0 * sigma * sigma;\n        let mut sum = 0.0;\n        \n        for i in 0..size {\n            let x = (i as i32 - center as i32) as f32;\n            let value = (-x * x / two_sigma_sq).exp();\n            kernel[i] = value;\n            sum += value;\n        }\n        \n        // Normalize\n        for value in &mut kernel {\n            *value /= sum;\n        }\n        \n        kernel\n    }\n    \n    fn convolve_horizontal(&self, image: &Image, kernel: &[f32]) -> Image {\n        let mut result = image.clone_image();\n        let kernel_center = kernel.len() / 2;\n        \n        for y in 0..image.height {\n            for x in 0..image.width {\n                let mut pixel_sum = vec![0.0; image.channels as usize];\n                \n                for (k, &weight) in kernel.iter().enumerate() {\n                    let sample_x = (x as i32 + k as i32 - kernel_center as i32)\n                        .max(0)\n                        .min(image.width as i32 - 1) as u32;\n                    \n                    let sample_pixel = image.get_pixel(sample_x, y);\n                    \n                    for c in 0..image.channels as usize {\n                        pixel_sum[c] += sample_pixel[c] as f32 * weight;\n                    }\n                }\n                \n                let final_pixel: Vec<u8> = pixel_sum.iter()\n                    .map(|&v| v.max(0.0).min(255.0) as u8)\n                    .collect();\n                \n                result.set_pixel(x, y, &final_pixel);\n            }\n        }\n        \n        result\n    }\n    \n    fn convolve_vertical(&self, image: &Image, kernel: &[f32]) -> Image {\n        let mut result = image.clone_image();\n        let kernel_center = kernel.len() / 2;\n        \n        for y in 0..image.height {\n            for x in 0..image.width {\n                let mut pixel_sum = vec![0.0; image.channels as usize];\n                \n                for (k, &weight) in kernel.iter().enumerate() {\n                    let sample_y = (y as i32 + k as i32 - kernel_center as i32)\n                        .max(0)\n                        .min(image.height as i32 - 1) as u32;\n                    \n                    let sample_pixel = image.get_pixel(x, sample_y);\n                    \n                    for c in 0..image.channels as usize {\n                        pixel_sum[c] += sample_pixel[c] as f32 * weight;\n                    }\n                }\n                \n                let final_pixel: Vec<u8> = pixel_sum.iter()\n                    .map(|&v| v.max(0.0).min(255.0) as u8)\n                    .collect();\n                \n                result.set_pixel(x, y, &final_pixel);\n            }\n        }\n        \n        result\n    }\n    \n    // Edge detection using Sobel operator\n    pub fn sobel_edge_detection(&self, image: &Image) -> Image {\n        let gray = if image.channels > 1 {\n            self.to_grayscale(image)\n        } else {\n            image.clone_image()\n        };\n        \n        let mut result = Image::new(image.width, image.height, 1);\n        \n        // Sobel kernels\n        let sobel_x = [-1.0, 0.0, 1.0, -2.0, 0.0, 2.0, -1.0, 0.0, 1.0];\n        let sobel_y = [-1.0, -2.0, -1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0];\n        \n        for y in 1..gray.height - 1 {\n            for x in 1..gray.width - 1 {\n                let mut gx = 0.0;\n                let mut gy = 0.0;\n                \n                for ky in 0..3 {\n                    for kx in 0..3 {\n                        let px = (x + kx - 1) as u32;\n                        let py = (y + ky - 1) as u32;\n                        let pixel = gray.get_pixel(px, py)[0] as f32;\n                        \n                        let kernel_idx = ky * 3 + kx;\n                        gx += pixel * sobel_x[kernel_idx];\n                        gy += pixel * sobel_y[kernel_idx];\n                    }\n                }\n                \n                let magnitude = (gx * gx + gy * gy).sqrt();\n                let edge_value = magnitude.min(255.0) as u8;\n                \n                result.set_pixel(x, y, &[edge_value]);\n            }\n        }\n        \n        result\n    }\n    \n    // Canny edge detection\n    pub fn canny_edge_detection(&self, image: &Image, low_threshold: f32, high_threshold: f32) -> Image {\n        // 1. Gaussian blur to reduce noise\n        let blurred = self.gaussian_blur(image, 1.4);\n        \n        // 2. Calculate gradients\n        let gray = if blurred.channels > 1 {\n            self.to_grayscale(&blurred)\n        } else {\n            blurred\n        };\n        \n        let (magnitude, direction) = self.calculate_gradients(&gray);\n        \n        // 3. Non-maximum suppression\n        let suppressed = self.non_maximum_suppression(&magnitude, &direction);\n        \n        // 4. Double threshold and edge tracking\n        self.double_threshold_and_tracking(&suppressed, low_threshold, high_threshold)\n    }\n    \n    fn calculate_gradients(&self, image: &Image) -> (Image, Vec<Vec<f32>>) {\n        let mut magnitude = Image::new(image.width, image.height, 1);\n        let mut direction = vec![vec![0.0; image.width as usize]; image.height as usize];\n        \n        for y in 1..image.height - 1 {\n            for x in 1..image.width - 1 {\n                let gx = image.get_pixel(x + 1, y)[0] as i32 - image.get_pixel(x - 1, y)[0] as i32;\n                let gy = image.get_pixel(x, y + 1)[0] as i32 - image.get_pixel(x, y - 1)[0] as i32;\n                \n                let mag = ((gx * gx + gy * gy) as f32).sqrt();\n                let dir = (gy as f32).atan2(gx as f32);\n                \n                magnitude.set_pixel(x, y, &[mag.min(255.0) as u8]);\n                direction[y as usize][x as usize] = dir;\n            }\n        }\n        \n        (magnitude, direction)\n    }\n    \n    fn non_maximum_suppression(&self, magnitude: &Image, direction: &[Vec<f32>]) -> Image {\n        let mut result = Image::new(magnitude.width, magnitude.height, 1);\n        \n        for y in 1..magnitude.height - 1 {\n            for x in 1..magnitude.width - 1 {\n                let angle = direction[y as usize][x as usize];\n                let mag = magnitude.get_pixel(x, y)[0];\n                \n                // Quantize angle to 0, 45, 90, 135 degrees\n                let angle_deg = (angle * 180.0 / std::f32::consts::PI + 180.0) % 180.0;\n                \n                let (n1, n2) = if angle_deg < 22.5 || angle_deg >= 157.5 {\n                    // 0 degrees - horizontal\n                    (magnitude.get_pixel(x - 1, y)[0], magnitude.get_pixel(x + 1, y)[0])\n                } else if angle_deg < 67.5 {\n                    // 45 degrees - diagonal\n                    (magnitude.get_pixel(x - 1, y - 1)[0], magnitude.get_pixel(x + 1, y + 1)[0])\n                } else if angle_deg < 112.5 {\n                    // 90 degrees - vertical\n                    (magnitude.get_pixel(x, y - 1)[0], magnitude.get_pixel(x, y + 1)[0])\n                } else {\n                    // 135 degrees - diagonal\n                    (magnitude.get_pixel(x + 1, y - 1)[0], magnitude.get_pixel(x - 1, y + 1)[0])\n                };\n                \n                let suppressed_value = if mag >= n1 && mag >= n2 { mag } else { 0 };\n                result.set_pixel(x, y, &[suppressed_value]);\n            }\n        }\n        \n        result\n    }\n    \n    fn double_threshold_and_tracking(&self, image: &Image, low: f32, high: f32) -> Image {\n        let mut result = Image::new(image.width, image.height, 1);\n        let mut edges = vec![vec![0u8; image.width as usize]; image.height as usize];\n        \n        // Apply thresholds\n        for y in 0..image.height {\n            for x in 0..image.width {\n                let pixel = image.get_pixel(x, y)[0] as f32;\n                \n                if pixel >= high {\n                    edges[y as usize][x as usize] = 255; // Strong edge\n                } else if pixel >= low {\n                    edges[y as usize][x as usize] = 128; // Weak edge\n                } else {\n                    edges[y as usize][x as usize] = 0; // No edge\n                }\n            }\n        }\n        \n        // Edge tracking by hysteresis\n        let mut changed = true;\n        while changed {\n            changed = false;\n            \n            for y in 1..image.height - 1 {\n                for x in 1..image.width - 1 {\n                    if edges[y as usize][x as usize] == 128 {\n                        // Check if connected to strong edge\n                        let mut has_strong_neighbor = false;\n                        \n                        for dy in -1..=1 {\n                            for dx in -1..=1 {\n                                if dx == 0 && dy == 0 { continue; }\n                                \n                                let nx = (x as i32 + dx) as usize;\n                                let ny = (y as i32 + dy) as usize;\n                                \n                                if edges[ny][nx] == 255 {\n                                    has_strong_neighbor = true;\n                                    break;\n                                }\n                            }\n                            if has_strong_neighbor { break; }\n                        }\n                        \n                        if has_strong_neighbor {\n                            edges[y as usize][x as usize] = 255;\n                            changed = true;\n                        }\n                    }\n                }\n            }\n        }\n        \n        // Convert to final image\n        for y in 0..image.height {\n            for x in 0..image.width {\n                let value = if edges[y as usize][x as usize] == 255 { 255 } else { 0 };\n                result.set_pixel(x, y, &[value]);\n            }\n        }\n        \n        result\n    }\n    \n    // Histogram equalization\n    pub fn histogram_equalization(&self, image: &Image) -> Image {\n        if image.channels != 1 {\n            let gray = self.to_grayscale(image);\n            return self.histogram_equalization(&gray);\n        }\n        \n        // Calculate histogram\n        let mut histogram = [0u32; 256];\n        for pixel in &image.data {\n            histogram[*pixel as usize] += 1;\n        }\n        \n        // Calculate cumulative distribution function\n        let mut cdf = [0u32; 256];\n        cdf[0] = histogram[0];\n        for i in 1..256 {\n            cdf[i] = cdf[i - 1] + histogram[i];\n        }\n        \n        // Find minimum non-zero CDF value\n        let cdf_min = cdf.iter().find(|&&x| x > 0).copied().unwrap_or(0);\n        let total_pixels = (image.width * image.height) as u32;\n        \n        // Create lookup table\n        let mut lut = [0u8; 256];\n        for i in 0..256 {\n            if cdf[i] > cdf_min {\n                lut[i] = ((((cdf[i] - cdf_min) as f32) / ((total_pixels - cdf_min) as f32)) * 255.0).round() as u8;\n            }\n        }\n        \n        // Apply lookup table\n        let mut result = image.clone_image();\n        for pixel in &mut result.data {\n            *pixel = lut[*pixel as usize];\n        }\n        \n        result\n    }\n}\n\n// Feature detection using Harris corner detector\n#[wasm_bindgen]\npub struct FeatureDetector {\n    k: f32,\n    threshold: f32,\n}\n\n#[wasm_bindgen]\nimpl FeatureDetector {\n    #[wasm_bindgen(constructor)]\n    pub fn new(k: f32, threshold: f32) -> FeatureDetector {\n        FeatureDetector { k, threshold }\n    }\n    \n    pub fn detect_corners(&self, image: &Image) -> Vec<Corner> {\n        let processor = ImageProcessor::new();\n        let gray = if image.channels > 1 {\n            processor.to_grayscale(image)\n        } else {\n            image.clone_image()\n        };\n        \n        // Calculate derivatives\n        let (ix, iy) = self.calculate_derivatives(&gray);\n        \n        // Calculate Harris response\n        let response = self.calculate_harris_response(&ix, &iy);\n        \n        // Non-maximum suppression and thresholding\n        self.extract_corners(&response)\n    }\n    \n    fn calculate_derivatives(&self, image: &Image) -> (Image, Image) {\n        let mut ix = Image::new(image.width, image.height, 1);\n        let mut iy = Image::new(image.width, image.height, 1);\n        \n        for y in 1..image.height - 1 {\n            for x in 1..image.width - 1 {\n                let dx = image.get_pixel(x + 1, y)[0] as i32 - image.get_pixel(x - 1, y)[0] as i32;\n                let dy = image.get_pixel(x, y + 1)[0] as i32 - image.get_pixel(x, y - 1)[0] as i32;\n                \n                ix.set_pixel(x, y, &[((dx + 255) / 2) as u8]);\n                iy.set_pixel(x, y, &[((dy + 255) / 2) as u8]);\n            }\n        }\n        \n        (ix, iy)\n    }\n    \n    fn calculate_harris_response(&self, ix: &Image, iy: &Image) -> Vec<Vec<f32>> {\n        let mut response = vec![vec![0.0; ix.width as usize]; ix.height as usize];\n        let window_size = 3;\n        let offset = window_size / 2;\n        \n        for y in offset..ix.height - offset {\n            for x in offset..ix.width - offset {\n                let mut a = 0.0;\n                let mut b = 0.0;\n                let mut c = 0.0;\n                \n                // Calculate structure matrix elements\n                for wy in y - offset..=y + offset {\n                    for wx in x - offset..=x + offset {\n                        let dx = (ix.get_pixel(wx, wy)[0] as f32 - 127.5) / 127.5;\n                        let dy = (iy.get_pixel(wx, wy)[0] as f32 - 127.5) / 127.5;\n                        \n                        a += dx * dx;\n                        b += dx * dy;\n                        c += dy * dy;\n                    }\n                }\n                \n                // Calculate Harris response\n                let det = a * c - b * b;\n                let trace = a + c;\n                let r = det - self.k * trace * trace;\n                \n                response[y as usize][x as usize] = r;\n            }\n        }\n        \n        response\n    }\n    \n    fn extract_corners(&self, response: &[Vec<f32>]) -> Vec<Corner> {\n        let mut corners = Vec::new();\n        let window_size = 3;\n        let offset = window_size / 2;\n        \n        for y in offset..response.len() - offset {\n            for x in offset..response[0].len() - offset {\n                let current = response[y][x];\n                \n                if current > self.threshold {\n                    // Non-maximum suppression\n                    let mut is_maximum = true;\n                    \n                    for wy in y - offset..=y + offset {\n                        for wx in x - offset..=x + offset {\n                            if wy != y || wx != x {\n                                if response[wy][wx] >= current {\n                                    is_maximum = false;\n                                    break;\n                                }\n                            }\n                        }\n                        if !is_maximum { break; }\n                    }\n                    \n                    if is_maximum {\n                        corners.push(Corner::new(x as u32, y as u32, current));\n                    }\n                }\n            }\n        }\n        \n        // Sort by response strength\n        corners.sort_by(|a, b| b.response().partial_cmp(&a.response()).unwrap());\n        corners\n    }\n}\n\n#[wasm_bindgen]\n#[derive(Debug, Clone)]\npub struct Corner {\n    x: u32,\n    y: u32,\n    response: f32,\n}\n\n#[wasm_bindgen]\nimpl Corner {\n    #[wasm_bindgen(constructor)]\n    pub fn new(x: u32, y: u32, response: f32) -> Corner {\n        Corner { x, y, response }\n    }\n    \n    #[wasm_bindgen(getter)]\n    pub fn x(&self) -> u32 { self.x }\n    \n    #[wasm_bindgen(getter)]\n    pub fn y(&self) -> u32 { self.y }\n    \n    #[wasm_bindgen(getter)]\n    pub fn response(&self) -> f32 { self.response }\n}\n\n// Real-time camera processing\n#[wasm_bindgen]\npub struct CameraProcessor {\n    video_element: HtmlVideoElement,\n    canvas: HtmlCanvasElement,\n    context: CanvasRenderingContext2d,\n    processor: ImageProcessor,\n    feature_detector: FeatureDetector,\n    current_filter: String,\n    is_processing: bool,\n}\n\n#[wasm_bindgen]\nimpl CameraProcessor {\n    #[wasm_bindgen(constructor)]\n    pub fn new(video_id: &str, canvas_id: &str) -> Result<CameraProcessor, JsValue> {\n        let document = web_sys::window().unwrap().document().unwrap();\n        \n        let video_element = document\n            .get_element_by_id(video_id)\n            .ok_or_else(|| JsValue::from_str(\"Video element not found\"))?\n            .dyn_into::<HtmlVideoElement>()?;\n        \n        let canvas = document\n            .get_element_by_id(canvas_id)\n            .ok_or_else(|| JsValue::from_str(\"Canvas element not found\"))?\n            .dyn_into::<HtmlCanvasElement>()?;\n        \n        let context = canvas\n            .get_context(\"2d\")?\n            .unwrap()\n            .dyn_into::<CanvasRenderingContext2d>()?;\n        \n        Ok(CameraProcessor {\n            video_element,\n            canvas,\n            context,\n            processor: ImageProcessor::new(),\n            feature_detector: FeatureDetector::new(0.04, 10000.0),\n            current_filter: \"none\".to_string(),\n            is_processing: false,\n        })\n    }\n    \n    pub fn start_processing(&mut self) {\n        self.is_processing = true;\n        self.process_frame();\n    }\n    \n    pub fn stop_processing(&mut self) {\n        self.is_processing = false;\n    }\n    \n    pub fn set_filter(&mut self, filter: String) {\n        self.current_filter = filter;\n    }\n    \n    fn process_frame(&self) {\n        if !self.is_processing {\n            return;\n        }\n        \n        let video_width = self.video_element.video_width() as f64;\n        let video_height = self.video_element.video_height() as f64;\n        \n        if video_width > 0.0 && video_height > 0.0 {\n            // Set canvas size to match video\n            self.canvas.set_width(video_width as u32);\n            self.canvas.set_height(video_height as u32);\n            \n            // Draw video frame to canvas\n            self.context\n                .draw_image_with_html_video_element_and_dw_and_dh(\n                    &self.video_element,\n                    0.0,\n                    0.0,\n                    video_width,\n                    video_height,\n                )\n                .unwrap();\n            \n            // Get image data\n            if let Ok(image_data) = self.context.get_image_data(0.0, 0.0, video_width, video_height) {\n                let mut image = Image::from_image_data(&image_data);\n                \n                // Apply selected filter\n                match self.current_filter.as_str() {\n                    \"grayscale\" => {\n                        let gray = self.processor.to_grayscale(&image);\n                        image = self.grayscale_to_rgba(&gray);\n                    }\n                    \"blur\" => {\n                        image = self.processor.gaussian_blur(&image, 2.0);\n                    }\n                    \"edge\" => {\n                        let edges = self.processor.sobel_edge_detection(&image);\n                        image = self.grayscale_to_rgba(&edges);\n                    }\n                    \"canny\" => {\n                        let edges = self.processor.canny_edge_detection(&image, 50.0, 150.0);\n                        image = self.grayscale_to_rgba(&edges);\n                    }\n                    \"corners\" => {\n                        let corners = self.feature_detector.detect_corners(&image);\n                        self.draw_corners(&corners);\n                        return; // Don't update the image\n                    }\n                    _ => {} // No filter\n                }\n                \n                // Put processed image back\n                if let Ok(processed_data) = image.to_image_data() {\n                    self.context.put_image_data(&processed_data, 0.0, 0.0).unwrap();\n                }\n            }\n        }\n        \n        // Schedule next frame\n        let processor_clone = self as *const CameraProcessor;\n        let callback = Closure::wrap(Box::new(move |_time: f64| {\n            unsafe {\n                (*processor_clone).process_frame();\n            }\n        }) as Box<dyn FnMut(f64)>);\n        \n        request_animation_frame(&callback);\n        callback.forget();\n    }\n    \n    fn grayscale_to_rgba(&self, gray: &Image) -> Image {\n        let mut rgba = Image::new(gray.width, gray.height, 4);\n        \n        for y in 0..gray.height {\n            for x in 0..gray.width {\n                let gray_val = gray.get_pixel(x, y)[0];\n                rgba.set_pixel(x, y, &[gray_val, gray_val, gray_val, 255]);\n            }\n        }\n        \n        rgba\n    }\n    \n    fn draw_corners(&self, corners: &[Corner]) {\n        for corner in corners.iter().take(100) { // Limit to top 100 corners\n            self.context.begin_path();\n            self.context.set_fill_style(&JsValue::from_str(\"red\"));\n            self.context\n                .arc(\n                    corner.x() as f64,\n                    corner.y() as f64,\n                    3.0,\n                    0.0,\n                    2.0 * std::f64::consts::PI,\n                )\n                .unwrap();\n            self.context.fill();\n        }\n    }\n}\n\n// WebGL integration for GPU acceleration\n#[wasm_bindgen]\npub struct WebGLProcessor {\n    gl: WebGlRenderingContext,\n    programs: HashMap<String, WebGlProgram>,\n    buffers: HashMap<String, WebGlBuffer>,\n    textures: HashMap<String, WebGlTexture>,\n}\n\n#[wasm_bindgen]\nimpl WebGLProcessor {\n    #[wasm_bindgen(constructor)]\n    pub fn new(canvas_id: &str) -> Result<WebGLProcessor, JsValue> {\n        let document = web_sys::window().unwrap().document().unwrap();\n        let canvas = document\n            .get_element_by_id(canvas_id)\n            .ok_or_else(|| JsValue::from_str(\"Canvas not found\"))?\n            .dyn_into::<HtmlCanvasElement>()?;\n        \n        let gl = canvas\n            .get_context(\"webgl\")?\n            .unwrap()\n            .dyn_into::<WebGlRenderingContext>()?;\n        \n        let mut processor = WebGLProcessor {\n            gl,\n            programs: HashMap::new(),\n            buffers: HashMap::new(),\n            textures: HashMap::new(),\n        };\n        \n        processor.initialize_shaders()?;\n        \n        Ok(processor)\n    }\n    \n    fn initialize_shaders(&mut self) -> Result<(), JsValue> {\n        // Vertex shader for image processing\n        let vertex_shader_source = r#\"\n            attribute vec2 a_position;\n            attribute vec2 a_texCoord;\n            varying vec2 v_texCoord;\n            \n            void main() {\n                gl_Position = vec4(a_position, 0.0, 1.0);\n                v_texCoord = a_texCoord;\n            }\n        \"#;\n        \n        // Fragment shader for Gaussian blur\n        let blur_fragment_source = r#\"\n            precision mediump float;\n            uniform sampler2D u_texture;\n            uniform vec2 u_resolution;\n            uniform float u_sigma;\n            varying vec2 v_texCoord;\n            \n            void main() {\n                vec2 texelSize = 1.0 / u_resolution;\n                vec4 color = vec4(0.0);\n                float totalWeight = 0.0;\n                \n                int kernelSize = int(u_sigma * 3.0);\n                for (int x = -kernelSize; x <= kernelSize; x++) {\n                    for (int y = -kernelSize; y <= kernelSize; y++) {\n                        vec2 offset = vec2(float(x), float(y)) * texelSize;\n                        float weight = exp(-0.5 * (float(x * x + y * y)) / (u_sigma * u_sigma));\n                        color += texture2D(u_texture, v_texCoord + offset) * weight;\n                        totalWeight += weight;\n                    }\n                }\n                \n                gl_FragColor = color / totalWeight;\n            }\n        \"#;\n        \n        // Create and compile shaders\n        let vertex_shader = self.compile_shader(WebGlRenderingContext::VERTEX_SHADER, vertex_shader_source)?;\n        let blur_fragment_shader = self.compile_shader(WebGlRenderingContext::FRAGMENT_SHADER, blur_fragment_source)?;\n        \n        // Create program\n        let blur_program = self.create_program(&vertex_shader, &blur_fragment_shader)?;\n        self.programs.insert(\"blur\".to_string(), blur_program);\n        \n        Ok(())\n    }\n    \n    fn compile_shader(&self, shader_type: u32, source: &str) -> Result<WebGlShader, JsValue> {\n        let shader = self.gl\n            .create_shader(shader_type)\n            .ok_or_else(|| JsValue::from_str(\"Unable to create shader object\"))?;\n        \n        self.gl.shader_source(&shader, source);\n        self.gl.compile_shader(&shader);\n        \n        if self.gl\n            .get_shader_parameter(&shader, WebGlRenderingContext::COMPILE_STATUS)\n            .as_bool()\n            .unwrap_or(false)\n        {\n            Ok(shader)\n        } else {\n            Err(JsValue::from_str(\n                &self.gl\n                    .get_shader_info_log(&shader)\n                    .unwrap_or_else(|| \"Unknown error creating shader\".into()),\n            ))\n        }\n    }\n    \n    fn create_program(&self, vertex_shader: &WebGlShader, fragment_shader: &WebGlShader) -> Result<WebGlProgram, JsValue> {\n        let program = self.gl\n            .create_program()\n            .ok_or_else(|| JsValue::from_str(\"Unable to create shader program\"))?;\n        \n        self.gl.attach_shader(&program, vertex_shader);\n        self.gl.attach_shader(&program, fragment_shader);\n        self.gl.link_program(&program);\n        \n        if self.gl\n            .get_program_parameter(&program, WebGlRenderingContext::LINK_STATUS)\n            .as_bool()\n            .unwrap_or(false)\n        {\n            Ok(program)\n        } else {\n            Err(JsValue::from_str(\n                &self.gl\n                    .get_program_info_log(&program)\n                    .unwrap_or_else(|| \"Unknown error creating program\".into()),\n            ))\n        }\n    }\n    \n    pub fn gpu_blur(&self, image: &Image, sigma: f32) -> Result<Image, JsValue> {\n        // This is a simplified implementation\n        // In practice, you would upload the image to a texture,\n        // run the GPU shader, and read back the result\n        \n        let start_time = performance_now();\n        \n        // For now, just return the original image with timing\n        let end_time = performance_now();\n        console_log!(\"GPU blur took {:.3}ms\", end_time - start_time);\n        \n        Ok(image.clone_image())\n    }\n}\n\n// Performance benchmarking\n#[wasm_bindgen]\npub fn benchmark_filters(image: &Image, iterations: u32) -> String {\n    let processor = ImageProcessor::new();\n    let mut results = Vec::new();\n    \n    // Benchmark grayscale conversion\n    let start = performance_now();\n    for _ in 0..iterations {\n        let _ = processor.to_grayscale(image);\n    }\n    let grayscale_time = (performance_now() - start) / iterations as f64;\n    results.push(format!(\"Grayscale: {:.3}ms\", grayscale_time));\n    \n    // Benchmark Gaussian blur\n    let start = performance_now();\n    for _ in 0..iterations {\n        let _ = processor.gaussian_blur(image, 2.0);\n    }\n    let blur_time = (performance_now() - start) / iterations as f64;\n    results.push(format!(\"Blur: {:.3}ms\", blur_time));\n    \n    // Benchmark edge detection\n    let start = performance_now();\n    for _ in 0..iterations {\n        let _ = processor.sobel_edge_detection(image);\n    }\n    let edge_time = (performance_now() - start) / iterations as f64;\n    results.push(format!(\"Edge detection: {:.3}ms\", edge_time));\n    \n    results.join(\", \")\n}\n\n// Module initialization\n#[wasm_bindgen(start)]\npub fn main() {\n    console_error_panic_hook::set_once();\n    console_log!(\"Computer vision WASM module loaded\");\n}",
    "key_concepts": [
      "image processing",
      "computer vision",
      "SIMD optimization",
      "WebGL acceleration",
      "edge detection",
      "feature detection",
      "real-time processing",
      "GPU computing",
      "filter algorithms",
      "performance optimization"
    ]
  }
]